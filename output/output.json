[
  {
    "title": "iTerm2 critical security release (iterm2.com)",
    "points": 268,
    "submitter": "tjwds",
    "submit_time": "2025-01-02T22:08:42 1735855722",
    "num_comments": 125,
    "comments_url": "https://news.ycombinator.com/item?id=42579472",
    "comments": [
      "I'm confused by the comments saying \"Just don't use iTerm2.\" The same class of issue can occur for any other project, and switching is not a very effective defense against it.If anything, having an embarrassing issue like this is probably going to improve the iTerm2 project's security posture in the medium term. It's like that joke about firing the engineer who caused the incident, and the manager who retorts, \"Why would I fire them? They just learned the hard way never to make this mistake again.\" (I'm paraphrasing.) I don't think that iTerm2 has had a notably high rate of critical security issues, and I suspect they won't make this class of mistake twice. (And if they do - then I will re-evaluate.)I suppose intuitively I would think that using the default MacOS Terminal app is a bit lower-risk than using iTerm2 or any other open source terminal emulator, as Terminal is a rather sparse piece of Apple-provided software with a low pace of change. But it's also closed source and impossible to audit, so there are tradeoffs there too.\n \nreply",
      "Looks like a case of print() debugging making it into production:https://github.com/gnachman/iTerm2/commit/63ec2bb0b95078a97a...\nhttps://github.com/gnachman/iTerm2/blame/5db0f74bf647f6d53ea...\n \nreply",
      "That's not unreasonable code in itself, it's writing to the file only if verbose mode is enabled.This is the commit which disabled verbose mode, just before the code which removed verbose framer logging entirely: https://github.com/gnachman/iTerm2/commit/014ba7ec40fc790f65...This is the commit which enabled VERBOSE mode: https://github.com/gnachman/iTerm2/commit/5db0f74bf647f6d53e... (from Jul 3, 2024)That is probably just from having set VERBOSE=1 while implementing or debugging something and forgetting to revert it to VERBOSE=0 before committing.\n \nreply",
      "It\u2019s been around for 3 years?\n \nreply",
      "About six months. File was originally authored a few years back, but looks like this slipped in here: https://gitlab.com/gnachman/iterm2/-/commit/5db0f74bf647f6d5...\n \nreply",
      "Disabled by default until 7 months ago.\n \nreply",
      "[flagged]",
      "9 month ago. I don't see a connection.\n \nreply",
      "In typescript dev I made \u201cconsole.log\u201d a linting error that cannot be merged. The occasional legitimate need uses console.infoI think print debugging is fine. It has a time and place.  But ideally find a way to protect yourself from accidentally leaving it in. It\u2019s such an easy mistake to make.\n \nreply",
      "in similar situations, instead of saying \"VERBOSE=1\", I say \"VERBOSE=getenv(\"MY_NAME_MY_APP_VERBOSE\") == '1'\", and set this env variable in my terminal when needed. This way there is zero chance I commit verbose-enabled debug code.\n \nreply"
    ],
    "link": "https://iterm2.com/downloads/stable/iTerm2-3_5_11.changelog",
    "first_paragraph": ""
  },
  {
    "title": "Advent of Code 2024 in pure SQL (databasearchitects.blogspot.com)",
    "points": 254,
    "submitter": "greghn",
    "submit_time": "2025-01-02T19:20:50 1735845650",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=42577736",
    "comments": [
      "I reacted to this title the way I react a new menu item at Taco Bell: a strange mixture of desire, shame, and admiration for human ingenuity.\n \nreply",
      "I work a lot with databases and I've seen... stuff. It's not as bad as you might think if you know what you are doing. Most RDBMSs support recursive CTEs, it feels like writing Prolog with a slightly sadistic syntax. For something like AoC the most difficult part is probably parsing the input.\n \nreply",
      "Speaking of parsing, back around y2k we were building an app that used XML everywhere, which was the style at the time, and our DBA wanted to write an xml parser in SQL (the api would involve sending XML to the database). That got vetoed.IMO, this kind of thing is what AoC is good for - you get to play with weird/obscure stuff without affecting your day job code.\n \nreply",
      "I did something with JSON back before there was reasonable native support - it's certainly not robust, but it handled a few syntax variants for a use case where we had an extra attribute column that serialized JSON, and wanted to surface one of the fields as a proper column on the table.https://blog.tracefunc.com/2011/11/19/parsing-json-in-sql-ht...\n \nreply",
      "Funnily, I\u2019m actively working on rewriting a stored procedure which parses an XML snippet as one of its argumentsLuckily it\u2019s not a handwritten XML parser though:\nhttps://learn.microsoft.com/en-us/sql/t-sql/functions/openxm...\n \nreply",
      "> Most RDBMSs support recursive CTEs, it feels like writing Prolog with a slightly sadistic syntax.Which makes sense as both are declarative logic-based languages.  IMHO, SQL and Prolog fundamentally have much in common.\n \nreply",
      "Thanks for that comment.I laughed aloud at \"It's not as bad as you might think if you know what you are doing.\"... because that pretty much describes all human activity :-)\n \nreply",
      "I'm as equally amazed by the solutions in this post's github repo as I am with Taco Bell's new chicken nuggets.\n \nreply",
      "but why? what would make you react at human ingenuity with shame and desire? is this something about you or something about them in particular? isnt the whole of HN about human ingenuity...?are we to feel Taco Bell menu about it all, what am I missing?\n \nreply",
      "This is just a guess, but if the OP's reason is similar to mine, DBMSs should be reserved for managing databases and not implementing complex logic.\n \nreply"
    ],
    "link": "http://databasearchitects.blogspot.com/2024/12/advent-of-code-2024-in-pure-sql.html",
    "first_paragraph": "A blog by and for database architects.\u00a0On a whim I decided to do this years advent of code in pure SQL. That was an interesting experience that I can recommend to everybody because it forces you to think differently about the problems. And I can report that it was possible to solve every problem in pure SQL.In many cases SQL was actually surprisingly pleasant to use. The full solution for day 11 (including the puzzle input) is shown below:Parsing the input is a bit painful in SQL, but it is not too bad. Lines 1-10 are simply the puzzle input, lines 11-17 split the input into individual lines, and lines 18-21 construct a 2D array from the input. The algorithm itself is pretty short, lines 22-27 perform a recursive traversal of the field, and lines 28-39 extract the puzzle answer from the traversal results. For this kind of small scale traversals SQL works just fine.Other days were more painful. Day 16 for example does conceptually a very similar traversal of a field, and it computes the"
  },
  {
    "title": "The Alder Lake SHLX Anomaly (tavianator.com)",
    "points": 52,
    "submitter": "panic",
    "submit_time": "2025-01-02T23:00:48 1735858848",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42579969",
    "comments": [
      "One fun thing about this is that spilling+restoring the register will fix it, so if any kind of context switch happens (thread switch, page fault, interrupt, etc.), the register will get pushed to the stack and popped back from it, and the code suddenly gets 3x faster.  Makes it a bit tricky to reproduce reliably, and led me down a few dead ends as I was writing this up.\n \nreply",
      "I wonder if this is a thing where the machine is trying to predict the actual value of the 'count' operand ...\n \nreply",
      "If it were a prediction/speculation thing, I would expect it to settle down long before 10,000 `SHLX`s are retired.\n \nreply",
      "How about trying \"xor ecx, ecx; inc ecx\"? Or the even shorter \"mov cl, 1\"?It is very strange to me that the instruction used to set the shift count register can make the SHLX instruction 3\u00d7 slower.I suspect this is a width restriction in the bypass/forwarding network.The 32-bit vs. 64-bit operand size distinction is especially surprising to me as SHLX only looks at the bottom 6 bits of the shift count.Unfortunately the dependency analysis circuitry seems not Intel-ligent enough to make that distinction.\n \nreply",
      "> How about trying \"xor ecx, ecx; inc ecx\"?Fast.  But inc rcx is slow.> Or the even shorter \"mov cl, 1\"?Fast.> I suspect this is a width restriction in the bypass/forwarding network...I think we just found the explanation on Twitter: https://x.com/corsix/status/1874965887108976858Alder Lake adds support for mov/add/sub with small immediates to the register renamer.  So `add rcx, 1` gets handled by the renamer, potentially with zero latency.Unfortunately shifts are slow when the shift count is renamed in this way.  This leads to fun things like `mov rcx, 1024` being fast while `mov rcx, 1023` is slow.  I'll update the blog post in a bit.\n \nreply",
      "Oooh, I forgot about this. Only thing I can think of is something like:1. Assume that some values can be treated internally as \"physical register plus a small immediate\"2. Assume that, in some cases, a physical register is known to be zero and the value can be represented as \"zero plus a small immediate\" (without reference to a physical register?)3. Since 'count' is always expected to be <64, you technically don't need to use a physical register for it (since the immediate bits can always just be carried around with the name).4. The 3-cycle case occurs when the physical register read cannot be optimized away??(Or maybe it's just that the whole shift operation can occur at rename in the fast case??)\n \nreply",
      "I got nothing here other than: this is very cool.\n \nreply",
      "I would have thought that the movs would have been dumped right into a rob entry without even going through the bypass network, much like a zeroing idiom does.\n \nreply",
      "Shifts were not always fast.  These old hacker news comments contain the details: https://news.ycombinator.com/item?id=2962770\n \nreply",
      "Indeed. Dynamic shifting was microcoded (not uop!) on the power pc for gen3. However shifting with immediate values was not.This leads to all sorts of strange performance workarounds.\nMike Acton refers to it here:\nhttps://macton.smugmug.com/Other/2008-07-15-by-Eye-Fi/n-xmKD...\n \nreply"
    ],
    "link": "https://tavianator.com/2025/shlx.html",
    "first_paragraph": " 2025-01-02\n Tavian BarnesAt the end of 2024, Harold Aptroot posted this:Apparently shlx is a \"medium latency\" (3 cycles) instruction on Alder Lake. My disappointment is immeasurable, and my day is ruined.\u2014 Twitter / Bluesky / MastodonI was immediately nerd sniped because I am into low-level performance analysis, and I happen to own an Alder Lake laptop.A bit of background: Alder Lake is the 12th generation of Intel Core processors.\nIt's the first generation with a \"hybrid architecture,\" containing both performance (P) and efficiency (E) cores.\nSHLX is a left-shift instruction introduced in the BMI2 instruction set.\nThe main difference with SHL is that SHLX doesn't affect the FLAGS register.\nIt's also a 3-operand instruction:Left-shift is one of the simplest things to implement in hardware, so it's quite surprising that it should take 3 whole CPU cycles.\nIt's been 1 cycle on every other CPU I'm aware of.\nIt's even 1 cycle on Alder Lake's efficiency cores!\nOnly the performance cores hav"
  },
  {
    "title": "Zildjian, a 400-year-old cymbal-making company in Massachusetts (wbur.org)",
    "points": 222,
    "submitter": "arbesman",
    "submit_time": "2024-12-31T17:12:51 1735665171",
    "num_comments": 118,
    "comments_url": "https://news.ycombinator.com/item?id=42560069",
    "comments": [
      "\"Zildjian\" is an Armenian last name, but \"Zildji\" (zilci) means \"cymbalist\"/\"cymbal-maker\", or more generically, \"bell-maker\" in Turkish. \"-ian\" is the Armenian patronymic suffix. The whole word means something like \"Cymbalistson\" which makes it the most fitting company name to produce cymbals.\n \nreply",
      "From the article, the cymbal-making came first, and then the name followed:The company\u2019s proprietary alloy was alchemized 13 generations ago in Constantinople (now Istanbul) by Debbie Zildjian\u2019s ancestor, Avedis I. He was trying to make gold, she said, but he ended up concocting a combination of copper and tin. \u201cThe mixing of those metals produced a very loud, resonant, beautiful sound,\u201d she said.Debbie explained that in 1618 the Ottoman sultan summoned Avedis to the Topkapi Palace to make cymbals for elite military bands. The metalsmith\u2019s work pleased the ruler, who gave him permission to found his own business in 1623. The sultan also bestowed Avedis the family name \"Zildjian\" which actually means cymbal maker. He went on to craft cymbals that were widely used, including in churches and by belly dancers.\n \nreply",
      "It makes sense though as \"-ian\" implies there was a \"Zildji\" before the brand existed. :)\n \nreply",
      "Sounds like the word came first, then the cymbals, then the word-as-name.It's not a Crapper situation where cymbals are named after this guy\n \nreply",
      "I wonder if anyone's bothered to assay their alloy to reverse engineer it.\n \nreply",
      "I'd be shocked if they hadn't. Particularly, cymbal makers who have already mapped out the other parts of the process. In fact they may already be using the same or similar alloys. Consider that violins are all made from approximately the same materials.It's a day's work in the right spectroscopy lab. A bit more difficult to figure out is how to turn the cast blank into a cymbal.And, finding a place in a mature market.\n \nreply",
      "The lesson I get from this is that people were less attached to their last names, and called themselves whatever they wanted.\n \nreply",
      "it ain't me, it ain't me, I ain't no cymbalistson, no, no*\n \nreply",
      "Zildjian's original craftsmanship actually lives on in Istanbul. Mehmet Tamdeger, who began apprenticing at age nine under Mikhail Zilcan (grandson of Kerope Zilcan, of K series fame) and master smith Kirkor Kucukyan, continued the traditional techniques from the 1950s K. Zilcan factory in Istanbul.What's fascinating is that Tamdeger and master smith Agop Tomurcuk preserved these methods by founding \"Istanbul\" cymbals. Initially exporting to the US under \"Zildjiler\" before switching to \"Istanbul\" in 1984, each cymbal was personally signed by both masters. After Agop's unexpected death in 1996, Mehmet continued under \"Istanbul Mehmet\", maintaining the 17th-century hand-crafting methods with the philosophy \"Machines don't have ears.\"The cymbals they make are particularly sought after by jazz drummers for what's known as the \"old K sound\" - referring to the original K Zildjians made in its place of birth.Here is one for sale:https://soundsanatolian.com/products/istanbul-mehmet-22-mika...\n \nreply",
      "A family dispute led to the founding of Sabian Cymbals in New Brunswick, Canada, in 1981. The products of both companies are considered amongst the best by percussionists.\n \nreply"
    ],
    "link": "https://www.wbur.org/news/2024/12/16/400-years-zildjian-cymbals-massachusetts",
    "first_paragraph": "Advertisement<iframe width=\"100%\" height=\"124\" scrolling=\"no\" frameborder=\"no\" src=\"https://player.wbur.org/news/2024/12/16/400-years-zildjian-cymbals-massachusetts\"></iframe>From symphonies to rock music, marching bands and advertising jingles \u2014 we hear Zildjian cymbals everywhere. Drummers across the globe know that name because it\u2019s emblazoned on every gleaming disc. What\u2019s less known is the Zildjian family has been making their famous cymbals \u2014 with a secret process \u2014 for more than 400 years.Since the 1970s, the Avedis Zildjian Co. has operated under the radar in Norwell, Massachusetts. We jumped at the chance to get inside the world\u2019s oldest cymbal manufacturer.Even in Massachusetts many people have no idea an industrial factory outside of Boston designs, casts, blasts, rolls, hammers, buffs and tests at least a million Zildjian cymbals each year.\u201cThere\u2019s a lot of mystique and a lot of history at this facility,\u201d said Joe Mitchell, the company's director of operations, as we walked"
  },
  {
    "title": "Optimizing Ruby's JSON, Part 4 (byroot.github.io)",
    "points": 62,
    "submitter": "jeremy_k",
    "submit_time": "2024-12-30T03:45:14 1735530314",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42546246",
    "comments": [
      "Very glad to see the work that byroot is doing as the new ruby-json maintainer!Since I was mentioned by name in part 3, perhaps I can provide some interesting commentary:> All this code had recently been rewritten pretty much from scratch by Luke Shumaker ... While this code is very clean and generic, with a good separation of the multiple levels of abstractions, such as bytes and codepoints, that would make it very easy to extend the escaping logic, it isn\u2019t taking advantage of many assumptions convert_UTF8_to_JSON could make to take shortcuts.My rewritten version was already slightly faster than the original version, so I didn't feel the need to spend more time optimizing it, at least until the simple version got merged; which I had no idea when that'd be because of silence from the then-maintainer. Every optimization would be an opportunity for more pain when rebasing away merge-conflicts; which was already painful enough the 2 times I had to do it while waiting for a reply.> One of these for instance is that there\u2019s no point validating the UTF-8 encoding because Ruby did it for us and it\u2019s impossible to end up inside convert_UTF8_to_JSON with invalid UTF-8.I don't care to dig through the history to see exactly what changed when, but: At the time I wrote it, the unit tests told me that wasn't true; if I omitted the checks for invalid UTF-8, then the tests failed.> Another is that there are only two multi-byte characters we care about, and both start with the same 0xE2 byte, so the decoding into codepoints is a bit superfluous. ... we can re-use Mame\u2019s lookup table, but with a twist.I noted in the original PR description that I thought a lookup table would be faster than my decoder.  I didn't use a lookup table myself (1) to keep the initial version simple to make code-review simple to increase likelihood that it got merged, and (2) the old proprietary CVTUTF code used a lookup table, and because I was so familiar with the CVTUTF code, I didn't feel comfortable being the one to to re-add a lookup table. Glad to see that my suspicion was correct and that someone else did the work!\n \nreply",
      "This was really enjoyable to read - I really enjoy this kind of in-the-weeds optimisation and the author explains it all really well. I was surprised at how much Oj was willing to put on the stack! But my background is embedded and so large stack allocations have ruined my day more than once\n \nreply",
      "I recommend reading the previous 3 parts too, plus I'm looking forward to the next parts. I love that it goes into details and very clearly explains the problems and solutions, at least if you're familiar with C and know some things about compiler implementations.\n \nreply",
      "The oj author should've contributed these changes instead of making a separate library.\n \nreply",
      "I haven't seen this many Ruby posts on HN since 2012.We've had a few months of pretty regular Ruby posts now, and the last week has had one almost every single day.I'm not a regular Rubyist, but I'm glad to see the language getting more attention.\n \nreply",
      "Agree. I am ready for a Ruby renaissance that is not so heavily focused on rails. I have built quite a few standalone utilities in ruby over the years and it\u2019s a joy compared many other languages and ecosystems.\n \nreply"
    ],
    "link": "https://byroot.github.io/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html",
    "first_paragraph": "\nDec 29, 2024\n      In the previous post, we established that as long as ruby/json wasn\u2019t competitive on\nmicro-benchmarks, public perception wouldn\u2019t change. Since what made ruby/json appear so bad on micro-benchmarks was its setup cost, we had to\nfind ways to reduce it further.So I decided to file this performance discrepancy as a bug, and investigate it as such and started\nprofiling Stephen\u2019s micro-benchmark with both ruby/json and oj:As mentioned in previous parts, I expected the extra allocation would be the main issue, and that re-using the JSON::State object would\nput us on par with Oj, but it\u2019s always good to revalidate our assumptions:Even without that extra allocation, we were still 20% slower, that was unexpected, and should be fixed before exploring ways to eliminate the State allocation.As always, this meant profiling, but this time I profiled both ruby/json and Oj to see where the difference might be:Full profileFull profileOnce I got the two profiles, it was a matter of p"
  },
  {
    "title": "TinyStories: How Small Can Language Models Be and Still Speak Coherent English? (2023) (arxiv.org)",
    "points": 129,
    "submitter": "tzury",
    "submit_time": "2025-01-02T17:54:19 1735840459",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=42576755",
    "comments": [
      "Edit: ah. This paper is from May 2023. Might be worth putting that in the title.---> Models with around 125M parameters such as GPT-Neo (small) or GPT-2 (small) can rarely generate coherent and consistent English text beyond a few wordsThese models are 5 years old.I have to wonder if the authors have seen RWKV 7 0.1B, because it blows away just about every other model I've seen at that size.The capabilities it has vs the examples in the paper are night and day.https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-1\n \nreply",
      "The age of tiny models is just about here. We are finally busting away from the standard transformer block and training. I have a side project that can dramatically shrink networks by a set of techniques I call sacrificial training[1]. I think things like this will finally swing things back to on prem and on device small models that are as capable as the big hosted models are now.[1] https://github.com/jmward01/lmplay/wiki/Sacrificial-Training\n \nreply",
      "RWKV is def. better than TinyStories 125MB.Unfortunately, I have only seen 3 models, 3B or over, handle RAG.Tested RWKV with a simple in-the-sports-news question and it didn't even get close to approaching the question. And nearly everything was fundamentally incoherent even in its internal reality (ex. Player gets 5000/game and is the first with 1000 in 16 games)(prompt: https://pastebin.com/sCLn5sCJ, response: https://pastebin.com/TqudvDbN)I don't think there's a position for LLMs that are \"just\" writers on the market in 2025.\n \nreply",
      "These tiny models in general have really weird failure modes. I tried the tiny stories prompt about asking mom for a dog who said no, and it output an incredibly dark story about how she asked her dad and they got a dog but it had pancreatic cancer (paraphrasing, it went into detail about the surgery etc.) and then starting writing an informational PSA about who is at risk of pancreatic cancer etc.\n \nreply",
      "Lest we forget that this stream-of-consciousness confusion was state of the art just a few years ago.It makes sense if you think about it: a small model's \"internal state\" isn't rich enough to keep track of whatever it was supposed to be talking about.It makes me think that the reason LLMs need to be so large is that the internal state needs to be bigger than a typical human \"idea\", whatever that might mean.\n \nreply",
      "What I find fascinating is how ML models hallucinate in a way that is sometimes reminiscent of a fever dream.\n \nreply",
      "It makes sense that the failure modes of language prediction look a lot like ADD.\n \nreply",
      "It's because they are precisely lacking attention\n \nreply",
      "I plan on checking out RWKV and seeing if I can add my sacrifical training techniques to it this weekend. There is a reason quantization works, it is because models are very badly trained right now. I think we can get really good performance on .1b and 1b models which opens up the world to fine-tuning again. I was playing with fine-tuning llama 7b and 13b a while back but the HW/SW stack made it so unwieldy and the ROI was terrible compared to just adjusting prompts on gpt-4o-mini and the like. I have hope that we are about to see single GPU, very simple, fine-tuning again as models shrink and GPUs grow.\n \nreply",
      "Would there be any way to distribute RAG across multiple smaller models? Rather than one giant model handling your entire document base, have it be more of a tree where the top level classifies the docs into top-level categories and sends it to submodels to subclassify, etc? (Doesn't have to be 1:1 classification). And same for q/a search?These could all presumably be the same physical instance, just each query would use a different system prompt and perhaps different embeddings. (I'm guessing; I don't actually know how RAG works). So, a little slower and clunkier, but presumably way more efficient. And match could be anywhere between horrible to better-than-one-large-model. This would be more like how businesses organize docs.Or maybe there's no real benefit to this, and each subclassifier would require just as big of a model as if you were to throw all docs into a single model anyway. I assume it's probably been tried before.\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2305.07759",
    "first_paragraph": "The arXiv Privacy Policy has changed. By continuing to use arxiv.org, you are agreeing to the privacy policy.Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Postgres UUIDv7 and per-back end monotonicity (brandur.org)",
    "points": 165,
    "submitter": "craigkerstiens",
    "submit_time": "2025-01-02T16:32:20 1735835540",
    "num_comments": 80,
    "comments_url": "https://news.ycombinator.com/item?id=42575900",
    "comments": [
      "I would strongly implore people not to follow the example this post suggests, and write code that relies on this monotonicity.The reason for this is simple: the documentation doesn't promise this property. Moreover, even if it did, the RFC for UUIDv7 doesn't promise this property. If you decide to depend on it, you're setting yourself up for a bad time when PostgreSQL decides to change their implementation strategy, or you move to a different database.Further, the stated motivations for this, to slightly simplify testing code, are massively under-motivating. Saving a single line of code can hardly be said to be worth it, but even if it were, this is a problem far better solved by simply writing a function that will both generate the objects and sort them.As a profession, I strongly feel we need to do a better job orienting ourselves to the reality that our code has a tendency to live for a long time, and we need to optimize not for \"how quickly can I type it\", but \"what will this code cost over its lifetime\".\n \nreply",
      "> [\u2026] code that relies on this monotonicity. The reason for this is simple: the documentation doesn't promise this property. Moreover, even if it did, the RFC for UUIDv7 doesn't promise this property.The \"RFC for UUIDv7\", RFC 9562, explicitly mentions monotonicity in \u00a76.2 (\"Monotonicity and Counters\"):    Monotonicity (each subsequent value being greater than the last) is \n    the backbone of time-based sortable UUIDs. Normally, time-based UUIDs \n    from this document will be monotonic due to an embedded timestamp; \n    however, implementations can guarantee additional monotonicity via \n    the concepts covered in this section.\n\n* https://datatracker.ietf.org/doc/html/rfc9562#name-monotonic...In the UUIDv7 definition (\u00a75.7) it explicitly mentions the technique that Postgres employs for rand_a:    rand_a:\n        12 bits of pseudorandom data to provide uniqueness as per\n        Section 6.9 and/or optional constructs to guarantee additional \n        monotonicity as per Section 6.2. Occupies bits 52 through 63 \n        (octets 6-7).\n\n* https://datatracker.ietf.org/doc/html/rfc9562#name-uuid-vers...Note: \"optional constructs to guarantee additional monotonicity\". Pg makes use of that option.\n \nreply",
      ">explicitly mentions monotonicity>optional constructsSo it is explicitly mentioned in the RFC as optional, and Pg doesn't state that they guaranty that option.  The point still stands, depending on optional behavior is a recipe for failure when the option is no longer taken.\n \nreply",
      "It's mentioned in the RFC as being explicitly monotonic based the time-based design.Implementations that need monotonicity beyond the resolution of a timestamp-- like when you allocate 30 UUIDs at one instant in a batch-- can optionally use those additional bits for that purpose.> Implementations SHOULD employ the following methods for single-node UUID implementations that require batch UUID creation or are otherwise concerned about monotonicity with high-frequency UUID generation.(And it goes on to recommend the obvious things you'd do: use a counter in those bits when assigning a batch; use more bits of time precision; etc.)The comment in PostgreSQL before the implementation makes it clear that they chose the third option for this in the RFC:     * variant bits. To ensure monotonicity in scenarios of high-\n     * frequency UUID generation, we employ the method \"Replace\n     * LeftmostRandom Bits with Increased Clock Precision (Method 3)\",\n     * described in the RFC. ...\n \nreply",
      "> It's mentioned in the RFC as being explicitly monotonic based the time-based design.It's explicitly partially monotonic.Or as other people would call it, \"not monotonic\".People are talking past each other based on their use of the word \"monotonic\".\n \nreply",
      "> So it is explicitly mentioned in the RFC as optional [\u2026]The use of rand_a for extra monotonicity is optional. The monotonicity itself is not optional.\u00a75.7 states:    Alternatively, implementations MAY fill the 74 bits, \n    jointly, with a combination of the following subfields, \n    in this order from the most significant bits to the least, \n    to guarantee additional monotonicity within a millisecond:\n\nGuaranteeing additional monotonicity means that there is already a 'base' level of monotonicity, and there are provisions for even more (\"additional\") levels of it. This 'base level' is why \u00a76.2 states:    Monotonicity (each subsequent value being greater than the last) is \n    the backbone of time-based sortable UUIDs. Normally, time-based UUIDs \n    from this document will be monotonic due to an embedded timestamp; \n    however, implementations can guarantee additional monotonicity via \n    the concepts covered in this section.\n\n\"Backbone of time-based sortable UUIDs\"; \"additional monotonicity\". Additional: adding to what's already there.* https://datatracker.ietf.org/doc/html/rfc9562\n \nreply",
      "\"this monotonicity\" that OP suggests people not use is specifically the additional monotonicity.Or to put it another way: OP is suggesting you don't depend on it being properly monotonic, because the default is that it is only partially monotonic.\n \nreply",
      "> Normally, time-based UUIDs from this document will be monotonic due to an embedded timestamp; however, implementations can guarantee additional monotonicity via the concepts covered in this section.\u201cNormally, I am at home because I do not have a reason to go out; however, sometimes I am at home because I am sleeping.\u201dNotice how this statement does not actually mean that I am always at home.\n \nreply",
      "Relying on an explicitly documented implementation behavior that the specification explicitly describes as an option is not an issue. Especially if the behavior is only relied on in a test, where the worst outcome is a failed testcase that is easily fixed.Even if the behavior went away, UUIDs unlike serials can always be safely generated directly by the application just as well as they can be generated by the database.Going straight for that would arguably be the \"better\" path, and allows mocking PRNG to get sequential IDs.\n \nreply",
      "The \"optional\" portion is this part of the spec, not the time part.> implementations can guarantee additional monotonicity via \n    the concepts covered in this section\n \nreply"
    ],
    "link": "https://brandur.org/fragments/uuid-v7-monotonicity",
    "first_paragraph": "I'm on X/Twitter at @brandur.Bluesky at brandur.org.An implementation for UUIDv7 was committed to Postgres earlier this month. These have all the benefits of a v4 (random) UUID, but are generated with a more deterministic order using the current time, and perform considerably better on inserts using ordered structures like B-trees.A nice surprise is that the random portion of the UUIDs will be monotonic within each Postgres backend:In our implementation, the 12-bit sub-millisecond timestamp fraction\nis stored immediately after the timestamp, in the space referred to as\n\u201crand_a\u201d in the RFC. This ensures additional monotonicity within a\nmillisecond. The rand_a bits also function as a counter. We select a\nsub-millisecond timestamp so that it monotonically increases for\ngenerated UUIDs within the same backend, even when the system clock\ngoes backward or when generating UUIDs at very high\nfrequency. Therefore, the monotonicity of generated UUIDs is ensured\nwithin the same backend.This is a "
  },
  {
    "title": "Ask HN: Who is hiring? (January 2025)",
    "points": 207,
    "submitter": "whoishiring",
    "submit_time": "2025-01-02T16:00:09 1735833609",
    "num_comments": 161,
    "comments_url": "https://news.ycombinator.com/item?id=42575537",
    "comments": [
      "St. Jude Children's Research Hospital | Principal Software Engineer, Rust Genomics Infrastructure | Memphis, TN | ONSITE or REMOTE | https://www.stjude.org/St. Jude Children's Research Hospital is hiring Rust software engineers to rebuild the genomics ecosystem in Rust. We work at the intersection of computer science and genomics, and we're trying to build a better foundation upon which genomics can be done using Rust. Come work with the individuals that wrote the Rust-based bioinformatics library, noodles (https://github.com/zaeleus/noodles), sprocket (https://github.com/stjude-rust-labs/wdl and https://github.com/stjude-rust-labs/sprocket), as well as many other projects (https://github.com/stjude-rust-labs).NOTE that prior experience in bioinformatics or biology is NOT required for any of the positions below. You must be interested in learning though! If you'd like to get a sense of what you'd be learning, check out the guide we wrote to teach software engineers about genomics here: https://learngenomics.dev.* Principal Software Engineer: https://talent.stjude.org/careers/jobs/JR4161?lang=en-usWith any questions, email me at clay.mcleod@stjude.org.\n \nreply",
      "Return | https://return.energy | Data platform engineer (EU only)We are hiring a data platform engineer who will work on platforms that accelerate the transition to carbon-free energy. Return\u2019s main activities are building and operating industrial-size Battery Energy Storage Systems and solar plants. Our operations are located in the Netherlands, Germany, and Spain.You will be making a measurable (country-level) impact on the transition to renewable energy.The tech team members have co-founded several companies and/or have experience with remote development teams since 2008. They will personally help you through most of the recruiting process (there is no recruiter involved).If you call yourself an SRE, DevOps engineer, or a backend engineer, you are also more than welcome to apply!More info at https://jobs.polymer.co/return\n \nreply",
      "Is the UK okay? It meets the \"five hours overlap with Amsterdam\" requirement even though it is not EU\n \nreply",
      "Juniper (YC W21) | Senior Software Engineer | Full-time | HYBRID NYC | juniperplatform.comJuniper is working to improve the messy financial infrastructure for US Healthcare. We've built an automated end-to-end insurance billing system for recurring care, starting with Autism clinics. It\u2019s a product that clinicians need and love.We automate and abstract the tedious, manual, repetitive work that goes into the administrative duties of running a clinic, so that clinicians can do what they do best \u2014 providing care.It starts with ingesting clinic data, and then create, validates, and submits claims to insurance providers across the country. If claims need corrections or appeals, most of the time we can handle those automatically or our CX and Operations team use our in-house internal tools. We also handle patient invoicing for co-pays, co-insurance, and deductibles (we never send anything to collections).We are a team of ~40 with strong product market fit. You\u2019ll be working with an engineering leadership team from AWS and Stripe to get clinicians back to work delivering care for kids.Email us at josh.paul@juniperplatform.com or apply at jobs.lever.co/juniperplatform\n \nreply",
      "ROCKSTAR GAMES | NYC-San Diego-New England| FULL-TIME | .NET SOFTWARE ENGINEERS | Existing Visa Transfers WelcomeA career at Rockstar Games is about being part of a team working on some of the most creatively rewarding and ambitious projects to be found in any entertainment medium. You would be welcomed to a dedicated and inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.RESPONSIBILITIESDevelop highly scalable server-side features for our online game console clients using object-oriented development in C#, ASP.NET, and SQL Server.Develop back-end services and APIs. Actively practice Test Driven Development (TDD) while developing new features and refactoring existing code.Work in an AWS cloud-based, event-driven microservice architecture with a high priority on web performance optimization.Collaborate with other Rockstar technology teams across our worldwide studios.New York: https://grnh.se/01daf4583usSan Diego: https://grnh.se/87116de23usNew England: https://grnh.se/3d1c2f9a3usYou can see our other openings here: https://www.rockstargames.com/careers/\n \nreply",
      "IBM | Hybrid in Cambridge, MA (Boston metro area) | Full Time | Research EngineerThe MIT-IBM Watson AI lab is hiring a Research Engineer.Information on base salary ranges etc. can be found at the posting: https://ibmglobal.avature.net/en_US/careers/JobDetail?jobId=...If you've been hacking on/with LLMs, please apply! The job posting casts a wide net, so please don't self-disqualify if you only check some of our boxes. Prior research experience is great but we're more interested in cool things you've built than in pdfs you've pushed through academic gauntlets :-)\n \nreply",
      "Klyo | NYC, In Person | Full Time | Full Stack Engineer | 100-150k, 1-2% EquityAt Klyo AI, we\u2019re building the AI-powered data and marketing assistant for small businesses, starting with the med spa space. Forget dashboards, charts, and data tools\u2014our AI seamlessly connects fragmented data to provide actionable insights, next steps, and clear answers, delivered in real time through text or email.We\u2019re pre-seed, growing fast (with paid clients who love us), and ready to scale. As our Founding Engineer, you\u2019ll be at the core of building, improving, and scaling our technical foundation and direction, helping us bring this vision to life.We are looking for product-minded full stack engineers who:   - Have had 5+ years of hands-on software engineer experience, especially at earlier stage startups\n   - Have experience leading projects end-to-end and taking ideas from conception to execution and iteration independently\n   - Are technically versatile:\n      - Experience building in AI/ML or NLP agents (OpenAI, LLMs, data pipelines, etc.).\n      - Strong backend experience with any programming language (we use python)\n      - Has worked with AWS infrastructure and PostgreSQL\n      - Familiar with React, Next.js or something similar for small/medium sized applications\n   - Customer-Focused: You care about solving real problems for users and  can balance technical decisions with customer impact.\n   - Resourceful & Scrappy: You love taking ownership, moving quickly, and figuring things out with limited resources.\n\nWhat We Offer   - Meaningful Equity (1-2%) in a fast-growing pre-seed startup.\n   - Competitive starting salary: $100K\u2013$150K (with room for growth)\n   - A chance to be a foundational part of Klyo AI and shape the technical future of a product solving real customer pain points.\n   - A collaborative, product-focused environment with a mission to change how small businesses use their data.\n\nHow to ApplyEmail your resume and a few sentences about why you\u2019re excited to join Klyo\nAI to founders@klyo.ai.\n \nreply",
      "Resemble AI | San Francisco Bay Area (office in Mountain View, CA) | Full-Time | Full-Stack EngineerWe're creating state of the art Generative Voice AI models. Looking for full stack, frontend and machine learning engineers that would love to create prototypes directly with the founders. Recently, we open sourced a state of the art speech enhancement model: https://github.com/resemble-ai/resemble-enhanceHere's what we're looking for:Full Stack Engineer - We are seeking a skilled Full Stack Engineer with experience with both Javascript and Python to join us. The ideal candidate will have a strong background in building and deploying web applications, a passion for working on cutting-edge AI technologies, and the ability to collaborate closely with our founders to create innovative prototypes.Backend Engineer - Looking for Ruby on Rails and/or Python Developers to join our backend team. Scale up ML systems, make inference run more efficiently, and expose public facing APIs.ML Engineer - Looking for engineers that are interested in deploying large foundational models and optimizing inference. Must know PyTorch well. Knowledge of ONNX, TensorRT is bonus.If interested, reach out directly to me: zohaib [at] resemble.ai\n \nreply",
      "Better Stack | https://betterstack.com | /^(Full-?stack|Frontend) Engineer$/i | Europe remote in UTC \u00b1 3hWe are software builders at :heart:\nCEO is a software engineer, COO is a software engineer and you guessed it; CTO is an engineer, too.We are engineers, making the tools we always wanted. If you love building amazing software, you're at the right address.Apply at https://betterstack.com/careers/fullstack-engineerHow we operate:- https://betterstack.com/careers- https://betterstack.com/careers/engineering- https://juraj.blog\n \nreply",
      "Machine Phase Systems | https://machinephase.systems/ | REMOTE | Software engineering, surface-science physicis, theoretical chemistry, mechanical engineeringMachine Phase Systems is making a straight-shot attempt at the grand vision of molecular nanotechnology: scalable nano factories able to produce atomically precise products using radically new materials.Open roles for chemistry and surface science, but also CAD/CAM software development, chemical simulations, mechanical design, and various internal software tools.Software stack depends on the application of course, but we work with Rust whenever possible and Flutter/Dart for user interfaces and Python for scientific compute.Use contact email at https://machinephase.systems\n \nreply"
    ],
    "link": "item?id=42575537",
    "first_paragraph": ""
  },
  {
    "title": "Diagnosing an Unusual WiFi Issue (2020) (ryuuta.net)",
    "points": 168,
    "submitter": "llimllib",
    "submit_time": "2025-01-02T16:42:06 1735836126",
    "num_comments": 60,
    "comments_url": "https://news.ycombinator.com/item?id=42575990",
    "comments": [
      "This is very similar to an issue I battled for months on MacBook Pro (one of the later Intel versions, like 2018-ish), although there problem was not in the HW itself but the current version of MacOS at that time (this is no longer an issue).I noticed that my WiFi had similar repeating lags .. about every 8-10s pings would go to a few hundred ms and then return to single/low double digits.Long story short, the problem was with several MacOS  components (and maybe some 3rd party software) requesting Location services to determine Mac\u2019s position. To do that, among other things, Mac scans WiFi around you (probably for the names/SSID?) and to do that, the current WIFI connection is temporarily put on a back burner, resulting in a brief delay in traffic. The solution was to minimize location services.\n \nreply",
      "This is a great example of good ideas destroying themselves. \"Software should occasionally be able to find out where the computer it is on physically is\" is a cool idea, but once it's there every single piece of crapware out there does it constantly.See also desktop notifications for websites\n \nreply",
      "There's a big difference there.You install an application you are giving it permission to do practically anything it wants to do with your system, including find the location as often as it wants to.Browsers have to ask you permission to show desktop notifications, or get your location, or anything else.\n \nreply",
      "> You install an application you are giving it permission to do practically anything it wants to do with your systemNot on macOS, AFAIK. You can add/remove permissions for that.\n \nreply",
      "This is a more recent feature. I\u2019m not sure if such granular permissions were in macOS back in 2020 when this blog post was written.\n \nreply",
      ">and to do that, the current WIFI connection is temporarily put on a back burner, resulting in a brief delay in traffic.I can't believe they ever thought that'd be a good idea.\n \nreply",
      "Probably have to sweep across the frequency bands, so it's physically the only way to do it. Still stupid to do it more than once every 15 minutes\n \nreply",
      "Fast switching on a background schedule while packets continue to flow but at slightly reduced rate should be possible. Might be very export controlled though given obvious application.\n \nreply",
      "You mean the RF circuitry has to continue working in the frequency of the current network and switch frequencies to scan for other networks in all bands simultabeously? I don't think consumer hardware is capable of that. It usually will send probes or listen passively for some time in a band before moving to the next one sequentially. It's an expensive operation.\n \nreply",
      "I'm not an expert but I think depending on design this is sacrificing one MIMO channel when active and adding another PLL.\n \nreply"
    ],
    "link": "https://ryuuta.net/blog/diagnosing-an-unsual-wifi-issue/",
    "first_paragraph": ""
  },
  {
    "title": "I am rich and have no idea what to do (vinay.sh)",
    "points": 227,
    "submitter": "vhiremath4",
    "submit_time": "2025-01-02T22:50:15 1735858215",
    "num_comments": 346,
    "comments_url": "https://news.ycombinator.com/item?id=42579873",
    "comments": [
      "Same situation, I truly empathise because it really does seem to take a lot of purpose out of everything. What I\u2019ve found is that you need to replace money/salary/financial success optimisation (assuming you spent a lot of your life and energy to this point focused on these, much like I did) with something else totally unconnected with being measured in that way. For me, I am focused on proving myself as a guitarist in the local jazz and blues scene. These people have no idea how much money I have and wouldn\u2019t give a shit if they did (I didn\u2019t really change my lifestyle after getting lucky so it\u2019s not obvious). So it\u2019s an area I can be creative, grow, and still feel like I\u2019m doing something. At the same time I\u2019m doing part time consulting, mainly for people I worked with in the past who have started companies, just to scratch the tech itch. So far so good but I can\u2019t say yet if it will stick. Maybe for you it\u2019s art, music, going and getting another unrelated degree, or something along those lines? If you have more money than you know what to do with, fundraising and supporting good causes can be really rewarding. Both in terms of giving back something to your local community, and having really nice social elements to it.One big piece of advice I have is to try to avoid letting others in your social network know exactly how successful you\u2019ve been. Everyone starts wanting to pitch you their investment idea and it can burn down friendships when their ideas are bad. Being a VC to your friends is a path to sadness for everyone.\n \nreply",
      "People need work to be happy. That doesn't have to be, say, office work necessarily: it can be making music full time, or volunteering at a hospital, or any number of other things.But you have to have something keeping you busy that makes you feel like you have a purpose.\n \nreply",
      ">Same situation, I truly empathise because it really does seem to take a lot of purpose out of everything.Mainly though if all the purpose-giving focus was on just getting money and the related grinding to begin with.Getting mega-rich didn't take the purpose out of Steve Jobs, for example, which was focused on building stuff with some specific twist (his idea of good design). Or Steve Wozniak for that matter, he found hobbies aplenty. Or take the Rolling Stones. Filthy rich, but did they ever give the impression they got bored? Or Dylan, equally rich, which doesn't even have the extravagant lifestyle of models and exotic vacations and high life the Stones had, but is still content to record, jam, play concerts etc. into his 80s.If the person has other interests, from programming to mountaineering, and from politics to art, they can still be there with or without money. Like the \"guitarist in the local jazz and blues scene\" thing.\n \nreply",
      "Paul Allen comes to mind. makes a hobby buying the most expensive artifacts known, as well as a bunch of other stuff like starting a band.\n \nreply",
      "This is my dream. Having enough money to be able to dedicate to things I like, trying to be good at something without worrying about money, or time, or being tired after work.Open a bookshop, being a rare book dealer, open a small museum about an author, research on a particular topic and write books...That would be the ultimate dream, though I am sure I won't ever be near to fulfill it.\n \nreply",
      "Problem then when you get bored, your bookstore still requires work.At a certain level of wealth, any job you can do can be done by someone else better and cheaper\n \nreply",
      "> For me, I am focused on proving myself as a guitarist in the local jazz and blues scene.So you\u2019re Dickey from The Talented Mr. Ripely?\n \nreply",
      "Do you have children? If not, it's a great use of time, especially without financial pressure\n \nreply",
      "Children are giver of immense sense of satisfaction that\u2019s totally disconnected to wealth (though being wealthy certainly helps). Just remember - no short cuts.\n \nreply",
      "That last point is salient. I grew very rich in the last 3 - 4 years and I funded a bunch of my friend's startup ideas. Now I cannot bear myself to reply to their happy new year wishes because how the relationships have soured.\n \nreply"
    ],
    "link": "https://vinay.sh/i-am-rich-and-have-no-idea-what-to-do-with-my-life/",
    "first_paragraph": ""
  },
  {
    "title": "XiangShan \u2013 open-source high performance RISC-V processor (github.com/openxiangshan)",
    "points": 134,
    "submitter": "gjvc",
    "submit_time": "2025-01-02T17:08:38 1735837718",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=42576242",
    "comments": [
      "This project is the first that tickles my brain in the right serendipitous ways; it merges topics of my recent interests.However, after a VERY short perusal, I grew a giant sense of empathy for non-native English speakers. The readme is gentle enough to English speakers (aka: +95% English) no less I felt like I muddled through renaming tokens in my mind as I went. However, that quickly showed me two things.1. It reminds me why I never seem to finish classic Russian literature\u2026 so often get lost in the introductory parade of names that are a cache miss for my usual set of names.2. This is perhaps a significant cultural muscle that has never been necessitated for English speakers. Since the earth has largely been using English (in some capacity) for significantly longer than my life span - as my favorite joke says in the punch line \u201cwhat do you call someone who only knows one language\u2026 uni-lingual\u2026 jk: American\u201dPS: it seems like there could be an open registry maintained by \u201cAmericans like me\u201d who would rather pre-process the code for tokens within the docs and src\u2026 seems like a \u201cDefinitelyTyped style\u201d definitions registry would be very niche, but SUPER useful.\n \nreply",
      "If anyone wants to play arround with simulating it, here is a Dockerfile I use:    # Dockerfile\n    FROM ubuntu:24.04\n\n    RUN apt-get update && apt-get install -y build-essential clang libclang-dev llvm-dev cmake libspdlog-dev vim git curl wget time default-jre default-jdk\n    RUN git clone --recursive https://github.com/OpenXiangShan/xs-env\n    WORKDIR /xs-env\n    RUN sed 's/apt\\S* install/\\0 -y/g;s/source /. /g;s/sudo //g' -i ./*.sh\n    RUN . ./env.sh && sed 's/\\/master/\\/master/g;s/$/; cd \\/xs-env/g' -i ./update-submodule.sh && ./update-submodule.sh\n\n\n    RUN . ./env.sh && ./setup-tools.sh\n    RUN . ./env.sh && . ./install-verilator.sh\n    RUN . ./env.sh && sed 's/^git submodule.*$//g;s/env.*$//g' -i ./setup.sh && . ./setup.sh\n\n    RUN . ./env.sh && make -C XiangShan init\n    RUN . ./env.sh && cd DRAMsim3 && mkdir build && cd build && cmake -D COSIM=1 .. && make -j 8\n    RUN . ./env.sh && make -C XiangShan emu CONFIG=DefaultConfig WITH_DRAMSIM3=1 MFC=1 -j 8\n\n    RUN . ./env.sh \\\n        && sed 's/unknown-//g;s/rv64gc/rv64gcv/g' -i $AM_HOME/am/arch/*.mk $AM_HOME/am/arch/isa/*.mk \\\n        && sed 's/define MSTATUS_FS.*$/define MSTATUS_FS 0x6600/g' -i $AM_HOME/am/src/*/isa/riscv/boot/*.S\n\n\n    WORKDIR nexus-am/apps/hello\n    RUN make ARCH=riscv64-xs\n\n    # $NOOP_HOME/build/emu --no-diff -i ./build/hello-riscv64-xs.bin 2>/dev/null\n\nMake sure you have 64GB of RAM. I only had 16GB, but allocating additional 48GB of swap worked.There are probably some redundant steps, but this worked for me last time I tried.\n \nreply",
      "why so much ram?\n \nreply",
      "64GB of RAM isn't that much for full chip simulation of a \"high performance\" CPU.\n \nreply",
      "That's a pretty huge amount of RAM even for a high performance core. The medium performance cores I've simulated use more like 300MB.I suspect it is the Scala compilation that requires all the RAM rather Verilator or the simulator.\n \nreply",
      "Maybe, I've never used Scala before. But in my experience simulations are way more resource intensive than compilation.\n \nreply",
      "yeah I'm super ignorant here, wondering, say you simulated this, could you run a VM OS against it? What kind of scale it it, personal computer or server (i7/xeon)?Or you just use it to compile programs against it?edit: I did skim the readme, I saw verilog makes me think FPGA\n \nreply",
      "You could simulate this on an FPGA platform, those aren't going to be cheap to hold a large design. Usually by running simulations on a PC you're just running very specific test cases.I've run CPU simulations on machines with 64GB of RAM before and it took several hours just to get to single-user shell in Linux. Different CPU design and computer, but the point is it's not something you'd typically use interactively.\n \nreply",
      "Interesting do it actually runs that's cool vs. a hyper visor which idk the difference but yeah\n \nreply",
      "https://github.com/OpenXiangShan/XiangShan-doc/blob/main/doc...The list of fused instructions is kinda weird; besides the ones that correspond to SH{1,2,3,4}ADD anyway, I don't think I expected any of the others.I don't see a mention of Sifive-style short jump predication there either, though I'm using Google Translate.\n \nreply"
    ],
    "link": "https://github.com/OpenXiangShan/XiangShan",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Open-source high-performance RISC-V processor\n      XiangShan (\u9999\u5c71) is an open-source high-performance RISC-V processor project.\u4e2d\u6587\u8bf4\u660e\u5728\u6b64\u3002Copyright 2020-2022 by Institute of Computing Technology, Chinese Academy of Sciences.Copyright 2020-2022 by Peng Cheng Laboratory.XiangShan-doc is our official documentation repository. It contains design spec., technical slides, tutorials and more.Our paper introduces XiangShan and the practice of agile development methodology on high performance RISC-V processors.\nIt covers some representative tools we have developed and used to accelerate the chip development process, including design, functional verification, debugging, performance validation, etc.\nThis paper is awarded all three available badges for artifact evaluation (Available, Functional, and Reproduced).\n\nPaper PDF | IEEE Xplore | BibTeX | "
  },
  {
    "title": "uBlock Origin GPL code being stolen by team behind honey browser extension (reddit.com)",
    "points": 572,
    "submitter": "extesy",
    "submit_time": "2025-01-02T17:27:28 1735838848",
    "num_comments": 270,
    "comments_url": "https://news.ycombinator.com/item?id=42576443",
    "comments": [
      "As if Honey isn't already under enough fire with half the youtube world releasing videos about their shady practices.\n \nreply",
      "Title is misleading. The original team behind Honey has created a new company that is doing this and not Honey itself which is owned by Paypal.\n \nreply",
      "Do we know when Honey started stealing affiliate links? Was it after the acquisition?\n \nreply",
      "I don\u2019t understand why people are surprised that they are earning money from affiliate links. They are very upfront about it. It is described in a page aptly titled \u201cHow does Honey make money?\u201d[1]. On their partner page the first link is to \u201cHow Honey Works with Affiliates\u201d [2], which describes their relationship with the affiliate networks.The only thing that I never understood was why brands would allow Honey to be an affiliate. Why would they want to pay Honey any money when Honey doesn\u2019t originate any traffi?[1] https://help.joinhoney.com/article/30-how-does-honey-make-mo...[2] https://get.joinhoney.com/business/how-honey-works-with-affi...\n \nreply",
      "> Why would they want to pay Honey any money when Honey doesn\u2019t originate any traffi?Paying Honey means you can limit the discounts available through Honey, sort of like a shitty protection scheme.Because Honey bills itself to the consumer as the be-all-end-all coupon and discount app and advertises itself as \"we know ALL the coupon codes and discounts\", a consumer with the Honey extension will likely not look outside of that for a discount and assume whatever they got from the extortion racket as the end customer was \"the best deal\".\n \nreply",
      "> The only thing that I never understood was why brands would allow Honey to be an affiliate. Why would they want to pay Honey any money when Honey doesn\u2019t originate any traffi?One YouTube channel, theo dot gg has a conspiracy theory about it which is honey:1. amassed a huge (rabid) user base \n2. Offered \"protection\" to companiesThe evidence presented is Amazon dot com affiliates walk on eggshells to avoid breaking Toss that Honey completely tramples on so at the very least honey is not subject to the same tos as everybody. However, Amazon dot com is very aware of honey evidenced by advisory warnings on Amazon dot com website from a few years ago.So I think basically the strategy here was:1. Pay a lot of money to buy a user base \n2. Offer protection to stores if they do certain things\n3. Deliberately don't give the best offers to users if the stores pay this protection money, wreck the store somehow(?) if they don't \n4. Profit\n \nreply",
      "Before, this is how ALL coupon sites/extensions have worked for decades.I'm frankly baffled it weren't more common knowledge, despite being common sense, before the MegaLag video.  Did people really think that sites like retailmenot.com or wethrift.com make you open tabs to the shop you're searching for coupons for before you can see the coupon code just for fun??Affiliate code stuffing is the coupon provider business model, it's not Honey-exclusive at all. I'd be surprised if you find a coupon site/extension that haven't always done that.\n \nreply",
      "It is pretty funny how the MegaLag video claimed it was hard to find discussion of this online, and cited a HN thread from over five years ago: https://news.ycombinator.com/item?id=21588663I suppose it's easy for us to forget how an average person really doesn't think about how cookies and referral links work.\n \nreply",
      "Yeah, as I watched the video all I could think was \"what the fuck did you think they were doing?\". I'm surprised technical youtube channels were caught by it, although maybe they did the calculation that the money Honey was paying was worth more than the affiliate sales they'd lose. There's also value to getting that money immediately, rather than at some unknown point in the future.The only part that seemed uncouth to me was setting the referral code when they hadn't actually found any coupons, and collaborating with retailers.\n \nreply",
      "> I'm surprised technical youtube channels were caught by it, although maybe they did the calculation that the money Honey was paying was worth more than the affiliate sales they'd lose.... and helping to screw everyone else over in the process. That is what makes advertising for Honey so unethical.\n \nreply"
    ],
    "link": "https://old.reddit.com/r/uBlockOrigin/comments/1hr6xjc/ubo_quick_filters_list_being_stolen_by_team/",
    "first_paragraph": ""
  },
  {
    "title": "PlasticList's Advice for Food Companies (twitter.com/natfriedman)",
    "points": 68,
    "submitter": "Jimmc414",
    "submit_time": "2025-01-02T18:35:57 1735842957",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=42577272",
    "comments": [
      "Recent and related:Plasticlist Report \u2013 Data on plastic chemicals in Bay Area foods - https://news.ycombinator.com/item?id=42525633 - Dec 2024 (188 comments)\n \nreply",
      "i've recently have been frustrated by the tooling out there to identify plastics in consumer products and just released https://getplasticfree.com/think it would be a helpful tool for people interested in this topic!\n \nreply",
      "Why are wood cutting boards outlawed for commercial kitchens.\n \nreply",
      "An argument that I\u2019ve heard is that wooden boards can get more infected with bacterial colonies if not washed and maintained properly. I\u2019m not sure how actually true this is though.\n \nreply",
      "Plastic cutting boards are mostly just plain undyed polyethylene (HDPE)- which is just a fully saturated perfectly straight hydrocarbon, similar to saturated fat or wax and lacks the kind of reactive functional groups that make other plastic polymers toxic. I think it is quite unlikely that HDPE in particular is toxic or endocrine disrupting to humans in the way a lot of other plastics seem to be.It's also basically just a very viscous fluid and I suspect would flow into grooves when a knife blade hits it, without releasing particles like harder more solid plastics would.Personally, I try to avoid having most plastics contact my food and water, but make an exception for HDPE.In general, each plastic polymer is very different from another chemically, and it makes sense to consider their safety independently, and not group all plastics together.\n \nreply",
      "Silicon dioxide is not chemically toxic. But you can put microfiber crystals of it in a mammal's lungs and get tumors that grow around them. It is not a huge stretch of the imagination from there to hypothesize that nano- and micro-particles of a nontoxic polymer could also cause problems.\n \nreply",
      "True- I don't think they are likely to specifically exhibit the drug like toxicity that some other plastics are responsible for, but you are right that doesn't rule out other potential issues from a small, hydrophobic, physical object.I'm not 100% sure HDPE is safe- and if not it might depend on how it is used, but I am less concerned about it than a lot of other plastics.\n \nreply",
      "That\u2019s a good point. Why do they say water bottles are so bad?  Can\u2019t they use something like hdpe?\n \nreply",
      "HDPE Nalgenes (branded \"Ultralite\") are my standard water bottle.  Unlike the clear plastic sort, they're not see-through, nor very heat/impact resistant, but they weigh next to nothing.  Just don't use 'em as a hot water bottle.\n \nreply",
      "The problem is cutting boards break off little bits of plastic with use and your body has evolved zero mechanism for disposing of microplastics once they are in your system.https://www.ewg.org/news-insights/news/2023/10/making-meals-...\nhttps://phys.org/news/2024-12-microplastics-multiple-human-t...\n \nreply"
    ],
    "link": "https://twitter.com/natfriedman/status/1874884925587087434",
    "first_paragraph": ""
  },
  {
    "title": "UpCodes (YC S17) is hiring remote recruiters to help make buildings cheaper (up.codes)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-01-02T21:01:41 1735851701",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://up.codes/careers?utm_source=HN",
    "first_paragraph": ""
  },
  {
    "title": "Shm\u00f8ergh Hog \u2013 The making of a simple analog synth (peterzimon.com)",
    "points": 8,
    "submitter": "b6dybuyv",
    "submit_time": "2024-12-30T20:07:40 1735589260",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.peterzimon.com/hog/",
    "first_paragraph": "The making of a simple analog synthWe finished the first version of a synthesizer that starts to resemble a real product. It's the same concept that I've already written about \u2013\u00a0a simple switches-over-knobs style analog synth for live performance, called Hog \u2013 but with completely reworked circuitry and enclosure.This post is about our process and how the Hog came to be, so I'm not going to write about how the instrument works. But to give you a bit of context, here is an overview of the main features:If you want details of the synth itself you can head over to shmoergh.com.The idea of the Hog came when we were messing around with the A1 prototype and found it tedious and time consuming to switch between sounds that are actually usable e.g. in a band. So we decided to design a very simple analog synth that has killer sound, and through purposeful limitations, it is very easy to work with. Kinda the opposite of what you expect of today's synthesizers with \"endless possibilities\".I experi"
  },
  {
    "title": "DOOM CAPTCHA (doom-captcha.vercel.app)",
    "points": 1129,
    "submitter": "denysvitali",
    "submit_time": "2025-01-01T14:12:15 1735740735",
    "num_comments": 256,
    "comments_url": "https://news.ycombinator.com/item?id=42566112",
    "comments": [
      "I tried to do it the intended way, but found it too difficult. I was able to cheese it by staying in the starting area and killing the enemies that spawned to the right.\n \nreply",
      "That isn't cheesing it, given those start conditions. That is a standard tactic when you only have the pistol (or are too low in ammo for other weapons).The pistol is crazy accurate in these games so you can pick enemies of from afar with a few shots each, and in this case they are firing shotguns which are very ineffective at long range (the game stimulates them as having unrealistically wide pellet spread, so even if a far-off enemy gets a pin-point shot you will only take minimal damage).I remember playing over the collage NetWare LAN and winning people who had better but less accurate weapons (usually the shotgun, or the double in later versions, as we found that the most cathartic) simply by keeping my distance. Works until someone gets close from behind, at which point if you respawn somewhere convenient you can find the bugger PDQ, and pick him off with the pistol for revenge. Even works against the rocket launcher, just make sure you don't get hit directly (d'oh) or hang around where it is easy for splash damage from misses to ruin your plans.It is a valid method for many DOOM-style games (as they were called in my day) and their offspring. Works well in HL2 where you can spam the trigger button as fast as you like and the basic pistol will fire at that rate without a limit (other weapons have a minimum shot latency).\n \nreply",
      "Do you remember the early \"bug\" in HL2 where you could bind shoot to mouse wheel up, then flick the wheel to magdump the pistol and blast anything? Good times :)\n \nreply",
      "I've played combat games where you can chirp in order to lure enemies towards you.Then you're incentivized to find a defensible spot and keep mashing the \"chirp\" button so you get a steady stream of enemies.You could remove the chirp button -- but then you're left sprinting out juust far enough that the enemy detects you, then run back somewhere defensible.  Not very satisfying.Or you can make it so enemies stream towards the player continuously, regardless of how close they are, without any trigger -- which is sort of equivalent to having the chirp button get mashed automatically.  Again, find somewhere defensible and mash the attack key.None of these approaches feel very satisfying.  There must be some clever approach to this issue which doesn't run into any of these problems.  A simple set of rules which leads to a large variety of combat challenges instead of a degenerate winning strategy.\n \nreply",
      "Well, this is not the first level, but this is the level entry weapon.Plus, left and right arrows rotate the characters since it's keyboard only, but in modern FPS you are used to having them laterally move you and you rotate with the mouse, so your reflexes are off.\n \nreply",
      "As in the original, you can use alt + left/right arrow keys to strafe.\n \nreply",
      "In Windows the issue is that alt+space will by default open the window's control menu (for minimize/maximize/move/etc.). Pressing space down and then alt will work though.\n \nreply",
      "So this is just as difficult as every other captcha then\n \nreply",
      "Good memory.But very platform dependant, so maybe OP is on a browser or OS that doesn't let you do that.I know it works on Chrome for me, but not on FF.\n \nreply",
      "Probably because firefox has alt+(left|right)arrow as global navigation bindings, and is capturing them before the captcha can get them.  requesting a fullscreen gaming mode avoids more key binding issues, but probably ruins the \"captcha\" feel.\n \nreply"
    ],
    "link": "https://doom-captcha.vercel.app/",
    "first_paragraph": "\n      A CAPTCHA that lets you play DOOM\u00ae to prove you're human (for\n      educational and entertainment purposes)\n    \n      The project works by leveraging Emscripten to compile a\n      minimal port of Doom to WebAssembly and enable\n      intercommunication between the C-based game runloop (g_game.c) and the\n      JavaScript-based CAPTCHA UI.\n    \n      Some extensions were made to the game to introduce relevant events\n      needed for its usage in the context of a CAPTCHA.\n    \nSee the v0 UI generation\n      or\n      get the source.\n    \nBuilt on the shareware version of DOOM\u00ae released publically for\n        non-commercial use. DOOM\u00ae is a registered trademark of id Software\n        LLC, a ZeniMax Media company.\nat least 3 monsters"
  },
  {
    "title": "Awesome Donations: A repository of FLOSS donation options (github.com/n1trux)",
    "points": 8,
    "submitter": "prompt_overflow",
    "submit_time": "2025-01-02T23:29:04 1735860544",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=42580231",
    "comments": [
      "Check out https://floss.fund too.See https://news.ycombinator.com/item?id=41857032\n \nreply",
      "Too bad the norm for FLOSS foundations is to take donations and use it for anything and everything except the purpose the foundation was created to promote.\n \nreply"
    ],
    "link": "https://github.com/n1trux/awesome-donations",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A repository of FLOSS donation options.\n      A repository of FLOSS donation options, sorted A-Z.Feel free to create pull requests (three projects or more). You can also send them via Jabber or eMail to me.The Free Software Foundation (FSF) is a nonprofit with a worldwide mission to promote computer user freedom and to defend the rights of all free software users.https://www.linuxfoundation.org/about/donateEurope:https://linuxfoundation.euThe Open Source Initiative (OSI) is a non-profit corporation with global scope formed to educate about and advocate for the benefits of open source and to build bridges among different constituencies in the open source community.Software Freedom Conservancy is a not-for-profit organization that helps promote, improve, develop, and defend Free, Libre, and Open Source Software (FLOSS) projects. Conse"
  },
  {
    "title": "Rules for writing software tutorials (refactoringenglish.com)",
    "points": 106,
    "submitter": "mtlynch",
    "submit_time": "2025-01-02T14:23:30 1735827810",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=42574641",
    "comments": [
      "There is a lot of good advice about details!Especially one that got my heart:> Some authors design their tutorials the way you\u2019d give instructions for an origami structure. It\u2019s a mysterious sequence of twists and folds until you get to the end, and then: wow, it\u2019s a beautiful swan!> A grand finale might be fun for origami, but it\u2019s stressful for the reader.\"Yes, a lot of tutorials are puzzle games. You need to guess other tools to install, which are obvious to the author, but not everyone.I would add a few things:* Have two types of examples - minimal and the most typical (one is to show the essence without distraction, the second to serve as a practical starting point) \n* Always provide the full code sequence to run code; if there are any assumptions, these should be listed explicitly (e.g. \"it needs Node 22\"); you hinted a bit, but since many tutorials miss that, it deserves attention.Even better, if it is possible to combine it into one point and make it runnable. For example, for a package I had been developing, livelossplot, I made  Jupyter Notebooks runnable in Colab:* https://colab.research.google.com/github/stared/livelossplot...\n* https://colab.research.google.com/github/stared/livelossplot...\n \nreply",
      "I hope that plenty of developers read this, especially folks on open source projects who don't have dedicated documentation people. There's so much bad documentation out there, and many of these tips are key.A couple more of my own:TEST YOUR DOCSAs @codetrotter suggests in another comment, run through your own tutorial with a fresh VM and follow it closely; you'll almost certainly find something to improve.But this works better if you have someone else try it out instead: get on a video call with them, have them share their screen and speak their thoughts out loud, and most importantly, don't help them. You're trying to find out if they can complete this without additional help. (Yes, it's a usability test.)BETTER SOFTWARE MAKES SIMPLER TUTORIALSThe article's rule about \"let computers evaluate conditional logic\" is a good one, but there are multiple places to fix that problem. Sometimes it's in the tutorial, sometimes it's in the software product itself. When the tutorial makes the reader do complex work, it may be a sign that the software has UX issues. You may not be in a position to fix it, but you can probably file an issue.For the example in the article: could you make the same package name work on all three Debian versions? It'd certainly improve the user experience, and probably make the installation process more resilient.\n \nreply",
      "Extending on the copy-pasteable snippets, another big improvement (flaw to avoid) is to include all imports to the code snippets.\n \nreply",
      "And the names of packages to install. Don't assume the imports match it. Check.\n \nreply",
      "Author here.I've been thinking for a long time about anti-patterns I see when following software tutorials, so I put together this list of things I think differentiate good tutorials from poor ones.I'm happy to hear any feedback on this list or hear about other things I should include.\n \nreply",
      "I have a minor nit to pick.  I actually prefer when tutorials provide the prompts for all code snippets for two reasons:1.  Many tutorials reference many languages.  (I frequently write tutorials for students that include bash, sql, and python.)  Providing the prompts `$`, `sqlite>` and `>>>` makes it obvious which language a piece of code is being written in.2. Certain types of code should not be thoughtlessly copy/pasted, and providing multiline `$` prompts enforce that the user copy/pastes line by line.  A good example is a sequence of commands that involves `sudo dd` to format a harddrive.  But for really intro-level stuff I want the student/reader to carefully think about all the commands, and forcing them to copy/paste line by line helps achieve that goal.That said, this is an overall good introduction to writing that I will definitely making required reading for some of my data science students.  When the book is complete, I'll be happily buying a copy :)\n \nreply",
      "> Certain types of code should not be thoughtlessly copy/pasted, and providing multiline `$` prompts enforce that the user copy/pastes line by line.I hardcore oppose this kind of thing, for the same reason I oppose people putting obstacles in the way of curl-to-bash.Adding the prompt character doesn\u2019t make people think, it just makes people press backspace. Frequently I\u2019m reading a tutorial because I\u2019m trying to assemble headless scripts for setting up a VM and I really just need verbatim lines I can copy/paste so I know I\u2019ve got the right arguments.\n \nreply",
      "Thanks for reading!>Many tutorials reference many languages. (I frequently write tutorials for students that include bash, sql, and python.) Providing the prompts `$`, `sqlite>` and `>>>` makes it obvious which language a piece of code is being written in.I think it's fine to show the prompt character, but I think it's the author's job to make sure that copy/paste still works. I've seen a lot of examples that use CSS to show the prompt or line number without it becoming part of copied text, and I'm highly in favor of that.I think if I had to choose between breaking copy/paste and making the language obvious with the prompt character, I'd exclude the prompt, but I think that's a matter of taste.>Certain types of code should not be thoughtlessly copy/pasted, and providing multiline `$` prompts enforce that the user copy/pastes line by line. A good example is a sequence of commands that involves `sudo dd` to format a harddrive. But for really intro-level stuff I want the student/reader to carefully think about all the commands, and forcing them to copy/paste line by line helps achieve that goal.Yeah, I agree about preventing the reader from copy/pasting something dangerous.In tutorials that require a reboot, I'll never include a reboot command bunched in with other commands because I don't want the user to do it by mistake. And I agree for something like `dd`, you'd want to present it in a way to make it hard for the reader to make mistakes or run it thoughtlessly.\n \nreply",
      "> I've seen a lot of examples that use CSS to show the prompt or line number without it becoming part of copied text, and I'm highly in favor of that.This is unfortunately not compatible with writing the tutorial in markdown to be rendered on github.\n \nreply",
      "I'm not sure about that. There are markdown rendering engines where you can specify the language of a codeblock and it will render with specific CSS based on the language. So you can do something like ```bash ... ``` and it will show the code with newlines prefixed by \"$\"\n \nreply"
    ],
    "link": "https://refactoringenglish.com/chapters/rules-for-software-tutorials/",
    "first_paragraph": "by Michael Lynch, published\nJanuary 2, 2025Most software tutorials are tragically flawed.Tutorials often forget to mention some key detail, preventing readers from replicating the author\u2019s process. Other times, the author brings in hidden assumptions that don\u2019t match their readers\u2019 expectations.The good news is that it\u2019s easier than you think to write an exceptional software tutorial. You can stand out in a sea of mediocre guides by following a few simple rules.The most common mistake tutorials make is explaining beginner-level concepts using expert-level terminology.Most people who seek out tutorials are beginners. They may not be beginners to programming, but they\u2019re beginners to the domain they\u2019re trying to learn about.In this tutorial, I\u2019ll show you how to create your first \u201cHello world\u201d SPA using React.Open the included hello.jsx file and change the greeting from \"Hello world\" to \"Hello universe\".The browser should hot reload with the new text. Because of React\u2019s efficient JSX tra"
  },
  {
    "title": "What Is miniKanren? (minikanren.org)",
    "points": 174,
    "submitter": "Bluestein",
    "submit_time": "2025-01-02T13:15:23 1735823723",
    "num_comments": 99,
    "comments_url": "https://news.ycombinator.com/item?id=42574125",
    "comments": [
      "Minikanren was the subject of a phenomenal talk by Matt Might for it's applications in medicine[0] https://www.janestreet.com/tech-talks/algorithm-for-precisio...\n \nreply",
      "Discussed a bit on HN:The Algorithm for Precision Medicine, talk by Matthew Might [video] - https://news.ycombinator.com/item?id=37814662 - Oct 2023 (14 comments)The Algorithm for Precision Medicine - https://news.ycombinator.com/item?id=29483549 - Dec 2021 (1 comment)\n \nreply",
      "A couple years ago, I tried to wrap my poor little non-developer head around how to use this, because I have a handful of things going on medically that seem (to me) to be connected, but I can't manage to get any doctors to care enough to help me figure out, but I was hopelessly out of my depth.Normally I can at least figure out how to use something, even if I don't understand how it works under the hood, but with this, I couldn't even figure out the next step.\n \nreply",
      "Sorry about that.mediKanren's source code is under MIT license, and is on GitHub.  Alas, the knowledge graphs we use for mediKanren aren't produced by us, and often have very complex licenses (one KG might include knowledge from 80 or 100 databases, each with a different license).  As a result, we can't just release the KGs that are needed to actually use mediKanren.  Also, creating high-quality queries that take into account all the nuances and quirks of the KGs is tricky, and changes as the KGs and the Biolink standard evolve.  As a result, mediKanren requires some expertise to use effectively, along with access to the KGs.An application that uses mediKanren as a back-end (along with other reasoners) is the NIH NCATS Biomedical Data Translator:https://ui.transltr.io/Please keep in mind that both Translator and mediKanren are designed for researchers and for biomedical research, not for patient care or treatment recommendations.\n \nreply",
      "It's surprisingly reassuring to realize it wasn't actually my fault that I couldn't figure it out. Thanks for explaining! I'll look into Translator and see if I can get anywhere that way.\n \nreply",
      "You might have better luck if you try today using Claude as support?\n \nreply",
      "Alas, you'd still need the knowledge graphs.  I hope the licensing issues for at least some of the KGs will be resolved soon.  It's a tricky issue.  Even some of the ontologies and controlled vocabularies in biomedicine can't be released publicly due to copyright restrictions (for example, full SemMedDB uses UMLS which uses SNOMED).\n \nreply",
      "That was an incredible read, a real-life Dr. House episode. And very exciting technology, too. Thanks for sharing.\n \nreply",
      "fantastic talk, thanks for sharing.\n \nreply",
      "... wherein:\"It will demonstrate progress to date, including the now-routine use of relational programming in miniKanren to identify personalized treatments for patients with some of the rarest and most challenging diseases in the world.\"... wherefrom I cannot help but be amazed at how personalization through data optimization apparently actually helps solve such things and can be an approach.-\n \nreply"
    ],
    "link": "http://minikanren.org/",
    "first_paragraph": ""
  },
  {
    "title": "Building a Knowledge System That Enhances Rather Than Replaces Thought (nsavage.substack.com)",
    "points": 58,
    "submitter": "nsavage",
    "submit_time": "2025-01-02T18:47:45 1735843665",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=42577387",
    "comments": [
      "After trying out a bunch of digital zettelkasten tools, I just went back to paper.This take may be a bit hot, but I actually think paper and pen is already the optimal maxima for thinking\u2014not for retrieval, mind you, but for helping us produce new thoughts. Zettelkasten (at least the way Luhmann used it) is meant for this purpose\u2014it is not a system for storing information and retrieving it but rather for supporting the creation of new connections.The computer aided tools are suboptimal for this because they lack the good constrains of paper (severely limiting the search space) and the good features (seamless ability to incorporate a variety of representational modes, text, image, equation, with zero overhead, and the ability to organize things freely in space). As much as the digital knowledge base sounds good in theory, I don't think it will ever be as optimal for generation of thought. If all you want to do is summon existing information, digital tools are evidently superior. I personally think a hybrid system where one \"thinks\" on paper and \"archives\" digitally (after the thinking is done) might be best, but ultimately, we will be most productive with whatever system we actually enjoy using.\n \nreply",
      "> When you're dealing with ten notes, it's trivial to dump them into an LLM and generate connections. With a hundred notes, it's still manageable. But what happens when you hit 10,000 notes? Or a million? We quickly run into the limitations of context windows and processing capacity. Vector search helps narrow things down, but it's prone to missing important connections that a human mind might naturally make.I run into the same problem. I made a RAG system and imported 15 years of reddit and HN content (my own message logs) + 2 years of LLM chats, totaling about 80MB of text. I can use it to retrieve fragments but there is duplication, and almost all duplicate fragments have slightly different approaches. How do I merge all of them, and how do I get a deduplicated taxonomy? I got about 290K unique keywords extracted from the text, it doesn't fit into LLMs.I am gravitating towards building graphs of ideas, and having a way to generate unique (non duplicate) new ideas while ingesting new text.\n \nreply",
      "Intriguing. I've been thinking of something similar. Do you have any notion of what constitutes an 'idea' in this context?\n \nreply",
      "> From Socrates worrying that writing would destroy memory [...]  Think of it as a partnership: the computer handles the organizational heavy lifting, while you focus on the thinking.I'm less worried about memory per se and more about failing to think, or getting brainwashed/ring-led by a system with its own biases and quirks. Any sufficiently complex organizing is thinking!Perhaps the simplest example is when quantities (numbers, easy to record) get a mental weight that overshadows and hides their dimensions (the definitions, what they really mean.) For example, a tendency to automatically assume a rising GDP number is an unqualified good sign.Stuff like LLMs bring that into newer and more-dangerous territory, because the model also contains uncountable subtle biases from its training data, and even if you know it isn't aligned (heh) with your own mental models you can't reliably change it. Much like false-memories implanted by interrogators, patterns in those systems can and will leak into the users. Whenever we can't \"think about how our thinking is being changed\", I'd say that's axiomatically bad.\n \nreply",
      "P.S.: Lest anyone think I'm a Luddite--not that I think that appellation is actually that bad--an example where I would use an LLM would be to help me generate synonyms or alternate inputs to a more-traditional search for a discrete external piece of information.For example, I might remember a book with a jester playing a lute and singing about ogres, and I just can't find any clear search results, because it was actually a bard strumming a harp with a poem about giants.This is much less dangerous than just throwing every dang thing into LLM inputs (since prompt injection isn't a fluke, it's a way of life) or filtering the results back through the same model in an opaque fashion.\n \nreply",
      "> What parts of note-taking should we digitize? What aspects should remain firmly in human hands? And most importantly, how do I create a tool that enhances rather than replaces human thought?My personal philosophy is to use the most primitive methods possible and only use technology when there really is a strong need to go to the next level. It exposes what I really need, what are the weaknesses, etc. For example, I take all my notes with pen and paper. But if I find that I'm really referring back to something, I might write it up in a document. I don't see the point in digitizing everything right away if I'm never going to use what I write.Moreover, writing things first by hand helps me remember them better and \"feel\" the knowledge through my hands.Same thing with photography. I don't tend to use the burst mode on my camera unless I REALLY need it. When it comes to accomplishing things, I found (personally) that asceticism with tools is best.\n \nreply",
      "> Moreover, writing things first by hand helps me remember them better and \"feel\" the knowledge through my hands.There was a science article recently that studied taking notes and it's results were that handwritten notes improved recall compared to typed notes.\n \nreply",
      "> create something that thoughtfully augments human intelligence rather than replacing itI htink this is a really cool design space, particularly with the framing of the purpose of Zettelkasten as reflecting your personal understanding of the world, your views, rather than a cold, dead categorization of facts and objects.How can we design software systems that enhance our sensemaking?- Encouraging us to ask more questions, or write down our thoughts? You can imagine the AI bringing snippets to your attention, asking: \"What do you make of this?\" or \"How might we connect these?\"- Augmenting our notes? Finding nubs of thought, and presenting research/articles to help us develop those lines some more- Collaboration suggestions? People who wrote about the same things?\n \nreply",
      "Recently I\u2019ve been imaging a world where social media algorithms were tuned to help people instead of \u201cdriving engagement\u201d with ever more outrage bait. Oh you\u2019re watching clips about machining and by your data profile you\u2019re an uneducated adult? Here are some trade school, financial assistance, and self help links to nudge you toward a better life! What a world that would be.\n \nreply",
      "Isn't this what Tiktok is in China? It mostly promotes educational and science content.\n \nreply"
    ],
    "link": "https://nsavage.substack.com/p/beyond-rag-building-a-knowledge-management",
    "first_paragraph": ""
  }
]