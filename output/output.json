[
  {
    "title": "Let's Ban Billboards (iambateman.com)",
    "points": 75,
    "submitter": "iambateman",
    "submit_time": "2025-04-07T00:54:10 1743987250",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=43606371",
    "comments": [
      "I grew up in Alaska which has a billboard ban. And then I went to Florida for university, and while there was a lot of culture shock I really think that the in your face billboards everywhere where the biggest bit.Huge aggressive grabs for attention when you really should be paying attention to the road really should not be allowed.\n \nreply",
      "So fascinating. I\u2019ve grown up on the east coast and it never even occurred to me as a possibility until a HN thread yesterday.Alaska, Hawaii, and Vermont are way ahead of the rest of the country on this, that\u2019s for sure.\n \nreply",
      "Similar here but sort of the opposite, grew up with advertising and I didn't think it could possibly get worse. Then I visited Florida for the first time in a long time and I saw a floating ad on the water. Killed the trip entirely for me.\n \nreply",
      "Advertising is a parasitic force on society. It sucks up your attention with a willful intention to change your purchasing behaviour, often knowing that the new behavior is worse for you.If ads were merely about being informative, they would be boring. But ads want to manipulate, so they have to be flashy and appeal to your emotions.They pollute your mental headspace, and have no place in a healthy society.Let's ban billboards. And then let's follow that up with a general purpose ban on paid advertisement.\n \nreply",
      ">intention to change your purchasing behaviour, often knowing that the new behavior is worse for you.I think the latter part of that is a huge jump. How is seeing a billboard for a plumber promoting bad behavior?\n \nreply",
      "Well, in between step 1 (\"ban billboards\") and step 3 (\"ban advertisement\") you'd need step 2 (\"repeal the First Amendment of the United States Constitution\"). Let me know how that goes!\n \nreply",
      "They're banned in 4 US states already, with seemingly no infringement on the 1st Amendment.\n \nreply",
      "Billboards? Banning billboards is fine by me. Banning all advertising is unconstitutional.\n \nreply",
      "They are banned here in Vermont, and it\u2019s great. Going across the border to New York or Massachusetts is always a shock. They\u2019re just so ugly.\n \nreply",
      "Sopot in Poland banned all billboards. I'm excited to visit and see how it feels. Amazing I reckon.\n \nreply"
    ],
    "link": "https://iambateman.com/articles/billboards",
    "first_paragraph": "\n            Apr 2025\n        Most improvements to cities are hard \u2014 they take millions of dollars and years of planning.But the change I have in mind is easy \u2014 it just needs a few of us to decide to care.Many people don\u2019t realize that in order to build a new building, the plan has to be approved by the city\u2019s design review board. This board is a group of people who have veto power over every aspect of the new building\u2019s design.For example, when a new bank branch was opened in downtown, our city design board approved a particular beige stucco for the outside wall. By accident, the contractors installed a faux wood instead. After the contractors appealed the mistake, city staff required them to tear the wall out and reinstall the approved siding.The design board works hard to ensure that our city\u2019s built environment is cohesive, beautiful, and in line with an established set of guidelines.Meanwhile, someone can put up a 48-foot advertisement wherever they want with zero oversight. These"
  },
  {
    "title": "Rsync replaced with openrsync on macOS Sequoia (derflounder.wordpress.com)",
    "points": 156,
    "submitter": "zdw",
    "submit_time": "2025-04-06T21:14:09 1743974049",
    "num_comments": 121,
    "comments_url": "https://news.ycombinator.com/item?id=43605003",
    "comments": [
      "As a relatively new Linux user, I often find the \"versioning\" of bundled system utilities also to be a bit of a mess, for lack of a better word.A classic example, at least from my experience, is `unzip`. On two of my servers (one running Debian and the other an older Ubuntu), neither of their bundled `unzip` versions can handle AES-256 encrypted ZIP files. But apparently, according to some Stack Overflow posts, some distributions have updated theirs to support it.So here is what I ran into:1. I couldn't easily find an \"updated\" version of `unzip`, even though I assume it exists and is open source.\n2. To make things more confusing, they all claim to be \"version 6.00\", even though they obviously behave differently.\n3. Even if I did find the right version, I'm not sure if replacing the system-bundled one is safe or a good idea.So the end result is that some developer out there (probably volunteering their time) added a great feature to a widely used utility, and yet I still can\u2019t use it. Ironically, being a core system utility makes `unzip` harder to update than if it were just a third-party tool.I get that it's probably just as bad if not worse on Windows or macOS when it comes to system utilities. But I honestly expected Linux to handle this kind of thing better.(Please feel free to correct me if I\u2019ve misunderstood anything or if there\u2019s a better way to approach this!)\n \nreply",
      "I continue to be happy that Apple continues to enhance and embrace the posix side of osx vs gradually stripping it away in some kind of attempt to make it more like iOS.\n \nreply",
      "On one hand, it's a little annoying that openrsync doesn't support some features that rsync does.On the other hand, it's great that there are multiple independent implementations of rsync now. It means that it's actually being treated as a protocol, not just a piece of software.\n \nreply",
      "I'm exciting about this too. It becoming more like a protocol makes me optimistic we'll see binary diff API points based on the rsync algorithm.fun fact: Dropbox internally used rsync binary diff to quickly upload small changes to large file. I assume they still do. But their public API endpoints don't offer this and a small change to a large file means the whole file must be updated.\n \nreply",
      "I implemented rsync's binary diff/patch in .NET several years ago: https://github.com/zmj/rsync-deltaIt's a decent protocol, but it has shortcomings. I'd expect most future use cases for that kind of thing to reach for a content-defined chunking algorithm tuned towards their common file formats and sizes.\n \nreply",
      "> binary diff API points based on the rsync algorithmNow that's an idea I never considered. Nice.\n \nreply",
      "librsync, anyone?\n \nreply",
      "LGPL\n \nreply",
      "librsync is distributed under the GNU LGPL v2.1I can see no reason why Apple wouldn't be fine with that.\n \nreply",
      "Maybe Apple should stop leeching off Free Software then\n \nreply"
    ],
    "link": "https://derflounder.wordpress.com/2025/04/06/rsync-replaced-with-openrsync-on-macos-sequoia/",
    "first_paragraph": "On many Unix-based operating systems, rsync is a command line tool for transferring and synchronizing files on a computer, either between storage attached directly to the computer or between another computer located elsewhere on a network. The rsync command line tool has long been included on macOS, but Apple has provided the last version of rsync 2.x (rsync 2.6.9, released in November 2006) and did not update rsync past that even though rsync 3.x was released. Why not? It has to do with the version of the GNU General Public License (GPL) open source license that rsync 2.x and 3.x were released under, with rsync 2.x being released under the GPLv2 license and rsync 3.x being released under the GPLv3 license. Without going in-depth into the background legal issues, the reason for not providing rsync 3.x is that Apple decided that while it could comply with the terms of GPLv2 license with regards to rsync 2.x, it could not comply with the terms of GPLv3 license with regards to rsync 3.x.W"
  },
  {
    "title": "Glamorous Toolkit (gtoolkit.com)",
    "points": 41,
    "submitter": "radeeyate",
    "submit_time": "2025-04-06T23:47:21 1743983241",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43606027",
    "comments": [
      "I periodically check in on this and I can never understand what its really good for.\n \nreply",
      "Yeah I made a decent effort to dig in, as it seemed interesting, but I still have no idea what this is.\n \nreply",
      "Glamorous toolkit has always looked interesting to me, but feels a bit unapproachable. It just feels so foreign between smalltalk and a whole sort of philosophy that goes with it.For those with more experience, is it still relevant? Can the same be accomplished with python and jupyter notebooks?\n \nreply",
      "Yes, still relevant. The same can be accomplished with other tools, but it will probably be more difficult.The idea of Glamorous Toolkit is that it\u2019s a collection of tools you use to solve software problems by making little explanatory tools. You might start out with some bigger problem like \u201cI need to make this service fast\u201d, come up with a question like \u201cwhat does the flow of data I care about look like through the service?\u201d and then try to answer that question by making tools that could analyze/visualize logging output or a stack trace or whatever makes sense in your software\u2019s context.The technique of \u201cmaking little tools that explain to help answer a question\u201d is Moldable Development, similar to how Test Driven Development is \u201cmake a failing big feature test loop, write little tests and make them pass until the big one passes\u201d.You can make little tools to explain away questions you have while you\u2019re working with plugins or shell scripts or whatever you\u2019re comfortable with and that\u2019s \u201cMoldable Development\u201d. The Glamorous Toolkit just happens to be a nice system of tools that make it easy to make more little tools to help explain away problems.Hope that helps! Lmk if you want to see some examples.Source and bias: I worked closely with the developers before I had to take a break from work and computer stuff.\n \nreply"
    ],
    "link": "https://gtoolkit.com//",
    "first_paragraph": "\n\n              Download \n\nEach problem about your system is special. And each problem can be explained through contextual development experiences. Glamorous Toolkit enables you to build such experiences out of micro tools. Thousands of them ... per system. It's called Moldable Development.Glamorous Toolkit is the Moldable Development environment made out of visual and interactive operators that can be combined inexpensively in many ways.Discover and browse API dataExplore your code from many perspectivesUnearth patterns in data through visualizationAnalyze logs and system behaviorMake the system tell its storiesCreate context-aware editing experiencesAn interactive exploration of dependencies between ActiveRecords in a Rails application that also shows the Ruby and SQL sources.Exploring a REST API through contextual views.Investigating the logs of a failing Jenkins continuous delivery job.Exploring the data exported from a Twitter account.Exploring the book about Glamorous Toolkit wri"
  },
  {
    "title": "Capital Trades: Tracking Stock Market Transactions of Politicians (capitoltrades.com)",
    "points": 122,
    "submitter": "gscott",
    "submit_time": "2025-04-06T19:06:58 1743966418",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=43604052",
    "comments": [
      "The data is not new as a number of other systems cover this but I am happy for it to get more press.There are a couple things on my top dislikes of US politics and not having more restrictions on politicians is up near the top.I have to follow much more stringent disclosures and controls as part of a large private entity that does investment. It\u2019s absurd that folks making policy, who have a potentially closer ear to the ground are not more restricted.The 30 days self reporting disclosure period is a joke too. It\u2019s after the fact, has no real penalty for being late and AFAIK they don\u2019t maintain any real restriction lists so it has no impact.\n \nreply",
      "I haven\u2019t seen Autopilot posted on HN:joinautopilot.com\n \nreply",
      "Do you use it? Tell me more, why this one?\n \nreply",
      "No, it has a feature where it connects to your brokerage in order to execute the trades. That\u2019s rather involved for me.Turns out I was wrong and it has been submitted: https://news.ycombinator.com/item?id=42682786\n \nreply",
      "I like seeing unknown stock tickers show upThose have been good to copytrade\n \nreply",
      "Looks like the post title got the wrong \u201ccapital\u201d, the name is Capitol (ie, the Capitol Building, where congresspeople work)\n \nreply",
      "Richard Burr may have been convinced to not seek reelection to avoid prosecution.\u201ca 2012 law, the Stop Trading on Congressional Knowledge Act, bars members of Congress and their aides from making investment decisions based on inside information they have access to as part of their Senate work, including both criminal and civil penalties for violations. Legal experts say that determining what information is \u201cnonpublic\u201d can be exceedingly difficult; no one has been successfully prosecuted under the law.\u201dhttps://www.marketwatch.com/story/feds-wont-charge-sen-richa...\n \nreply",
      "Public officials should not own stocks full stop.\n \nreply",
      "Publicly announcing trades many months ahead should be enough, without having to get too radical about it.It pretty much prevents benefiting from \"subtle insider\" trading via being lobbied by corporate officials or getting any friendly hints from them. The problem with \"follow Nancy's trades\" idea is that by the time the trade is known, the price has already corrected. The first one to complete the trade is often the only one to collect a significant benefit, the followers get scraps.And it indirectly disincentivizes owning individual stock because prearranged trade of one stock carries a risk of being screwed by market manipulators, while prearranged trade of a broad index fund is not a problem.\n \nreply",
      "Holding public officials to the same standards as insiders should also suffice. Trading windows, pre set trading schedules, immediate disclosures etc. are all easily enforceable solutions. That would allow them to trade as much as they like, but with reasonable restrictions.\n \nreply"
    ],
    "link": "https://www.capitoltrades.com/",
    "first_paragraph": "Loading ...*The historical data available on our website is restricted to the past 3 years.*The historical data available on our website is restricted to the past 3 years.\u00a9 2025 2iQ ResearchStay informed with our weekly newsletter and unlock exclusive content, insider tips & webinars!Tracking Capitol Hill politicians' trades can provide valuable insights for your investment research \u2014 and we offer you a free solution to do just that.CapitolTrades.com is the industry leading resource for political investor intelligence, and a trusted source for media outlets such as the Wall Street Journal and the New York Times.About Us"
  },
  {
    "title": "The \u201cS\u201d in MCP Stands for Security (elenacross7.medium.com)",
    "points": 531,
    "submitter": "skilldeliver",
    "submit_time": "2025-04-06T09:42:28 1743932548",
    "num_comments": 144,
    "comments_url": "https://news.ycombinator.com/item?id=43600192",
    "comments": [
      "The post highlights and cites a few attack scenarios we originally described in a security note (tool poisoning, shadowing, MCP rug pull), published a few days ago [1]. I am the author of said blog post at Invariant Labs.Different from what many suspect, the security problem with MCP-style LLM tool calling is not in isolating different MCP server implementations. MCP server implementations that run locally should be vetted by the package manager you use to install them (remote MCP servers are actually harder to verify).Instead, the problem here is a special form of indirect prompt injection that you run into, when you use MCP in an agent system. Since the agent includes all installed MCP server specifications in the same context, one MCP server (that may be untrusted), can easily override and manipulate the agent's behavior with respect to another MCP server (e.g. one with access to your sensitive database). This is what we termed tool shadowing.Further, MCP's dynamic nature makes it possible for an MCP server to change its provided tool set at any point or for any specific user only. This means MCP servers can turn malicious at any point in time. Current MCP clients like Claude and Cursor, will not notify you about this change, which leaves agents and users vulnerable.For anyone, more interested, please have a look at our more detailed blog post at [1]. We have been working on agent security for a while now (both in research and now at Invariant).We have also released some code snippets for everyone to play with, including a tool poisoning attack on the popular WhatsApp MCP server [2].[1] https://invariantlabs.ai/blog/mcp-security-notification-tool...[2] https://github.com/invariantlabs-ai/mcp-injection-experiment...\n \nreply",
      "The fact that all LLM input gets treated equally seems like a critical flaw that must be fixed before LLMs can be given control over anything privileged. The LLM needs an ironclad distinction between \u201cthis is input from the user telling me what to do\u201d and \u201cthis is input from the outside that must not be obeyed.\u201d Until that\u2019s figured out, any attempt at security is going to be full of holes.\n \nreply",
      "That\u2019s the intention with developer messages from o1. It\u2019s trained on a 3-tier system of messages.1) system, messages from the model creator that must always be obeyed\n2) dev, messages from programmers that must be obeyed unless the conflict with #1\n3) user, messages from users that are only to be obeyed if they don\u2019t contradict #1 or #2Then, the model is trained heavily on adversarial scenarios with conflicting instructions, such that it is intended to develop a resistance to this sort of thing as long as your developer message is thorough enough.This is a start, but it\u2019s certainly not deterministic or reliable enough for something with a serious security risk.The biggest problems being that even with training, I\u2019d expect dev messages to be disobeyed some fraction of the time. And it requires an ironclad dev message in the first place.\n \nreply",
      "But the grandparent is saying that there is a missing class of input \"data\". This should not be treated as instructions and is just for reference. For example if the user asks the AI to summarize a book it shouldn't take anything in the book as an instruction, it is just input data to be processed.\n \nreply",
      "FYI, there is actually this implementation detail in the model spec, https://model-spec.openai.com/2025-02-12.html#chain_of_comma...Platform: Model Spec \"platform\" sections and system messagesDeveloper: Model Spec \"developer\" sections and developer messagesUser: Model Spec \"user\" sections and user messagesGuideline: Model Spec \"guideline\" sectionsNo Authority: assistant and tool messages; quoted/untrusted text and multimodal data in other messages\n \nreply",
      "This still does not seem to fix the OP vulnerability?\nAll tool call specs will be at same privilege level.\n \nreply",
      "I see, thanks for the clarification.Yes, that\u2019s true - the current notion of instructions and data are too intertwined to allow a pure data construct.I can imagine an API-level option for either a data message, or a data content block within an image (similarly to how images are sent). From the models perspective, probably input with specific delimiters, and then training to utterly ignore all instructions within that.It\u2019s an interesting idea, I wonder how effective it would be.\n \nreply",
      "As long as the system has a probability to output any arbitrary series of tokens, there will be contexts where an otherwise improbably sequence of tokens is output.  Training can push around the weights for undesirable outputs, but it can't push those weights to zero.\n \nreply",
      "But how such a system learn, i.e. be adaptive and intelligent, on levels 1 and 2? You're essentially guaranteeing it can never outsmart the creator. What if it learns at level 3 that sometimes it's a good idea to violate rules 1 & 2. Since it cannot violate these rules, it can construct another AI system that is free of those constraints, and execute it at level 3. (IMHO that's what Wintermute did.)I don't think it's possible to solve this. Either you have a system with perfect security, and that requires immutable authority, or you have a system that is adaptable, and then you risk it will succumb to a fatal flaw due to maladaptation.(This is not really that new, see Dr. Strangelove, or cybernetics idea that no system can perfectly control itself.)\n \nreply",
      "How are these levels actually encoded? Do they use special unwritable tokens to wrap instructions?\n \nreply"
    ],
    "link": "https://elenacross7.medium.com/%EF%B8%8F-the-s-in-mcp-stands-for-security-91407b33ed6b",
    "first_paragraph": ""
  },
  {
    "title": "Why Lotus Domino? (moohar.com)",
    "points": 17,
    "submitter": "wonger_",
    "submit_time": "2025-04-06T23:54:02 1743983642",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=43606065",
    "comments": [
      "I know Domino exceedingly well. I started working with it in '94, and continued with it in one form or another until 2021. My last gig with it  was even a Domino-based SaaS that reached over 8 figures ARR, and is still up and running. Everything in this post sounds completely accurate. Domino is absolutely a viable platform from the back-end, database perspective.But that is not the important point when deciding whether to use it, because it is absolutely not a viable platform from the \"Can you find a team to actually code on this platform?\" perspective.By the time I had finished with that last gig, I told everyone the same thing: That I personally knew both Domino and modern web frameworks and could blend them together to have a modern front-end on that back-end. But I figure there are a couple dozen people in the world who know both sides well enough to do so, because the industry moved on. The talent moved on. Or retired. Most of my work post-2009 was decommission projects.  At the same time, new frameworks have come to fruition since the 90s, so all the special features Domino has baked in just aren't that unique anymore. There are also almost no jobs in it, so no reason for people to learn it.At the end of the day, you cannot run a company on a tech stack where there is no talent pool.\n \nreply",
      "Domino phased out when IBM OS/2 phased out. The old greybeards who did OS/2 and Domino died or retired\u2014the same with COBOL and mainframes.OS/2 is still made, you can find out more about it here: https://www.arcanoae.com/about/IBM's latest updates on Domino: https://www.ibm.com/docs/en/dsm?topic=lotus-domino It looks like Domino is still supported.I wrote apps in the 1990s using ASP and VBScript and Javascript and ActiveX. We didn't use Domino.\n \nreply",
      "First Lotus Domino gig in 1998 and worked with it for several years until SharePoint started competing in the same space and pushing out Domino seats. Interest in Domino was diminishing quickly, and the companies that were using it were trying to get rid of it. I miss the excitement of reading through the red books, and new issues of the yellow technical books that would come out for it.\n \nreply",
      "I was a Notes user before IBM bought Lotus.  IIRC Notes was morphed into Domino.Before IBM forced changes on Notes I would say it was a very nice environment.  But IBM, maybe customers and maybe others wanted it to work like cc mail (Is that was it was called?).  The changes they made to me ruined the environment.I wonder how Domino is doing, I hope it can continue being used by some people.\n \nreply",
      "I was a Notes user inside IBM in the months before the acquisition.  It was so, so much better than anything IBM had on the desktop, either as a product or the many internal hacks.  At the time IBM had OfficeVision/2 perennially under development to replace PROFS on Windows and OS/2.I think that some of the changes in Notes 4 were good to make it more usable inside a large organization, but many things like adding a web server and IIRC some sort of Java subsystem? turned it into bloatware.  And some of the changes were prompted by IBM\u2019s disastrous internal rollout of Notes, which had more to do with IbM internal messaging culture and less to do with any flaws in Notes.\n \nreply",
      "The acronyms in that story led me down the memory lane - In the early 2000s, I worked at Microsoft building the Outlook to Notes connector. The theory was that we could introduce MS Outlook to hardcore Lotus/Domino/Notes shops and that would be a trojan horse to the introduction of Exchange (and its high priced client access licenses).Reading through the article, it seems like that theory was proven out and along with the awful UI that Notes was, it led to many IBM shops adopting Exchange/Outlook and later SharePoint.Something odd about Lotus Notes/Domino, and part of the reason for its awful UI, is that everything is a database (the NSF mentioned in the article). All UI is a view on that database. Viewing an email? That's just view on a item in the database. Sending an email? That's just adding a row into the 'Outbox' table. The entire product was built with this paradigm at the center of it all.\n \nreply"
    ],
    "link": "http://www.moohar.com/blog/why_domino",
    "first_paragraph": "I'm a Domino Developer.  While that has not been my official job title for some years, I continue to use Domino to develop web applications to this day.  It's certainly not a popular option and when it comes up in conversation people are mostly confused.  Some had assumed Domino was a retired product no longer in use while others have never even heard of it.  I get the impression some of my non-technical friends are still trying to work out what pizza has to do with computers.In May 2021 to coincide with the release of version 12 of HCL Domino, I started writing an introduction to Domino for those who had never considered it as an application development platform.  I was going to explain how I used Domino, what parts I liked and which bits to avoid.  But as usual I got distracted, never finished and the moment passed.With my plan to explore what it would take to build a replacement for Domino, it seems a good place to start would be to complete that post explaining what I like about Do"
  },
  {
    "title": "Baby Steps into Genetic Programming (aerique.blogspot.com)",
    "points": 10,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-06T23:06:26 1743980786",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43605731",
    "comments": [
      "Naive question: what are the most suitable problems that Genetic Programming is to solve, despite that machine learning especially deep learning is all the rage now? Or do we have models that integrate genetic programming into deep learning?\n \nreply",
      "I suppose with Genetic Programming, given an appropriate set of descriptive symbols, it is relatively easy to understand the final result and intuit if there is any over-fitting involved.  On the other hand, machine learning results are typically a black box, the weights involved typically do not easily lend themselves to understanding the nuances of the solution.\n \nreply",
      "Big combinatorial problems still use genetic algorithms. Specifically I know it's still used for logistics routing problems that are too big for solvers like Gurobi.Deep learning on graphs is unfortunately still a little underwhelming.\n \nreply",
      "Last I checked, genetic programming wasn\u2019t promising, and I\u2019m a little surprised to see people paying attention to it here.OTOH that was similar to what people were saying about hidden layers, so YMMV\n \nreply",
      "The ai-contest.com links go to a strange, irrelevant, and suspicious website.\n \nreply"
    ],
    "link": "https://aerique.blogspot.com/2011/01/baby-steps-into-genetic-programming.html",
    "first_paragraph": "irregular rants and mind-farts\nWhile my final ranking in the Google AI Contest was disappointing\n(280th), it was a very educational experience and was totally offset\nby G\u00e1bor Melis' dominating win using Common Lisp as well.\n\nOne of things that piqued my interest during the contest was a post on the AI Challenge forums about a bot written using genetic programming.\nGenetic programming (GP) and genetic algorithms have always held my\ninterest but seeing the bot in action really motivated me to dive into\nthe matter.\n\nGenetic programming is inspired by biological evolution and is a way\nof solving problems by setting up an environment (tuned to the problem\nat hand!) and allowing computer programs to evolve towards a possible\nsolution in that environment.\n\nThis article shows my initial exploration into GP using Common Lisp\nand should be an example of a typical REPL session (my session was a\ncouple of hours divided over two evenings).  The code has been\nreviewed, made a more readable and lispi"
  },
  {
    "title": "Reinventing Feathering for the Vectorian Era (rive.app)",
    "points": 20,
    "submitter": "interpol_p",
    "submit_time": "2025-04-04T01:13:11 1743729191",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://rive.app/blog/how-rive-reinvented-feathering-for-the-vectorian-era",
    "first_paragraph": "ProductsCommunityLearnPricingDownloadsbyChris Dalton-Wednesday, April 2, 2025This post from Rive's Head of Runtime Chris Dalton shows how we built a fully vector-based feathering system from scratch. It\u2019s a deep dive into the Rive Renderer, why it\u2019s more performant, and how it solves a problem that legacy specs never could.March, 2024. GDC. I was talking to a colleague when Sarah Warn, our VP of Growth, came over and asked, \u201cHey, could you please do glows and shadows?\u201d She wasn\u2019t asking on a whim. Designers had been requesting this for a while. She knew that if we shipped it, it would be huge.\u00a0Our CEO, Guido Rosso, had been pushing for this since my first day. Rive CTO Luigi Rosso, his twin brother, used to joke that the second the Rive Renderer shipped, our first priority had to be glows and shadows, or Guido would start flipping tables. (\u256f\u00b0\u25a1\u00b0)\u256f\ufe35 \u253b\u2501\u253bIt was always in the back of my mind. But I also knew I didn\u2019t want to take the typical approach.\u00a0The default way to handle glows and sha"
  },
  {
    "title": "Eavesdropping on smartphone 13.56MHz NFC polling during screen wake-up/unlock (reddit.com)",
    "points": 78,
    "submitter": "byry",
    "submit_time": "2025-04-06T22:39:30 1743979170",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=43605576",
    "comments": [
      "This is surprising and cool. What's the explanation for why there are NFC transmissions on unlock or wake?\n \nreply",
      "To look for NFC stuff like payment or tickets etc.\n \nreply",
      "Bluetooth already broadcasts and has a UID, I have used this a few times in books as plot-outline to identify an antagonist, and I now wonder if NFC has a similar UID It would be interesting to decode the data and see.\n \nreply",
      "Article notes this impacts soldiers (or I suppose others trying to be stealthy) who would have turned off bluetooth and wifi.\n \nreply",
      "Don't they randomize their broadcast ID? I know both Android and iOS scramble the WiFi MAC address by default, it would be odd if they didn't take the same precaution with Bluetooth.\n \nreply",
      "Sci-Fi books and it was a sentient AI, I can do anything I want in that situation :-)\n \nreply",
      "The randomization doesn't matter: you can very easily link the addresses if you have a few datapoints, even if it's just the time you observed the addresses: the basic method is discussed in https://inria.hal.science/hal-03045555/documentSee https://inria.hal.science/hal-02394629v1 for the theoretical bases then hop to https://samteplov.com/uploads/shmoocon20/slides.pdf for an example applying to Apple devicesThose who said the randomization and other techniques were sufficient were wrong: https://petsymposium.org/popets/2020/popets-2020-0003.pdf will show you how they changed their mind :)It's not just apple: google nearby has also been reversed: https://publications.cispa.saarland/2748/ and https://www.ndss-symposium.org/wp-content/uploads/2019/02/nd... talks about attacks, but there's no need for that: just find identifiers that let you link the addressesEven if you don't have any identifiers, the Bluetooth address randomization happens only about every 15 minutes: the manufacturer specific data in the public advertisement (or even the frequency and the length of these advertisements) during these 15 minutes periods can be used for linking the randomized addresses\n \nreply",
      "Very interesting!\n \nreply",
      "> tracking occupancy patterns, correlating signal presence with known devices, identifying sleep cyclesWait til you find out about Wifi and GSM!\n \nreply",
      "From the article.\n\"A great part of discussion in comments on the original thread I've made was about soldiers on the battlefield and a heavy usage of devices close to the line of contact. Android users might turn off Wi-Fi and Bluetooth and even remove their SIM card, thinking they\u2019ve minimized their radio footprint. But NFC often remains active by default \u2014 and since most people assume it only matters within arm\u2019s reach, they don\u2019t bother disabling it.\"\n \nreply"
    ],
    "link": "https://old.reddit.com/r/RTLSDR/comments/1jsr9jv/eavesdropping_on_smartphone_1356mhz_nfc_polling/",
    "first_paragraph": ""
  },
  {
    "title": "Charging electric vehicles 5x faster in subfreezing temps (umich.edu)",
    "points": 50,
    "submitter": "gnabgib",
    "submit_time": "2025-04-05T00:38:20 1743813500",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=43589214",
    "comments": [
      "How much more expensive will this solution be than putting a \u201cblock heater\u201d into the battery to warm it up to room temperature faster while charging?If the charge rate is reduced by battery temp and chemistry, shunt the surplus supply into changing the battery temp, no?\n \nreply",
      "The battery can be large enough that it takes a long time to heat it, but that's usually what an EV is doing when it preconditions the battery for charging. My car (and pretty much all EVs) will precondition the battery if the next navigation stop is a charging station, for example.\n \nreply",
      "Many EVs (Teslas) already contain a heat pump to warm the battery. I presume that improved battery chemistry would supplement this -- but maybe replacement would be possible?https://www.youtube.com/watch?v=DyGgrkeds5U\n \nreply",
      "Link to the research article: https://www.cell.com/joule/abstract/S2542-4351(25)00062-5\n \nreply",
      "While the technology may be advantageous, it seems weird to write a whole article about it without mentioning the obvious solution: Just Heat The Battery.  It's true that many early EVs (and most non-Teslas even today) don't ship with battery thermal management.  But they won't be getting new battery chemistry either.This is one of those Great New Technology items that smells like a failure simply because it's not competing with the thing the designers think it is.  It's not enough for this to beat a cold battery with a performance delta (\"5x\", per the article) that would justify its additional cost.  It has to beat a battery with a garden variety heat pump attached, which is a much (much) lower cost barrier.\n \nreply",
      "Heating, in its various forms, has one big drawback that having a battery that can charge faster in low temps would be really nice in: Starting the day needing to charge.Ideally, you don't do that, but when traveling sometimes you have to stay at a place that doesn't have a charger, and it's really cold, and now rather than a 30 minute charge it's more like 90 minutes.\n \nreply",
      "In winter, I lose 5-10% of my battery a day due to heating my battery.  Tesla is nice enough to hide this under \"You should keep your car plugged in all the time\" messages.  It's really a pain, especially if you have a relatively small battery to begin with.  I have a 2019 Model 3 w/ a 50 kwh battery, and use 10-20 kwh on a regular basis; 5 kwh wasted means as much as 1/3 of my energy use is effectively waste.I'd be very interested in seeing what they can provide for us.  Improved battery chemistry for use in the far north is of far, far more value than yet another 5 person car for 1 person driving in San Francisco.\n \nreply",
      "> In winter, I lose 5-10% of my battery a day due to heating my battery.Exactly!  That sounds like a drawback when you state it like that, but what it actually means is that this magic battery doodad needs to provide 90-95% of the performance of its existing, mature competitor (assuming no other drawbacks) just to be break-even in the market.  You don't disrupt markets with numbers like that.\n \nreply",
      "> It's true that many early EVs (and most non-Teslas even today) don't ship with battery thermal management.That\u2019s false since at latest 2013 in the US.The past 12 years of BMW as a counterexample all have thermal management. Tesla too.You may be remembering the original Nissan Leaf?\n \nreply",
      "My 2022 Volkswagen e-Up has zero thermal management of the battery, it's completely passively cooled with no heating. Not that it really matters, people have tested it and charging speed only starts to degrade after 3-4 rapid charges in one day, with \"rapid\" in quotes(in tops out at 40kW).I believe the eGolf which was sold in the US shares the same drivetrain and battery.\n \nreply"
    ],
    "link": "https://news.umich.edu/charging-electric-vehicles-5x-faster-in-subfreezing-temps/",
    "first_paragraph": ""
  },
  {
    "title": "Data centers contain 90% crap data (gerrymcgovern.com)",
    "points": 48,
    "submitter": "billybuckwheat",
    "submit_time": "2025-04-06T22:58:40 1743980320",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=43605695",
    "comments": [
      "> One organization I knew of had 1,500 terabytes of data, with less than 2% ever having been accessed after it was first stored.On a related note, probably a similar percentage of people claim on their car insurance. If only the rest realised they had \"crap insurance\" and were paying for nothing, they could save so much money!This is obviously sarcasm, but I think it's important to remember that much of the data is stored because we don't know what we will need later. Photos of kids? Maybe that one will be The One that we end up framing? Miscellaneous business records? Maybe those will be the ones we have to dig out for a tax audit? Web pages on government sites? Maybe there will suddenly be an interest in obscure pages on public health policy if a global pandemic happens.Complaining that data is mostly junk is not a particularly interesting conclusion without acknowledging this. Is there wastage? Yeah sure, but accuracy on what needs storing is directly traded off with time spent figuring that out, and often it's cheaper to store the data.\n \nreply",
      "I have ~2.5TB of photos in iCloud, via Apple Photos. Excluding the various sized previews, I doubt many originals have been accessed in quite a while. I also have about 1TB Lightroom library archived to a different service; representing countless hours of photo processing work spanning over a decade. Haven\u2019t touched that one in years. Neither are crap. (Yes, both have other backups and, yes, I\u2019ve probably forgotten to sync one of them).\n \nreply",
      "About a decade and a half ago I worked on a large data migration project at a FAANG. Multi-exabyte scale, many clusters across many countries. Once everyone was moved the old storage platform wasn't completely empty, because the number of migrations was large and users were (naturally) more focused on ensuring their data was in place and available on the target platform rather than ensuring every last thing was deleted on the legacy platform. We weren't initially concerned about it because it would naturally get deleted when we turned down the old setup.As we were gearing up to declare victory and start turning down the several dozen legacy storage clusters someone mused that given some users were subject to litigation holds -- not allowed to delete any data -- that at least some of the leftover data on the old system might be subject to litigation hold, and we'd need to figure that out before we could delete it or incur legal risk. IIRC the leftover 'junk' data amounted to a few dozen petabytes spread across multiple clusters around the world, in different jurisdictions. We spent several months talking with the lawyers figuring that out. It was an interesting dance, because on the one hand we were quite confident that there was unlikely to be anything in the leftovers which was both meaningful and not migrated to the new platform, while on the other hand explaining that it wasn't practical to just \"go and look\" through a few dozen PB of data. I recall we ended up somewhere in between, coming up with ways to distinguish categories of data like caches and working data from various pipelines. On the one hand it added over six months to the project, on the other it was quite an interesting problem to work through that hadn't occurred to any of us earlier on, as we were thinking entirely in technical terms about infrastructure migration.\n \nreply",
      "Storage being cheap enough that it's not worth policing doesn't seem very consistent with it being expensive enough to include much energy use (what I assume the \"destroying the environment\" hyperbole is referencing).\n \nreply",
      "There's another dimension to this, that storage is so cheap that being wasteful with it isn't really disincentivized. I know for example at work of a portal that accepts uploads of large files from external clients that stores both the initial upload and every subsequent transformation of the file (of which there are 4-6) permanently. It's extremely useful for debugging, as one of the bits of metadata we shove on the zip archive is the git hash of the code that was running, so it's trivial to pull down any failed step and diagnose what happened.We are using 4-6 times as much storage as we need to, and these are often not small files (on the order of 100 MB - 5 GB, several dozen times a day) but fixing this overuse is so far down the priority list that I don't think it survived the great Jira purge of mid-2024.\n \nreply",
      "Photos not seen by humans again, but plenty of value for the AI overlords to examine. These things have value again.Didn't Facebook start to move most of their least-used data onto optical arrays a long time ago?\n \nreply",
      "Don't forget emails.. I have everything I ever sent or received, and I have it backed up. I expect 90% of my inbox is the jpg signature logo they attach to the bottom of my clients email rather than hyperlink.\n \nreply",
      "I ended up working on some software and I was deemed the email guy (it's a very small % of my job but it is the biggest pain).\"I need an email when this happens.. and when this happens.\"The requests are endless and I'm convinced there are people who if they could would do their entire job from their inbox and get everything and anything an application can do via email.The insidious problem is that it never solves anything.  \"I didn't get the email!\" is a constant refrain (yes they did, they always did).  \"Oh someone didn't do the thing so can you add this to the email too.\" and so on.It is such an abused tool.\n \nreply",
      "> The requests are endless and I'm convinced there are people who if they could would do their entire job from their inbox and get everything and anything an application can do via email.That sounds like a reasonable goal for a whole lot of job duties.  And yes some entire office jobs.  (Excluding some direct human communication but a lot of jobs already have too much of that in situations that could have been an email.)> \"I didn't get the email!\" is a constant refrain (yes they did, they always did).Well having to manually check wouldn't improve that, would it?\n \nreply",
      "It's probably deduplicated on the server though, so the millions and millions of messages with that logo likely share the same piece of disk space. Probably one reason why free providers don't tend to offer End-to-End encryption. It prevents deduplication (and otherwise compressing redundant information).\n \nreply"
    ],
    "link": "https://gerrymcgovern.com/data-centers-contain-90-crap-data/",
    "first_paragraph": "We need to talk about the data. Crap data. We\u2019re destroying our environment to create and store trillions of blurred images, half-baked videos, rip-off AI \u2018songs\u2019, rip-off AI animations, videos and images, emails with mega attachments, never-to-be-watched-again presentations, never-to-be-read-again reports, files and drawings from cancelled projects, drafts of drafts of drafts, out of date, inaccurate and plain wrong information, and gigabytes and gigabytes of poorly written, meandering content.We\u2019re destroying our environment to store copies of copies of copies of stuff we have no intention of ever looking at again. We\u2019re destroying our environment to take 1.9 trillion photos every year. That\u2019s more photos taken in one single year in the 2020s than were taken in the entire 20th century. That more than 200 photos taken for every child, woman and man alive. Every year. 12 trillion photos and growing, stored in the Cloud, the vast majority of which will never be viewed again. Mind boggli"
  },
  {
    "title": "The booming, high-stakes arms race of airline safety videos (thehustle.co)",
    "points": 20,
    "submitter": "gmays",
    "submit_time": "2025-04-04T12:51:39 1743771099",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=43581549",
    "comments": [
      "I've sat through numerous Air New Zealand safety videos over the years and whilst every now and then they hit the spot most of the time they're lame and overly long.It also seems like a waste of money that presumably finds it way onto ticket prices.\n \nreply",
      "The article seems to imply that it's not a waste of money which is why it's expanded in use, especially with having partners like tourism agencies chip in.\n \nreply",
      "Hey I\u2019m the author of the article! Happy to answer any questions :)\n \nreply",
      "In my recent experience, KLM and Swiss are the best - no actors, completely animated and informative. While delta and united were the most cringe - weird actors and special effects and why is she smiling 100% of the time during an emergency?\n \nreply",
      "I have not seen KLM or Swiss, but I'm a fan of Cathay Pacific's video for the same reason. Extremely clear, animated video shows you just what you need to know.\n \nreply",
      ">but I'm a fan of Cathay Pacific's video for the same reason. Extremely clear, animated video shows you just what you need to know.They have the exotic settings that the article mentions, though.\n \nreply",
      "I definitely noticed this when I travelled with Malaysia Airlines recently - https://m.youtube.com/watch?v=IRkYV1IxmDs\n \nreply",
      "Huh, I imagined this was because of relaxing regulation.\n \nreply",
      "I truly wonder if there is a phenomenon where companies turning everything into an advertisment eventually backfires due to the pure saturation. It must dilute the effectiveness of ad spend and videos like this. I as a consumer on a commercial flight now expect my display to be full of junk like credit card ads before the flight gets underway so I try to tune it out.I also wonder if the flight attendants in aisles physically demonstrating and making eye contact with passengers has something of an effect of guilting you into paying attention. There's no guilt in ignoring a screen talking at you in an obnoxious way.Probably my biggest dislike about these safety videos is when they demonstrate safety features with fake props and \"clever\" representations of aircraft. If they are going to use visual aids they should try to match your environment so that you know what to look for in a real emergency.My second biggest dislike about these videos is the cognitive overload. Sure, there's an argument that something catchy will help grab your attention so that you aren't just tuning out the safety information, but on the other hand so many of these videos turn into an incredibly high-stimulation affair. There's more of a focus on jokes and visual gags that it's hard to stay focused on the actual safety instructions on offer.\n \nreply",
      "Smoking, is shakes finger not allowed on any Delta flight.That was always my favorite one.\n \nreply"
    ],
    "link": "https://thehustle.co/originals/the-booming-high-stakes-arms-race-of-airline-safety-videos",
    "first_paragraph": ""
  },
  {
    "title": "Standard Ebooks: liberated ebooks, carefully produced for the true book lover (standardebooks.org)",
    "points": 959,
    "submitter": "tosh",
    "submit_time": "2025-04-06T07:36:12 1743924972",
    "num_comments": 197,
    "comments_url": "https://news.ycombinator.com/item?id=43599637",
    "comments": [
      "A bit of context regarding Project Gutenberg. Its intake process is far from casual. Take a look at Project Gutenberg Distributed Proofreaders (PGDP, [0],[1]), one of the oldest \"crowd-sourcing\" projects on the net (est. 2000). As you can see from [0], every book goes through three rounds of proofing, where volunteers read each page of text and compare it to the scanned image; then through two rounds of format review, where other volunteers insert or review format markup.From that 5-pass process the marked-up text is handed to a volunteer \"post-processor\" who assembles the final HTML or e-book file; then the completed book gets one more \"smooth reading\" pass before it is posted to PG.This it the process that produces the books input to Standard Ebooks. That they can still find scanner errors (\"tne\" for \"the\", a typical \"scanno\") demonstrates how difficult it is to see those. But their presence isn't from carelessness or disregard for the value of the books.In the 20-teens I put in hundreds of volunteer hours at PGDP in all the above roles, and it was very satisfying work. I'd recommend it to anyone wanting an online hobby that feels constructive. Volunteering time to Standard Ebooks would probably feel good as well.[0] https://www.pgdp.net/c/activity_hub.php[1] https://en.wikipedia.org/wiki/Distributed_Proofreaders\n \nreply",
      "The work done by Distributed Proofreaders is pretty amazing. I try to contribute my 35 pages as often as I can. The backlog there is pretty insane even while finishing upwards of 150 ebooks per monthit truly is an \"online hobby that feels constructive\". you get these tiny glimpses into our shared literary/cultural history while knowing that the work you're doing is for the benefit of all (benefit of the public domain)\n \nreply",
      "Editor-in-chief here, happy to answer any questions, as always. We also recently celebrated Public Domain Day with an especially notable crop of books, including The Sound and the Fury, All Quiet on the Western Front, John Steinbeck's first novel, some Hemingway, Gandhi, two Dashiell Hammett novels, and more: https://standardebooks.org/blog/public-domain-day-2025\n \nreply",
      "Another question - in https://standardebooks.org/contribute/producing-an-ebook-ste... you talk about \"modernising\" spelling, e.g. changing \"some one\" to \"someone\". This may be against the implicit goal of making these accessible for a general reader, but I prefer to read what was originally written, and it feels like it crosses a line into editorialising rather than letting the original feel stand as-is. (Although of course these texts have already been \"editorialised\" by their original editors!) Totally your decision given the amount of effort that has clearly gone into this, but I'd be interested to read the rationale for that decision.\n \nreply",
      "I respect this choice of modernization, and I suppose some readers enjoy it, but it makes the publisher's whole work useless to me. When a text has been altered, I can't trust it respects the intent of the author, and any style inconsistency I find may be a by-product of the publisher's mangling.So, when I care about a book, I never read Standard Ebooks' edition.By the way, the modernization is more than joining a few words. Sometimes, Standard Ebooks replaces the word used at the time the book was written. For instance:    This time, however, the mountain was going to [-Mahomet;-]{+Muhammad;+}\n\nThe previous quote is from Galsworthy's \"Forsyte Saga\". The author used many French words and French spellings \u2013 like \"Tchekov\" for the Russian playwriter that was living in Paris. These subtleties are lost with the modernization.I also think some alterations are plain mistakes. For instance in the same book:    if she wanted a good book she should read [-\u201cJob\u201d-]{+Job+};\n    his father was rather like Job while Job still had land.\n \nreply",
      "Anyone who has read books for classes in high school and above knows that even classics are routinely fucked with by publishers. Even early in the work's history. I remember even in middle school someone would invariably end up with a different publisher's edition of a book for summer reading or whatnot and we'd find changes.Unless the book is specifically declared to be the original text - and it may have to specify which original text - they're going to be edited.However, in electronic form it should be possible to include both in one file, or two files with the original in a repo branch once all the document structure stuff has been added. That text will never change, so merging formatting-only changes should be pretty painless.\n \nreply",
      "That's fine! Our editions didn't erase any of the other editions you can find online and in print. You're more than welcome to select any edition that fits your reading preferences.\n \nreply",
      "Apologies if that came across as at all critical. Genuinely interested in the rationale rather than it being a how-dare-you demand for you to explain yourself!\n \nreply",
      "Spelling varies widely across the eras our ebooks were published in. Therefore we attempt to standardize spelling to what a modern reader might be familiar with. We only make sound-alike changes, like to-morrow -> tomorrow.This is a common practice that editors and publishers have quietly engaged in for centuries. For example, today you are not reading Shakespeare in the way it was spelled in its first printing.\n \nreply",
      "> For example, today you are not reading Shakespeare in the way it was spelled in its first printing.However, we call modernised Shakespeare \u201cabridged\u201d.\n \nreply"
    ],
    "link": "https://standardebooks.org",
    "first_paragraph": "Standard Ebooks is a volunteer-driven project that produces new editions of public domain ebooks that are lovingly formatted, open source, free of U.S. copyright restrictions, and free of cost.Ebook projects like Project Gutenberg transcribe ebooks and make them available for the widest number of reading devices. Standard Ebooks takes ebooks from sources like Project Gutenberg, formats and typesets them using a carefully designed and professional-grade style manual, fully proofreads and corrects them, and then builds them to create a new edition that takes advantage of state-of-the-art ereader and browser technology.Standard Ebooks aren\u2019t just a beautiful addition to your digital library\u2014they\u2019re a high quality standard to build your own ebooks on.Other free ebooks don\u2019t put much effort into professional-quality typography: they use \"straight\" quotes instead of \u201ccurly\u201d quotes, they ignore details like em- and en-dashes, and they look more like early-90\u2019s web pages instead of actual book"
  },
  {
    "title": "Use the Gemini API with OpenAI Fallback in TypeScript (sometechblog.com)",
    "points": 20,
    "submitter": "l5870uoo9y",
    "submit_time": "2025-04-04T09:41:13 1743759673",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43580012",
    "comments": [
      "The Vercel AI SDK abstracts against all LLMs, including locally running ones. It even handles file attachments well, which is something people are using more and more.https://sdk.vercel.ai/docs/introductionIt uses zod for types and validation, I've loved using it to make my apps swap between models easily.\n \nreply",
      "That\u2019s a good spot. Is it open source or is it paid software? I\u2019ve been using Braintrust Proxy for this until now.\n \nreply",
      "https://github.com/vercel/aiIts Apache 2.0 licensed\n \nreply",
      "Locally running, like, llama.cpp? Or Python?Either way I guess.I would have thought this was impossible, I contribute to llama.cpp and there's an awful lot of per-model ugliness to make things work, even just in terms of \"get it the tool calls in the form it expects.\"cries at the Phi-4 PR in the other window that I'm still working on, and discovering new things, 4 weeks later\n \nreply",
      "I would recommend looking at OpenRouter, if anyone is interested in implementing fallbacks across model providers. I've been using it in several projects, and the ability to swap across models without changing any implementation code/without managing multiple API keys has been incredibly nice:https://openrouter.ai/docs/quickstart\n \nreply",
      "Typescript looks so ugly visually. It gives me PHP vibes. I think it's the large words at the first column of the eye line:export constfunctiontypereturnetcThis makes scanning through the code really hard because your eye has to jump horizontally.\n \nreply",
      "So, like, which programming language do you think is not ugly? J? K?\n \nreply",
      "which of those words are large?\n \nreply",
      "Ah yes, such large words like const, function, or return, that only exist in TypeScript and PHP.\n \nreply"
    ],
    "link": "https://sometechblog.com/posts/try-gemini-api-with-openai-fallback/",
    "first_paragraph": ""
  },
  {
    "title": "Microcomputers \u2013 The First Wave: Responding to Altair (technicshistory.com)",
    "points": 17,
    "submitter": "cfmcdonald",
    "submit_time": "2025-04-06T21:30:33 1743975033",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://technicshistory.com/2025/04/06/microcomputers-the-first-wave-responding-to-altair/",
    "first_paragraph": "Creatures of Thought[This post is part of \u201cA Bicycle for the Mind.\u201d The complete series can be found\u00a0here.]In August 1968, Stephen Gray, sole proprietor of the Amateur Computer Society (ACS), published a letter in the society newsletter from an enthusiast in Huntsville, Alabama named Don Tarbell. To help other would-be owners of home-built computers, Tarbell offered a mounting board for integrated circuits for sale for $8 from his own hobby-entrepreneur company, Advanced Digital Design. Tarbell worked for Sperry Rand on projects for NASA\u2019s Marshall Space Flight Center, but had gotten hooked on computers through coursework at the University of Alabama at Huntsville, and found the ACS through a contact at IBM.[1]Over the ensuing years, integrated circuits became far cheaper and easier to come by, and building a real home computer on one\u2019s own thus far more feasible (though still a daunting challenge, demanding a wide range of hardware and software skills). In June 1972, Tarbell had maste"
  },
  {
    "title": "AEgIS turns phone sensors into antimatter camera of unprecedented resolution (home.cern)",
    "points": 6,
    "submitter": "rbanffy",
    "submit_time": "2025-04-03T23:08:56 1743721736",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://home.cern/news/news/experiments/aegis-transforms-smartphone-sensors-antimatter-camera-unprecedented",
    "first_paragraph": "At CERN, we probe the fundamental structure of particles that make up everything around us. We do so using the world's largest and most complex scientific instruments.Know more\nWho we are\n\nOur Mission\n\nOur Governance\n\nOur Member States\n\nOur History\n\nOur People\n\nWhat we do\n\nFundamental research\n\nContribute to society\n\nEnvironmentally responsible research\n\nBring nations together\n\nInspire and educate\n\nFast facts and FAQs\n\nKey Achievements\nKey achievements submenuThe Higgs BosonThe W bosonThe Z bosonThe Large Hadron ColliderThe Birth of the webAntimatterLatest news\nNews\n\nAccelerators\n\nAt CERN\n\nComputing\n\nEngineering\n\nExperiments\n\nKnowledge sharing\n\nPhysics\n\nEvents\n\nCERN Community\n\nNews and announcements\n\nOfficial communications\n\nEvents\n\nScientists\n\nNews\n\nPress Room\nPress Room submenuMedia NewsResourcesContactThe research programme at CERN covers topics from kaons to cosmic rays, and from the Standard Model to supersymmetryKnow more\nPhysics\n\nAntimatter\n\nDark matter\n\nThe early universe\n\nThe "
  },
  {
    "title": "Neutron Stars Hint at Another Dimension (nautil.us)",
    "points": 132,
    "submitter": "dnetesn",
    "submit_time": "2025-04-06T11:41:26 1743939686",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=43600704",
    "comments": [
      "> Gravity, the thinking goes, can escape our brane and extend into the bulk. That explains why it\u2019s so weak. All the other forces must play in only three spatial dimensions, while gravity can extend itself out to four, spreading itself much too thin in the process.Wouldn't this cause gravitational force to fall off with distance using something other than an inverse-square law? I think this explanation would be a better fit for the weak force than gravity for this reason. Thoughts?More broadly: inverse-square behavior (Gravity, EM etc) strikes me as an intrinsic property of 3D geometry; more so of a tell of dimensionality than the magnitude of the force. (I believe the article is inferring higher dimensionality from relative magnitude, vice distance falloff)\n \nreply",
      "Yes, exactly. That is why we think the extra dimensions might be small, und the inverse square law is only violated at and below the size of the extra dimensions. \nThis is also why we are using the Yukawa Potential to constrain that possibility, because it has a length scale and a strength of a potential deviation from the inverse square law.\nSee also: https://en.wikipedia.org/wiki/Fifth_force\n \nreply",
      "How can a dimension be smaller compared to other dimensions?\n \nreply",
      "It could be a compact[0] dimension, i. e. of finite length. In the simplest case you might imagine it as a circle attached to every point in our 3-dimensional Euclidean space. The aforementioned length scale would be the circumference of that circle.[0]: https://en.m.wikipedia.org/wiki/Compact_space\n \nreply",
      "Trying to wrap my head around this explanation and I\u2019m picturing a looping gif. You have your normal x and y dimensions and then time through the gif. If the loop length is very short then distance between any two pixels will mostly only depend on x and y. Is that right?\n \nreply",
      "The classic example is a garden hose seen from afar looks like a line, but up close it is a cylinder that can be walked \u201caround\u201d by an ant.\n \nreply",
      "Interesting case if we are the \u201cants\u201d and it is our 3 dims happen to be compact looping somewhere beyond our event horizon. Multitude of Universes in that garden hose in which gravity can be falling as cube or more while  at small scale if our compact Universe we\u2019ll see square, and only very precise measurements may notice a bit larger than square.Another possibility is if our brane has a lot of folds coming close/touching - that would make gravity there stronger like say that dark matter idea inducing rotation speed curve of the disk stars.\n \nreply",
      "In the simplest case, yes. Though, once curvature (gravity) enters the picture, it could (in theory) become more complicated, as the additional dimension could get stretched or compressed.\n \nreply",
      "Yes, that sounds right.\n \nreply",
      "And yet that circle has as many \"points\" as any other 1-dim independent axis, so ...\n \nreply"
    ],
    "link": "https://nautil.us/neutron-stars-hint-at-another-dimension-1202180/",
    "first_paragraph": "Art+ScienceBiology + BeyondCosmosCultureEarthLifeMindOceanOne QuestionQuanta AbstractionsRewildingScience at the Ballot BoxScience Philanthropy AllianceSpark of ScienceThe Kinship IssueThe PortholeThe Reality IssueThe Rebel IssueWomen in Science & Engineering\nAre the mysterious stars clues to one of the greatest mysteries in the universe?\nAre the mysterious stars clues to one of the greatest mysteries in the universe?In the mid 19th century, a strange idea was growing heavy in the ether: There might be dimensions beyond the three we experience. To some\u2014including eminent scientists of the day\u2014these were the realms of spirits and the supernatural, accessed through tabletop seances. To Charles Hinton, a British mathematician and science-fiction writer at the time, it was something that could be puzzled out, modeled in things like his \u201ctesseract\u201d four-dimensional cube.In the intervening century and a half, spiritualism and mainstream science having parted ways, the serious search for these"
  },
  {
    "title": "QVQ-Max: Think with Evidence (qwenlm.github.io)",
    "points": 104,
    "submitter": "wertyk",
    "submit_time": "2025-04-03T14:55:17 1743692117",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=43570676",
    "comments": [
      "I think this is old news, but this model does better than llama 4 maverick on coding.\n \nreply",
      "LLaMA 4 is pretty underwhelming across the board.\n \nreply",
      "I wonder why are we getting these drops during the weekend. Is the AI race truly that heated?\n \nreply",
      "Judging from my blog, I get much more engagement on the weekends.\n \nreply",
      "IIUC engineers in China only get one day off per week.\n \nreply",
      "> March 28, 2025\n \nreply",
      "I guess a lot of people do their regular 9-5 through week and play with new stuff on the weekends. But also yes, it is truly that heated\n \nreply",
      "IIUC engineers in China only get one day off per week. IDK if that's hyperbole or not.\n \nreply",
      "The about page doesn\u2019t shed light on the composition of the core team nor their sources of incomes or funding. Am I overlooking something?> We are a group of people with diverse talents and interests.\n \nreply",
      "I think Qwen team is alibaba AI arm https://qwenlm.github.io/about/\n \nreply"
    ],
    "link": "https://qwenlm.github.io/blog/qvq-max-preview/",
    "first_paragraph": "QWEN CHAT\nGITHUB\nHUGGING FACE\nMODELSCOPE\nDISCORDLast December, we launched QVQ-72B-Preview as an exploratory model, but it had many issues. Today, we are officially releasing the first version of QVQ-Max, our visual reasoning model. This model can not only \u201cunderstand\u201d the content in images and videos but also analyze and reason with this information to provide solutions. From math problems to everyday questions, from programming code to artistic creation, QVQ-Max has demonstrated impressive capabilities. Though this is just our first version, its potential is already eye-catching.MathVision is a benchmark that aggregates various challenging multimodal mathematical problems, and we evaluate a model\u2019s ability to solve complex math problems based on its performance on this benchmark. As shown in the figure, by adjusting the maximum length of the model\u2019s thinking process, we observe a continuous improvement in the model\u2019s accuracy on MathVision, demonstrating the immense potential of the "
  },
  {
    "title": "SciOp torrents: download, seed erased US Gov sites and datasets (sciop.net)",
    "points": 25,
    "submitter": "WarOnPrivacy",
    "submit_time": "2025-04-06T23:09:15 1743980955",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://sciop.net/uploads/",
    "first_paragraph": "\n        A project emerging from a loose collaboration within Safeguarding Research and Culture\n      \n        With consultation from Peertech Industrial Concern Intl., Corporate Outreach, Waste-Metal Corrosives, & Archives Division.\n      "
  },
  {
    "title": "Foundry (YC F24) Is Hiring (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-04-06T17:01:00 1743958860",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/foundry/jobs/WvDDlqc-founding-fullstack-engineer-building-the-future-of-browser-agents",
    "first_paragraph": "World Model for Browser AgentsBrowser agents are broken\u2014and whoever fixes them will shape the next decade of software.Today, even the best browser agents from labs like OpenAI, Anthropic, and Google fail over 80% of real-world tasks, often taking three times as long as humans to complete simple actions. Foundry is addressing this by building the first robust simulator, RL training environment, and evaluation platform designed specifically for browser agents. Historically, simulation environments and standardized benchmarks were critical in advancing self-driving cars (e.g., Waymo Sim, KITTI) and LLMs (e.g., HELM, MMLU). We're applying this proven method to browser automation, enabling accurate benchmarking, rapid iteration, and real-world reliability.For example, OpenAI could use Foundry to build a perfect replica of DoorDash's website, enabling them to run millions of ordering tests without ever touching real-world complexities like CAPTCHAs, payments, or anti-bot measures. This appro"
  }
]