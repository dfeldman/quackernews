[
  {
    "title": "Is AI the new research scientist? Not so, according to a human-led study (ufl.edu)",
    "points": 17,
    "submitter": "gnabgib",
    "submit_time": "2025-03-29T00:32:19 1743208339",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=43511539",
    "comments": [
      "Another headline to correct: \"whiney desperate scientists fearing their grift is up, claim that AI research isnt that good\"\n \nreply",
      "It will never be. I don't know why people keep trying to make it into a research scientist. It's a great helper but it has no original insight and breakthroughs happen through original insight.\nLLMs are simply a conditional probability net of existing data so it can never ever have an original insight. I don't know why this is so hard.\n \nreply",
      "I wouldn\u2019t be so dismissive. Research is just a loop of hypothesis, experiments, collect data, make new hypothesis. \nThere\u2019s so creativity required for scientific breakthroughs, but 99.9% percent of scientists don\u2019t need this creativity. Just need grit and stamina.\n \nreply",
      "The biggest problem with LLMs isn't that it lacks original insight. It's that the insight is so original that we call that insight hallucinations.We like to think Humans are the most creative things on the face of the earth and we don't like to attribute creativity to LLMs. The sad reality is that LLMs are likely more creative then humans.\n \nreply",
      "I think the distinction is that hallucinations are incorrect. You can be super creative building a new chair, but if you can\u2019t sit in it, it\u2019s not a chair.\n \nreply",
      "Right. So you have a testing framework/agent/other llm. It\u2019s not like our brain is one independent machine. It\u2019s various parts all contributing different aspects of intelligence.",
      "Most humans are also too creative, but we have moderating impulses that tell us so much. Very few humans have the skill of being able to ride the cutting edge without going too far off either side of it, and most can only do that in a very narrow subfield.\n \nreply",
      "And why is there even a desire to replace research scientists? Presumably this is the kind of job humans find meaningful and are good at. I don't understand AI as a replacement for humans instead of a smart tool for humans to make use of.\n \nreply",
      "Why? to increase productivity and improve the human condition.  If AI can do research then technological and scientific progress will increase dramatically.\n \nreply",
      "There's an unknown cost if all human endeavor becomes replaceable by AI. I would be cautious about this.\n \nreply"
    ],
    "link": "https://news.warrington.ufl.edu/faculty-and-research/ai-research-scientist/",
    "first_paragraph": "In a comprehensive study examining the capabilities of artificial intelligence in academic research, University of Florida researchers have found that while AI can be a valuable assistant, it falls short of replacing human scientists in many critical areas.Assistant Professor Geoff TomainoThe research, detailed in a paper titled \u201cAI and the advent of the cyborg behavioral scientist,\u201d tested how well popular generative AI models including OpenAI\u2019s ChatGPT, Microsoft\u2019s Copilot and Google\u2019s Gemini could handle various stages of the research process.The team put these AI systems through six stages of academic research \u2013 starting with ideation, literature review and research design, followed by documenting results, extending the research and the final manuscript production \u2013 while limiting any human intervention on their part.What they discovered was a mixed bag of capabilities and limitations, presumably good news for research scientists wondering if AI will take their job.\u201cA pervasive fea"
  },
  {
    "title": "We hacked Gemini's Python sandbox and leaked its source code (at least some) (landh.tech)",
    "points": 405,
    "submitter": "topsycatt",
    "submit_time": "2025-03-28T18:12:58 1743185578",
    "num_comments": 84,
    "comments_url": "https://news.ycombinator.com/item?id=43508418",
    "comments": [
      "Their \"LLM bugSWAT\" events, held in vibrant locales like Las Vegas, are a testament to their commitment to proactive security red teaming.I don't understand why security conferences are attracted to Vegas. In my opinion its a pretty gross place to conduct any conference.\n \nreply",
      "relatively cheap event space and hotels. it's hard to find a city to host a large conference.\n \nreply",
      "What don't you understand. Vegas is literally built for conferences.\n \nreply",
      "You answered your own question.\n \nreply",
      "Real, I feel the exact same way.\n \nreply",
      "That's the system I work on! Please feel free to ask any questions. All opinions are my own and do not represent those of my employer.\n \nreply",
      "Is the interactive python sandbox incompatible with thinking models? It seems like I can only get the interactive sandbox by using 2.0 flash, not 2.0 flash thinking or 2.5 pro.\n \nreply",
      "That's a good question! It's not incompatible, it's just a matter of getting the flow right. I can't comment too much on that process but I'm excited for the possibilities there.\n \nreply",
      "Oh, I see Gemini can run code as part of the thinking process. I suppose the sandbox that happens in was the target of this research, while code editing in Gemini Canvas just has a button to export to Colab for running. The screenshots in the research show a \"run\" button for generated code in the chat, but I'm not seeing that exact interface.In any case, I share your excitement.\n \nreply",
      "Canvas actually has a mix of this sandbox (with a different container) and fully client-side.The \"run\" option for generated code was removed due to underutilization, but the sandbox is still used for things like the data analysis workflow and running extensions amongst other things. It's really just a general purpose sandbox for running untrusted code server-side.\n \nreply"
    ],
    "link": "https://www.landh.tech/blog/20250327-we-hacked-gemini-source-code/",
    "first_paragraph": ""
  },
  {
    "title": "Noise cancellation improves turn-taking for AI Voice Agents (krisp.ai)",
    "points": 19,
    "submitter": "davitb",
    "submit_time": "2025-03-25T03:56:17 1742874977",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43467988",
    "comments": [
      "Great! For me \"turn-taking\" has been one of the big downfalls of the voice agents. It always seems to break in, just let the silence continue when I'm done talking or pause when it hears the slightest cough or car noise.\n \nreply",
      "If using chatGPT advance voice mode, the recent upgraded version seems better, plus, if you're on an iPhone, you can turn on Voice Isolation in the Control Center which will filter out almost all sounds from the phone microphone except for your speaking voice, which made chatGPT behave as one would hope -- I believe the setting is specific to the current microphone using app.\n \nreply"
    ],
    "link": "https://krisp.ai/blog/improving-turn-taking-of-ai-voice-agents-with-background-voice-cancellation/",
    "first_paragraph": ""
  },
  {
    "title": "Digital Echoes and Unquiet Minds (chrbutler.com)",
    "points": 94,
    "submitter": "delaugust",
    "submit_time": "2025-03-28T20:29:32 1743193772",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=43509548",
    "comments": [
      "Byung-Chul Han in burnout society introduces the concept of hyperattention, which is the kind of attention that seems efficient at first, because it gives the impression of enabling you to multitask, but in reality it robs you from any deep and meaningful connection to anything around you.That's is pretty much what happens with anything tech nowadays. Because we see technology as a pure feat of rationality where in fact what we consume are nothing more than cultural artifacts, which will invariably reflect the fundamental problems of the society in which these artifacts are forged. In our case, in the Burnout Society, it's potentializing hyperattention.\n \nreply",
      "Is he really saying anything new here with this concept?  I've read a few of his books, and I can't think of one original or incisive idea or framework that is genuinely interesting or provocative.  Eg, he talks about us today being aspirational subjects in a neoliberal world.  I do agree, but this is not exactly illuminating .I don't mean to dump on him, but he's mentioned so often now when subjects like this are brought up.\n \nreply",
      "Maybe he's just not for you. This is actually really unfair to anyone writing philosophy these days. That the dude has to revolutionize the way we think with some deep and original insight otherwise his work is worthless. Is that really the only value taken from philosophy? How about hermeneutics or social communication? I believe Han excels in the latter and is bringing more and more thinkers from different fields to think about the fundamental problems of society, people with technical and scientific backgrounds that would otherwise not join the debate and help design a better society.\n \nreply",
      "It's a fair question.  I'm not sure that I need to have my mind blown.  There's certainly philosophy I read where somebody will be writing broadly about a school of thought or a niche aspect.  I think what I find dull about Byung-Chul Han is that he writes with the affect of gusto, but there is no insightful pay-off to match.  There's nothing to grab on to, at least for me.\n \nreply",
      "IMO this means that your internal \"algorithm\" is over-trained for novelty.The truth, once discovered, ceases to be new. Does that mean the truth is not worth anything after an initial moment of discovery? Or (this is rhetorical, obviously), is it possible that the things that our mind tells us are worth pursuing/engaging and those things that are ACTUALLY worth pursuing/engaging are not always (or even OFTEN) commensurate?\n \nreply",
      "The way I see it, engagement with concepts that you have fully understood is meaningless in that you\u2019ll only marvel at your ability to understand things, rather then come up with a new insight from the engagement.But most of the time, we don\u2019t actually fully understand things, and intimately reflecting on something will often yield new facets, insights you didn\u2019t have before, and deepen your understanding.\n \nreply",
      "Maybe I didn't make myself clear enough.  I read all kinds of philosophy (time permitting!) and it certainly doesn't have to be novel.  However, when a philosopher adopts a rhetorical tone, I expect there to be some kind of catalyzing payload to justify it.  Is that not reasonable?I'd say truth is always being either discovered and recovered, and there's usually not too much difference.  There's rarely anything new under the sun.\n \nreply",
      "> I believe Han excels in the latter and is bringing more and more thinkers from different fields to think about the fundamental problems of society, people with technical and scientific backgrounds that would otherwise not join the debate and help design a better society.He had one hit book fifteen years ago and now exists primarily as a meme. One doesn\u2019t really see people deeply engaging with his arguments; they tend to agree that whatever the object of the new book is \u201ca problem\u201d and fill in the details with their own ideology.Or maybe I\u2019m wrong! I\u2019d be interested in a link to someone actually taking him seriously, whether within or without philosophy.\n \nreply",
      "Why do you need a proxy? Can't you just go read his materials and see for yourself if you should take him serious or not? Do the work if you are really that interested, I think you won't be disappointed.\n \nreply",
      "I think he's taken pretty seriously.  He was tenured at UdK for a while, which is a very prestigious European university.  But somehow he has pushed Chomsky off the mantle to become the poster-boy for the criticism of neoliberalism.  This is really not helping him shed the meme of being some kind of K-pop philosopher.\n \nreply"
    ],
    "link": "https://www.chrbutler.com/digital-echoes-and-unquiet-minds",
    "first_paragraph": "\nWhen the iPhone was first introduced in 2007, the notion of an \u201ceverything device\u201d was universally celebrated. A single object that could serve as phone, camera, music player, web browser, and so much more promised unprecedented convenience and connectivity. It was, quite literally, the dream of the nineties. But the better part of twenty years later, we\u2019ve gained enough perspective to recognize that this revolutionary vision came with costs we did not anticipate.\n\nDistraction, of course, is the one we can all relate to first. An everything device has the problem of being useful nearly all the time, and when in use, all consuming. When you use it to do one thing, it pushes you toward others. In order to avoid this, you must disable functions. That\u2019s an interesting turn of events, isn\u2019t it? We have made a thing that does more than we need, more often than we desire. Because system-wide, duplicative notifications are enabled by default, the best thing you could say about the device\u2019s de"
  },
  {
    "title": "Show HN: An Almost Free, Open Source TURN Server (github.com/lvidgen)",
    "points": 47,
    "submitter": "cookie_monsta",
    "submit_time": "2025-03-28T22:46:43 1743202003",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=43510710",
    "comments": [
      "99% of this does not depend on Oracle, you can do this on any vm hosting platform you can get. The only point of using Oracle is the price point which will vanish as soon as they can cease using it to build market share. Good to show btw. Nice instructions. They're  mostly platform neutral. It might be a different interface to manage on another host of course but the outcome would be much the same.\n \nreply",
      "Thanks, and you're exactly right - the Oracle bit is probably the most basic, interchangeable part of the whole stack. The tricky bit there for me was all the ports/firewall configuration which like you say will be the same/very similar anywhere.For hobby projects like this I have had no complaints with OCI but yeah, you would have to be crazy to use it in production.\n \nreply",
      "How to doc recommends using Oracle Free Tier but they recently had a breach and leaked login server data https://www.bleepingcomputer.com/news/security/oracle-custom...\n \nreply",
      "This how to is extremely comprehensive and well written. You have a knack for writing technical tutorials and documentation that are accessible, clear and simple. Well done!Good prose, clearly not written by AI - respect!\n \nreply",
      "Cheers :) I trained and worked as a writer in my previous career, so it's nice to know that at least some of those chops remain. Like every other writer on the planet, I've tried AI for generating some base text that I could then tweak, but I find myself spending so much time rewriting that it's quicker just to do it from scratch...\n \nreply",
      "Great write up! It isn\u2019t free, but the price/what it offers is really great with Hetzner. I switched from digital ocean.Did you evaluate any other TURN servers? I\u2019m curious about your thoughts of the Elixir and Go ones. Maybe even more exist, I haven\u2019t looked recently\n \nreply",
      "The problem I see with TURN is there's basically no way to prevent people from abusing it publicly for relaying any traffic they want, without any of your own web sites or WebRTC apps involved.\n \nreply",
      "Basic authentication is covered in Section 11[0]There are more thoughts on tightening up authentication in the last section \"Tightening and tidying\"Apologies if I have misunderstood your comment[0]https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Serv...\n \nreply",
      "Respect++ for what you said about Peerjs. I used those servers myself for testing when I wrote my own TURN client and always felt a little bad about it. But it saved me tons of time before setting up my own. Now I have my own server (though not as well setup as yours -- your guide is good.)This is a valuable contribution. IMO, the Internet needs more STUN, TURN, and MQTT servers. It's even more valuable if they support as many protocols as possible and have IPv4 / IPv6. For STUN -- running it with two IPs means it can support bind requests which is necessary for testing NAT types.\n \nreply",
      "Oh, thanks that's very kind of you to say. PeerJS is great - it takes a lot of the complexity out of WebRTC and replaces it with a nice, clean API. I think it was an OK decision for them to use Google for their TURN server - really, the best use case for their cloud server is exactly as you described - get your PoC working, and then if you're serious, implement your own\n \nreply"
    ],
    "link": "https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/howto.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          The WebRTC implementation posted here relies on the PeerJS Cloud Server. It's pretty reliable (I haven't seen any major outage in 5+ years), but hitching yourself to someone else's wagon always carries an element of risk - if they decide to pull the pin on their project that page will die, possibly without much warning.A secondary concern is that the Cloud Server relies on Google's TURN server when required. Google has a history of axing services and products, sometimes with little or no notice. Additionally, some people have privacy concerns about running their data through anything associated with the big G.So is it possible to create an independant, open source TURN server that you completely control at minimal expense? Yes it is, with the possible irony that here we are relying on the free tier of Oracle Cloud Infrastructure (OCI). Plent"
  },
  {
    "title": "Xee: A Modern XPath and XSLT Engine in Rust (startifact.com)",
    "points": 281,
    "submitter": "robin_reala",
    "submit_time": "2025-03-28T06:48:18 1743144498",
    "num_comments": 143,
    "comments_url": "https://news.ycombinator.com/item?id=43502291",
    "comments": [
      "Great to see that somebody else creates a true open source XSLT 3 and XPATH 3 implementation!I worked on projects which refused to use anything more modern than XSLT & XPATH 1.0 because of lack of support in the non Java/Net World (1.0 = tech from 1999). Kudos to Saxon though, it was and is great but I wished there were more implementations of XSLT 2.0 & XPATH 2.0 and beyond in the open source World... both are so much more fun and easier to use in 2.0+ versions.\nFor that reason I've never touched XSLT 3.0 (because I stuck to Saxon B 9.1 from 2009). I have no doubt it's a great spec  but there should be other ways than only Saxon HE to run it in an open source way.It's like we have an amazing modern spec but only one browser engine to run it ;)\n \nreply",
      "Well, it's not as if this is the first free alternative. Here is a wonderful, incredibly powerful tool, not written in Java, but in Free Pascal, which is probably too often underestimated: Xidel[1]. Just have a look at the features and check its Github page[2]. I've often been amazed at its capabilities and, apart from web scraping, I mainly use it for XQuery executions - so far the latest version 0.9.9 has also implemented XPath/XQuery 3.1 perfectly for my requirements. Another insider tip is that XPath/XQuery 3.1 can also be used to transform JSON wonderfully - JSONiq is therefore obsolete.[1] https://www.videlibri.de/xidel.html[2] https://github.com/benibela/xidel\n \nreply",
      "Forget to add, for latest XQuery up to 4.0, there is also BaseX [1] \u2014 this time a Java program. It has a great GUI/IDE for XQuery rapid prototyping.[1] https://basex.org/basex/xquery/\n \nreply",
      "interesting, did not know about that one! Thanks. (Small) but XSLT is not covered by it which is my main usage of XPATH unfortunately.I will do some experiments with using newer XPATH on JSON... that could be interesting.\n \nreply",
      "I've worked on archive projects with complex TEI xml files (which is why when people say xml is bad and it should be all json or whatever, I just LOL), and fortunately, my employer will pay for me to have an editor (Oxygen) that includes the enterprise version of Saxon and other goodies. An open-source xml processing engine that wasn't decades out of date would be a big deal in the digital humanities world.\n \nreply",
      "I don't think people realize just how important XML is in this space (complex documentary editing, textual criticism, scholarly full-text archives in the humanities). JSON cannot be used for the kinds of tasks to which TEI is put. It's not even an option.Nothing could compel me to like XSLT. I admire certain elements of its design, but in practice, it just seems needlessly verbose. But I really love XPath, though.\n \nreply",
      "XML is great for documents.If your data is essentially a long piece of text, with annotations associated with certain parts of that text, this is where XML shines.When you try to use XML to represent something like an ecommerce order, financial transaction, instant message and so on, this is where you start to see problems. Trying to shove some extremely convoluted representation of text ranges and their attributes into JSON is just as bad.A good \"rule of thumb\" would be \"does this document still make sense if all the tags are stripped, and only the text nodes remain?\" If yes, choose XML, if not, choose JSON.\n \nreply",
      "My hope is that we can get a little collective together that is willing to invest in this tooling, either with time or money. I didn't have much hope, but after seeing the positive response today more than before.\n \nreply",
      "There are many humongous XML sources. E.g. the Wikipedia archive is 42GB of uncompressed text. Holding a fully parsed representation of it in memory would take even more, perhaps even >100GB which immediately puts this size of document out of reach.The obvious solution is streaming, but streaming appears to not be supported, though is listed under Challenging Future Ideas: https://github.com/Paligo/xee/blob/main/ideas.mdHow hard is it to implement XML/XSLT/XPATH streaming?\n \nreply",
      "Anything could be supported with sufficient effort, but streaming hasn't been my priority so far and I haven't explored it in detail. I want to get XSLT 3.0 working properly first.There's a potential alternative to streaming, though - succinct storage of XML in memory:https://blog.startifact.com/posts/succinct/I've built a succinct XML library named Xoz (not integrated into Xee yet):https://github.com/Paligo/xozThe parsed in memory overhead goes down to 20% of the original XML text in my small experiments.There's a lot of questions on how this functions in the real world, but this library also has very interesting properties like \"jump to the descendant with this tag without going through intermediaries\".\n \nreply"
    ],
    "link": "https://blog.startifact.com/posts/xee/",
    "first_paragraph": "For the last two years I've been working on a programming language\nimplementation in Rust named Xee. Xee stands for \"XML Execution Engine\" and\nit supports modern versions of XPath and XSLT. Those are programming languages,\nand yes, that's XML stuff.Now hold on. Your brain might shut down when I talk about XML. I totally get\nthat XML may not be your cup of tea. But I'm also going to be talking about a\nstrange different world of technology where everything is specified, and the\nimplementation of a programming language using Rust, so I hope you still decide\nto read on if those topics could interest you.And if XML does happen to be your cup of tea, I think you should be excited\nabout Xee, as I think it can help secure a better future for XML technologies.Here's the Xee repository.There are two highlights: a command-line tool\nxee\nthat lets you do XPath queries, and a Rust library\nxee-xpath to issue XPath\nqueries from Rust.In 2023 I was asked by Paligo, my amazing and generous\nclient, whethe"
  },
  {
    "title": "NSA F9T53 Opsec Special Bulletin: Signal Vulnerability (scribd.com)",
    "points": 6,
    "submitter": "stefankuehnel",
    "submit_time": "2025-03-29T00:38:44 1743208724",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43511586",
    "comments": [
      "Any application that does cross-device authentication is vulnerable to QRLJacking (this type of vulnerability) to some extent, the same way any application with username/password authentication is vulnerable to phishing.\n \nreply",
      "Weakness in the linked devices security model. And so by extension, tools like \"beeper\"If you don't link devices and check there are no linked devices your side of things is OK but you have no certainty in group chats or the other side one on one. So it's down to your own trust in the other party/parties.\"Two can keep a secret if one of them is dead\"\n \nreply"
    ],
    "link": "https://www.scribd.com/document/843124910/NSA-full",
    "first_paragraph": "NSA fullAI-enhanced descriptionNSA fullAI-enhanced descriptionAboutSupportLegalSocialGet our free appsAboutLegalSupportSocialGet our free apps"
  },
  {
    "title": "xAI has acquired X, xAI now valued at $80B (twitter.com/elonmusk)",
    "points": 381,
    "submitter": "rvz",
    "submit_time": "2025-03-28T21:23:42 1743197022",
    "num_comments": 406,
    "comments_url": "https://news.ycombinator.com/item?id=43509923",
    "comments": [
      "He has done this move before with Tesla buying Solar City.  When you do a deal with yourself you can assign any value you want to assets, it isn\u2019t a competitive process.  In the previous case Solar City was dying but its acquisition by Tesla was pitched as a great synergy.https://www.businessinsider.com/solarcity-tesla-energy-belea...There were a few lawsuits from Tesla shareholders about the acquisition regarding self dealing but they didn\u2019t succeed:https://en.wikipedia.org/wiki/SolarCity\n \nreply",
      "You\u2019re burying the lede here, which is that the Delaware Chancery Court rules that Tesla had paid a fair price for Solar City: https://www.businessinsider.com/elon-musk-wins-solarcity-tes...\n \nreply",
      "OP mentions the lawsuits did not succeedIts not like the courts are investment banks with an evaluation arm. They are just judging if anything reaches the point where shareholders were legally harmed, which still gives a lot of gray area to the acquiring company.\n \nreply",
      "Lawsuits can fail for lots of reasons without a decision on the merits. It seems relevant that the reason the lawsuit failed is because the court looked at the fairness of the transaction and determined that Tesla paid a fair price.\n \nreply",
      "This whole thread is true consistent statements that differ only in emphasis.\n \nreply",
      "Doesn\u2019t mean it\u2019s also a fair price this time\n \nreply",
      "\"did not act unlawfully\"and\"paid a fair price\"are two entirely different things.\n \nreply",
      "They are, but in the relevant Delaware law the latter point matters when there is a potential conflict of interest, so the Delaware court ruled on that.\n \nreply",
      "The \"fair price\" standard and ruling is about both the process and the price.  And the standard is likely not what most people would assume it to be,  particularly as stated by the OP,  resting on matters such as \"was and is the transaction synergistic to Tesla?\"  It's also notable that the court found several process flaws created by Musk but ultimately determined the Tesla board was independent enough that it was likely fair.Was it actually fair as evaluated by any outsider on first principles?  Probably not.  Was it criminally unfair?  No.\n \nreply",
      "Is that what a corporate lawyer would say?\n \nreply"
    ],
    "link": "https://twitter.com/elonmusk/status/1905731750275510312",
    "first_paragraph": ""
  },
  {
    "title": "DIY PTP Grandmaster Clock with a Raspberry Pi (jeffgeerling.com)",
    "points": 28,
    "submitter": "ingve",
    "submit_time": "2025-03-28T21:37:21 1743197841",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43510036",
    "comments": [
      "I wonder what kind of accuracy could be had with a cheapie USB GPS receiver. I wouldn't use that anywhere I had Internet connectivity, but in a disconnected location I wonder if it would get within a few ms of GPS time. I have an old USB GPS that shows up as a serial device (FTDI, or more likely a counterfeit) that I used back in my wardriving days, and later for moving map navigation on a laptop on road trips (as a dedicated navigator/passenger). It might be fun to dig it up and try it out.Since I know Jeff frequents HN I'll go meta for a second and say that I noticed the Neatpatch cable management in the rack. I've been a fan of Neatpatch for a good long time. I don't use them in racks there there will be much churn, but they're mighty nice in locations that get wired once and only touched again when switches get replaced. It really makes a rack look-- erm-- nest.\n \nreply",
      "If you're looking to setup a GPS-disciplined time-server at home, I highly recommend this writeup: https://austinsnerdythings.com/2025/02/14/revisiting-microse...In the author's latest post he also sets up a pi as PTP grandmaster: https://austinsnerdythings.com/2025/02/18/nanosecond-accurat...\n \nreply",
      "https://www.timebeat.app/Also making some very nice stuff at great price points.\n \nreply",
      "Interesting.  I might have to get this PTP board, as I've never played with that.  How much more precision do you get on the client side by eliminating the chronyd <-> network packet latency?  There is still switching latency (I'm sure those things have buffers, because everything has a buffer these days) and the scheduling latency on the client side.  Will I be able to notice this improvement with the right tools?(In the past, I did this: https://github.com/jrockway/beaglebone-gps-clock, so I have a testbench for this sort of thing.)Also, does anyone know if RTK helps much with timing?  Every so often I connect up my clock to the NYS DOT RTK network (free!) and ... it works, but I don't know if it helps with anything.\n \nreply",
      "> and the scheduling latency on the client side.You might be surprised by how many PCs already have PTP capable NICs. I think it's standard on Intel's network chipsets. On Linux, just look for /dev/ptp0However, PTP support is far from standard on network switches; and it doesn't work over wifi, or with USB-to-ethernet converters. So for sure plenty of clients can't use it.> Will I be able to notice this improvement with the right tools?If you're a precision timing aficionado? Possibly!Just set up two devices with ethernet and GPIO pins, one that takes in a GPS 1PPS signal and acts as a PTP server, then a second that acts as a PTP client and outputs 1PPS.Then connect your two 1PPS signals to the two inputs of an oscilloscope, trigger on one and watch how much the other is off by.Make sure the PTP client is downloading big files, under heavy CPU load and suchlike, so you can see the effects of those.\n \nreply",
      "PTP is mostly used for industrial control systems that need to have very precisely synchronized timing. The precision you can achieve depends a great deal on the clock hardware you're using. Network hardware, i.e. whether timing in network hardware is deterministic, also plays an important role. So the question is less \"what can PTP do,\" it's more \"what can my hardware do with PTP.\" Fundamentally PTP is just measuring network latency and applying that correction. But the quality of that measurement is critical, and there's nothing PTP can do to mask a crummy oscillator or a switch with non-deterministic timing.\n \nreply",
      "Little bit controversial post - does not matter that much, few miliseconds either way, consistency is more important. just think what those clocks are used for inside of your hardware and you get your answer.even \"old\" time signals like DCF77, WWV.... are sufficient enough for home lab. they can be heard even inside of a buildings, where GPS can have problems. And you can think about RTK signal as a signal in this more available signal category.Most strange thing to me is that i have to set correct time in long wave radios (receiver), when they can just receive any of all those time signals.\n \nreply"
    ],
    "link": "https://www.jeffgeerling.com/blog/2025/diy-ptp-grandmaster-clock-raspberry-pi",
    "first_paragraph": ""
  },
  {
    "title": "How Kerala got rich (aeon.co)",
    "points": 301,
    "submitter": "lordleft",
    "submit_time": "2025-03-28T16:27:44 1743179264",
    "num_comments": 171,
    "comments_url": "https://news.ycombinator.com/item?id=43507286",
    "comments": [
      "I was born in the US but my parents are from Kerala and I still have family there that I visit.One thing I found interesting was the pride in literacy and education. Kerala has a 96% literacy rate which is the highest in India [1].It's one of my favorite places to visit. Unlike other parts of India such as Bengaluru, Mumbai and Hyderbad -- it's tropical and lush with much less pollution than what you might see in those other parts of India.My parents have a home in a rural community which hasn't changed much in the past few decades compared to somewhere like Bengaluru. It's quiet and slow with a high important on family relationships. No doubt it's westernizing, albeit slower than other parts of India - but for now it still holds much of the charm I've known since I was a kid.[1] https://en.wikipedia.org/wiki/Literacy_in_India\n \nreply",
      "> Unlike other parts of India such as Bengaluru, Mumbai and Hyderbad -- it's tropical and lush with much less pollution than what you might see in those other parts of India.Somewhat ironically these are relatively low pollution as large cities in India go. There is still a good amount of greenery in Bengaluru (it is famous for it) but obviously far less than a few decades ago, as many residents lament.\n \nreply",
      "Bangalore today is a shadow compared to the Garden City it once was.For outsiders not in the know, Bangalore was famous for its beautiful lakes and the lush greenery around them. It was absolutely something else, finding these beautiful water bodies smack in the middle of what is supposed to be a major city. The weather was cool, almost like a warm European summer (which is extremely cool by Indian standards).Then they got greedy, drained the lakes, built real estate and office properties on them and now Bangalore is an unbearable cesspit just like any other Indian city. Bad weather, bad traffic and a shit scenery.I still have some photos of my visits to Bangalore in my childhood a couple of decades back, and the visual contrast between past and present is so stark. Of course, locals love to resent the regression of the city, but they also love their coin.\n \nreply",
      "Hey, Mumbai folks will fight you for supremacy on bad scenery. Course we concede the actual crown to our dearest friends in Delhi.\n \nreply",
      "I'm not usually not the type to be preoccupied with green policy, but this was heart wrenching to hear.\n \nreply",
      "My family is part of the indigenous people of Mumbai, and my mom and dad's pictures of their childhood homes and stories are almost unbelievable if you visit now. My grandparents old bungalow is still on google maps, now surrounded by skyscrapers, but in the pictures, it's all fields and trees.\n \nreply",
      "I had no idea and thank you for sharing. Why did it fall apart?\n \nreply",
      "Source: Grad student from Bengalaru I got lunch with.It became India's Silicon Valley. Acecnture. Infosys. Western IT money came pouring in and never stopped.https://www.businessinsider.com/india-silicon-valley-bengalu...\n \nreply",
      "Fittingly, I\u2019ve heard [0] a similar transformation happened to Silicon Valley itself. Apparently it used to be a bunch of orchards.[0]: https://www.reddit.com/r/bayarea/comments/10672gn/til_before...\n \nreply",
      "The connection between education and wealth is very strong. Very sad that the US has decided to pursue a trajectory towards poverty in this area.\n \nreply"
    ],
    "link": "https://aeon.co/essays/how-did-kerala-go-from-poor-to-prosperous-among-indias-states",
    "first_paragraph": "Ernakulam, Kerala, India, 2018. Photo by Barry Lewis/Gettyby Tirthankar Roy & K Ravi Raman\u00a0+ BIOErnakulam, Kerala, India, 2018. Photo by Barry Lewis/Gettyis professor in economic history at the London School of Economics. His books include the co-authored Law and the Economy in Colonial India (2016) and Law and the Economy in a Young Democracy (2022).is an Expert Member of the Kerala State Planning Board. He is the author of Global Capital and Peripheral Labour (2009) and Political Ecospatiality: Livelihood, Environment, and Subaltern Struggles (2024).Edited bySam HaselbyIndia is a union of 28 states (provinces). The population in some of these states is bigger than that of the largest European countries. For example, Uttar Pradesh is home to more than 240 million people, almost three times the population of Germany. Although a part of a federal union, every state has a unique history, shaped by its environment and natural resources, princely or British colonial heritage, language and "
  },
  {
    "title": "How to write blog posts that developers read (refactoringenglish.com)",
    "points": 318,
    "submitter": "rbanffy",
    "submit_time": "2025-03-28T11:01:19 1743159679",
    "num_comments": 108,
    "comments_url": "https://news.ycombinator.com/item?id=43503872",
    "comments": [
      "My general takes (as someone who also has a somewhat popular blog) is thatThe inverted pyramid is almost always the correct format for your text.  I often put the tweet-length version of the post in the title or first paragraph.  Get to the point quickly, then elaborate.  Means you can bail out at any point of the text and still take home most of what mattered, while the meticulous crowd can have their nitpicks addressed toward the end.The problem of finding an audience is best solved by being really transparent about what you're about.  Inverted pyramid solves that.  There's no point to drawing in people who aren't going to be interested.  Retaining existing readers beats capturing new readers.I'm less bullish on images, unless they are profoundly relevant to the text.  Illustrations for the sake of having illustrations are no bueno in my opinion.  You want to reduce distractions and visual noise.  Images should above all never be funny.\n \nreply",
      "> The inverted pyramid is almost always the correct format for your text. I often put the tweet-length version of the post in the title or first paragraph. Get to the point quickly, then elaborate. Means you can bail out at any point of the text and still take home most of what mattered, while the meticulous crowd can have their nitpicks addressed toward the end.This sounds similar to what I was taught, in high school ~30 years ago, about journalism. When you write an article for the paper, the first sentence should have the who, what, when, where. The reader should be able to get the basic, relevant information from the first sentence then start giving more details as you go along. This is not only for the reader but to make it easier for the editor if/when they need to cut an article short then they can just cut text from the end.\n \nreply",
      "It may be worth noting that there are historical reasons why newspapers in particular used that format, especially wire copy. The idea was that, in layout, typeset stories could be cut at more or less an arbitrary point. Magazine stories are much less likely to follow this exact format although they still tend not to completely bury the lede.\n \nreply",
      "> cut at a more or less arbitrary pointCut literally - I worked on a student newspaper (with professional phototypesetting gear, comparable to the city papers - AKI Ultrasystem) and second-tier \"filler\" content was just set in a single long column, then pasted up on the layout boards (hot wax as the adhesive) and then trimmed when it ran out of space (with an x-acto blade.) Reading that class of content was kind of optional for the layout editor, at least at 10:30pm when trying to get the boards out the door for an 11pm press deadline...\n \nreply",
      "> the first sentence should have the who, what, when, whereI utterly despise modern long form journalism which does not establish any of these things until 1/3 through the article. It\u2019s infuriating.\n \nreply",
      "It's not just long form journalism. The basic five-paragraph essay, taught in every school from elementary through university level, violates this principle. When you're learning to write, there is an implicit assumption that you have a captive audience \u2014 even if it's limited to your teacher \u2014 who is forced to read your work. So there is generally insufficient emphasis on \"getting to the point.\" Instead, you're taught to \"grab the reader's attention,\" with an exciting sentence or visual anecdote. That's what you're seeing in long form journalism that usually starts with some narrative description of a central character in the story.Whereas in the real world, you are competing for attention, and nobody has to read what you write. So if your goal is to convey information, you better get to the point. But if your goal is to tell a story, then what's the rush?\n \nreply",
      "The articles were intended for you to read. If you find them annoying, maybe they weren't written for you.\n \nreply",
      "> The articles were intended for you to readOr they were intended for you to scroll further on the page and load more ads and autoplay videos.Good essays start with their thesis, expand upon that, and conclude by bringing it back to it.There is no reason journalism should veer away from a format that works for one goal (information dissemination),  unless there are other goals at play (longer engagement).\n \nreply",
      "Perhaps novels should be written in the inverted triangle format.\n \nreply",
      "Perhaps there's a difference between fiction and non-fiction\n \nreply"
    ],
    "link": "https://refactoringenglish.com/chapters/write-blog-posts-developers-read/",
    "first_paragraph": "by Michael Lynch, published\nMarch 27, 2025I recently spoke to a developer who tried blogging but gave up because nobody was reading his posts. I checked out his blog, and it was immediately obvious why he didn\u2019t have any readers.The developer had interesting insights, but he made so many mistakes in presenting his ideas that he was driving everyone away. The tragedy was that these errors were easy to fix. Once you learn to recognize them, they feel obvious, but some bloggers make these mistakes for years.I know because I\u2019m one of them.I\u2019ve been blogging about software development for nine years. My best posts have reached 300k+ readers, but many of them flopped, especially in my first few years.Over time, I\u2019ve learned techniques that help some blog posts succeed and the pitfalls that cause others to languish in obscurity.I\u2019m going to say a bunch of gloaty things to establish credibility, but it feels gross, so let\u2019s just get it out of the way:My software blog receives 300k-500k unique "
  },
  {
    "title": "iCloud Mail has DNS misconfigured (mail-tester.com)",
    "points": 7,
    "submitter": "wildekek",
    "submit_time": "2025-03-29T00:22:21 1743207741",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43511464",
    "comments": [
      "So, Apple sends the wrong EHLO domain when trying to send emails out. This results in them dropping emails to their own users. Can't get past Apple's level 1 support. How can I get to someone that maintains their SMTP k8s cluster?\n \nreply",
      "https://support.apple.com/en-us/102322#:~:text=If%20you%20st...\n \nreply",
      "p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com is one hell of a name, though.Did you try postmaster@apple.com, hostmaster@apple.com, or icloudadmin@apple.com (not traditional, but given in their docs)?\n \nreply"
    ],
    "link": "https://www.mail-tester.com/test-p3tdhnk3o",
    "first_paragraph": "What we retained as your current SPF record is:Verification details:The DKIM signature of your message is:Your public key is:Key length: 2048bitsDMARC DNS entry found for the domain _dmarc.vooijs.eu:\"v=DMARC1; p=reject; rua=mailto:postmaster@vooijs.eu; pct=100; adkim=r; aspf=r\"Verification details:Your IP address 57.103.88.93 is associated with the domain p-east1-cluster7-host9-snip4-10.eps.apple.com.Nevertheless your message appears to be sent from p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com.You may want to change your pointer (PTR type) DNS record and the host name of your server to the same value.Your IP address 57.103.88.93 is associated with the domain p-east1-cluster7-host9-snip4-10.eps.apple.com.Nevertheless your message appears to be sent from p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com.You "
  },
  {
    "title": "Optimizing Matrix Multiplication on RDNA3 (seb-v.github.io)",
    "points": 50,
    "submitter": "skidrow",
    "submit_time": "2025-03-25T09:55:21 1742896521",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43469535",
    "comments": [
      "Is the author a genius or has AMD questionable software?\n \nreply",
      "Many of the optimizations here rely heavily on the size of matrix and it's relationship to hardware specific details, like LDS size, how they're banked and register count.It's probably not surprising that you can grind a decent improvement over a general solution, and many of the improvements shown here will need to be re-balanced, or even simply not work, for kernels working on different matrix layouts. Similarly for trying to work on different hardware - even in the same architecture and generation these sort of details are often changing.And all that required going down to the ISA level, which is a lot less easy (certainly less documented) for Nvidia - for example the \"inspiration\" post linked [0] on CUDA didn't beat cuBLAS also didn't try modifying the SASS directly, so there might be similar level gains unrealized there.[0] https://siboehm.com/articles/22/CUDA-MMM\n \nreply",
      "> like LDS size, how they're banked and register count.but you're acting like they pick these numbers using a random number generator for each generation when it's just reasonable/rational stuff like \"here's 2x more LDS or more registers for free because the new process node is 2x smaller\". like you must realize that they're not throwing everything away and starting completely from scratch for every new gen right? incidentally, while LDS will grow and # of registers will grow, there's absolutely no way they'd change the banking - e.g., CUDA hasn't changed it since 2.0.\n \nreply",
      "No, but it's not obviously clear that other sized kernels will hit the same bottlenecks seen in the post. It's not really shown one way or the other - is it that the rocm kernels are just inefficient, or just the author identified one that wasn't particularly well optimized? And do these opportunities for improvement really mean that the software is \"Questionable\", or just that you cannot really do an equivalent comparison at the level of ISA on other vendor's software stacks?I'm not trying to minimize the work here, it's interesting and a good example of the sort of lengths you can go to in order to squeeze that last little bit of performance out (and again, showing the advantages of public ISA documentation and support for users working at that level), I just took issue to the parent comment seeming to use this work as evidence of a poor baseline.\n \nreply",
      "ROCm multiplies in 4.5ms and the author multiplies in 2.8ms. The naive algorithm is 136ms. I don't think anyone at AMD is losing sleep over this; for a general purpose library this isn't horrible performance. It could be better, hand optimising to specific conditions often is. But as this blog post shows, optimising kernels is the sort of thing that people can do for fun and post blogs about if they care. They don't need AMD to be involved.The problem with ROCm isn't that it only half-utilises the hardware, the problem was that someone trying to write this blog post in 2020 would have had (or at least the probability was rather high) a heading somewhere around implementing Kernel 0 talking about how the software crashed or the kernel panicked when they tried to run the benchmarks. That was what happened to me when I tried a conceptually similar exercise. I was wandering around HN posting comments about how there were no articles like this one to be found for AMD hardware and musing whether it was technically possible to do.This makes me wish I'd bought an RDNA3 card instead of a Nvidia one for my last purchase. Not that I really regret the choice, AMD are going to have to show that they're interested in supporting consumer cards for a little longer to get me to trust them again although they're on the right path.\n \nreply",
      "This is really cool. 60% is no joke and as a 7900XTX owner I would love the performance boost.Well done!\n \nreply",
      "> Furthermore, performing custom ISA optimizations makes these changes RDNA3-specificthis is overblown at least wrt forward compatibility - all of the instructions used are in RDNA4 and most of them are even in CDNA3 (CDNA4 isn't public yet?) and the ones that aren't exactly there are only slightly renamed (ds_load -> ds_read). Sure it's annoying but it's not the end of the world to have some `#ifdef`s in your code (that's not very much different from what the compiler itself is going to do anyway).\n \nreply"
    ],
    "link": "https://seb-v.github.io/optimization/update/2025/01/20/Fast-GPU-Matrix-multiplication.html",
    "first_paragraph": "Hi everyone !In this post, I will share with you all the steps to write an optimized FP32 matrix multiplication on AMD RDNA3 GPU outperforming rocBLAS by 60%. I will cover some basics and explain all the optimizations I have implemented. This will be done in a iterative way in 8 differents Kernels.Figure 1: sneak peek of the performance resultsI primary intended to work on this to deepen my understanding of RDNA3 and try out HIP and I felt like I needed to share what I learned doing this :).Few things I like to say before we start :That being said, let\u2019s start !There is a lot of research happening on the way to improve the performance of matrix multiplication nowadays. Being a core algorithm in ML applications, any FLOPS we can exploit is golden.Before proceeding, let\u2019s recall the basics of matrix multiplication. Given two matrices:Their product, \\(C\\), is computed as follows:where \\(C\\) is the resulting matrix of size \\(M,N\\).For each output value of matrix C, we compute the dot produ"
  },
  {
    "title": "Finley (YC W21) Is Hiring a Technical Implementations Specialist (rippling.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-03-28T21:01:49 1743195709",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://ats.rippling.com/finley-technologies/jobs",
    "first_paragraph": "8  roles across\u00a0all departments\u00a0in\u00a0all locationsEngineeringSF, NY, RemoteEngineeringSF, NY, RemoteOperationsSF, NY, RemotePost SalesSF, NY, RemotePost SalesSF, NY, RemotePost SalesSF, NY, RemoteSalesSF, NY, RemoteSalesSF, NY, Remote"
  },
  {
    "title": "Show HN: Hexi \u2013 Modern header-only network binary serialisation for C++ (github.com/emberemu)",
    "points": 71,
    "submitter": "Chaosvex",
    "submit_time": "2025-03-28T17:37:42 1743183462",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=43508061",
    "comments": [
      "I know it's a convention since the inception of the language, but the operator overload abuse of the bitshift operator still makes me sad every time I see it :(\n \nreply",
      "On the plus side, it's optional. The same thing can be achieved with put()/get() equivalents.\n \nreply",
      "You are not alone.  many on the standard committee are trying to get rid of it. std::print is the new way to do io instead of cout in part so you don't have to abuse shift for io.  This is new in c++23 though so few people know about it.Bjarne appears to prefer cout though, so it isn't universal.\n \nreply",
      "Danish Bjarne may have his < right next to lshift. He needs to use shift+. to enter colon.On US layout colon is a single keypress but < is shift+.This may explain the discrepancy.\u2014- from someone who read Bjarne at 16yo. All hail the Bjarne\n \nreply",
      "What are the exact constraints on the struct contents, i.e. what is it that your library can't serialize?I tried adding std::string to the UserPacket (from the README)  struct UserPacket {\n  //    uint64_t user_id;\n  //    uint64_t timestamp;\n  //    std::array<uint8_t, 16> ipv6;\n        std::string test;\n  };\n\nand the compilation fails - https://onlinegdb.com/B_RJd5Uws\n \nreply",
      "With more complex structures, you need to specify how it should behave. The definition for 'more complex' here is basically no virtual functions, virtual base classes, is trivially copyable and constructible and a few others.Basically, if it seems like memcpying the structure might be a reasonable thing to do, it'll work. This is why types like std::array will work but std::vector and std::string won't. It can handle those types when inserted individually but not in aggregate since there's no reflection.The compiler barf does tell the user why it was rejected but... average C++ errors, even with concepts. Not the greatest.main.cpp:136:52: note: the expression \u2018is_trivial_v [with T = UserPacket]\u2019 evaluated to \u2018false\u2019\n  136 | concept pod = std::is_standard_layout_v<T> && std::is_trivial_v<T>;\n \nreply",
      "Wow that api looks fantastic! Bravo!I'd like to read an even more thorough overview of how it works and all the gotchas before I'd consider using this 'in production' but the API looks very easy to use and very elegant.EDIT: just hit the section on portability, seems like you would always have to use that API, yeah? I feel like when you are writing network code you simply have to make it portable from the get-go. I guess I'm always thinking about having it run on client machines.\n \nreply",
      "Thanks. The documentation could definitely be fleshed out with some more examples.You'd likely want to always use that API (or layer something on top of it) unless you're in control of both ends and know they were built with the same toolchain & settings. One area where I've skipped over it is by writing a basic code gen tool (albeit unfinished as most personal projects) that generates the serialisation functions at compile-time from a very basic DSL that describes the network structures (of a game protocol I don't control). If it detects that the current toolchain is going to generate a binary-compatible struct layout and there aren't any variable length fields in there (no strings, basically), it'll generate a memcpy (via using get/put on the stream) rather than per-field (de)serialisation. If it can guarantee alignment of the buffer, which is a tougher requirement to meet, it'll give you a view directly into the network buffer so you effectively have zero-overhead deserialisation. Very much a work in progress but there's scope for making things quite efficient with just a few basic building blocks.\n \nreply",
      "That code-gen would be fantastic. I have commercial applications for this, so I'll keep an eye on your space.\n \nreply",
      "Fun! It reminds me of my own attempt at this: https://github.com/louisabraham/ubufIt can generate efficient JS and C++ from a simple YAML file.\n \nreply"
    ],
    "link": "https://github.com/EmberEmu/Hexi",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Header-only, lightweight C++ library for binary streaming. Network data handling made easy peasy!\n      \n\n\n\n\n\n\nHexi is a lightweight, header-only C++23 library for safely handling binary data from arbitrary sources (but primarily network data). It sits somewhere between manually memcpying bytes from network buffers and full-blown serialisation libraries.The design goals are ease of use, safety when dealing with untrusted data, a reasonable level of flexibility, and keeping overhead to a minimum.\nWhat Hexi doesn't offer: versioning, conversion between different formats, handling of text-based formats, unloading the dishwasher.Incorporating Hexi into your project is simple! The easiest way is to simply copy hexi.h from single_include into your own project. If you'd rather only include what you use, you can add include to your include "
  },
  {
    "title": "Decomposing a Factorial into Large Factors (terrytao.wordpress.com)",
    "points": 100,
    "submitter": "surprisetalk",
    "submit_time": "2025-03-28T14:55:54 1743173754",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=43506238",
    "comments": [
      "Edit: as pointed out, you can't simply divide by each number, because then its not equal to original number factorial.  However, I've fixed the algorithm somewhat maintaining the basic ideaThe \"naive\" way  100!= 2*3*4*...*99*100\n\nObviously t(100) > 1. If we can get rid of the single 2, we know that t(100) > 2.  If you multiply the whole thing by 2/2 (=1),  100! = (2/2)*2*3*4*...*50*...99*100\n       = (2*2/2)*3*4*...*50*...99*100\n       = (4/2)*3*4*...*50*...99*100\n       = 4*3*4*...*50*...99*(100/2)\n       = 3*4*4*...*50*50*...99\n\nWe can continue with t(100) > 3 by multiplying by 3/3 and pairing it with 99, i.e. 99*3*(3/3) = (99/3)*3*3 = 33*9  yielding  100! = 4*4*5*...*9*9*10*..*33*33*...*50*50...*97*98\n\nHowever, once we get to t(100) > 4, trying to get rid of 4, we have to skip 98 since its not divisible by 4.  The other problem is we have two 4s...  If we had instead using 98 for getting rid of 2, we can then use 100, and 96 for the other 4.  This is our first \"gotcha\" for the naive algorithm of always picking the largest number, which seems intuitive at first glance.Now if we test all possibilities starting with 2, we get 48 choices for the dividing 2 (even numbers > 2, not including 2 which will not increase t(100) beyond 2.  Then ~33 choices for dividing 3 (depending if our div of 2 resulted in a factor of 3), ~25 for 4, But notice since we now have two 4s, we have to do it twice, so its 25*24 choices for getting rid of 4.*\n \nreply",
      "The  naive way has to have a 1 in it since what you give only has 99 factors.\n \nreply",
      "> 100 = 3*4*...*50*50*...99You can\u2019t replace 2*100 with 50, it has to be 4*50. But there\u2019s no reason you have to divide by 2 at all - why not replace 2*99 with 6*33?\n \nreply",
      "Thanks, I've fixed the ideaThe basic idea is to \"pair\" the lowest numbers with the highest ones - sort of pushing everything towards the middle valuesLike I said, its naive greedy and non-optimal - otherwise time would be linear.\n \nreply",
      "Out of curiosity, I wondered how tight these bounds are. Consider the case of 300,000 which Terry has put a lower bound of 90,000 on, and would like a bound of 100,000 on. If a perfect division of factors into equal buckets could be achieved, the answer would be 110366.49020484093 per bucket. That's e^(log(n!)/n), to within the precision that Python calculates it. (My first try was to use Stirling's formula. That estimated it at 110366.49020476094, which is pretty darned close!)A straightforward greedy approach will see those final buckets differing by factors of around 2. Which is a lot worse than Terry's current approach.This really is a knapsack problem.\n \nreply",
      "As a kid I was bugged by the fact that Stirling formula doesn't give exact integer result, so I set to find my own formula. I failed, but discovered that sum from 1 to N is (n*n+n)/2. Surely if perfect formula for sum exists, for multiplication should exist too.\n \nreply",
      "https://en.wikipedia.org/wiki/Gamma_function\n \nreply",
      "I think they mean a (traditionally) closed form expression, for which I don't know if there is a particularly simple explanation of why there isn't such a form but there is for summing integers to n instead of multiplying them.\n \nreply",
      "For those who are curious how we can construct such a function, and why it looks so funky on the negative side, I strongly recommend this video https://www.youtube.com/watch?v=v_HeaeUUOnc\n \nreply",
      "Is there a standard notation for the product of all even numbers up to N and for the product of all odd numbers up to N?  I know if N is even then the product of evens is = (N/2)! * 2^(N/2) so I guess notation for that is a little redundant, but there is no simple formula for the product of the odd numbers.\n \nreply"
    ],
    "link": "https://terrytao.wordpress.com/2025/03/26/decomposing-a-factorial-into-large-factors/",
    "first_paragraph": "Updates on my research and expository papers, discussion of open problems, and other maths-related topics.  By Terence Tao26 March, 2025 in math.NT, paper | Tags: Erdos, factorial function, factorisation | by Terence Tao \nI\u2019ve just uploaded to the arXiv the paper \u201cDecomposing a factorial into large factors\u201c. This paper studies the quantity , defined as the largest quantity such that it is possible to factorize  into  factors , each of which is at least . The first few values of this sequence are \nThis quantity  was introduced by Erd\u00f6s, who asked for upper and lower bounds on ; informally, this asks how equitably one can split up  into  factors. When factoring an arbitrary number, this is essentially a variant of the notorious knapsack problem (after taking logarithms), but one can hope that the specific structure of the factorial  can make this particular knapsack-type problem more tractable. Since \nSome further exploration of  was conducted by Guy and Selfridge. There is a simple cons"
  },
  {
    "title": "The Real Book (2021) (99percentinvisible.org)",
    "points": 86,
    "submitter": "Tomte",
    "submit_time": "2025-03-28T16:39:10 1743179950",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=43507404",
    "comments": [
      "As an aside, fake books are a great way to get your feet wet learning how to extemporize while still having some guidance around the chord progression and melody.If you have an iPad, there's an app called iReal Pro with loads of lead sheets that add in some accompaniment (drums, guitar, etc.) so you can \"play along\" as well.https://www.irealpro.com\n \nreply",
      "iReal Pro is a great resource, but what it provides are not lead sheets, they are just chord charts. Lead sheets have the melody of the song in standard notation, along with chord names and sometimes lyrics. iReal Pro's charts give chord names only.\n \nreply",
      "I get very frustrated with cats on the stage who rely too much on the iReal Pro.  If they don't know the melody, then they easily get lost when, for instance, an intro or other section is skipped (such as when the singer re-enters on the bridge after solos), and in general their comping tends to not be aware of how the melody fits in with the changes.  At least when reading a leadsheet, readers know how the melody and harmony interact and can better play fills around the melody.\n \nreply",
      "iReal Pro is awesome. When playing music with new people (especially jazz), it feels like everyone has it, and you can quickly make sure you're playing the same charts.It's also available on Android, and it's a one-time payment, no-subscription app. Easily one of the most valuable music purchases I've made.\n \nreply",
      "it's also great being able to change tempo, style, key, etc.  iReal Pro is used by every pro musician i know around town\n \nreply",
      "Threads 4 and 2 years agohttps://news.ycombinator.com/item?id=34536638https://news.ycombinator.com/item?id=26737142\n \nreply",
      "99% invisible is one of my most favourite podcasts, I recommend it every time when I talk about podcasts to someone\n \nreply",
      "It's the first podcast I ever heard of, when my friend first explained that word to me. Glad to see it's still around.\n \nreply",
      "The Real Book was pretty fundamental helping me learn jazz. I think a lot of jazz people look down on it (or those who need it), but I didn't really get deep enough to see that. There's a short video from Adam Neely that opened my eyes to that a bit.https://youtu.be/dD0e5e6wI_A?feature=shared\n \nreply",
      "Who looks down on the Real Book?\n \nreply"
    ],
    "link": "https://99percentinvisible.org/episode/the-real-book/",
    "first_paragraph": ""
  },
  {
    "title": "The Art of DJing: Avalon Emerson (2019) (ra.co)",
    "points": 69,
    "submitter": "easyThrowaway",
    "submit_time": "2025-03-28T19:22:14 1743189734",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=43509061",
    "comments": [
      "A few months on Hacker News there was a post about Mixxx[1], an open-source DJ software.  It prompted me to download it and play around.  It's very cool.  Despite being a complete novice, I learned a few things after a dozen hours of playing around:* I don't have a physical controller, but I can understand why people always use them.  Keyboard and mouse are not fully sufficient.* The built-in key and beat detection is really quite good for house music, and it gets you most of the way there in terms of managing song transitions (but not all the way there)* A side effect of consuming 99% of all of my music from youtube and spotify means I have no local library to feed into Mixxx (I ended up yt-dlp'ing a bunch of stuff)* There is a true art in song selection, and I don't possess this skill.[1] https://mixxx.org/\n \nreply",
      ">  I don't have a physical controllerThere are a lot of really cheap USB based controllers on the second hand market - I've got an old USB 1.1 based controller that was state of the art in 2007 and was used by some famous DJs back in the day for 50\u20ac and it's working perfectly fine - it's only midi - you can dump the hex values using midi tools in Linux when you turn the nobs.Surprisingly for me latency and interactivity are no problem. Eqing, pitch, jogwheel all is fast enough and feels like analog. However I'm not a professional but I didn't recognize any noticable delay.You can even scratch using the jog. I'm sure there is a reason for the price difference to modern hardware but from a haptics and sound perspective it's perfectly fine. Mixxx is doing all the hard work.Mixxx has a really long list of supported devices: https://github.com/mixxxdj/mixxx/wiki/Hardware-CompatibilityYou probably need another soundcard for headphones, there also exist lots of cheap old USB soundcards for that - there are also controllers with an audio interface like Vestax VCI-300.Then it's up to you to practice. I'm also struggling to get better but it's really all you need to DJ. I'm also yt-dlp'ing my collection which feels strange but is budget friendly :)I've used to DJ hobbyist style using vinyl ages ago and I'm not missing anything. You can ignore the sync button, hide the bpm on the screen and mix only using your ears like you'd do with vinyl only.\n \nreply",
      "Song selection comes from hours of listening to music in the style you will be playing. Eventually, you will hear a riff from one song and it will make you think of another song. Those will be interesting to mix together. You might hear one song with a bass line that you really like with a melody line that is on the lighter side. You might then come across a song with a strong melody, but a bass line that could be punched up. Combine the two with some appropriate EQing, and make your own mix. After mixing for awhile, you will learn to listen in a different way than just someone listening to music.Using a tool to beat match has always been considered \"cheating\", but it is obvious why it is a tool. Beat matching is probably the most technically challenging aspect. Eventually, you'll even get a feel for songs that are close in tempo--most music in a genre will be pretty close by default. Learning to ride this bike with training wheels is just an option I did not have. Being able to manually adjust the pitch/tempo (depending on equipment) without the auto tools becomes quite satisfying.Some DJs talk about knowing what key a song is in, and if it will mix into another song. If you then have to adjust the pitch for beat matching, how does that affect the key of the song and how it now mixes? I've never claimed to do this, but after playing in school band I can at least hear the wahwahwah from something being out of tune (or was that the nitrous??). Maybe if you're mixing some prog-trance with sustained chords you might hear that, but I'd suggest finding a different place in the track to be mixing.The physical controller is precisely why I love vinyl.\n \nreply",
      "> After mixing for awhile, you will learn to listen in a different way than just someone listening to music.There is a whole other side to song selection which is reading the room and figuring out what the audience needs next. That side isn't visible until you happen to start actually playing for an audience but it's ultimately the most important one, I think.> If you then have to adjust the pitch for beat matching, how does that affect the key of the song and how it now mixes?Music hardware/software can now do a pretty good job of changing speed and pitch independently. \"Time-stretching\" is the older term for how those algorithms work and they've gotten pretty good over the years.I don't know how newer DJ software behaves by default you when change tempo. It's been a long time since I DJed.But, also, producers making music for dancefloors know what they are doing and anticipate this. Most tracks made for DJs will have a long intro and outro that is mostly drums and other atonal instruments. That way DJs can mix without having to worry about keys clashing as much.It always feels really good when you find two tracks that harmonize well with each other and you can mix their tonal parts together in the transition.> The physical controller is precisely why I love vinyl.100%. Beatmatching vinyl is one of those lovely zen activities, like driving a manual transmission, catching the wind in a sailboat, or hitting balls at a driving range. You're always chasing the perfectly smooth execution and never quite getting there.\n \nreply",
      "Using a tool to beat match has always been considered \"cheating\", but it is obvious why it is a tool.I guess in the same way that using a higher-level language than Assembly is \"cheating.\" I'm not sure if you're referring specifically to the Sync feature (which is still largely frowned upon) or more generally analyzed beatgrids, BPM readouts and Master Tempo (which keeps the pitch in tune when you change the tempo), but the vast majority of practicing DJs today are not needing/using the old school vinyl beatmatching techniques.Call it whatever you want but you're going to be incredibly hard-pressed to find anyone that can mix as smoothly on vinyl as someone decent with CDJs. Sure it's a cool dying art and analog and all that but at this point virtually anyone trying to play vinyl out is sacrificing the listener's experience  for cool points (including the physical issues with reproducing sound from delicate machinery in a chaotic environment).\n \nreply",
      "> Call it whatever you want but you're going to be incredibly hard-pressed to find anyone that can mix as smoothly on vinyl as someone decent with CDJs. Sure it's a cool dying art and analog and all that but at this point virtually anyone trying to play vinyl out is sacrificing the listening experience for cool pointsThat's a sad commentary on today's DJs then. Yes, there were some very bad vinyl DJs that loved the shoes in the dryer mixes and could not advance past that. They love the \"beatmatch\" magic. Doesn't mean that those that could are less of a DJ which is what you're trying to say?My perfect setup would be vinyl controllers of a digital player which is very much a thing. Of course, hearing a DJ mix vinyl that is older with all of the snap crackle pops of a burning log is not pleasant, but that does not diminish the vinyl as a controller being superior to a tiny plastic spin wheel on a digital controller.\n \nreply",
      "That's a sad commentary on today's DJs then.Not really, you just have a lot more information and tools at your disposal. It's going to be a better performance. In no other area of endeavor is anyone expected to limit themselves to decades-old technology, that would just be madness.but that does not diminish the vinyl as a controller being superior to a tiny plastic spin wheel on a digital controller.How is it superior? We've just covered so many ways it's inferior. I have a number of friends that are really into vinyl, I've never really \"gotten\" it, there's no argument other than this kind of nostalgic fetish (which I'm not saying is for nothing, but I usually just want to use whatever technology I can to create the best experience for the listener).\n \nreply",
      "If you've never used vinyl enough to \"get it\", then how can you say that it's inferior. The tactile experience of controlling the sound with the vinyl is so different than some digital plastic feeling controller. Yes, the higher end CDJs have a better feel to them decades later, but it is still not the same.At this point we might as well be arguing about tab vs spaces. Using vinyl is my thing, and it is just not going to be possible to explain why I like it so much without the both of us being at the gear. Words do not convey the same as the touch\n \nreply",
      "you're arguing about something different to the person you're replying to.\n \nreply",
      "He's.... not tho?> but that does not diminish the vinyl as a controller being superior to a tiny plastic spin wheel on a digital controller.It's absolutely objective, but the feel of vinyl on a slipmat is absolutely so much nicer than a jog wheel.But many ppl barely even use jog wheels these days. Just nudging to get in time.When you spend countless hours getting the right light touch on a vinyl that Tactile feel is absolutely lacking when it comes to more digital interfaces.I'm not arguing vinyl records sound better. GP and me are arguing that it feels better.\n \nreply"
    ],
    "link": "https://it.ra.co/features/3392",
    "first_paragraph": ""
  },
  {
    "title": "Plasmonic Modulators Can Break the Wireless Terahertz Barrier (ieee.org)",
    "points": 10,
    "submitter": "pseudolus",
    "submit_time": "2025-03-25T01:17:35 1742865455",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43467181",
    "comments": [
      "Li-fi. This combined with ultrasonic and we'll be surrounded by non radio signals!\n \nreply",
      "It's funny calling light \"wireless\".It's not wrong exactly. Light can be transmitted wirelessly. Optical cables aren't even usually called \"wires\". It just sounds odd.\n \nreply"
    ],
    "link": "https://spectrum.ieee.org/terahertz-waves-2671362433",
    "first_paragraph": "Accelerate Your Engineering Career: Subscribe to Our FREE Newsletter \u2192The tech could find a home in 6G networks and AI data centersMatthew S. Smith is a contributing editor for IEEE Spectrum and the former lead reviews editor at Digital Trends.A new plasmonic modulator [in gold] transfers signal information from an electrical wave to an optical wave at higher speeds than other modulator technologies.Modern telecommunications infrastructure relies on a broad range of technologies. But ironically, some of these technologies can\u2019t readily communicate with each other. The electrical signals used for wireless communications, for example, can\u2019t just be shoved into the fiber-optic infrastructure that forms the backbone of modern networks. Instead, they must be first converted to light (and then back again). This important task is performed by a network component called an electro-optic (EO) modulator. \u201cAll information that you have is in the electrical world, but once it leaves your house, it"
  },
  {
    "title": "Building a modern durable execution engine from first principles (restate.dev)",
    "points": 60,
    "submitter": "whoiskatrin",
    "submit_time": "2025-03-27T13:51:44 1743083504",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=43493665",
    "comments": [
      "Looks very interesting. How does it compare to Temporal?\n \nreply",
      "There are a few dimensions where this is different.(1) The design is a fully self-contained stack, event-driven, with its own replicated log and embedded storage engine.That lets it ship as a single binary that you can use without dependency (on your laptop or the cloud). It is really easy to run.It also scales out by starting more nodes. Every layer scales hand-in hand, from log to processors. (you should give it an object store to offload data, when running distributed)The goal is a really simple and lightweight way to run yourself, while incrementally scaling to very large setups when necessary. I think that is non-trivial to do with most other systems.(2) Restate pushes events, compared to Temporal pulling activities. This is to some extent a matter of taste, though the push model has a way to work very naturally with serverless functions (lambda, CF workers, fly.io, ...).(3) Restate models services and stateful functions, not workflows. This means you can model logic that keeps state for longer than what would be the scope of a workflow (you have like a K/V store transactionally integrated with durable executions). It also supports RPC and messaging between functions (exactly-once integrated with the durable execution).(4) The event-driven runtime, together with the push model, gets fairly good latencies (low overhead of durable execution).\n \nreply",
      "One of the authors worked on Apache Flink but is too modest to include that interesting detail! So I'm adding it here. Hopefully he won't mind.\n \nreply",
      "All of the Restate co-founders com from various stages of Apache Flink.Restate is in many ways a mirror image to Flink.\nBoth are event-streaming architectures, but otherwise make a lot of contrary design choices.(This is not really helpful to understand what Restate does for you, but it is an interesting tid bit about the design.)       Flink     |   Restate\n  -------------------------------\n                 |\n    analytics    |  transactions\n                 |\n  coarse-grained |  fine-grained\n    snapshots    | quorum replication\n                 |\n   throughput-   |  latency-sensitive\n    optimized    |  \n                 |\n  app and Flink- |  disaggregated code\n  share process  |   and framework\n                 |\n      Java       |      Rust\n\nthe list goes on...\n \nreply",
      "They mention it in their about page: https://restate.dev/about\n \nreply",
      "Thanks\u2014sounds like it was more than one of them!\n \nreply",
      "Interesting, how does it compare to Inngest and DBOS?\n \nreply",
      "Hey, I work on Restate. There are lots of differences throughout the architecture and the developer experience, but the one most relevant to this article is that Restate is itself a self-contained distributed stream-processing engine, which it uses to offer extremely low latency durable execution with strong consistency across AZs/regions. Other products tend to layer on top of other stores, which will inherit the good things and the bad things about those stores when it comes to throughput/latency/multi-region/consistency.We are putting a lot of work into high throughput, low latency, distributed use cases, hence some of the decisions in this article. We felt that this necessitated a new database.\n \nreply",
      "Hi,I'm building a distributed application based on Hypergraphs, because the data being processed is mostly re-executable in different ways.It's so refreshing to read this, I was also sitting down many nights and was thinking up about the same problem that you guys solved. I'm so glad about this!Would it be possible to plug other storage engines into Restate?\nThe data-structure that needs to be persisted allows multiple-path execution and instant re-ordering without indexing requirements.I'm mostly programming in Julia and would love to see some little support for it too =)Great work guys!\n \nreply",
      "Thank you for the kind words!The storage engine is pretty tightly integrated with the log, but the programming model allows you to attach quasi arbitrary state to keys.So see whether this fits your use case, would be great to better understand the data and structure you are working with. Do you have a link where we could look at this?\n \nreply"
    ],
    "link": "https://restate.dev/blog/building-a-modern-durable-execution-engine-from-first-principles/",
    "first_paragraph": ""
  }
]