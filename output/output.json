[
  {
    "title": "Happy 20th Birthday, Y Combinator (twitter.com/garrytan)",
    "points": 873,
    "submitter": "btilly",
    "submit_time": "2025-03-11T14:14:35 1741702475",
    "num_comments": 172,
    "comments_url": "https://news.ycombinator.com/item?id=43332658",
    "comments": [
      "\"Founders at Work\", written by Jessica is what got me into HN (and I was an initial lurker for quite sometime).https://en.wikipedia.org/wiki/Founders_at_WorkNote: YC didn't have HN to begin with, it was launched 1-year later (Oct 2006 as seen by pg profile). And the book was launched the subsequent year (2007).https://news.ycombinator.com/user?id=pg\n \nreply",
      "In case you\u2019re not aware, there is a podcast by Jessica Livingston and Carolyn Levy called \u201cThe Social Radars\u201d that interviews founders.\n \nreply",
      "Downloading it now. I didn't know about it. Looks like there are a lot of big names!\n \nreply",
      "Such an inspiring book - I still have it by my desk :) I bought it because they covered Joel's FogBugz and 37Signal's Basecamp (I was building a competitor product back then).\n \nreply",
      "I remember the initial PG announcement about the founder's summer program and wanting desperately to be a part of it.  I wasn't at a place in my life where I ever could join YC but the tribe that's been built by everyone involved has added tremendous value to my life.  I'll always be incredibly grateful that this place and YC exists.\n \nreply",
      "Happy Birthday, YC! I've been a regular participant in the HN community since 2012. All these years HN has inspired me and during this time I've learned a lot. I started back in the days of building FIDO, when the first point networks appeared. Of course, I\u2019d love to see more communities and fewer bots, but progress is unstoppable. I wish the HN community to thrive and remain strong for many years to come.I'm creating a mobile reader (iOS app) specifically for HN and if you want to join to speed up the process, you're Welcome!https://www.acpul.org/blog/yc-happy-birthday-20For those who don't have iOS, I started a Twitch stream for the vibe.https://www.twitch.tv/guynpcPS: I fear that I\u2019ll never get into YC and in the future there will be no more startups, only an AI, and I\u2019ll have to work as a battery cell in the Matrix.\n \nreply",
      "[I guess the tweet refers to YC the incubator, not the web site of news, but I want to focus on the latter]: I registered on HN a few days after it was created. The HN community was incredibly instrumental to my career, my ability to keep up with the development community, with like-minded people, and to have a voice, the times my posts and projects reached this home page. Thank you, for for all of that. Now, I see that, inevitably, as this place becomes bigger and bigger, there is no longer that strange, odd and wonderful \"90s News Groups\" alike quality. Despite the decline, I still find quite some value visiting this place every day.\n \nreply",
      "Agreed. HN was how I learned about tech growing up in poverty (back when I used to think Googlers all wore lab coats!) and gave me the inspiration to both study CS and pursue the career I was lucky enough to end up in. The bigger HN gets the more it has qualities I don't really like, but it's also the last text platform I consume without curation on my part. (I know dang and the mod team do a heroic job, but I do very little curation of my own here, unlike Bluesky, X, or Discord where I do a lot of things to keep my feeds/channels useful to me.)\n \nreply",
      "I agree. For me though it was only when slashdot started to shrink that I heard about HN, so I was a bit late to the party. To be fair, I still check slashdot almost daily!\n \nreply",
      "Happy birthday YC!  YC has created a ton of value, and I can say is responsible for the major inflection point in my career.  I'm forever grateful to Paul, Jessica, Robert, and Trevor for seeing the value in the reddit team before anyone else did.Incidentally, reddit turns 20 in just a few weeks (if you count from incorporation :) )\n \nreply"
    ],
    "link": "https://twitter.com/garrytan/status/1899092996702048709",
    "first_paragraph": ""
  },
  {
    "title": "Sorting Algorithm with CUDA (ashwanirathee.com)",
    "points": 23,
    "submitter": "ashwani-rathee",
    "submit_time": "2025-03-11T23:47:43 1741736863",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=43338405",
    "comments": [
      "This is not a fast way to sort on GPU. The fastest known sorting algorithm on CUDA is Onesweep, which uses a lot of sophisticated techniques to take advantage of GPU-style parallelism and work around its limitations.Linebender is working (slowly) on adapting these ideas to GPUs more portably. There's a wiki page here with some resources:https://linebender.org/wiki/gpu/sorting/\n \nreply",
      "Onesweep paper (Nvidia 2022): https://research.nvidia.com/publication/2022-06_onesweep-fas...Onesweep GitHub repo: https://github.com/b0nes164/GPUSorting\n \nreply",
      "The second one is Thomas Smith's independent reimplementation of Onesweep. For the official version, see https://github.com/NVIDIA/cccl . The Onesweep implementation is in cub/cub/agent/agent_radix_sort_onesweep.cuh .\n \nreply",
      "For a more convenient way to use GPUs for algorithms like this, the Futhark language [1] can be very valuable. It is a very high-level language that compiles to GPU instructions, which can be accessed as Python libraries. In their website there is an example of a merge sort implementation [2].[1] https://futhark-lang.org/\n[2] https://futhark-lang.org/examples/merge-sort.html\n \nreply",
      "Is this cross-platform in the sense that it will execute on AMD and Intel GPUs as well as NVIDIA?\n \nreply",
      "Do you use futhark in prod? Do you use it at all actually?\n \nreply",
      "Kind of a fun toy problem to play around with. I noticed you had thread coarsening as an option to play around with - there is often some gain to be had here. I think this is also a fun thing to play around with Nsight on - things that are impacting your performance aren't always obvious and it is a pretty good profiler - might be worth playing around with. (I wrote about a fun thing I found with thread coarsening and automatic loop unrolling with Nsight here: https://www.spenceruresk.com/loop-unrolling-gone-bad-e81f66f...)You may also want to look at other sorting algorithms - common CPU sorting algorithms are hard to maximize GPU hardware with - a network sort like bitonic sorting involves more work (and you have to pad to a power of 2) but often runs much faster on parallel hardware.I had a fairly naive implementation that would sort 10M in around 10ms on an H100. I'm sure with more work they can get quite a bit faster, but they need to be fairly big to make up for the kernel launch overhead.\n \nreply",
      "The TL;DR is the implementer was able to get use GPUs to get merge sort speedups that exceeded CPUs once the number of elements being sorted was >10,000,000.thrust::sort is an Nvidia C++ library; I am not clear whether it is related to CUDA or not actually; the article author started out with CUDA implementing a merge sort, but once it was slower than CPU the author tried thrust::sort library and was able to get a faster result in some cases.  The article author did not yet try a parallel merge sort.I would be curious if anyone knows what database engines take advantage of GPUs and see actual sort/query performance boosts and on what sized datasets. My impression is that a few engines have tried it, but the payoff is small enough that industry-wide people haven't adopted it.\n \nreply"
    ],
    "link": "https://ashwanirathee.com/blog/2025/sort2/",
    "first_paragraph": " Created in March 11, 2025    2025  \u00a0 \u00b7 \u00a0   sorting \u00a0 \u00b7 \u00a0   algorithms Building on my previous post on sorting algorithms, I implemented the same algorithms using CUDA to explore performance improvements through parallel computing. The goal is to see how we can leverage the power of parallel computing to speed up our sorting algorithms. I went for a NVIDIA recruiting event some days ago, that was a great event and it motivated me to try to rewrite the sorting algorithms using CUDA.I\u2019ll take merge sort as our test algorithm because it nicely divides the problem into smaller subproblems with two equal halves, which is a good fit for parallel computing.Below is the basic top down merge sort logic, where I recursively divide the array into two halves until I reach the base case of a single element, and then merge the sorted halves back together.To merge two sorted arrays, we compare their starting elements, pick the smaller one for the output array, and move the pointers forward.Now let\u2019s "
  },
  {
    "title": "Fastplotlib: GPU-accelerated, fast, and interactive plotting library (medium.com/caitlin9165)",
    "points": 325,
    "submitter": "rossant",
    "submit_time": "2025-03-11T16:33:24 1741710804",
    "num_comments": 124,
    "comments_url": "https://news.ycombinator.com/item?id=43334190",
    "comments": [
      "Every two weeks or so I peruse github looking for something like this and I have to say this looks really promising. In statistical genetics we make really big scatterplots called Manhattan plots https://en.wikipedia.org/wiki/Manhattan_plot and we have to use all this highly specialized software to visualize at different scales (for a sense of what this looks like: https://my.locuszoom.org/gwas/236887/). Excited to try this out\n \nreply",
      "Hey! This sounds like a really interesting use case. If you run into any issues or need help with the visualization, please don't hesitate to post an issue on the repo. We can also think about adding an example demo of a manhattan plot to help too!\n \nreply",
      "If you\u2019re working in R with ggplot2, you could also consider the `ggrastr` package, specifically, `ggrastr::geom_point_rast`\n \nreply",
      "> powered by WGPU, a cross-platform graphics API that targets Vulkan (Linux), Metal (Mac), and DX12 (Windows).The fact that they are using WGPU, which appears to be a Python native implementation of WebGPU, suggests there is an interesting possible extended case. As a few other comments suggest, if one knows that the data is available on a machine in a cluster rather than on the local machine of a user, it might make sense to start up a server, expose a port and pass along the data over http to be rendered in a browser. That would make it shareable across the lab. The limit would be the data bandwidth over http (e.g. for the 3 million point case) but it seems like for simpler cases it would be very useful.That would lead to an interesting exercise of defining a protocol for transferring plot points over http in such a way they could be handed over to a the browser WebGPU interface efficiently. Perhaps even a more efficient representation is possible with some pre-processing on the server side?\n \nreply",
      "> the data is available on a machine in a cluster rather than on the local machine of a userjupyter-rfb lets you do remote rendering for this, render to a remote frame buffer and send over a jpeg byte stream. We and a number of our scientific users use it like this. https://fastplotlib.org/ver/dev/user_guide/faq.html#what-fra...> defining a protocol for transferring plot pointsThis sounds more like GSP, which Cyrille Rossant (who's made some posts here) works on, it has a slightly different kind of use case.\n \nreply",
      "What is GSP in this context? Searching Python GSP brings up Generalized Sequence Pattern (GSP) algorithm [1] and Graph Signal Processing [2], neither of which seem to be a protocol. I also found \"Generic Signaling Protocol\" and \"Global Sequence Protocol\" which also don't seem relevant. Forgive me if GSP is some well know thing which I am just not familiar with.1. https://github.com/jacksonpradolima/gsp-py2. https://pygsp.readthedocs.io/en/stable/\n \nreply",
      "WGPU is a Rust thing more than a Python thing.\n \nreply",
      "Fair, I was looking at the wgpu-py [1] page but only skimmed it. It does indeed look like a wrapper over wgpu-native [2] which is written in Rust.1. https://github.com/pygfx/wgpu-py2. https://github.com/gfx-rs/wgpu-native\n \nreply",
      "I have watched recordings of your recent representation and decided to finally give it a try last week. My goal is to create some interactive network visualizations - like letting you click/box select nodes and edges to highlight subgraphs which sounds possible with the callbacks and selectors.Haven't had the time to get very far yet, but will gladly contribute an example once I figure something out. Some of the ideas I want to eventually get to is to render shadertoys(interactively?) into a fpl subplot (haven't looked at the code at all, but might be doable), eventually run those interactively in the browser and do the network layout on the GPU with compute shaders (out of scope for fpl).\n \nreply",
      "Hi! I've seen some of your work on wgpu-py! Definitely let us know if you need help or have ideas, if you're on the main branch we recently merged a PR that allows events to be bidirectional.\n \nreply"
    ],
    "link": "https://medium.com/@caitlin9165/fastplotlib-driving-scientific-discovery-through-data-visualization-418f8bff094c",
    "first_paragraph": ""
  },
  {
    "title": "New tools for building agents (openai.com)",
    "points": 254,
    "submitter": "meetpateltech",
    "submit_time": "2025-03-11T17:04:57 1741712697",
    "num_comments": 92,
    "comments_url": "https://news.ycombinator.com/item?id=43334644",
    "comments": [
      "I don't know how much this API churn is going to help developers who are trying to integrate OAI into real, actual, non-wrapper products. Every vendor-managed state machine that handles conversation, messages, prompt hand-off, etc., has ultimately proven inadequate, presumptive or distracting for my use cases.At the end of the day, all I ever seem to use is the chat completion API with structured outputs turned on. Despite my \"basic\" usage, I am employing tool use, recursive conversations, RAG, etc. I don't see the value in outsourcing state management of my \"agent\" to a 3rd party. I have way more autonomy if I keep things like this local.The entire premise of these products is that you are feeding a string literal into some black box and it gives you a new string. Hopefully, as JSON or whatever you requested. If you focus just on the idea of composing the appropriate string each time, everything else melts away. This is the only grain that really matters. Think about other ways in which we compose highly-structured strings based upon business state stored in a database. It's literally the exact same thing you do when you SSR a webpage with PHP. The only real difference is how it is served.\n \nreply",
      "I mirror this sentiment. Even their \"function calling\" abstraction still hallucinates parameters and schema, and the JSON schema itself is clearly way too verbose and breaks down completely if you feed it anything more complex than 5 very simple function calls. This just seems to build upon their already broken black box abstractions and isn't useful for any real world applications, but it's helpful for getting small proof-of-concept apps going, I guess...\n \nreply",
      "This bit feels like we are being pushed away from the existing API for non-technical reasons?> When using Chat Completions, the model always retrieves information from the web before responding to your query. To use web_search_preview as a tool that models like gpt-4o and gpt-4o-mini invoke only when necessary, switch to using the Responses API.Porting over to the new Responses API is non-trivial, and we already have history, RAG and other things an assistant needs already.\n \nreply",
      "I get the sense that these sorts of tools are more for power users than for software engineers with production AI experience.\n \nreply",
      "I just use OpenAI to help me build these \"necessary\" patterns against their own API.  Why make me use some framework when the AI is the framework?\n \nreply",
      "100%. I'll build the application, thanks.But you can't expect them not to try.\n \nreply",
      "\u201c These new tools streamline core agent logic, orchestration, and interactions, making it significantly easier for developers to get started with building agents\u201dSounds exactly like \u201cthe cloud\u201d, especially AWS. Basically \u201cget married to our platform, build on top of it, and make it hard to leave.\u201d The benefits are that it\u2019s easy to get started. And also that they invested in the infrastructure, but now they are trying to lock you in by storing as much state and data as possible with them withoit an easy way to migrate. So, increase your switching costs. For social networks the benefit was that they had the network effect but that doesn\u2019t apply here.\n \nreply",
      "There's a really good thread on Twitter from the designer of the new APIs going into the background behind many of the design decisions: https://twitter.com/athyuttamre/status/1899541471532867821Here's the alternative link for people who aren't signed in to Twitter: https://nitter.net/athyuttamre/status/1899541471532867821\n \nreply",
      "The nitter link is appreciated!\n \nreply",
      "TIL about Nitter, so grateful as I have Twitter blocked on my computer and phone.\n \nreply"
    ],
    "link": "https://openai.com/index/new-tools-for-building-agents/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Factorio Learning Environment \u2013 Agents Build Factories (jackhopkins.github.io)",
    "points": 600,
    "submitter": "noddybear",
    "submit_time": "2025-03-11T12:02:02 1741694522",
    "num_comments": 180,
    "comments_url": "https://news.ycombinator.com/item?id=43331582",
    "comments": [
      "OK, You\u2019ve permanently nerd-baited me, and I wish to apply for a job at the Anthropic Factorio lab immediately.I can\u2019t tell from the paper or these comments if you\u2019re sending multimodal data back \u2014 I\u2019m guessing no, because many of these models aren\u2019t multimodal. But some are \u2014 and of course we now have recently released Qwen 2.5 VLM which seems to be quite strong for its size.You harp on this lack of spatial ability a fair amount, which - fair enough - and you mention difficulties in both planning and spatial planning. Are you sending images back? If not, any thoughts on this?Thanks for this amazing bit of work, I really am reorganizing my day to play with it now.P.s. seems like MCP enabling the python library is a natural must-do so that all tool-enabled LLMs everywhere can play factorio.\n \nreply",
      "Currently it's a text-only modality environment but we are planning to support vision in the future. We did run a couple of tests and saw that including screenshots of the game state did not improve performance on the off-the-shelf models. As the complexity of the game state grew and the screenshots were filled with more entities, the models got even more confused and started hallucinating directions, entities etc or weren't capable of troubleshooting factories with apparent mistakes (i.e missing transport belt, wrongly rotated inserter). We think it's because the VLMs currently aren't good at spatial reasoning in high-detailed images, likely this would improve significantly with finetuningGood point with MCP as well given it has been blowing up lately, we'll look into that!\n \nreply",
      "That makes sense and it\u2019s really interesting - it is a challenging visual test for sure; thousands of entities, either multi tier visual representations (screen, map, overview map) or a GIANT high res image. I hereby propose FLE-V a subset benchmark for visual models where they just turn a factorio image into a proper FLE description. And maybe the overview and map images as well.\n \nreply",
      "Such research could have hundreds of billions of dollars in downstream GDP implications when applied to real industrial settings.\n \nreply",
      "Not to mention the increased productivity of everyone not wasting their time in factorio (myself included) because the optimal solution is known.\n \nreply",
      "Well I better get training!\n \nreply",
      "> As the complexity of the game state grew and the screenshots were filled with more entities, the models got even more confused and started hallucinating directions, entities etc or weren't capable of troubleshooting factories with apparent mistakes (i.e missing transport belt, wrongly rotated inserter). We think it's because [...]I think you just described a research paper that would advance sota. Less describing why, but how. (Assuming it's not just, wy finetuned the model and it worked perfectly)\n \nreply",
      "Sounds almost like a visual \"needle in a haystack\" type of work, that could be quite interesting!\n \nreply",
      "Where\u2019s Waldo test for vlm\n \nreply",
      "Why would screenshots be necessary if a textual description of the factory state is both easier to interpret and less prone to confusion? The game is played on a grid, so converting the game state to ascii ought to be trivial.\n \nreply"
    ],
    "link": "https://jackhopkins.github.io/factorio-learning-environment/",
    "first_paragraph": "Claude Sonnet 3.5 builds factories\n                                Large Language Models (LLMs) are rapidly saturating existing benchmarks, necessitating new open-ended evaluations.\n                                We introduce the Factorio Learning Environment (FLE), based on the game of Factorio, that tests agents in long-term planning, program synthesis, and resource optimization.\n                            \n                                FLE provides open-ended and exponentially scaling challenges - from basic automation to complex factories processing millions of resource units per second.\n                                We provide two settings:\n                            \n                                We demonstrate across both settings that models still lack strong spatial reasoning.\n                                In lab-play, we find that LLMs exhibit promising short-horizon skills, yet are unable to operate effectively in constrained environments, reflecting limitations i"
  },
  {
    "title": "NASA to launch space observatory that will map 450M galaxies (nbcnews.com)",
    "points": 159,
    "submitter": "gmays",
    "submit_time": "2025-03-08T00:07:15 1741392435",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=43296184",
    "comments": [
      "\"The SPHEREx mission <snip> will map the entire sky four times over two years, offering scientists a chance to study how galaxies form and evolve, and providing a window into how the universe came to be.\"So each object will be scanned ~6 months from the previous scan. How much evolving within the universe will be noticeable within that 2 year run? My gut response is not much, but that's why we do the science to see the changes.\"designed to map the celestial sky in 102 infrared colors \"So I'm guessing the coolant used to make IR scanning possible will be the limiting factor on operational time span. This article didn't say where this satellite will be parked either, but wikipedia[0] shows it to be a geosync orbit. Would have been interesting to be able to design a replaceable coolant module to extend the observations to really make seeing the evolution possible. Obviously complexity adds to cost and design time, so of course they didn't. Just dreamingAs an example, the study of the stars orbiting around SagA* are very revealing, but have required > 10 years of observations.[0] https://en.wikipedia.org/wiki/SPHEREx\n \nreply",
      "To answer three of your questions:- It is passively cooled rather than using an expendable coolant- \"SPHEREx relies on an entirely passive cooling system \u2014 no electricity or coolants are used, simplifying the spacecraft\u2019s design and operational needs.\"- It is a Medium-Class Explorers (MIDEX) mission - Investigations characterized by definition, development, mission operations, and data analysis costs not to exceed $180 to $200 million total cost to NASA. \nI think the cost of ground support eats into the budget length. The original estimate for project was $241M, so it was a large MIDEX- It is in a Polar orbit around Earth at the day-night (terminator) linehttps://www.jpl.nasa.gov/press-kits/spherex/https://explorers.gsfc.nasa.gov/missions.htmlhttps://spaceflightnow.com/2019/02/14/nasa-selects-mission-t...\n \nreply",
      "Possibly stupid question: how does this polar orbit stay over the terminator?  And how is the terminator defined for a polar orbit here, since both the north and south poles are on the terminator only at the equinoxes?\n \nreply",
      "ah, I misread the Orbital Parameters on the wiki. that day-night orbit is also a LEO which makes it even more possible to do a manned mission for upgrades. Oh, wait, we no longer have a shuttle for those types of missions.\n \nreply",
      "Even a Dragon could bring enough hardware and a crew for a small upgrade or repair (to say nothing of the upcoming Starship).\n \nreply",
      "Dragon lacks a Remote Manipulator System (Robot Arm) and a airlock. things that make servicing objects in space a lot easier. Im sure somewhere at NASA or SpaceX there is rough set of specs on what a shuttle like starship would look like complete with payload bay, robot arm, and eva airlock.\n \nreply",
      "The complete specs of the arm may now belong to a hostile nation.\n \nreply",
      "If you're alluding to Russia, they've had them. They even failed in making their version of a shuttle. With what money would they do anything with now?If you're alluding to China, they probably had the data from the Russians anyways.Otherwise, I'm out of guesses to your vagueness.\n \nreply",
      "Canada built the shuttle arms: https://en.m.wikipedia.org/wiki/Canadarm\n \nreply",
      "https://en.m.wikipedia.org/wiki/Canadarm#\n \nreply"
    ],
    "link": "https://www.nbcnews.com/science/space/nasa-spherex-space-observatory-launch-map-galaxies-universe-rcna190877",
    "first_paragraph": "ProfileSectionsLocaltvFeaturedMore From NBCFollow NBC News news AlertsThere are no new alerts at this timeA new NASA space observatory is scheduled to launch into orbit this week on a lofty mission to map more than 450 million galaxies.The SPHEREx mission (short for Spectro-Photometer for the History of the Universe, Epoch of Reionization and Ices Explorer) will map the entire sky four times over two years, offering scientists a chance to study how galaxies form and evolve, and providing a window into how the universe came to be.\u201cIt\u2019s going to answer a fundamental question: How did we get here?\u201d Shawn Domagal-Goldman, acting director of the astrophysics division at NASA headquarters, said in a recent news briefing.The launch from Vandenberg Space Force Base in California was paused for the night less than an hour before a scheduled 8:10 p.m. PT takeoff window on Monday.The launch window was pushed to 8:10 p.m. PT on Tuesday, NASA said.\"Due to unfavorable weather at the launch site and "
  },
  {
    "title": "In contrast to Earth, Mars's middle atmosphere appears driven by gravity waves (phys.org)",
    "points": 45,
    "submitter": "wglb",
    "submit_time": "2025-03-09T03:15:51 1741490151",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=43305842",
    "comments": [
      "Referenced article: https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023JE00...\n \nreply",
      "> Not to be confused with gravitational waves from massive stellar bodies, [gravity waves] are an atmospheric phenomenon when a packet of air rises and falls due to variations in buoyancy.For those similarly confused by the title as I.\n \nreply",
      "I used to thing programmers were bad a naming things until I became interested in physics.\n \nreply",
      "Related to this discussion, astronomers\u2019 usage of \u2018metal\u2019 is a fun example.\n \nreply",
      "\"it can't be that bad, can it?\"> astronomers use the word metals as convenient shorthand for all elements except hydrogen and heliumwhat, ok\n \nreply",
      "To keep on topic, that makes Earth's and Mars' atmospheres consist of metals.\n \nreply",
      "Isn't there predicted to be liquid metallic hydrogen in Jupiter's core?\n \nreply",
      "Yeah, fun, right?I've looked up why before, tldr it's just because historically astronomers have never had to care in any detail about chemical reactions (this is not strictly true of course, but somewhat close for at least a large subset). So they just need a term for \"crap that came from stars\".\n \nreply",
      "Eh, that grosses over the defining difference that hydrogen, helium, and a little bit of lithium are everywhere everywhen all at once because of The Bog Bang, whereas everything else is concentrated due to being produced in supernovas and neutron stars.\n \nreply",
      "And musicians!\n \nreply"
    ],
    "link": "https://phys.org/news/2025-03-contrast-earth-mars-middle-atmosphere.html",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: Sift Dev (YC W25) \u2013 AI-Powered Datadog Alternative",
    "points": 51,
    "submitter": "Akula112233",
    "submit_time": "2025-03-11T17:00:46 1741712446",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=43334589",
    "comments": [
      "Your python sdk's <https://pypi.org/project/sift-dev-logger> GH link is 404: <https://github.com/sift-dev/python-sdk> Navigating upward shows the fork of SigNoz which I think is funnyThere was no GH link for your npm dep so maybe they're both private. Although npmjs shows your npm one as ISC licensed, likely because of the default in package.json\n \nreply",
      "Can it run completely on prem ?In most of the industries I work in we would never just send you our logs.What stops me from building my own logger that sends a request to write a record to a DB and later asks an LLM what it means ?Where is the pricing information?Why do I need to login visit your homepage? How would I pitch this to my boss if they can\u2019t read what it does ?Edit:\nhttps://runsift.com/pricing.htmlI see the landing page. The pricing should be clear though \u201c Contact Us\u201d is scary.\n \nreply",
      "> Can it run completely on prem ?Yep we have an on-prem offering as well, got similar notes from folks before!> What stops me from building my own logger that sends a request to write a record to a DB and later asks an LLM what it means ?Great question! The main limitation over brute force is the sheer volume of noise, and therefore relevant context. We tried this and realized it wasn't working. From a numbers perspective, at even just 10s of GBs/day scale of data (not even close to enterprise scale), mainstream LLMs can't provide the context windows you need for more than a few minutes of operational data. And larger models suffer from other factors (like attention diffusion / dilution & drift).> I see the landing page. The pricing should be clear though \u201c Contact Us\u201d is scary.\nNoted!\n \nreply",
      "Thanks!I hope my tone wasn\u2019t too brash.If you can update the pricing I might be able to pitch this to my org later this year. We\u2019d definitely like an on prem solution though!\n \nreply",
      "> SiftDev flags silent failures, such as two microservices updating the same record within 50msI don't understand, what about that is a \"silent failure\"?in order for your product to even know about it, wouldn't I need to write a log message for every single record update?and if my architecture allows two microservices to update the same row in the same database...maybe it happening within 50ms is expected?that could be an inefficient architecture for sure, but I'm confused as to whether your product is also trying to give me recommendations about \"here's an architectural inefficiency we found based on feeding your logs to an LLM\"> You can then directly ask your logs questions like, \u201cWhat's causing errors in our checkout service?\u201d or \u201cWhy did latency spike at 2 AM?\u201d and immediately receive insightful, actionable answers that you\u2019d otherwise manually be searching for.the general question I have with any product that's marketing itself as being \"AI-powered\" - how do hallucinations get resolved?I already have human coworkers who will investigate some error or alert or performance problem, and come to an incorrect conclusion about the cause.when that happens I can walk through their thought process and analysis chain with them and identify the gap that led them to the incorrect conclusion. often this is a useful signal that our system documentation needs to be updated, or log messages need to be clarified, or a dashboard should include a different metric, etc etc.if I ask your product \"what caused such-and-such outage\" and the answer that comes back is incorrect, how do I \"teach\" it the correct answer?\n \nreply",
      "> I don't understand, what about that is a \"silent failure\"?Silent failures can be \"allowed\" behavior in your applications that aren't actually labeled as errors but can be irregular. Think race conditions, deadlocks, silent timeouts, or even just mislabeled error logs.> in order for your product to even know about it, wouldn't I need to write a log message for every single record update?That's right, and this may not always feasible (or necessary!), but if your application can be impacted by errors like these, perhaps it may be worth logging anyway.> the general question I have with any product that's marketing itself as being \"AI-powered\" - how do hallucinations get resolved?> and if my architecture allows two microservices to update the same row in the same database...maybe it happening within 50ms is expected?> if I ask your product \"what caused such-and-such outage\" and the answer that comes back is incorrect, how do I \"teach\" it the correct answer?For these concerns, human-in-loop feedback is our preliminary approach! We have our own internally running to account for changes and false errors, but having explanations from human input (even as simple as \"Not an error\" or \"Missed error\" buttons) is very helpful.> when that happens I can walk through their thought process and analysis chain with them and identify the gap that led them to the incorrect conclusion. often this is a useful signal that our system documentation needs to be updated, or log messages need to be clarified, or a dashboard should include a different metric, etc etc.Got it, I imagine it'll be very helpful for us to display our chain of thought from our dashboards too. Great feedback, thank you!\n \nreply",
      "Funny I was thinking this week logging needs some magic.Log diving takes a lot of time especially during some kind of outage/downtime/bug where the whole team might be watching a screen share of someone diving into logs.At the same time I am sceptical about \"AI\" especially if it is just an LLM stumbling around.Understanding logs is probably the most brain intensive part of the job for me, more so than system design, project planning or coding.This is because you need to know where the code is logging, imagine code paths in your head and you constantly see stuff that is a red herring or doesn't make sense.I hope you can improve this space but it won't be easy!\n \nreply",
      "Very relatable experience with log diving, feels very much like a needle-in-haystack problem that gets so much harder when you're not the only one who contributed to the source of errors (often the case).As for the skepticism with LLMs stumbling around raw logs: it's super deserved. Even the developers who wrote the program often refer to larger app context when debugging, so it's not as easy as throwing a bunch of logs into an LLM. Plus, context window limits & the relative lack of \"understanding\" with increasingly larger contexts is troublesome.We found it helped a lot to profile application logs over time. Think aggregation, but for individual flows rather than similar logs. By grouping and ordering flows together, it's bringing the context of thousands of (repetitive) logs down to the core flows. Much easier to find when things are out of the ordinary.Still a lot of improvements in regards to false positives and variations in application flows.\n \nreply",
      "The best way to improve this is to just generate decent useful and actionable logs. Sifting through a trash heap is where the problem is. No magic will suddenly turn that trash into gold.You have to do this at the inception of the software you\u2019re building rather then strap it on the donkey when something breaks (the usual way).\n \nreply",
      "Yep, but it's sometimes a compromise people may be unwilling to make. Too often I hear (and have seen via DD customers) horror stories about initiatives to fix observability squashed by teams in hopes of shipping.Moving fast has it's downsides and I can't say I blame people for deprioritizing good logging practices. But it does come back to bite...Though as a caveat, you don't always have control over your logs -- especially with third party services, large but fragmented engineering organizations, etc. -- even with great internal practices, there's always something.On another note, access to codebase + live logs gives room to develop better auto-instrumentation tooling. Though perhaps cursor could do a decent enough job at starting folks off\n \nreply"
    ],
    "link": "item?id=43334589",
    "first_paragraph": ""
  },
  {
    "title": "The US island that speaks Elizabethan English (bbc.com)",
    "points": 192,
    "submitter": "pseudolus",
    "submit_time": "2025-03-11T14:24:48 1741703088",
    "num_comments": 106,
    "comments_url": "https://news.ycombinator.com/item?id=43332752",
    "comments": [
      "One of the starting points of this article is that the current president has signed an executive order \"making English the country's official language\".I think it's important to remind people what executive orders can and can't do.  An executive order is an instruction sent to the government itself.  It instructs government workers how to perform their job.  It is not directed at the American public (though it can and does have an effect on the American public by way of government policy).As such, this current executive order effectively does nothing.  We've attempted to pass laws that make English the national language, but have consistently failed to do so.And personally, I'm for having English be the national language of America (as a bilingual American myself), but this executive order does not make that so.\n \nreply",
      "Reading the executive order[1], the only change is to revoke Clinton's executive order 13166 (\"Improving Access to Services for Persons With Limited English Proficiency\")[2]. There are no specific instructions of what it implies to revoke this order.My interpretation is that federal agencies will stop providing non-English services, unless these are already happening at 0 cost. (For example, not instructing agents to speak only English, but no longer considering second language proficiency in future hiring.)IANAL, but there may be legal complications, as order 13166's stated goal is to prevent title VI discrimination on the basis of national origin. However, the revocation explicitly states it should implemented consistently with applicable laws.[1] https://www.whitehouse.gov/presidential-actions/2025/03/desi...[2] https://www.transportation.gov/civil-rights/civil-rights-awa...\n \nreply",
      "> As such, this current executive order effectively does nothing.That's not true.  For example, there was a story the other day of a librarian who was instructed to throw away all passport application forms in Spanish, as they would no longer be accepted.If you go to the official Spanish page, you can see that the links to the forms are either broken or now redirected to their English version:https://travel.state.gov/content/travel/es/pasaportes/requis...That's just one example of many.\n \nreply",
      "I assume GP meant as a legal instrument, rather than it's sociological effect. (Otherwise there would be little point to the comment? They mean to prevent the latter by raising awareness of the former.)\n \nreply",
      "Thanks. Feels funny seeing people say this government is doing nothing or nonsense and has no ulterior motives or implications.\nFunny in the sense of: are they blind? are they naive? or are they supporters?Hundred of technocrats and modern nobility cannot be wrong.\n \nreply",
      "There's an effect to be sure.  I am, however, talking about legal status.  As one of the other commenters pointed out, the actual text of the executive action is about rolling back a previous executive action designed to prevent Title VI discrimination.  So, if I were affected as mentioned in the parent post to this, I would be reaching out to the ACLU to find a lawyer to help with challenging this.As to the stated wording though, \"making English the country's official language\" (which mirror's wording used in the most recent presidential address), the executive order has no power to do so, because it's not a law.\n \nreply",
      ">Funny in the sense of: are they blind? are they naive? or are they supporters?You\u2019re not understanding the comment you are laughing at.There was no legal change, there was an operations change in how the federal government does things.It\u2019s still legal to speak whatever language you want and you don\u2019t need to speak English\n \nreply",
      "i live in japan. i do all my paperwork in japanese. yes it is hard. no i dont think they need to offer it in english. i learn new kanji every time.\n \nreply",
      "Japan is famously anti-immigrant though.  Almost everyone in Japan is of Japanese ancestry.The USA was built on immigration.  It's called \"the great melting pot\" for a reason.\n \nreply",
      "There are many countries around the world which conduct paperwork in more than one language.\n \nreply"
    ],
    "link": "https://www.bbc.com/travel/article/20190623-the-us-island-that-speaks-elizabethan-english",
    "first_paragraph": "Native Americans, English sailors and pirates all came together on Ocracoke Island in North Carolina to create the only American dialect that is not identified as American.I'd never been called a \"dingbatter\" until I went to Ocracoke, North Carolina for the first time. I've spent a good part of my life in the state, but I'm still learning how to speak the\u00a0Hoi Toider\u00a0brogue. The people here just have their own way of speaking: it's like someone took Elizabethan English, sprinkled in some Irish tones and 1700s Scottish accents, then mixed it all up with pirate slang. But the Hoi Toider dialect is more than a dialect. It's also a culture, one that's slowly fading away. With each generation, fewer people play meehonkey, cook the traditional foods or know what it is to be \"mommucked\".In an effort to put his \"America first\" stamp on the nation's speech, US President Donald Trump recently signed an executive order making English the country's official language. It marks the first time in the "
  },
  {
    "title": "Show HN: We built a Plug-in Home Battery for the 99.7% of us without Powerwalls (pilaenergy.com)",
    "points": 160,
    "submitter": "coleashman",
    "submit_time": "2025-03-11T15:48:33 1741708113",
    "num_comments": 229,
    "comments_url": "https://news.ycombinator.com/item?id=43333661",
    "comments": [
      "Judging by the negativity here you're going to be a massive success -- search up the dropbox, airbnb, coinbase and ethereum launch threads if you want to feel good about where you're at. :)That said, I like this idea -- a modern coordinated UPS. I live in an area where people have 3-10 days a year of no power; being able to pick and choose what power they'd use during an outage would be a significant benefit to them.Good luck!\n \nreply",
      "Thanks so much! We'll address as much feedback as we can of course, but I hear you :D\n \nreply",
      "How many watts max output? Couldn't see it on the site. Thanks!\n \nreply",
      "Pila means cock (as in dick) in Portuguese and this whole post and website are hilarious. Dick energy. I'm holding off tears. Definitely wouldn't recommend plugging in your pila into any outlet.\n \nreply",
      "It also means battery in Spanish.\n \nreply",
      "And Italian. It\u2019s actually named after Alessandro Volta\u2019s (the guy who named the Volt) name for the \"Pila di Volta\" - his stack of soaked rags that stored electricity, or what we'd nowadays call a battery stack. Pila is a Pile that stores electricity or a Battery - Pila :)\n \nreply",
      "Huh. I always sorta associated the word with a voltaic pile ( https://en.wikipedia.org/wiki/Voltaic_pile ), which... https://en.wiktionary.org/wiki/pila gives an etymology of coming from Latin's \"p\u012bla\" = \"pillar\", which feels close? Or maybe it's just a coincidence.\n \nreply",
      "That\u2019s 100% it! It was named after the Voltaic Pile or Pile/Stack of Volts.\n \nreply",
      "One time set-up:\n1- Plug Pila in\n:D\n \nreply",
      "The results are shocking!\n \nreply"
    ],
    "link": "https://pilaenergy.com",
    "first_paragraph": "Get days of automatic backup power \u2014\u00a0Smart, silent, and safe.  Whether you own or rent, there\u2019s no rewiring necessary \u2014 Pila connects to a standard wall outletSmart software optimizes your home energy year-round and notifies you of anomaliesPila provides seamless, silent backup power \u2014 Whether you\u2019re home or away.Get instant outage notifications and see exactly how much backup time you have left.No tools, no rewiring \u2014 Pila plugs into a standard 120-volt wall outlet. Power passes through Pila\u2019s onboard battery to appliances and devices.Our Battery Mesh Network makes it easy to add Pila to new rooms and appliances across your home. Pairing takes seconds.Pila immediately starts working in the background to protect you from blackouts and optimize your energy.With right-sized power for your budget, Pila is backup power designed to grow with your needs.Monitor and control your home from anywhere in the worldSmarter over time with free over-the-air software updatesiOS & AndroidFree \u2014 No subs"
  },
  {
    "title": "A 10x Faster TypeScript (microsoft.com)",
    "points": 1369,
    "submitter": "DanRosenwasser",
    "submit_time": "2025-03-11T14:32:23 1741703543",
    "num_comments": 630,
    "comments_url": "https://news.ycombinator.com/item?id=43332830",
    "comments": [
      "Hi folks, Daniel Rosenwasser from the TypeScript team here. We're obviously very excited to announce this! RyanCavanaugh (our dev lead) and I are around to answer any quick questions you might have. You can also tune in to the Discord AMA mentioned in the blog this upcoming Thursday.\n \nreply",
      "Hey Daniel.I write a lot of tools that depend on the TypeScript compiler API, and they run in a lot of a lot of JS environments including Node and the browser. The current CJS codebase is even a little tricky to load into standard JS module supporting environments like browsers, so I've been _really_ looking forward to what Jake and others have said will be an upcoming standard modules based version.Is that still happening, and how will the native compiler be distributed for us tools authors? I presume WASM? Will the compiler API be compatible? Transforms, the AST, LanguageService, Program, SourceFile, Checker, etc.?I'm quite concerned that the migration path for tools could be extremely difficult.[edit] To add to this as I think about it: I maintain libraries that build on top of the TS API, and are then in turn used by other libraries that still access the TS APIs. Things like framework static analysis, then used by various linters, compilers, etc. Some linters are integrated with eslint via typescript-eslint. So the dependency chain is somewhat deep and wide.Is the path forward going to be that just the TS compiler has a JS interop layer and the rest stays the same, or are all TS ecosystem tools going to have to port to Go to run well?\n \nreply",
      "Reading the article, it looks like they are writing go, so will probably be distributing go binaries.\n \nreply",
      "Maybe they'll also be distributed in WASM too, which is easier to be integrated with JavaScript codebases.\n \nreply",
      "Would running WASM be any faster than running JS in V8?\n \nreply",
      "In my experience it is pretty difficult to make WASM faster than JS unless your JS is really crappy and inefficient to begin with. LLVM-generated WASM is your best bet to surpass vanilla JS, but even then it's not a guarantee, especially when you add js interop overhead in. It sort of depends on the specific thing you are doing.I've found that as of 2025, Go's WASM generator isn't as good as LLVM and it has been very difficult for me to even get parity with vanilla JS performance. There is supposedly a way to use a subset of go with llvm for faster wasm, but I haven't tried it (https://tinygo.org/).I'm hoping that Microsoft might eventually use some of their wasm chops to improve GO's native wasm compiler. Their .NET wasm compiler is pretty darn good, especially if you enable AOT.\n \nreply",
      "I think the Wasm backends for both Golang and LLVM have yet to support the Wasm GC extension, which would likely be needed for anything like real parity with JS.  The present approach is effectively including a full GC implementation alongside your actual Golang code and running that within the Wasm linear memory array, which is not a very sensible approach.\n \nreply",
      "> the Wasm GC extension, which would likely be needed for anything like real parity with JSWell, for languages that use a GC. People who are writing WASM that exceeds JS in speed are typically doing it in Rust or C++.\n \nreply",
      "The major roadblocks for WasmGC in Golang at the moment are (A) Go expects a non-moving GC which WasmGC is not obligated to provide; and (B) WasmGC does not support interior pointers, which Go requires.https://github.com/golang/go/issues/63904#issuecomment-22536...\n \nreply",
      "These are no different than the issues you'd have in any language that compiles to WasmGC, because the new GC'd types are (AIUI) completely unrelated to the linear \"heap\" of ordinary WASM - they are pointed to via separate \"reference\" types that are not 'pointers' as normally understood.  That whole part of the backend has to be reworked anyway, no matter what your source language is.\n \nreply"
    ],
    "link": "https://devblogs.microsoft.com/typescript/typescript-native-port/",
    "first_paragraph": "Today I\u2019m excited to announce the next steps we\u2019re taking to radically improve TypeScript performance.The core value proposition of TypeScript is an excellent developer experience.\nAs your codebase grows, so does the value of TypeScript itself, but in many cases TypeScript has not been able to scale up to the very largest codebases.\nDevelopers working in large projects can experience long load and check times, and have to choose between reasonable editor startup time or getting a complete view of their source code.\nWe know developers love when they can rename variables with confidence, find all references to a particular function, easily navigate their codebase, and do all of those things without delay.\nNew experiences powered by AI benefit from large windows of semantic information that need to be available with tighter latency constraints.\nWe also want fast command-line builds to validate that your entire codebase is in good shape.To meet those goals, we\u2019ve begun work on a native por"
  },
  {
    "title": "What Ketamine Does to the Human Brain (theatlantic.com)",
    "points": 25,
    "submitter": "aagha",
    "submit_time": "2025-03-12T00:29:54 1741739394",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.theatlantic.com/health/archive/2025/03/ketamine-effects-elon-musk/681911/",
    "first_paragraph": "Excessive use of the drug can make anyone feel like they rule the world.Produced by ElevenLabs and  News Over Audio (Noa) using AI narration. Listen to more stories on the Noa app.Last month, during Elon Musk\u2019s appearance at the Conservative Political Action Conference, as he hoisted a chain saw in the air, stumbled over some of his words, and questioned whether there was really gold stored in Fort Knox, people on his social-media platform, X, started posting about ketamine.Musk has said he uses ketamine regularly, so for the past couple of years, public speculation has persisted about how much he takes, whether he\u2019s currently high, or how it might affect his behavior. Last year, Musk told CNN\u2019s Don Lemon that he has a ketamine prescription and uses the drug roughly every other week to help with depression symptoms. When Lemon asked if Musk ever abused ketamine, Musk replied, \u201cI don\u2019t think so. If you use too much ketamine you can\u2019t really get work done,\u201d then said that investors in hi"
  },
  {
    "title": "India's Battle to Control the Democracy Narrative (theplankmag.com)",
    "points": 59,
    "submitter": "ethan_smith",
    "submit_time": "2025-03-11T20:50:39 1741726239",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=43336872",
    "comments": [
      "The Economist has a democracy index. The US dropped to \"flawed democracy\" after the coup attempt and has not recovered.[1][1] https://en.wikipedia.org/wiki/The_Economist_Democracy_Index\n \nreply",
      "A few things that stand out (not that it's that shocking!)- Narratives matter -- a lot . Second order effects of such subjective rankings are real . Imagine getting a credit downgrade because someone perceives the democracy to be under threat- \"the government had reverse-engineered the ranking, strategically identifying procedural tweaks that directly boosted India\u2019s scores in Delhi and Mumbai\u2014the two cities evaluated by the World Bank\" .I love the whole cynical nature of this. This is statecraft at it's finest ( I render no moral judgements here :) ). This is reminiscent of Machiavelli or Kautilya (Chanakya) [0]A lot more to digest but will post them as a reply on this thread.[0] https://en.wikipedia.org/wiki/Chanakya\n \nreply",
      "Statecraft at its finest? Next, I'll hear that KPI manipulation sets the standard for good engineering...\n \nreply",
      "The real question is why did anyone even think KPIs were effective in the first place.\n \nreply",
      "I once took a deep dive into the methodology of one of the custodians of \"democracy rankings\". It is one of the 2 most popular custodians.Their methodology for each country was different.For India their methodology was to survey 36 important people in the country. They did not disclose who these people were.The survey asked them to share whether democracy was \"backsliding\" or whether it was becoming stronger, than the past.\n \nreply",
      "A pivotal quote in the article:>How could theocratic states with no separation of religion and government score higher than India? How could a country with universal suffrage and constitutional rights rank below nations that didn\u2019t even hold elections?Since the article talks quite a bit about Sanjeev Sanyal, I think it might be interesting to point to some of his podcasts.Like this one: https://www.youtube.com/watch?v=yiW-mH4qIOQ. Here he points out how the media has misrepresented India and exaggerated and sensationalized issues.Similarly, India has taken criticism from the West over its more ambitious projects like Sardar Vallabhai Patel's statue, and the space program. So taking the West's word with a grain of salt is quite valid.Further, the article points out that the government is trying to game the ranking while outwardly saying that they don't matter. This seems hypocritical at first glance but it also points out that having lower rankings affects investor confidence and borrowing rates. You can be against a broken system while still trying to appease it because it's not going to change immediately. The Indian Government needs to work within the system until something better can be created.I am not fully supportive of everything the NDA government has done but I don't think there is another leader in India who can feasibly win an election right now and I refuse to support INC until they get rid of the Gandhi dynasty.Also, please look at the podcast from this timestamp[2], where he further shows why people in general but Indians specifically should be skeptical of Western narratives. This is also supported by the book Unnatural Selection by Mara Hvistendahl[2]:https://youtu.be/gNVMvlfMbCU?list=PLgZQtm7d9Z1K9TCynoA3S0QWv...\n \nreply",
      "Sometimes I do find it bizzare when western media praises a theocratic absolute monarchy like Saudi Arabia for \u201cmodernizing\u201d (by allowing women to drive and allowing them to not have chaperones) while simultaneously these same media organizations accuse a constitutional liberal democracy like India (which has strict separation of powers and an active independent Supreme Court) of somehow being authoritarian or fascist or some other slur.\n \nreply",
      "The BJP is certainly authoritarian and fascistic, this is not contested. The country itself though probably isn\u2019t. They failed to get an outright majority in the recent elections, and perhaps the main reason they still win is the opposition is completely incapable of reform (like the OP said they keep putting up members of the Gandhi family despite them losing elections repeatedly).\n \nreply",
      "> The country itself though probably isn\u2019t.It's hard to define that - on average? In the long run? What would a Indian who is Muslim say - 'well, it's ok because on average or in the long run, it's ok'?\n \nreply",
      "Has there been an Indian government that will be viewed favorably through western lenses?- Pt. Nehru wanted Socialism and State Control.- Indira Gandhi brought the Emergency and all that came with \nthat- PM Vajpayee conducted the nuclear test- PM Modi is viewed as an authoritarian and fascistI think these cover the most influential leaders over the last 75 years. Only PM  Manmohan Singh stands up to such scrutiny.\n \nreply"
    ],
    "link": "https://www.theplankmag.com/india-democracy-narrative",
    "first_paragraph": "We will email you when we publish. No spam. Sign up.In March 2021, at the India Today Conclave, External Affairs Minister S. Jaishankar openly dismissed international democracy rankings. You have a set of self-appointed custodians of the world, who find it very difficult to stomach that somebody in India is not looking for their approval...They invent their rules, their parameters, pass their judgements, and then make out as though this is some kind of global exercise.To Jaishankar, these rankings were not some neutral measure of governance. They were political tools wielded against countries that refused to follow Western-defined standards. His comments were a direct response to India\u2019s democratic downgrade by international agencies. Freedom House, the U.S.-based watchdog monitoring global democratic rights, had stripped India of its \u201cfree\u201d status for the first time since the Emergency era of 1975-77, highlighting specific concerns such as increasing violence targeting Muslims, restri"
  },
  {
    "title": "What Is It Like to Be a Bass? Fish-Eye View Photography (1919\u201322) (publicdomainreview.org)",
    "points": 5,
    "submitter": "prismatic",
    "submit_time": "2025-03-08T05:02:28 1741410148",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://publicdomainreview.org/collection/fish-eye-view-photography/",
    "first_paragraph": "Search The Public Domain ReviewIn a series of publications spanning the 1910s and 1920s, anglers attempted to crack the puzzle of fishing \u2014 what makes a fish bite, or not \u2014 through photography. Fisherman-scientists experimented with the cameras of their day to capture the world as seen from the fish\u2019s eye. They created above-ground observation tanks, cordoned off sections of streams, and submerged \u201cperiscope\u201d-like devices encased in glass. They grappled with dilemmas of distortion and refraction. Ultimately, the images they produced \u2014 of flies (real and fake) suspended on the water\u2019s surface, of fishing line, and sometimes even of the photographers themselves \u2014 have their own avant-garde quality. These photos are an exercise in cross-species empathy: they are an effort to enter the mind of the fish through the lens of the camera.\u201cImagine yourself, then, under the water, on the bed of a river. Seen from below, the surface of the water would appear as an extensive mirror, with the river-"
  },
  {
    "title": "Continue (YC S23) Is Hiring a Software Engineer in San Francisco (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-03-11T21:01:39 1741726899",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/continue/jobs/smcxRnM-software-engineer",
    "first_paragraph": "Create, share, and use custom AI code assistantsContinue is seeking an outstanding software engineer to help us build state-of-the-art autocomplete and codebase retrieval, who thinks rigorously and pays attention to the smallest details. In this role, you will work on fundamental, but highly open-ended problems where deliberate measurement, rapid experimentation, and empathy for users push forward the product.About youPlease keep in mind that we are describing the background that we imagine would best fit the role. If you don\u2019t meet all the requirements, but you are confident that you are up for the task, we absolutely want to get to know you!What you will doWe\u2019re a startup, so you\u2019ll have to be ready to do whatever is required to accomplish our mission. However, you can definitely expect to:We believe there is an opportunity to create a future where developers are amplified, not automated. This is why we are enabling developers to create, share, and use custom AI code assistants with "
  },
  {
    "title": "Show HN: Krep a High-Performance String Search Utility Written in C (davidesantangelo.github.io)",
    "points": 122,
    "submitter": "daviducolo",
    "submit_time": "2025-03-11T16:12:43 1741709563",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=43333946",
    "comments": [
      "Those CPU features (AVX2 and whatnot) need to be detected at runtime, too, however.Those ifdefs only detect if the compiler supports them, i.e. at build-time only.So... your program only compiles with AVX2 and others if the compiler supports them; so you should compile where the compiler has all those features (because you want everything to be compiled into one executable, of course), and then use runtime checks to make sure the CPU on which the program is run has actually support for AVX2, for example, as it can select the best implementation based on the available CPU features.To make things a bit more complicated, let me quote a part from one of the projects he has: \"The detection is performed at configure time through both CPUID flags and actual instruction execution tests on the host machine, verifying support in both the CPU and operating system.\". Currently what you are doing is the \"OS\", or rather, compiler, since you are using only macro definitions.Once you add this, then \"Automatically leverages SSE4.2 and AVX2 instructions when available for maximum throughput.\" from the list of features on the website will be correct / accurate.If interested, someone I know (or rather, follow) has a single header file for detecting CPU features at runtime (for C), and he also has a build-time detection one, but that has much more features.\n \nreply",
      "You can read my blog post about the project at https://dev.to/daviducolo/introducing-krep-building-a-high-p...\n \nreply",
      "Interesting.  You may be interested in a more modern search algorithm to replace Boyer Moore.  I recently presented HashChain, a very fast sublinear search algorithm at the Symposium of Experimental Algorithms.https://drops.dagstuhl.de/storage/00lipics/lipics-vol301-sea...It's the fastest sublinear search algorithm around in almost all cases.  I also have a guaranteed worst-case linear version (which is still sublinear and much faster than Boyer Moore in the average case).Sample code is available here:https://github.com/nishihatapalmer/HashChainIf you're interested, let me know.\n \nreply",
      "Hi David.    $ (for x in `seq 1 100000`; do echo 'I am a Test Vector HeLlO World '\"$x\"; done) > /dev/shm/krep_tmp\n\nBest of three runs shown:    $ time ./krep -i hello /dev/shm/krep_tmp\n    Found 43721 matches\n    Search completed in 0.0017 seconds (2017.44 MB/s)\n    Search details:\n      - File size: 3.52 MB\n      - Pattern length: 5 characters\n      - Using AVX2 acceleration\n      - Case-insensitive search\n    real        0m0,005s\n    user        0m0,001s\n    sys         0m0,004s\n    $ time ./krep HeLlO /dev/shm/krep_tmp\n    Found 82355 matches\n    Search completed in 0.0014 seconds (1259.72 MB/s)\n    Search details:\n      - File size: 1.71 MB\n      - Pattern length: 5 characters\n      - Using AVX2 acceleration\n      - Case-sensitive search\n    real        0m0,004s\n    user        0m0,003s\n    sys         0m0,004s\n    $ time ./krep -i \"HeLlO World\" /dev/shm/krep_tmp\n    Found 99958 matches\n    Search completed in 0.0021 seconds (1700.54 MB/s)\n    Search details:\n      - File size: 3.52 MB\n      - Pattern length: 11 characters\n      - Using AVX2 acceleration\n      - Case-insensitive search\n    real        0m0,005s\n    user        0m0,002s\n    sys         0m0,004s\n    $ time ./krep \"I am a Test Vector HeLlO World\" /dev/shm/krep_tmp\n    Found 3964 matches\n    Search completed in 0.0149 seconds (235.83 MB/s)\n    Search details:\n      - File size: 3.52 MB\n      - Pattern length: 30 characters\n      - Using AVX2 acceleration\n      - Case-sensitive search\n    real        0m0,016s\n    user        0m0,015s\n    sys         0m0,001s\n    $ time ./krep -i \"I am a Test Vector hello World\" /dev/shm/krep_tmp\n    Found 3964 matches\n    Search completed in 0.0178 seconds (197.70 MB/s)\n    Search details:\n      - File size: 3.52 MB\n      - Pattern length: 30 characters\n      - Using AVX2 acceleration\n      - Case-insensitive search\n    real        0m0,021s\n    user        0m0,017s\n    sys         0m0,004s\n\nBenchmark with fgrep (the first run was good enough):    $ time fgrep -ci hello /dev/shm/krep_tmp\n    100000\n    real        0m0,003s\n    user        0m0,003s\n    sys         0m0,000s\n    $ time fgrep -ci \"I am a Test Vector hello World\" /dev/shm/krep_tmp\n    100000\n    real 0m0,010s\n    user 0m0,009s\n    sys         0m0,000s\n    $ time fgrep -c \"I am a Test Vector HeLlO World\" /dev/shm/krep_tmp\n    100000\n    real 0m0,005s\n    user 0m0,004s\n    sys         0m0,001s\n\nThis is a model name: Intel(R) Core(TM) i9-10900K CPU @ 3.70GHz. There's 40gb of ram free and 10 cores doing nothing. shell is cpuset. On commit 95ed1853b561396c8a8bcbbdd115ed6273848e3f (HEAD -> main, origin/main, origin/HEAD). gcc is 13.3.0-6ubuntu2~24.04tl;dr: krep produces obviously wrong results slower than fgrep.\n \nreply",
      "Consider using a bigger haystack. Your timings are so short that you're mostly just measuring the overhead of running a process.This is relevant to krep because it spawns threads to search files (I guess for files over 1MB?).This does not mean your benchmark is worthless. It just means you can't straight-forwardly generalize from it.\n \nreply",
      "The incorrect results are far more important than the times!\n \nreply",
      "I agree.\n \nreply",
      "That's a good point, though the readme does flatly state that krep \"is designed with performance as a primary goal,\" so the lede's generalization that it is \"blazingly fast\" isn't correct, despite the later, more deeply buried caveat that \"Performance may vary based on hardware, file characteristics, and search pattern\" (which describes all software). And the comment you answered doesn't say just that krep is \"slower\" than fgrep; it says krep \"produces obviously wrong results\" slower.Edit: and the fact that krep lacks regular-expression support means it's not a replacement for grep or meaningfully comparable with it.\n \nreply",
      "I try my best to interpret pithy phrases describing a project as first order approximations, rather than literal statements of truth that perfectly generalize. Pithiness is important for communicating ideas quickly, but precision and pithiness are often in tension with one another. So I adjust my expectations accordingly.Yes, I agree that the wrong results are bad. But that doesn't invalidate my point. I even went out of my way to clarify that the benchmark wasn't worthless. Benchmarking the small input case is absolutely worth it. You just can't tell much about its scaling properties when your measurement is basically \"how fast does the process start and stop.\" Which, again, to be clear, IT MATTERS. It just probably doesn't matter as much as readers might think it matters when they see it.So treat my comment as adding helpful context for readers that aren't experts in benchmarking grep tools from someone experienced in... benchmarking grep tools. :-) (And regexes in general. See: https://github.com/BurntSushi/rebar)\n \nreply",
      "I'm curious why krep runs faster with large files in a multithreaded manner?Naively, isn't IO the bottleneck?IE, I'd think that loading a file would be slow enough that krep would be IO-bound?Do you have a typical ratio of IO time to search time on a modern disk and CPU?What about a producer-consumer model where one thread reads files and creates an in-memory queue of file contents; and a different thread handles the actual searching without pauses for IO?Edit: If you're truly CPU-bound, another variation of producer-consumer is to have a single thread read files into queues, and then multiple threads searching through files. Each thread would search through a single file at a time. This eliminates the shared memory issue that you allude to with overlap.\n \nreply"
    ],
    "link": "https://davidesantangelo.github.io/krep/",
    "first_paragraph": "A blazingly fast string search utility for performance-critical applicationsOptimized algorithms and memory-mapped file I/O deliver up to 5x faster search speeds than traditional tools.Automatically leverages SSE4.2 and AVX2 instructions when available for maximum throughput.Parallel processing for large files with intelligent chunk boundaries to ensure accurate results.Dynamically chooses the best algorithm based on pattern characteristics and hardware capabilities.Uses memory mapping and minimal allocations to reduce memory overhead while maintaining performance.Familiar command-line interface that's easy to use while providing powerful capabilities.# Basic search$ krep \"error\" system.log# Case-insensitive search with 8 threads$ krep -i -t 8 \"ERROR\" large_logfile.log# Count occurrences only$ krep -c \"TODO\" *.c# Search within a string$ krep -s \"Hello\" \"Hello world\"\n                krep consistently outperforms traditional search tools across various file sizes and search patterns.\n   "
  },
  {
    "title": "Ask HN: How do you handle VAT / Sales Tax accounting as B2C SaaS?",
    "points": 36,
    "submitter": "throw_1VJ51pMb",
    "submit_time": "2025-03-08T08:57:10 1741424230",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=43298663",
    "comments": [
      "Anrok is great! Anrok generates and files US returns. We still have to file EU OSS returns quarterly (based on the Reports created by Anrok), but it's manageable. Stay far away from Avalara... it's unusable and the contracts are predatory IMO. Filing UK VAT has been a mess.I'm @ a US-SaaS company using Stripe and Quickbooks.\n \nreply",
      "EU SaaS solo owner here (about 10 years so far). I gave up on B2C entirely. It's just too much hassle. My accountant starts screaming in horror whenever I mention VAT MOSS. Whenever I looked into the rules, I saw a snake pit with moving snakes.Additionally, B2C has tight margins, so eating into those hurts a lot.Whenever I looked at companies like Quaderno, they looked great, but when I actually tried to use them, it turned out that their solutions are far from perfect and often incomplete or simply incorrect (e.g. I would not comply with local laws in my country). This is a common theme: even B2B invoicing, which is far simpler, is not implemented correctly by companies that say they do \"invoicing\". For example, Stripe invoicing won't do JPK_FA or KSeF in Poland (SAF-T reporting), which pretty much makes it a no-go. Many service providers are also incapable of producing bi-lingual invoices.I ended up using Braintree (don't make that mistake) and now I'm migrating to Stripe \u2014 but for payments only. I have my own subscriptions and invoicing, and I use a local (Polish) company that has an invoicing API to produce JPK_FA/KSeF data.If I were to even look at B2C, I wouldn't even consider doing anything on my own. I would go with Paddle, carefully considering my margins.I realize this is not the answer you were looking for but it's a real-life data point.\n \nreply",
      "What a big question. With so many new sales taxes hitting rhe world its now a nightmare for us global companies, especially in the digital services and the travel industry.We employ our own bookkeepers (in Africa) who operate a range of accounting systems for each company in the group (5 countries).As CEO I tend to do the teaching and review but the team does the lodgement.  (I am an Australian Chartered Accountant and former tax agent so get the rules fairly easily).Most lodgements are online. The US is the exception. We also find there are free services for lodging electronically.A lot of the accounting systems are way overpriced so we don't use many of their up market solutions.We have built our own invoicing and Billing system this week with AI so expect we'll create more of our own apps over the coming year.My bookkeeping team has some spare capacity so let me know if we can maybe help you out.\n \nreply",
      "We use Sphere ( https://www.getsphere.com ), and it\u2019s the only good solution I know of for international VAT that handles everything end-to-end (registration, calculation, filing, and remittance).We use Stripe Billing, and we actually use Anrok for US sales tax compliance. They\u2019re solid domestically, but they don\u2019t do international registration, filing, and remittance; they only do calculation.There are also firms like VAT IT (vatcompliance.com) that can do this if you want to work with a more traditional service provider.\n \nreply",
      "Hey, just curious, since you actually might know about this. My country (Norway) has extremely strict import rules. All items must have the VAT paid on them, and if they don\u2019t, you have to pay the VAT plus an administrative fee in order to pick up the item. However, there have been plenty of times where I paid VAT to the store, but then I still get charged VAT upon pick up.  According to the postal service, this is because \u201cthe company didn\u2019t register their VOEC number electronically for the shipment\u201d and then they tell me to get the company to refund the VAT, and I guess go fuck myself for the administration fee.Leaving aside the utter garbage that is the Norwegian postal system, do you know what that means? Is that something that just happens as a matter of course when using Sphere? Is that a common feature among platforms that offer the service? I have no clue how unique Norway is or isn\u2019t in this regard, but I imagine countries in general want to collect VAT for imports.\n \nreply",
      "This isn't really related, as I understand it.The Norwegian VOEC system[1] is modeled on the EU IOSS system[2].As with normal import declarations, missing documentation means you cannot claim any exceptions etc. Thus if the store forgot to register the VOEC number when they shipped the item, the one filing the declaration, say the postal service, has to assume VAT hasn't been paid.Now, if this had been a normal customs declaration, one could simply submit a corrected declaration with the correct documentation later. However, since such low-value goods aren't declared using a normal customs declaration, one cannot do this.They also don't want spend their resources cleaning up someone else's mess, thus they leave it up to the shop that made the error to fix the problem by reimbursing you the VAT they collected.And yes, as a customer this sucks, as the shop often will just shrug and claim they don't know or they did the right thing.[1]: https://www.skatteetaten.no/en/person/duties/purchases-from-...[2]: https://vat-one-stop-shop.ec.europa.eu/index_en\n \nreply",
      "i think this matter is confused because it contains two distinct things:a.) accounting for the VAT owned to dozens different countries andb.) \"remitting\": actually paying the VAT to the tax agencies of dozens different countriesmany services help with part a.), but i haven't found a single one that helps with part b.) - you can only circumvent the issue by selling on a platform (like the different app stores or \"FastSpring\" or awful awful \"Paddle\") that do it for you because they are the merchant-of-recordour solution is to defer all payments for countries that collect VAT (EU plus UK plus like a dozen evil ones [1]) to FastSpring (which collects AND remits VAT), while selling to countries that don't collect VAT via Stripe.this works well if you are a small company and you fall below the \"VAT thresholds\" in place by most countries, but if you are big and breach most thresholds this solution is less effective.[1] AE, AL, AO, BH, BY, CH, CL, CO, CR, DZ, EC, GE, IN, KE, KR, MD, MX, RS, RU, SA, TJ, UG, VN\n \nreply",
      "What are your issues with paddle? I found them perfectly fine fwiw.Why is this related to thresholds if you're using a merchant of record?You can't do this on country codes, if you're going to do this I would suggest whitelisting country's you know not to charge vat anywhere inside the country rather than vice versa.\n \nreply",
      "In case someone thinks this stuff is simple and you can go with country codes for VAT: have you heard about countries like AX (\u00c5land Islands, part of Finland)? Do you remember that GB used to be within the EU VAT zone, but now isn't? How about handling XI (Northern Ireland) and the migration of customers from GB to XI? Or (one of my favorites) \u2014 do you realize that parts of ES are not within the EU VAT zone (for example, Canary Islands)?This stuff is crazy. B2B sales are relatively simple, but B2C is a nightmare.\n \nreply",
      "Can you elaborate on your bad experiences with Paddle?\n \nreply"
    ],
    "link": "item?id=43298663",
    "first_paragraph": ""
  },
  {
    "title": "The Startup CTO's Handbook (github.com/zachgoldberg)",
    "points": 47,
    "submitter": "simonebrunozzi",
    "submit_time": "2025-03-11T22:18:42 1741731522",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=43337703",
    "comments": [
      "One way I try to get my head around things like this is to skip to a section I understand deeply and see what they said. Here, the claim is made:Don't try to get a compliance certificate at the last minute. Preparing for and conducting an audit such as for PCI DSS or SOC 2 from start to finish is a lengthy process, ranging from six to twelve months for most startups. Starting early and maintaining compliance is cheaper than starting late and doing rework.This is basically the opposite of the advice I would give a startup. SOC2 attestations in particular are easy to get, and are a waste of money to obtain preemptively before there are purchase orders on the line for them.There are things you should start doing early that lay the groundwork for attestations, but you should be doing them anyways, even if you never plan to get a SOC2 (and if a big-ticket customer never demands it, you shouldn't SOC2). That's stuff like setting up single sign-on and having protected git branches; simple best practices.Anyone else want to spot check other parts of this document? I wouldn't feel qualified to challenge most of it.\n \nreply",
      "Made an account just to say that I respectfully disagree solely when it comes to accounting and supply chain processes in an enterprise ERP. Unwinding un-auditable processes costs so much f\u2019ing time and money while the business still has to run that I\u2019ve found it to be cheaper and better to be auditable from day 1, in this one specific instance.\n \nreply",
      "Yeah, in my experience, most companies who are going to 1) do business with early stage startups and 2) want SOC2 report, are going to be totally fine with writing \u201cstartup X will get their SOC2 type 1 in the next six months\u201d into the contract and moving forward, so long as someone technical can get on the phone with their IT people convince them you are reasonably competent.\n \nreply",
      "Great approach. I ctrl-F'd for databases, good info there generally. The only thing that gave me pause: a startup doesn't need to focus on SQL vs. NoSQL in 2025 with such good json support in the most popular SQL databases. Just use PostgreSQL or MySQL -- whichever your engineers have more experience with -- use CloudSQL or RDS which will take care of the hard stuff like backups and replication for you, use read replicas for BI with a good visualization tool, you'll be good with that for a good while before you need to fork over 5/6 figures for Snowflake or anything else.\n \nreply",
      "Has anyone worked in a \"two crews\" system where there wasn't resentment? Or where people didn't want to naturally migrate to the \"future crew\".I like the idea of this on paper. I have a hard time believing it can work in practice. The closest I've seen are library teams that build some service (say a design system + components) that other teams utilize.\n \nreply",
      "Popular in 2023 (452 points, 156 comments) https://news.ycombinator.com/item?id=37971795\n \nreply"
    ],
    "link": "https://github.com/ZachGoldberg/Startup-CTO-Handbook/blob/main/StartupCTOHandbook.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          Disclaimer:The publisher and the author make no representations or warranties of any kind with respect to this book or its contents, and assume no responsibility for errors, inaccuracies, omissions, or any other inconsistencies herein.At the time of publication, the URLs displayed in this book refer to existing websites owned by the author and/or the author's affiliates. WorldChangers Media is not responsible for, nor should be deemed to endorse or recommend, these websites; nor is it responsible for any website content other than its own, or any content available on the Internet not created by WorldChangers Media.2023, Zach Goldberg, zach@zachgoldberg.comPaperback: 978-1-955811-56-9Ebook: 978-1-955811-57-6Library of Congress Control Number: 2023918702Cover design: Michael Rehder /www.rehderandcompanie.com/\nLayout and typesetting: Paul Baill"
  },
  {
    "title": "Backyard Cyanide (suziepetryk.com)",
    "points": 102,
    "submitter": "tancik",
    "submit_time": "2025-03-11T17:46:01 1741715161",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=43335110",
    "comments": [
      "Stonefruit pits contain cyanide. (Including almonds.) I made apricot preserves one time and the recipe called for slivered pits to add a bit of flavor. Research it, it appears that you'd need to eat several hands full to poison yourself. And since it doesn't bioaccumulate, eating tiny bits is probably okay. (YMMV/not a doctor/don't rely on this/etc.)\n \nreply",
      "\"The dose makes the poison\" but I'm not in a hurry to make myself a test case for no good reason. Tastier preserves might be a good enough reason.\n \nreply",
      "Your body actually produces a small amount of cyanide endogenously, if it makes you feel any better. It has some role in cell signalling.\n \nreply",
      "Cody's Lab on YouTube drank 17 mg of cyanide for a video, but not surprisingly it's now private. Quotes include:* It tastes like baking soda* I've got a tremor [in my arm] and my breathing is slightly more rapidCyanide fortunately can't accumulate, so it's far less spooky than heavy metals (lead, chromium, mercury), perfluoroalkanes (PFAS), or some other strange organic molecules that might cause cancer.\n \nreply",
      "I have no idea how that guy is still alive after all the things he has gone out of his way to expose himself to.\n \nreply",
      "I think apple seeds are the most common (non-stone-fruit anyway) example of this.\n \nreply",
      "Bitter almonds contain amygdalin which is cyanogenic. You can't make a number of preparations without them (some types of marzipan or almond pastries and Disaronno come to mind).\n \nreply",
      "This is not the case, however, for bitter almonds.\n \nreply",
      "even with bitter almonds a grown up needs to eat quite a bit, many old recipes ask for a few bitter almonds in a preparation.A child could die with 5-6 whole bitter almonds, but they are really, really bitter so it's not that easy to accidentally do that.\n \nreply",
      "My grandmother introduced us to a world of old-school delicacies, including Jordan almonds, candy-coated in a thick hard shell, and in pastel colors.On more than one occasion, I ate a box or two of those, so many that I had painful bellyaches and worse. It may not have been cyanide, but it was an instructive childhood lesson in \"too much of a good thing\".It's scary to think how much knowledge of poisons was in our home with my father's profession, and mother's hobby of murder mysteries. When the 1982 adulteration scandal hit the news, I honestly had mixed feelings about the message it sent to consumers.https://en.wikipedia.org/wiki/Chicago_Tylenol_murders\n \nreply"
    ],
    "link": "https://suziepetryk.com/blog/cyanide.html",
    "first_paragraph": "There\u2019s a bushy tree in my backyard with these dark red fruit \u2014 the kind that makes some primal instinct scream at you across millennia, \n        but you can\u2019t tell if it wants you to eat them or not.I used a plant app to identify it (like a true horticultural expert): it\u2019s Prunus laurocerasus, or cherry laurel. \n          The most innocent of names. Apparently a popular landscaping choice given its dense foliage.Apparently also a popular source of poison used by the ancient Roman Emperor Nero to assassinate his enemies.My own tree, not producing fruit at the time of writing. An example of cherry laurel \n            fruit. An unwitting victim could drink water from their local well, or from a glass at a lively dinner, never detecting cyanide distilled \n        from cherry laurel leaves. This was likely thanks to Locusta, Nero\u2019s go-to poisoner, whom he freed from prison after she poisoned \n        his step-father (why let talent go to waste?). Historians speculate on her exact arsenal, "
  },
  {
    "title": "Mapping the University of Chicago's 135-year expansion into Hyde Park and beyond (chicagomaroon.github.io)",
    "points": 189,
    "submitter": "speckx",
    "submit_time": "2025-03-11T13:50:22 1741701022",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=43332424",
    "comments": [
      "this is mine! thanks for the share. code for the project is all open source here: https://github.com/chicagomaroon/data-visualizations/tree/ma.... this was my first larger custom story project. maplibre for the map, waypoints for scroller helper and the rest just vanilla js/html/css. hosted on github pages. i have another project that has lots of other examples of cool viz i like (filter to about visualizations) https://content-we-love-54fa79867044.herokuapp.com/\n \nreply",
      "Thank you for working on and sharing this project, it's a wonderful example of how maps help tell / connect the stories through the years. It was also nice to see the piece you drew inspiration from that you linked to in another comment.I'm curious -- each section (after the transitional animation) seems like it translates quite well to being a fixed page, and I'm wondering if you've looked at there being an easy way to generate a version that could be printed?The reason I ask is that I'm working on a family history project which involves various locations, maps, newspaper stories and old photographs, and whilst something interactive feels like it would be an engaging way to do it, for the long term it's always good to have a printed copy of anything :)I could imagine if there was an easy way to generate a print version of your articles, some people would pay for a copy (that was printed professionally in a suitable photobook-style format).Apologies if there is a simple way to generate this and I've missed it in my cursory glance around the code :)\n \nreply",
      "This is absolutely lovely. Thank you.The underlying map is modern across all timelines. What would be super awesome is if the underlying map would also change, based on historical propery deeds, maps and ariel photos. For example, the 1893 world's fair is when much housing was constructed. The entire coastline also changed during this timeline. This would be an order of magnitude more work...\n \nreply",
      "love that idea! reminds me of a piece by the philadelphia inquirer that i drew inspo from : https://www.inquirer.com/history/inq2/chinatown-history-time...\n \nreply",
      "Is there a place to submit an issue with the data? The final map makes it look like a bunch of properties around the neighborhood were purchased by the University between 2004 and 2005. But I recognize one of them (5125 S. Kenwood, just south of Hyde Park Blvd/51st St.) as my first grad school apartment: I lived there throughout the 1998-99 academic year, and it was definitely a university-owned/managed building at the time.\n \nreply",
      "yes, can send an email to data@chicagomaroon.com! there are a chunk of apartments that were very hard to get exact dates for so a few are approx but would love to improve the accuracy.\n \nreply",
      "This must be the first time I\u2019ve seen the scrolling story thing actually work. Great job!\n \nreply",
      "Interesting, it's been around for awhile, I have rarely had trouble. This one was the one that I loved the most: https://www.nytimes.com/interactive/2019/07/16/world/europe/....\n \nreply",
      "https://ig.ft.com/baltic-sea/ this one from this week I thought was excellent\n \nreply",
      "it's really awesome !\n \nreply"
    ],
    "link": "https://chicagomaroon.github.io/data-visualizations/2025/uchicago-property/",
    "first_paragraph": "Scroll Down\n\n\n                        As the University of Chicago has expanded its property\n                        footprint on the South Side, conflicting priorities,\n                        land use disputes, and racial tension have characterized\n                        a historically fraught \u201ctown and gown\u201d relationship with\n                        the surrounding neighborhoods. Setting the stage for\n                        others to follow, the University was the first higher\n                        education institution to embark on an urban renewal\n                        campaign of its kind, a topic University scholars and\n                        students have written on extensively.\n                    \n                        The following narration is not an exhaustive history;\n                        rather, it traces the contours of shifting values and\n                        priorities that have contributed to the University\u2019s\n                        current institution"
  }
]