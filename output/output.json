[
  {
    "title": "GPT-5.2 (openai.com)",
    "points": 759,
    "submitter": "atgctg",
    "submit_time": "2025-12-11T18:04:47 1765476287",
    "num_comments": 597,
    "comments_url": "https://news.ycombinator.com/item?id=46234788",
    "comments": [
      "I have been using chatGPT a ton over the last months and paying the subscription. Used it for coding, news, stock analysis, daily problems, and a whatever I could think of. I decided to give Gemini a go when version three came out to great reviews. Gemini handles every single one of my uses cases much better and consistently gives better answers. This is especially true for situations were searching the web for current information is important, makes sense that google would be better. Also OCR is phenomenal chatgpt can't read my bad hand writing but Gemini can easily. Only downsides are in the polish department, there are more app bugs and I usually have to leave the happen or the session terminates. There are bugs with uploading photos. The biggest complaint is that all links get inserted into google search and then I have to manipulate them when they should go directly to the chosen website, this has to be some kind of internal org KPI nonsense. Overall, my conclusion is that ChatGPT has lost and won't catch up because of the search integration strength.reply",
      "> Only downsides are in the polish departmentWhat an understatement. It has me thinking \u201eman, fuck this\u201c on the daily.Just today it spontaneously lost an entire 20-30 minutes long thread and it was far from the first time. It basically does it any time you interrupt it in any way. It\u2019s straight up data loss.It\u2019s kind of a typical Google product in that it feels more like a tech demo than a product.It has theoretically great tech. I particularly like the idea of voice mode, but it\u2019s noticeably glitchy, breaks spontaneously often and keeps asking annoying questions which you can\u2019t make it stop.reply",
      "ChatGPT web UI was also like this for the longest time, until a few months ago: all sorts of random UI bugs leading either to data loss or misleading UI state. Interrupting still is very flaky there too. And on the mobile app, if you move away from the app while it's taking time to think, its state would somehow desync from the actual backend thinking state, and get stuck randomly; sometimes restarting the app fixes it, sometimes that chat is that unusable from that point on.And the UI lack of polish shows up freshly every time a new feature lands too - the \"branch in new chat\" feature is really finicky still, getting stuck in an unusable state if you twitch your eyebrows at wrong moment.reply",
      "> ChatGPT web UI was also like this for the longest timeCopilot Chat has been perfect in this respect. It's currently GPT 5.0, moving to 5.1 over the next month or so, but at least I've never lost an (even old) conversation since those reside in an Exchange mailbox.reply",
      "i basically can't use the ChatGPT app on the subway for these reasons. the moment the websocket connection drops, i have to edit my last message and resubmit it unchanged.it's like the client, not the server, is responsible for writing to my conversation history or somethingreply",
      "it took me a lot of tinkering to get this feeling seamless in my own apps that use the api under the hood. i ended up buffering every token into a redis stream (with a final db save at the end of streaming) and building a mechanism to let clients reconnect to the stream on demand. no websocket necessary.works great for kicking off a request and closing tab or navigating away to another page in my app to do something.i dont understand why model providers dont build this resilient token streaming into all of their APIs. would be a great featurereply",
      "> It has me thinking \u201eman, fuck this\u201c on the daily.That's sometimes me with the CLI. I can't use the Gemini CLI right now on Windows (in the Terminal app), because trying to copy in multiple lines of text for some reason submits them separately and it just breaks the whole thing. OpenCode had the same issue but even worse, it quite after the first line or something and copied the text line by line into the shell, thank fuck I didn't have some text that mentions rm -rf or something.More info: https://github.com/google-gemini/gemini-cli/issues/14735#iss...At the same time, neither Codex CLI, nor Claude Code had that issue (and both even showed shortened representations of copied in text, instead of just dumping the whole thing into the input directly, so I could easily keep writing my prompt).So right now if I want to use Gemini, I more or less have to use something like KiloCode/RooCode/Cline in VSC which are nice, but might miss out on some more specific tools. Which is a shame, because Gemini is a really nice model, especially when it comes to my language, Latvian, but also your run of the mill software dev tasks.In comparison, Codex feels quite slow, whereas Claude Code is what I gravitate towards most of the time but even Sonnet 4.5 ends up being expensive when you shuffle around millions of tokens: https://news.ycombinator.com/item?id=46216192 Cerebras Code is nice for quick stuff and the sheer amount of tokens, but in KiloCode/... regularly messes up applying diff based edits.reply",
      "Any time its safety stuff triggers, Gemini wipes the context. It's unusable because of this because whatever is going on with the safety stuff, it fires too often. I'm trying to figure out some code here, not exactly deporting ICE to Guantanamo or whatever.reply",
      "The more Gemini and Nano-Banana soften their filters, the more audience it will take from other platforms. The main risk is payment providers banning them, I can't imagine bank card providers to remove payments to Google.reply",
      "On a flip side chatgpt app now has years of history that sometimes useful (search is pretty ok, but could improve) but otherwise I'd like to remove most of it - good luck doing so.reply"
    ],
    "link": "https://openai.com/index/introducing-gpt-5-2/",
    "first_paragraph": ""
  },
  {
    "title": "Nokia N900 Necromancy (yaky.dev)",
    "points": 43,
    "submitter": "yaky",
    "submit_time": "2025-12-12T00:04:29 1765497869",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=46239177",
    "comments": [
      "Why go through that device-breaking battery dance when you can still get a BL-5J battery pretty much everywhere?Booting from an SD card, while possible, is rather impractical on N900 because it gets disconnected whenever you open the back cover.The N900 that lays next to me right now still works as a phone. I have to replace its screen though, as recently it took some damage in my pocket and got a small crack in its bottom middle. Touch still works perfectly though, so I'm not in a hurry :Dreply",
      "> The N900 that lays next to me right now still works as a phone.It soon won't be. 3G and 2G network are being depreciated quickly around the worldreply",
      "Should still be fine for at least a few years here.reply",
      "I had one of these around 2011! Used it to host a websocket server - a novelty at the time - during a conference talk, and it held up to 30+ clients before dying.reply",
      "Man, I miss my N80ie. The towns I lived in didn\u2019t get UMTS/3G until the \u201810s, but the EDGE radios were enough. Loved Symbian, miss it.reply",
      "My first Internet phone was the Nokia 9000, which was limited to GSM (9600bps). I built and debugged one of the first major music streaming services on that connection because I was working remote and my DSL got cut off. I had to add a 2Kbps stream option to the production servers for myself just so I could test it.reply",
      "N900 has nothing to do with Symbian.reply",
      "I had an n800 in college (it wasn't a phone, it was an \"internet tablet\"). _Loved_ that thing.reply",
      "There are DOZENS OF US!Picture me in 2007. \"The iPhone. Psh. Like I'm going to switch to Cingular and pay thirty dollars for a data plan!\" (Keep in mind that's $47 in today's dollars!)I would use my N800 and Bluetooth-tether to my Verizon flip phone when on the go. It was mildly useful for things like LiveJournal and I'm sure the Twitter of that time would have worked on whatever browser Maemo had. But I had to admit by 2008 that I wanted a smartphone instead of this second device with a stylus.In those days though, browsing the web as though you were on a desktop was thought to be the goal to aspire to. Even the iPhone launched with the default behavior in Safari being showing whole desktop webpages, and you zoomed in to the parts you wanted to use. It took a year or two for people to figure out 'responsive' and within 4 years most sites were starting to be designed for small portrait screens. At that point the landscape N800 style was at a disadvantage since the mobile sites being designed to be a little leaner, were the wrong layout, but the desktop sites were pretty heavy for a mobile device to handle. And as \"apps\" ate the world that probably put the final nail on our little N-series.reply",
      "I loved my N900. Enough that I eventually replaced it with an N9. It wasn't the same, tho. The N900 had a certain charm.reply"
    ],
    "link": "https://yaky.dev/2025-12-11-nokia-n900-necromancy/",
    "first_paragraph": "Building a fake battery, adding a USB-C port, booting from SD card, and giving a new life to a classic Linux smartphone.My friend Dima sent me his old-school classic Nokia N900. The battery is very old, and it does not boot as-is. So naturally, I wanted to see if I can resurrect it.Yes it is! (Unless there are other hardware issues)I ran a smartphone without a battery a few years ago.Cut and soldered a quick prototype to connect instead of the battery. Resistors are to emulate the \"normal\" temperature by providing expected resistance between the third pin and ground. See link above for details.Hooked up a large supercapacitor to the battery pins and to a +5V source. If I recall correctly, using a capacitor without additional power did not work.And it boots!Now, let's make something that can fit into the battery compartment.These supercapacitors are nice, but way too large. After searching on Mouser, I found FM0H473ZF, 47000 mF (0.047F) capacitors in a rectangular case that is only 5mm "
  },
  {
    "title": "Denial of service and source code exposure in React Server Components (react.dev)",
    "points": 198,
    "submitter": "sangeeth96",
    "submit_time": "2025-12-11T20:46:46 1765486006",
    "num_comments": 96,
    "comments_url": "https://news.ycombinator.com/item?id=46236924",
    "comments": [
      "React Server Components always felt uncomfortable to me because they make it hard to look at a piece of JavaScript code and derive which parts of it are going to run on the client and which parts will run on the server.It turns out this introduces another problem too: in order to get that to work you need to implement some kind of DEEP serialization RPC mechanism - which is kind of opaque to the developer and, as we've recently seen, is a risky spot in terms of potential security vulnerabilities.reply",
      "I was a fan of NextJS in the pages router era. You knew exactly where the line was between server and client code and it was pretty easy to keep track of that. Then I've began a new project and wanted to try out app router and I hated it. So many (to me common things) where just not possible because the code can run in the client and on the server so Headers might not always be available and it was just pure confusion whats running where.reply",
      "I think we (the Next.js user community) need to organize and either convince Vercel to announce official support of the Pages router forever (or at least indefinitely, and stop posturing it as a deprecated-ish thing), or else fork Next.js and maintain the stable version of it that so many of us enjoyed. Every time Next comes up I see a ton of comments like this, everyone I talk to says this, and I almost never hear anyone say they like the App Router (and this is a pretty contrarian site, so if they existed I\u2019d expect to see them here).reply",
      "I would highly recommend just checking out TanStack Router/Start instead. It fills a different niche, with a slightly different approach, that the Next.js app router just hasn't prioritized enabling anymore.What app router has become has its ideal uses, but if you explicitly preferred the DX of the pages router, you might enjoy TanStack Router/Start even more.reply",
      "I've been using React since its initial release; I think both RSC and App Router are great, and things are better than ever.It's the first stack that allows me to avoid REST or GraphQL endpoints by default, which was the main source of frontend overhead before RSC. Previously I had to make choices on how to organize API, which GraphQL client to choose (and none of them are perfect), how to optimize routes and waterfalls, etc. Now I just write exactly what I mean, with the very minimal set of external helper libs (nuqs and next-safe-action), and the framework matches my mental model of where I want to get very well.Anti-React and anti-Next.js bias on HN is something that confuses me a lot; for many other topics here I feel pretty aligned with the crowd opinion on things, but not on this.reply",
      "Some of the anti-next might be from things like solid-start and tanstack-start existing, which can do similar things but without the whole \"you've used state without marking as a client component thus I will stop everything\" factor of nextjs.Not to mention the whole middleware and being able to access the incoming request wherever you like.reply",
      "I pretty much dumped a side project that was using next over the new router. It's so much more convoluted, way too many limitations. Who even really wants to make database queries in front end code? That's sketchy as heck.reply",
      "A lot of functionality is obviously designed for Vercel's hosting platform, with local equivalents as an afterthought.reply",
      "This is what I asked my small dev team after I recently joined and saw that we were using Next for the product \u2014 do we know how this works? Do we have even a partial mental model of what's happening? The answers were sadly, pretty obvious. It was hard enough to get people to understand how hooks worked when they were introduced, but the newer Next versions seem even more difficult to grok.I do respect the things React + Next team is trying to accomplish and it does feel like magic when it works but I find myself caring more and more about predictability when working with a team and with every major version of Next + React, that aspect seems to be drifting further and further away.reply",
      "This happens in Next.js as well https://github.com/vercel/next.js/discussions/11106reply"
    ],
    "link": "https://react.dev/blog/2025/12/11/denial-of-service-and-source-code-exposure-in-react-server-components",
    "first_paragraph": "December 11, 2025 by The React TeamSecurity researchers have found and disclosed two additional vulnerabilities in React Server Components while attempting to exploit the patches in last week\u2019s critical vulnerability.These new vulnerabilities do not allow for Remote Code Execution. The patch for React2Shell remains effective at mitigating the Remote Code Execution exploit.The new vulnerabilities are disclosed as:We recommend upgrading immediately due to the severity of the newly disclosed vulnerabilities.If you already updated for the Critical Security Vulnerability last week, you will need to update again.If you updated to 19.0.2, 19.1.3, and 19.2.2, these are incomplete and you will need to update again.Please see the instructions in the previous post for upgrade steps.Further details of these vulnerabilities will be provided after the rollout of the fixes are complete.These vulnerabilities are present in the same packages and versions as CVE-2025-55182.This includes versions 19.0.0,"
  },
  {
    "title": "Rivian Unveils Custom Silicon, R2 Lidar Roadmap, and Universal Hands Free (riviantrackr.com)",
    "points": 203,
    "submitter": "doctoboggan",
    "submit_time": "2025-12-11T18:17:19 1765477039",
    "num_comments": 290,
    "comments_url": "https://news.ycombinator.com/item?id=46234920",
    "comments": [
      "Autonomy subscriptions are how things are going to go, I called this a long time ago. It makes too much sense in terms of continuous development and operations/support to not have a subscription -- and subscriptions will likely double as insurance at some point in the future (once the car is driving itself 100% of the time, and liability is always with the self driving stack anyway).Of course, people won't like this, I'm not exactly enthused either, but the alternative would be a corporation constantly providing -- for free -- updates and even support if your car gets into an accident or stuck. That doesn't really make sense from a business perspective.reply",
      "Agreed, it seems inevitable that autonomy and insurance are going to be bundled.1. Courts are finding Tesla partially liable for collisions, so they've already got some of the downsides of insurance (aka the payout) without the upside (the premium).2. Waymo data shows a significant injury reduction rate.   If it's true and not manipulated data, it's natural for the car companies to want to capture some of this upside.3. It just seems like a much easier sell.    I wouldn't pay $100/month for self-driving, but $150 a month for self-driving + insurance?   That's more than I currently pay for insurance, but not a lot more.   And I've got relatively cheap insurance: charging $250/month for insurance + self-driving will be cheaper than what some people pay for just insurance alone.I don't think we need to hit 100% self-driving for the bundled insurance to be viable.   90% self-driving should still have a substantially lower accident rate if the Waymo data is accurate and extends.reply",
      "History suggests it won't be that clean.1. High-severity accidents might drop, but the industry bleeds money on high-frequency, low-speed incidents (parking lots, neighborhood scrapes). Autonomy has diminishing returns here; it doesn't magically prevent the chaos of mixed-use environments.2. Insurance is a capital management game. We\u2019ll likely see a tech company try this, fail to cover a catastrophic liability due to lack of reserves, and trigger a massive backlash.It reminds me of early internet optimism: we thought connectivity would make truth impossible to hide. Instead, we got the opposite. Tech rarely solves complex markets linearly.reply",
      "Auto insurers don't face a \"catastrophic liability\" bankrupting scenario like home insurers might in the case of a natural disaster or fire.reply",
      "A bad hail storm comes close. Hail damage can total a car.reply",
      "> Insurance is a capital management game. We\u2019ll likely see a tech company try this, fail to cover a catastrophic liability due to lack of reserves, and trigger a massive backlash.Google, AFAIK the only company with cars that are actually autonomous, has US$98 Billion in cash.It'd have to be a hell of an accident to put a dent in that.reply",
      "I doubt autonomous car makers will offer this themselves. They'll either partner with existing insurers or try to build a separate insurance provider of their own which does this.My guess, if this actually plays out, is that existing insurers will create a special autonomy product that will modify rates to reflect differences in risk from standard driving, and autonomy subscriptions will offer those in a bundle.reply",
      "> High-severity accidents might drop, but the industry bleeds money on high-frequency, low-speed incidents (parking lots, neighborhood scrapes). Autonomy has diminishing returns here; it doesn't magically prevent the chaos of mixed-use environments.This seems like it can be solved with a deductible.reply",
      "I think there will actually be a couple interesting adjustments/market forces acting in the car companies' favor.First, if the insurance applies to fully autonomous driving only, then I suspect they\u2019ll reach a point where the cost of insurance+automation ends up being less than just insurance through third parties.Second, cutting into the traditional insurance market share is likely to increase costs for those who remain on traditional insurance, assuming there\u2019s a significant enough number of people jumping ship. Combined, this creates a huge incentive for more users to jump on the self-driving bandwagon.reply",
      "I would pay so much for my own SUV to self-drive as well as Waymo.Keyword: my own SUV. Not a rental. With the possibility for me to take over and drive it myself if service fails or if I want to do so.The significant unlock is that I get to haul gear, packages, family. I don't need to keep it clean. The muddy dogs, the hiking trip, the week-long road trip.If my car could drive me, I'd do way more road trips and skip flying. It's almost as romantic as a California Zephyr or Coast Starlight trip. And I can camp out of it.No cramped airlines. No catching colds by being packed in a sardine can with a stressed out immune system.No sharing space with people on public transit. I can work and watch movies and listen to music and hang out with my wife, my friends. People won't stare at me, and I can eat in peace or just be myself in my own space.I might even work in a nomadic lifestyle if I don't have to drive all the time. Our country is so big and there's so much to see.One day you might even be able to attach a trailer. Bikes, jet skis, ATVs. People might simply live on the road, traveling all the time.Big cars seem preferable. Lots of space for internal creature comforts. Laying back, lounging. Watching, reading, eating. Changing clothes, camping, even cooking.Some people might even buy autonomous RVs. I'm sure that'll be a big thing in its own right.It's bidirectional too! People can come to you as you go to them. Meet in the middle. Same thing with packages, food, etc.This would be the biggest thing in travel, transport, logistics, perhaps ever. It's a huge unlock. It feels downright revolutionary. Like a total change in how we might live our lives.This might turn big suburbs from food/culture deserts into the default places people want to live as they have more space for cheaper - because the commute falls apart.This honestly sounds better than a house, but if you can also own an affordable large home in the suburbs as your home base - that's incredible. You don't need a tiny expensive place in the city. You could fall asleep in your car and wake up for breakfast in the city. Spend some time at home, then make a trek to the mountains. All without wasting any time. No more driving, no more traffic. Commuting becomes leisure. It becomes you time.This is also kind of a super power that big countries (in terms of area) with lots of roads and highways will enjoy the most. It doesn't do much in a dense city, but once you add mountains and forests and streams and deserts and oceans - that's magic.Maybe our vast interstate highway infrastructure will suddenly grow ten times in value.Roads might become more important than ever. We might even start building more.If the insurance and autonomy come bundled as a subscription after you purchase or lease your vehicle, that's super easy for people to activate and spend money on.This is such a romantic dream, and I'm so hyped for this.I would pay an ungodly sum to unlock this. It can't come soon enough. Would subscribe in a heartbeat.reply"
    ],
    "link": "https://riviantrackr.com/news/rivian-unveils-custom-silicon-r2-lidar-roadmap-universal-hands-free-and-its-next-gen-autonomy-platform/",
    "first_paragraph": "  Ordering a Rivian? Use code JOSE1715716 to earn 250 points + 3 months of free RAN charging.  Ordering a Rivian? Use code JOSE1715716 to earn 250 points + 3 months of free RAN charging.RJ opened the first ever Autonomy and AI Day explaining why Rivian believes it is positioned to lead in this next phase of the industry. The company is leaning hard into compute, custom hardware, large scale AI systems, and a shared data foundation that touches every part of the ownership experience.Let\u2019s break it all down.One of the biggest announcements was RAP1, Rivian\u2019s first in house processor built on a 5nm multi chip module. It delivers 1600 sparse INT8 TOPS and can push 5 billion pixels per second inside the new Gen 3 Autonomy Computer. Rivian even built its own AI compiler and platform software to support it. This shows Rivian is no longer just integrating off the shelf chips, it is now designing silicon specifically for its autonomy roadmap.The ACM3 (Autonomy Compute Module 3) autonomy compute"
  },
  {
    "title": "The highest quality codebase (gricha.dev)",
    "points": 425,
    "submitter": "Gricha",
    "submit_time": "2025-12-08T21:33:09 1765229589",
    "num_comments": 290,
    "comments_url": "https://news.ycombinator.com/item?id=46197930",
    "comments": [
      "Claude is really good at specific analysis, but really terrible at open-ended problems.\"Hey claude, I get this error message: <X>\", and it'll often find the root cause quicker than I could.\"Hey claude, anything I could do to improve Y?\", and it'll struggle beyond the basics that a linter might suggest.It suggested enthusiastically a library for <work domain> and it was all \"Recommended\" about it, but when I pointed out that the library had been considered and rejected because <issue>, it understood and wrote up why that library suffered from that issue and why it was therefore unsuitable.There's a significant blind-spot in current LLMs related to blue-sky thinking and creative problem solving. It can do structured problems very well, and it can transform unstructured data very well, but it can't deal with unstructured problems very well.That may well change, so I don't want to embed that thought too deeply into my own priors, because the LLM space seems to evolve rapidly. I wouldn't want to find myself blind to the progress because I write it off from a class of problems.But right now, the best way to help an LLM is have a deep understanding of the problem domain yourself, and just leverage it to do the grunt-work that you'd find boring.reply",
      "That's why you treat it like a junior dev. You do the fun stuff of supervising the product, overseeing design and implementation, breaking up the work, and reviewing the outputs. It does the boring stuff of actually writing the code.I am phenomenally productive this way, I am happier at my job, and its quality of work is extremely high as long as I occasionally have it stop and self-review it's progress against the style principles articulated in its AGENTS.md file. (As it tends to forget a lot of rules like DRY)reply",
      "I think we have different opinions on what's fun and what's boring!reply",
      "You've really hit the crux of the problem and why so many people have differing opinions about AI coding. I also find coding more fun with AI. The reason is that my main goal is to solve a problem, or someone else's problem, in a way that is satisfying. I don't much care about the code itself anymore. I care about the thing that it does when it's done.Having said that I used to be deep into coding and back then I am quite sure that I would hate AI coding for me. I think for me it comes down to \u2013 when I was learning about coding and stretching my personal knowledge in the area, the coding part was the fun part because I was learning. Now that I am past that part I really just want to solve problems, and coding is the means to that end. AI is now freeing because where I would have been reluctant to start a project, I am more likely to give it a go.I think it is similar to when I used to play games a lot. When I would play a game where you would discover new items regularly, I would go at it hard and heavy up until the point where I determined there was either no new items to be found or it was just \"more of the same\". When I got to that point it was like a switch would flip and I would lose interest in the game almost immediately.reply",
      "A few counterpoints:1. If you don't care about code and only care about the \"thing that it does when it's done\", how do you solve problems in a way that is satisfying? Because you are not really solving any problem but just using the AI to do it. Is prompting more satisfying than actually solving?2. You claim you're done \"learning about coding and stretching my personal knowledge in the area\" but don't you think that's super dangerous? Like how can you just be done with learning when tech is constantly changing and new things come up everyday. In that sense, don't you think AI use is actually making you learn less and you're just justifying it with the whole \"I love solving problems, not code\" thing?3. If you don't care about the code, do the people who hire you for it do? And if they do, then how can you claim you don't care about the code when you'll have to go through a review process and at least check the code meaning you have to care about the code itself, right?reply",
      "Why can't both things be true? You can care about the code even if you don't write it. You can continue learning things by reading said code. And you can very rigidly enforce code quality guidelines and require the AI adhere to them.reply",
      "I think it ultimately comes down to whether you care more about the what, or more about the how. A lot of coders love the craft: making code that is elegant, terse, extensible, maintainable, efficient and/or provably correct, and so on. These are the kind of people who write programming languages, database engines, web frameworks, operating systems, or small but nifty utilities. They don't want to simply solve a problem, they want to solve a problem in the \"best\" possible way (sometimes at the expense of the problem itself).It's typically been productive to care about the how, because it leads to better maintainability and a better ability to adapt or pivot to new problems. I suppose that's getting less true by the minute, though.reply",
      "Crafting code can be self-indulgent since most common patterns have been implemented multiple times in multiple languages.  A lot of time the craft oriented developer will reject an existing implementation because it doesn't match their sensibilities.  There is absolutely a role for craft, however the amount of craft truly needed in modern development is not as large as people would like. There are lots of well crafted libraries and frameworks that can be adopted if you are willing to accommodate their world view.reply",
      "As someone who does that a lot... I agree. Self-indulgent is the word. It just feels great when the implementation is a perfect fit for your brain, but sometimes that's just not a good use of your time.Sometimes, you strike gold, so there's that.reply",
      "I kind of struggle with this. I basically hate everyone elses code, and by that I mean I hate most people's code. A lot of people write awesome code but most people write what I'd call trash code.And I do think there's more to it than preference. Like there's actual bugs in the code, it's confusing and because it's confusing there's more bugs. It's solving a simple problem but doing so in an unnecessarily convoluted way. I can solve the same problem in a much simpler way. But because everything is like this I can't just fix it, there's layers and layers of this convolution that can't just be fixed and of course there's no proper decoupling etc so a refactor is kind of all or nothing. If you start it's like pulling on a thread and everything just unravels.This is going to sound pompous and terrible but honestly some times I feel like I'm too much better than other developers. I have a hard time collaborating because the only thing I really want to do with other people's code is delete it and rewrite it. I can't fix it because it isn't fixable, it's just trash. I wish they would have talked to me before writing it, I could have helped then.Obviously in order to function in a professional environment i have to suppress this stuff and just let the code be ass but it really irks me. Especially if I need to build on something someone else made - itsalmost always ass, I don't want to build on a crooked foundation. I want to fix the foundation so the rest of the building can be good too. But there's no time and it's exhausting fixing everyone else's messes all the time.reply"
    ],
    "link": "https://gricha.dev/blog/the-highest-quality-codebase",
    "first_paragraph": "Have you seen one of the experiments where people have been re-feeding the same image to the AI agent a bunch of times?Or Marques Brownlee's youtube videos where the video is reuploaded a 1000 times?Over the Thanksgiving weekend I had some time on my hands and tasked Claude to write an app that guestimates macronutrients in some foods based on description + photo. There's some interesting setup in getting it right, but that's boring. It has created a great, functional app for me, but then I forced it to do a small, evil experiment for me.I've written a quick script that looped over my codebase and ran this command....and havoc it wrecked. Over 200 times of unmitigated madness. I have tweaked the prompt here and there when I've been seeing it overindexing on a single thing, but with enough iterations it started covering a lot of ground.. from full code coverage and more tests than functional code, to rust-style Result types, to.. estimating entropy of hashing function (???).This was run"
  },
  {
    "title": "An SVG is all you need (recoil.org)",
    "points": 138,
    "submitter": "sadiq",
    "submit_time": "2025-12-11T19:25:14 1765481114",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=46235959",
    "comments": [
      "I love SVG!  Recently I needed to render markdown in SVG and found no library existed for that yet so I released one:github: https://github.com/davefowler/markdown-svg\nplayground: https://markdown-svg-production.up.railway.appreply",
      "Even though the article is mostly talking about visualizations, but I thought I'd share that I did at one point build a dance choreography software that renders the UI entirely SVG. I was surprised as to how well that worked.If you're curious, it's called StageKeep, and you can find it here. https://stagekeep.com/The original project used React Three Fiber, but refactored it to SVG for reasons I don't quite remember. I was inspired by signed distance functions, and the fact that one function could have such an outsized visual effect. Although the software doesn't use SDFs, but I like the idea of atomic functions that accepts some input, and outputs SVG.reply",
      "Very cool. Are you a dancer yourself?reply",
      "Wow, that is really cool. As a stage director I touch on choreography a bit. It would be really cool to pre-plan blocking with something like that.reply",
      "I agree with the author when they write:\"\"\"\nIn my idealistic vision of how scientific publishing should work, each paper would be accompanied by a fully interactive environment where the reader could explore the data, rerun the experiments, tweak the parameters, and see how the results changed. \n\"\"\"I do like seeing larger labs/companies releasing research full of SVGs. In recent memory, I quite liked this from NVIDIA:https://research.nvidia.com/labs/dbr/blog/illustrated-evo2/reply",
      "Without the OP's proposed use of SVG, what format would someone use? PDFs won't handle it well - unless PDF's interactivity capabilities are much better than I think. We never developed a client-side multimedia file format; all we have are text formats like Word and PDF, which embed images decently, and embed multimedia and interactivity (beyond form filling) in awkwardly and in a limited manner.reply",
      "What's wrong with SVG? Notebooks have their issues but are kinda this conceptually. I guess FLAs and Flash too. But you say we never developed a \"client-side multimedia file format\". Is that not exactly what html + js are for?reply",
      "Interactive and SVGs don't really mix, although intuitively it would seem that they do. Rendering remotely complex SVGs tale multiple seconds, while any kind of interactivity demands ~30+ frames per seconds.Without interactivity, postscript is vector graphics too.reply",
      "How complex are you talking about?   I've done animations with hundreds of elements and it's fine.reply",
      "Around 15 years ago, I built a barbecue controller. This controller had four temperature probes that could be used to check the temperature of the inner cooking chamber as well as various cuts of meat. It controlled servos that opened and closed vents and had a custom derived PID algorithm that could infer the delayed effects of oxygen to charcoal.Anyway, of relevance to this thread is that the controller connected to the local wireless network and provided an embedded HTTP server with an SVG based web UI that would graph temperatures and provided actual knobs and dials so that the controller could be tweaked. SVG in the browser works nicely with Javascript.reply"
    ],
    "link": "https://jon.recoil.org/blog/2025/12/an-svg-is-all-you-need.html",
    "first_paragraph": "2025-12-09SVGs are pretty cool - vector graphics in a simple XML format. They are supported on just about every device and platform, are crisp on every display, and can have embedded scripts in to make them interactive. They're way more capable than many people realise, and I think we can capitalise on some of that unrealised potential.Anil's recent post Four Ps for Building Massive Collective Knowledge Systems got me thinking about the permanence of the experimentation that underlies our scientific papers. In my idealistic vision of how scientific publishing should work, each paper would be accompanied by a fully interactive environment where the reader could explore the data, rerun the experiments, tweak the parameters, and see how the results changed. Obviously we can't do this in the general case - some experiments are just too expensive or time-consuming to rerun on demand. But for many papers, especially in computer science, this is entirely feasible.That line of thought reminded"
  },
  {
    "title": "Litestream VFS (fly.io)",
    "points": 219,
    "submitter": "emschwartz",
    "submit_time": "2025-12-11T17:59:10 1765475950",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=46234710",
    "comments": [
      "Oh hey this is using my go sqlite vfs module[0]. I love it when I find out some code I wrote is useful to others![0]: https://github.com/psanford/sqlite3vfsreply",
      "It worked great! Thanks for your work on it.reply",
      "that's all we really want in life.reply",
      "> What we\u2019re doing here is instantaneous point-in-time recovery (PITR), expressed simply in SQL and SQLite pragmas.> Ever wanted to do a quick query against a prod dataset, but didn\u2019t want to shell into a prod server and fumble with the sqlite3 terminal command like a hacker in an 80s movie? Or needed to do a quick sanity check against yesterday\u2019s data, but without doing a full database restore? Litestream VFS makes that easy. I\u2019m so psyched about how it turned out.Man this is cool. I love the unix ethos of Litestream's design. SQLite works as normal and Litestream operates transparently on that process.reply",
      "This is such a clean interface design:  export LITESTREAM_REPLICA_URL=\"s3://my-bucket/my.db\"\n  export AWS_ACCESS_KEY_ID=\"your-access-key\"\n  export AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\n\n  sqlite3\n\n  .load litestream.so\n  .open file:///my.db?vfs=litestream\n  PRAGMA litestream_time = '5 minutes ago'; \n  select * from sandwich_ratings limit 3;reply",
      "For macos users,brew install sqlite3, then change the bottom part:  /opt/homebrew/opt/sqlite/bin/sqlite3\n  .load litestream sqlite3_litestreamvfs_init\n  .open file:///my.db?vfs=litestream\n\nyou have to manually pass in the init function namereply",
      "This is great... just got it working using bun:sqlite! Just need to have \"LITESTREAM_REPLICA_URL\" and the key id and secret env vars set when running the script.  import { Database } from \"bun:sqlite\";\n  Database.setCustomSQLite(\"/opt/homebrew/opt/sqlite/lib/libsqlite3.dylib\");\n\n  // Load extension first with a temp db\n  const temp = new Database(\":memory:\");\n  temp.loadExtension(\"/path/to/litestream.dylib\", \"sqlite3_litestreamvfs_init\");\n\n  // Now open with litestream VFS\n  const db = new Database(\"file:my.db?vfs=litestream\");\n\n  const fruits = db.query(\"SELECT * FROM fruits;\").all();\n  console.log(fruits);reply",
      "Cool that you got this to work! How did you get the \"dylib\" location or file.reply",
      "The litestream one, from the litestream github releases page!reply",
      "brew list sqlite\n\ngives you the installed path, works for any formula.reply"
    ],
    "link": "https://fly.io/blog/litestream-vfs/",
    "first_paragraph": "I\u2019m Ben Johnson, and I work on Litestream at Fly.io. Litestream is the missing backup/restore system for SQLite. It\u2019s free, open-source software that should run anywhere, and you can read more about it here.Again with the sandwiches: assume we\u2019ve got a SQLite database of sandwich ratings, and we\u2019ve backed it up with Litestream to an S3 bucket.Now, on our local host, load up AWS credentials and an S3 path into our environment. Open SQLite and:SQLite is now working from that remote database, defined by the Litestream backup files in the S3 path we configured. We can query it:This is Litestream VFS. It runs SQLite hot off an object storage URL. As long as you can load the shared library our tree builds for you, it\u2019ll work in your application the same way it does in the SQLite shell.Fun fact: we didn\u2019t have to download the whole database to run this query. More about this in a bit.Meanwhile, somewhere in prod, someone has it in for meatball subs and wants to knock them out of the bracket \u2013"
  },
  {
    "title": "Programmers and software developers lost the plot on naming their tools (larr.net)",
    "points": 147,
    "submitter": "todsacerdoti",
    "submit_time": "2025-12-11T18:06:42 1765476402",
    "num_comments": 230,
    "comments_url": "https://news.ycombinator.com/item?id=46234806",
    "comments": [
      "GNU's version of Yacc is called Bison. Pine Is Not Elm (even though that was never an official acronym). UNIX was UNICS which was a pun on MULTICS. I couldn't for the life of me tell you what dd stands for. nano is a copy of pico which was the \"PIne COmposer\". Postfix is a completely opaque portmanteau of post (as in mail) and \"bug fix\". C++ is \"C incremented\", and C is the successor of B, which is the successor of BCPL.Developers haven't \"lost the plot\", we never had it in the first place.Inversely, Clang, LLDB, jq, fzf, loc are modern projects perfectly in line with the author's notion of a good name. \"mise-en-place\" is the perfect metaphor for what mise does.reply",
      "> I couldn't for the life of me tell you what dd stands for.Data(set) Definition. But that name does not make any sense whatsoever by itself in this context, neither for the tool (it hardly \"defines\" anything), nor for UNIX in general (there are no \"datasets\" in UNIX).Instead, it's specifically a reference to the DD statement in the JCL, the job control language, of many of IBM's mainframe operating systems of yore (let's not get into the specifics of which ones, because that's a whole other can of complexity).And even then the relation between the DD statement and the dd command in UNIX is rather tenuous. To simplify a lot, DD in JCL does something akin to \"opening a file\", or rather \"describing to the system a file that will later be opened\". The UNIX tool dd, on the other hand, was designed to be useful for exchanging files/datasets with mainframes. Of course, that's not at all what it is used for today, and possibly that was true even back then.This also explains dd's weird syntax, which consists of specifying \"key=value\" or \"key=flag1,flag2,...\" parameters. That is entirely alien to UNIX, but is how the DD and other JCL (again, of the right kind) statements work.reply",
      "> what dd stands forhttps://groups.google.com/d/msg/alt.folklore.computers/HAWoZ...reply",
      "Naming is a big part of programming, you'd expect software to have good descriptive names.reply",
      "How do you discriminate between 2 different things that ostensibly have similar features, but do it in different ways without getting very large names? What if you modify software or just part of it to make it something distinctively new, should it keep the name or add to it? What if I revert that non-trivial feature and add a different non-trivial one. Now what is it?I would hope the author realizes the core counterpoint when re-reading \"We\u2019re using Viper for configuration management, which feeds into Cobra for the CLI, and then Melody handles our WebSocket connections, Casbin manages permissions, all through Asynq for our job queue\" - because the real names, are the roles the tools play. The implementation name is incidental and amorphous, since you can make wild changes to software, rendering the name without much utility beyond a project label. Project labels are necessarily opaque, for the same good reasons software is. The idea is more important than the details. They are a conflux of interests and plans, not a market label. If market labels were fixed to functionality, the world would be worse off for obvious reasons of practicality and marketability.reply",
      "https://en.wikipedia.org/wiki/Back_Orifice_2000 was pretty clear about what it did.https://en.wikipedia.org/wiki/BitchX less so.reply",
      "> I couldn't for the life of me tell you what dd stands for.Traditionally, according to folklore? \"Delete disk\" or \"destroy data\". (Because it was commonly used to write raw disk blocks.)reply",
      "Another, similar name it is sometimes jokingly referred to under is \u201cdestroyer of disks\u201d.https://web.archive.org/web/20081206105906/http://www.noah.o...reply",
      "> grep (global regular expression print), awk (Aho, Weinberger, Kernighan; the creators\u2019 initials), sed (stream editor), cat (concatenate), diff (difference). Even when abbreviated, these names were either functional descriptions or systematic derivations.If you asked someone unfamiliar with unix tools what they thought each of these commands did, diff is the only one which they would have even the slightest chance of guessing. It's ridiculous to complain about \"libsodium\" and then hold up \"awk\" as a good name.reply",
      "https://en.wikipedia.org/wiki/Libiberty was always my favorite ridiculous name. It was named so you can link it with -liberty.reply"
    ],
    "link": "https://larr.net/p/namings.html",
    "first_paragraph": "\n\nThis section was labeled under, or is related to Programming\n\nThis post was discussed in HackerNews\n\nIn Dec 2022 I watched Richard Stallman\u2019s talk on the EmacsConf, it was titled \u201cWhat I\u2019d like to see in Emacs\u201d. One of the interesting points Mr. Stallman pointed out in this talk was \u201cmemorable names\u201d, \u201cI think every package that you [\u2026] should have a name that helps you remember what job it does. [\u2026] We\u2019ve had a tendency to give packages names for the sake of pure wordplay or lack of obvious meaning\u201d. That Stallman felt compelled to make this point in 2022 tells you everything about how far we\u2019ve fallen, even within the Emacs ecosystem (known for its descriptive naming conventions, dired for directory editor, eshell for Emacs shell).\n\nThere\u2019s an odd tendency in modern software development; we\u2019ve collectively decided that naming things after random nouns, mythological creatures, or random favorite fictional characters is somehow acceptable professional practice. This would be career s"
  },
  {
    "title": "The architecture of \u201cnot bad\u201d: Decoding the Chinese source code of the void (suggger.substack.com)",
    "points": 63,
    "submitter": "Suggger",
    "submit_time": "2025-12-11T14:21:14 1765462874",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=46231709",
    "comments": [
      "I have spent thousands of hours doing market research and practicing jobs to be done in product strategy.Something that occured to me years ago is we have a quirk in English language that gets in the way. We don't say \"unwant\", and we don't clearly differentiate between a lack of want and a repulsion or unwant.Someone might say \"I don't want x\" or \"I don't need x\" and it's unclear if:- they see no value in x- they see small enough value in x that they don't care- they see negative valueSo much time and energy is wasted on misunderstandings that stem from this ambiguity.It ruins products, is loses deals, it screws up projections, it confuses executives, etc.It gets in the way of accurately empathizing with and understanding each other.Because \"I unwant x\" means something extremely different than \"I don't want x\". Unwant implies some other value that x is getting in the way of. Understanding other peoples' values is what enables accurate empathy for them. Accurately empathizing with customers is what enables great products and predictable sales.reply",
      "I think you mean https://en.wiktionary.org/wiki/diswant, or \u201creject\u201d.reply",
      "\"unalive\" is an empathetic mood.Unwant could be too familiar, conjuring \"unwanted\".reply",
      "\"I don't care about x\" clearly indicates a lack of want but is considered ruder than \"I don't want x\".reply",
      "This makes me think of a tool from semiotics called the Greimas square where you can have opposing concepts e.g. A and B (ugly & beautiful, for & against, legal & illegal).At the surface level they can appear as binaries, but the negation of A is not equivalent to B and vice versa (e.g. illegal is not equivalent to not-legal) and encourages the consideration of more complex meta-concepts which at surface level seem like contradictions but are not (both beautiful and ugly, neither for or against).--Others have pointed out that English speakers do have the capacity, and do use these sort of double negatives that allow for this ambiguity and nuance, but if you are an English-only speaker, I do believe that there are concepts that are thick with meaning and the meaning cannot accurately be communicated through a translation - they come with a lot of contextual baggage where the meaning can not be communicated in words alone.--As a New Zealander who's lived in the U.S. for the last 15 years, I've realized in conversations with some native Americans where despite sincere (I think) efforts on both sides, I've not been able to communicate what I mean. I don't think it's anything to do with intelligence, but like author hints how language shapes how we think and therefore our realities.--I've never found poetry to be interesting, but recently I've come to appreciate how I think poets attempt to bypass this flaw of language, and how good poets sometimes seem to succeed!reply",
      "Western culture is predicated on a sort of positivist metaphysics, and our language reflects that. Whereas in the east, the langauges and cultures have both long ago (as in, thousands of years ago) assimilated the precepts of non-dualism, which brings with it a greater degree of subtlety, through its embedded understanding of  equanimity, dependent arising, and so on. It's a different ontological root, and therefore a different schema altogether.Knowing what I know of you guys in NZ, a lot of that sort of thinking has made its way into popular understanding by way of encounters with the Maori people, and some of it has to do with more modern notions of pluralism, and some of it has to do with British politeness.All that to say, it is not your fault nor the Americans fault that there's a gap in understanding. It's the byproduct of where those two schemas do not connect.reply",
      "native Americans or Native Americans? the latter would be more like the Moriori and fit the context better, but somehow native English speakers who arent interlegible are also interesting.reply",
      "The language pattern the author refers to is called litotes (https://en.wikipedia.org/wiki/Litotes), but to say that English doesn\u2019t use them is\u2026 not quite right.reply",
      "Not quite right, but not quite wrong, no? The pattern seems similar, but I think of litotes (as the Wikipedia article suggests) as a rhetorical device: the assertion-by-negation carries an ironic charge, and strikes the (Western) ear by standing out from the ordinary affirmative register.If I'm understanding the author's account of Chinese assertion-by-negation correctly, doesn't it sound like assertion-by-negation is the ordinary case in that linguistic tradition, and it's the assertive case that jars the ear? Same pattern, different effect?reply",
      "I think it's especially American English that doesn't use litotes as much as British English or the other Western European languages.This piece seems to be very much about American English, when I read something like:> In English, this feels bizarre. If something is good, you say: Nice Great Perfect Brilliantreply"
    ],
    "link": "https://suggger.substack.com/p/the-architecture-of-not-bad-decoding",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Sim \u2013 Apache-2.0 n8n alternative (github.com/simstudioai)",
    "points": 144,
    "submitter": "waleedlatif1",
    "submit_time": "2025-12-11T17:20:11 1765473611",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=46234186",
    "comments": [
      "This looks really cool for DIYing workflows, especially since you seem to have a very useful selection of tools!Did you build your own agent engine? Why not LangGraph?Say I was building a general agentic chat app with LangGraph in the backend (as it seems to provide a lot of infrastructure for highly reliable and interactive agents, all the way up to a protocol usable by UIs, plus a decent ecosystem, making it very easily extensible). Could I integrate with this for DIY workflows in a high quality fashion (high-precision updates and control)?Is there a case for switching out LangGraph\u2018s backend with Sim (can you build agents of the same quality and complexity - I\u2019m thinking coding agent)? Could it interact with LangGraph agents in a high quality way so you can tap that ecosystem?Can I use Sim workflows with my current agent, say, via MCP?reply",
      "1. we wanted to have full control over the agent orchestration and the execution since we didn't like the abstractions that many of the existing frameworks had built, and didn't want to have dependencies in places we didn't need them. so, we built the orchestration and execution engine from scratch, allowing us to do neat things like human in the loop, settings that run the same block 10 times concurrently, etc.2. this would kind of serve as a drop-in replacement for langgraph. you could build a workflow with an agent and some tools, perhaps some form of memory. then, just deploy that as an API, call it from your frontend, and consume the streamed response on your chat client and without the need to maintain any infra at all.3. we have a generic code block and an api block used to call APIs for integrations that we may not have, and you can use those to plug (langgraph) agents into the Sim ecosystem.4. we are adding in the ability to deploy your workflow as an MCP server in the next week, stay tuned :) in the meantime, you can deploy the workflow as an API and have the agent call it as a tool. moreover, you can use the workflow block in sim to call other agents/worklows as well, so its easy to encapsulate a lot of complexity in a `parent` workflow that you call that dynamically routes and uses different tools based on the task at handreply",
      "Their deployment stuff has been turning me off lately; everyone is rushing to monetize - which I understand and support - but I feel like Langsmith is creeping further and further into Langchain|graph and it makes me hesitant to invest. It\u2019s giving AWS-like gentle but firm lock-in vibes, I wonder if they have any PMs from there.I do like the way they\u2019ve been able to leverage Langgraph workflows to build agents - it seems like the right abstraction to me - and I also feel their middleware approach is very Django-y which I also like. Are you enjoying their stack?reply",
      "So here is a case that I wanted to implement in n8n a few years ago and it required quite heavy JS blocks:- I want to check some input - pick one of your 138 blocks- I want to extract a list of items from that input- I want to check which items did I encounter before <- that's the key bit- Do something for the items that have not been encountered before; bonus point for detecting updated and deleted items- Rinse and repeatIt could be a row added to a CSV file, a new file dropped into a Nextcloud folder, a list of issues pulled from a repo, or an RSS feed (Yahoo! Pipes, what a sweet memory).How good is the support for such a case in Sim? And did it get better in n8n?reply",
      "I really like windmill.dev which should support your scenario just finereply",
      "N8n can definitely do this.They recently added native tables, albeit still just a few data types, you can store stuff in and use in workflows.reply",
      "this is actually a perfect use case, mostly deterministic workflows that need LLMs to fill in the gaps or do the knowledge work. As you mentioned, you can either add it as a row in a CSV file (sheets), use the baked-in memory block and treat it as simple storage, store the row in supabase, or use the knowledgebase. Basically, there are a ton of ways that this can be done that don't require you to maintain the memory solution yourself. you can even detect the updated and deleted items by keeping some sort of version-controlled snapshot of each row in the csv and updating it as you go.I can't tell you whether it got better in n8n, but I can definitively say that this sounds like a great candidate workflow to build in sim :)reply",
      "But does that require AI agents? Well, maybe the extraction step, if it's not CSV but a general-case web page.reply",
      "Maybe in the middle, processing the items - classifying, summarizing.But the post bills the tool as an n8n alternative. Therefore, I am evaluating it as such. Solid basics before the AI whizbang.reply",
      "the agents would be great in the instructions where we need to `do something`, but asides from that is sounds like a pure orchestration task.now, handling an integration to something like google sheets myself for a task this small is a nightmare, not to mention the separate table I'd need to keep to store the access token & refresh token and the permissions I'd need to get from google. on top of that, hosting it somewhere and then monitoring it.reply"
    ],
    "link": "https://github.com/simstudioai/sim",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Open-source platform to build and deploy AI agent workflows.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\nBuild and deploy AI agent workflows in minutes.\n\n\n\n\nDesign agent workflows visually on a canvas\u2014connect agents, tools, and blocks, then run them instantly.\n\nLeverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.\n\nUpload documents to a vector store and let agents answer questions grounded in your specific content.\n\n\u2192 http://localhost:3000Docker must be installed and running on your machine.Access the application at http://localhost:3000/Run Sim with local AI models using Ollama - no external APIs required:Wait for the model to download, then visit http://localhost:3000. Add more models with:If you alrea"
  },
  {
    "title": "Craft software that makes people feel something (rapha.land)",
    "points": 240,
    "submitter": "lukeio",
    "submit_time": "2025-12-11T13:45:08 1765460708",
    "num_comments": 116,
    "comments_url": "https://news.ycombinator.com/item?id=46231274",
    "comments": [
      "> created solely for myself; I never had the intention of making it [...] mainstreamThis is how many artists have worked. They make something for themself, and one day they show it to someone else ... or they just get the urge to share it more widely, often without the hope that anyone will really be interested. Or they keep it for themself.I think Tolkien is in that group, for example. But don't get the wrong idea from an extreme outlier: much of the time, others aren't interested, or not many are. Sometimes, nobody is interested until after you've forgotten about it or passed away. Who cares? That's one reason you need to make it for yourself. Also, I think that otherwise it provides much less expression and insight into another person, which is at the core of art. There is a fundamental human need to 'externalize the imagination'.reply",
      "Several years ago, I wrote an angry email to loved ones about something I\u2019d seen in national news (USA) about my city. A friend replied saying that he thought I should submit it to a local paper. Ended up as an op-ed. Not a major claim to fame, but I was still pleased that someone cared enough about my words to publish.reply",
      "If you are actually making it for yourself then it shouldn\u2019t matter. I think sometimes people tell themselves they are doing it for them, but then they start thinking \u201cwell what would so and so think\u201d. I know I\u2019ve done it, but once I started actually making things for me, I could feel the difference.reply",
      "> This is how many artists have worked. They make something for themself, and one day they show it to someone elseThat model depended on personal wealth or (more often) patronage. Because the supply of wealthy patrons was limited, it meant that you had fewer artists pursuing their visions. Everyone else needed to find menial jobs.Now, we democratized access to patronage, but it means that to support yourself, you need to deliver what gets you the most clicks, not what your soul craves.I sort of wish we still had both models, but I think that wealthy patrons have gone out of fashion in favor of spending money on crypto and AI.reply",
      "> That model depended on personal wealth or (more often) patronage.\"They make something for themself, ..\"For the vast majority of people this means doing it on the side, in addition to their day-job. I've known a lot of artists in my time and we all have day jobs. You do art for yourself because you love to create, not expecting to make any significant money on it.reply",
      "Right, which works great if your daytime job is being a professor at Oxford, but maybe less so if your only opportunity is farm labor or other physically exhausting job.Today, more people have the opportunity to dabble in art than ever before.reply",
      "He started writing his stories long before he was a Professor. It was while he was a young man fighting in the First World War.reply",
      "Personally I've found it much easier to sustain creative stuff on the side while doing a non-knowledge-based job than a knowledge-based one. Mental exhaustion is much more of a drag than physical. (Though the knowledge-based hours were longer too, which I'm sure was a factor.)reply",
      "There are plenty of impovrished, struggling artists - it's a cliche - and especially unknown ones creating for themselves.> Everyone else needed to find menial jobs.That doesn't mean you can't create art. Anthony Trollope worked for the post office. Einstein, who externalized imagination in somewhat different way and attributed much to art, was a patent clerk. New York and LA are filled with waitstaff-artists. A friend hired a moving company that almost exclusively hired artists as movers (I know - they weren't too skinny?).reply",
      "I sincerely never understood the \u201cstarving artist\u201d thing. Everyone needs to be able to provide for themselves. The whole starving artist thing always came across (to me) as someone who refused to work because\u2026 art?Art, like anything else, lines up somewhere between a hobby and a career. Similar to athletes, somehow the cream just rises to the top.You never hear about \u201cstarving athletes\u201d I guess is what I mean.reply"
    ],
    "link": "https://rapha.land/craft-software-that-makes-people-feel-something/",
    "first_paragraph": "So, I woke up today. Got my coffee, family went to sleep, and I have a free afternoon.I thought about writing something. I may delete this article, but if you are reading this, it means I went through with it.Recently, people have been asking me why I\u2019m pausing Boo to work on a programming language. I think it would actually be cool to write down how I feel.Boo is a code editor I created solely for myself; I never had the intention of making it a mainstream editor. Of course, it would be fun if people used it, but that was never my goal. This year I got it working in a functional state, where I can actually use it for my daily work. It has innovative human-keyboard navigation and replaces the LSP system with something faster and less costly for the OS. So why on earth am I not open-sourcing it? That\u2019s what people keep asking me.First, let\u2019s go step by step.My mind isn\u2019t really moved by the idea that it would be a success or a failure \u2014 the end user of Boo is me. I don\u2019t feel it\u2019s there"
  },
  {
    "title": "UK House of Lords attempting to ban use of VPNs by anyone under 16 (alecmuffett.com)",
    "points": 270,
    "submitter": "nvarsj",
    "submit_time": "2025-12-11T20:32:22 1765485142",
    "num_comments": 256,
    "comments_url": "https://news.ycombinator.com/item?id=46236738",
    "comments": [
      "On a related note, they built their digital ID so that third parties could verify attributes (it's NOT just a single-service login across government + a linking ID across government services, which is how it was sold by the BBC).They're pretty close to completely de-anonymising the internet for UK citizens. Say they introduce an Australian-style social media ban for under 16s, then requires all social media to link their accounts to digital IDs for this verification.Naturally the only remaining loophole is if a UK citizen manages to avoid being flagged as British ever by using a VPN, so I expect they will focus on that going forwards. Keep in mind the UK already arrests and imprisons vast numbers of people for speech offences, there's no slippery-slope argument here because the UK is already at the bottom of the slope as an ultra-authoratitarian anti-speech nation.reply",
      "> On a related note, they built their digital ID so that third parties could verify attributesIsn\u2019t that the entire point of government ID of any variety? The only reason anyone ever asks to see ID is so they can use it verify attributes of your identity, such as name and age. Otherwise what\u2019s the point of an Identity Document, if it\u2019s not to document something?Digital ID has always been sold as something approximating your passport/Driver License (there is no official government ID in the UK), but digital, on your phone, and actually a government identity document. Rather than a government document that has a specific purpose (such as crossing the border or driving a car), which people pretend is government ID. Something that can cause a serious problem for people because passports and driver\u2019s licenses aren\u2019t free to obtain, replace or keep valid. Plus the government departments that issue them refuse to take any responsibility or liability for the accuracy or validity of the documents for any use case outside their very specific role in narrow government functions, like crossing the border, or figuring out if you\u2019re allowed to drive a car.The UK already has citizen SSO that stretches across all digital government services, and has had that for a decade plus now. Although it\u2019s not really attached your identity, it\u2019s just a unified auth system so government departments don\u2019t end up creating their own broken auth systems instead.reply",
      "> Isn\u2019t that the entire point of government ID of any variety?Ideally this could be done without deanonymizing accounts to service providers unless the user wants to for a 'verified' account linked to their identity publically but I don't think any digital ID system has been built that way. Imagine it acting like OAuth but instead of passing back an identity token it's just verification of age, platforms would store that which would show they had performed the age verification and could be used for other age gates if there are any.reply",
      "You're totally right that it would be easy from a tech perspective to do that. it's a shame that:(A) most people cannot grasp how it could be that \"GovSSO\" can attest \"This person you just sent our way just logged into GovSSO [with biometric 2FA], and they are at least 16 years old\" without the receiving system having any way of knowing who that citizen is or even whether they're 16 or 99.(B) very real terrible government policies the UK has (like jailing people for speech, and like demanding encryption backdoors that compromise the security, at minimum, of the whole of every British citizen's devices, and at worst every device in the world) incline anyone who's paying attention to assume that the government will somehow use anything related to \"ID\" and \"internet\" to do idiotic things like figuring out who owns a Twitter account that committed some wrongspeak so the bobbies can come round them up.reply",
      "A digital ID can be better than a passport / driver license, because it can verify only specific attributes of the bearer to a third party. E.g. only the fact that you're older than 21 in a liquor store or a car rental, but not other details readily visible in a passport.reply",
      "Nobody asked for it. Digital ID is being introduced to help the government, not the people.reply",
      "> Keep in mind the UK already arrests and imprisons vast numbers of people for speech offencesI think you\u2019ve been spending too much time on Twitterreply",
      "> While figures show that the total number of arrests for online posts fell to 9,700 last year, down from a record 13,800 in 2023...https://freespeechunion.org/daily-mail-investigation-exposes...reply",
      "This is based on statistics for the Malicious Communications Act. That includes people sending, for example, threatening messages to an ex partner.Not all of them are online posts, in fact probably a minorityreply",
      "That's what would be reasonably expected, but it's not backed up by the information.> The total arrest figures are likely to be far higher because eight forces failed to respond to freedom of information requests or provided inadequate data, including Police Scotland, the second largest force in the UK. Some forces also included arrests for \u201cthreatening\u201d messages, though these do not fall under the specified sections. [emphasis added]https://www.thetimes.com/uk/crime/article/police-make-30-arr... (https://archive.is/kC5x2#selection-3325.0-3325.335)reply"
    ],
    "link": "https://alecmuffett.com/article/134925",
    "first_paragraph": "by Alec MuffettThis is deranged, each nation\u2019s boomers and reactionaries attempting to outdo the others:\u201cAction to prohibit the provision of VPN services to children in the United Kingdom\u201d \u2026 the provider of any Relevant VPN Service which is, or is likely to be \u2014 (i) offered or marketed to persons in the United Kingdom; (ii) provided to a significant number of persons. (c) must make provision for the monitoring and effective enforcement of the child VPN prohibition.VPNs are a technology which anyone can implement for themselves. \u201cRegulatory compliance\u201d of them is not feasible, it\u2019d be like banning DIY.Not to mention it would include The Tor Project.Your email address will not be published. Required fields are marked *Comment * Name * Email * Website  \n\n\u0394 Proudly powered by WordPress "
  },
  {
    "title": "Christmas Tree Exec (wikipedia.org)",
    "points": 14,
    "submitter": "jamesgill",
    "submit_time": "2025-12-06T05:07:44 1764997664",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://en.wikipedia.org/wiki/Christmas_Tree_EXEC",
    "first_paragraph": ""
  },
  {
    "title": "Powder and stone, or, why medieval rulers loved castles (1517.substack.com)",
    "points": 28,
    "submitter": "areoform",
    "submit_time": "2025-12-11T21:35:52 1765488952",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=46237501",
    "comments": [
      "Interesting read. Digging in and fortifying positions is very much still a crucial part of war. For example, in the current Russo-Ukrainian war, structures such as trenches, bunkers, basements, towers, buildings etc. are crucial for holding onto terrain. Also obstacle-like structures such as concertina wire, anti-tank ditches, dragon's teeth, minefields, czech-hedgehogs, etc. are all over the place. Wherever soldiers appear, they basically dig in and start fortifying, constructing structures both for their own protection as well as for obstructing enemy movement. An interesting recent development are kilometers-long anti-drone tunnels along key logistical routes, meant mostly for stopping rotary FPV drones that are trying to intercept logisticsreply",
      "> kilometers-long anti-drone tunnels along key logistical routes, meant mostly for stopping rotary FPV drones that are trying to intercept logisticsWhere they put nets over the road for camoflage or physically catching the drones, right?I couldn't find a good picture and for a second I thought you meant an earthen tunnel.reply",
      "Happy to see \"de bello Gallico\" mentioned. The finale, the siege of Alesia, was all about building.reply"
    ],
    "link": "https://1517.substack.com/p/powder-and-stone-or-why-medieval",
    "first_paragraph": ""
  },
  {
    "title": "Almond (YC X25) Is Hiring SWEs and MechEs (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-12-11T21:00:10 1765486810",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/almond-2/jobs",
    "first_paragraph": "Robots designed for the era of AIOur mission is to free humans from physical labor with robotics.We imagine a future where robots handle the essential, repetitive work and humans are free to create, connect, and pursue what truly matters to them.To build that future we\u2019re starting from the ground up with hardware. Our first product is a California-designed and assembled humanoid arm. Surrounding it, we\u2019re developing advanced controls, intuitive data collection, and a full AI stack that makes deployment effortless in real industrial environments. We\u2019re proving it on our own assembly line first.\u00a9 2025 Y Combinator"
  },
  {
    "title": "Pdsink: USB Power Delivery Sink library for embedded devices (github.com/pdsink)",
    "points": 7,
    "submitter": "zdw",
    "submit_time": "2025-12-07T04:14:03 1765080843",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/pdsink/pdsink",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        USB PD Sink implemetation for embedded.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.USB PD Sink library for embedded devices.This library focuses on the most common needs of PD\u2011powered projects and on\nease of use.Features:Not supported:See docs and examples.Note that this package uses ETL but does not pin a\nspecific version, to avoid conflicts with your application. Set a specific\ndependency version in your application to keep the configuration stable.Other projects with USB PD support:Documentation:\n        USB PD Sink implemetation for embedded.\n       There was an error while loading. Please reload this page.\nThere was an error while l"
  },
  {
    "title": "The Walt Disney Company and OpenAI Partner on Sora (openai.com)",
    "points": 149,
    "submitter": "inesranzo",
    "submit_time": "2025-12-11T14:05:16 1765461916",
    "num_comments": 415,
    "comments_url": "https://news.ycombinator.com/item?id=46231493",
    "comments": [
      "buried the lede:> As part of the agreement, Disney will make a $1 billion equity investment in OpenAI, and receive warrants to purchase additional equity.I say this with no snark or disdain: Sam has mastered the art of the flywheel.Re licensed ai videos, if anyone wants to see the perspective the C-suites are being sold on, check out this episode of Belloni's The Town, in which they discuss the vision for AI + IP \n https://overcast.fm/+AA4DU9JreIEreply",
      "Disney said \"Our IP is $1B for a 3yr license, or we sue\"Altman said \"We can pay with equity, but let's frame it as an investment\"No cash exchangedreply",
      "Disney is actually paying $1B so it makes no sense. OpenAI gets the IP plus $1B.reply",
      "I'm actually curious, how do we know for a fact that this is the case?reply",
      "Disney loves the idea of giving investors an angle to bet on AIreply",
      "This is probably very similar to what happened!reply",
      ">I say this with no snark or disdain: Sam has mastered the art of the flywheel.It's been his entire career. Guy has made billions of dollars from talking.reply",
      "Yeah, he\u2019s a sociopathreply",
      "Did we forget about Enron? Or are we deliberately retconning it? Many such cases.reply",
      "Lmao your user name.I like the phrase \u201cvulture capital\u201dreply"
    ],
    "link": "https://openai.com/index/disney-sora-agreement/",
    "first_paragraph": ""
  },
  {
    "title": "My productivity app is a never-ending .txt file (2020) (jeffhuang.com)",
    "points": 157,
    "submitter": "simonebrunozzi",
    "submit_time": "2025-12-11T19:30:58 1765481458",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=46236037",
    "comments": [
      "I've been noticing lately, at least for myself, that useful technology stopped happening like 10-20 years ago. If all you could use was tech from 2000 and before you would have a pretty stable stack that just worked (without a monthly subscription.)There is also this article today: https://jon.recoil.org/blog/2025/12/an-svg-is-all-you-need.h...  about how great good ol' svg is.   And then every recurring article about using RSS instead of all the other siloed products.textfiles, makefiles, perl, php, rss, text based email, news groups, irc, icq, vim/emacs, sed, awk; all better than the crap they have spawned that is supposed to be \"better\".Out of curiosity, what technology in the past 5 years do you use that you actually find better than something from 20 years ago?reply",
      "- Uv for Python- Nix- Performant Virtualization- Ghostty- DuckDB and, in general, performant OLAPDon't get me wrong as I do feel the core of your thesis is correct.  Emacs is my editor and I just finished writing a nicely recursive set of gMake for cloud a pipeline.  Most of my core software tools haven't changed appreciably since the mid 2000s--right around the time git came out.edit: I had no idea Nix was so old.  I guess it just feels very \"new\" in my zeitgeist.reply",
      "> what technology in the past 5 years do you use [...]I don't use any software made in the past 5 years.I think software has improved in the last 20 years.  - Linux container runtimes\n  - Linux hardware support\n  - NixOS (19.5 years old!)\n\nMy terminal has more colors. My browser got slower.My vi became vim became neovim. The keybindings are almost the same, but they adapt to newer virtual terminals.As a programmer, my ability to express myself has got more nuanced. Programming languages have got better.But the software itself doesn't seem to be better. Everything still depends on C, and the older programs live the longest.reply",
      "> all you could use was tech from 2000 and before you would have a pretty stable stack that just workedThe improvements made during the late 2000s and 2010s mostly had to do with making the functionality of these technologies accessible to non-technical users. I was younger and probably more mentally agile back then, but I remember the first iTouch I ever bought being very intuitive to use; you could usually intimate what you wanted to do without even looking it up. I got so accustomed to this intuitiveness (Windows Vista being an unhappy interruption in those series of memories) that by the time Windows 8 rolled around I was completely taken aback by how bad it was.I mentioned in another comment that these productivity apps only really see a positive net expected value at the enterprise level, where they aren\u2019t primarily used for efficiency but as coordination mechanisms and institutional memory. Individual users can only really hope to take advantage of them if they are intuitive to use.From what I\u2019ve observed, most of these UX failures are not the result of a lack of technical aptitude, nor an issue of cost, but of failures in institutional coordination (principal-agent problems and things like that) or the market simply being cornered; both follow the general trend of consolidation in the tech industry. The companies that are making most of our software are huge and they lack the competition to incentivize them to improve.reply",
      "What\u2019s an iTouch?reply",
      "iTouch was a common nickname for the iPod Touch[0].\nIt was essentially an iPhone without a cellular connection.[0]: https://en.wikipedia.org/wiki/IPod_Touchreply",
      "I'd say Obsidian (just over five years old, since its first release), which is ironic because it's basically just a UI on top of text files.reply",
      "I don't think it's better than org-mode, but org-mode is also post-2000 so doesn't count here. Obsidian isn't open source, isn't plain text enough, and is slow.Markdown also falls outside the pre-2000 window as well. But, it's closely based on email and news conventions.reply",
      "I'd definitely agree with you on that one.  Also notice how the company doesn't push monthly subscriptions on people and just lets their program exist out there.reply",
      "But it's not, it's a database. That is annoying\u00f8y hard to move around and version controlreply"
    ],
    "link": "https://jeffhuang.com/productivity_text_file/",
    "first_paragraph": "\r\nThe biggest transition for me when I started college was learning to get organized. There was a point when I couldn't just remember everything in my head. And having to constantly keep track of things was distracting me from whatever task I was doing at the moment.\r\n\r\nSo I tried various forms of todo lists, task trackers, and productivity apps. They were all discouraging because the things to do kept getting longer, and there were too many interrelated things like past meeting notes, calendar appointments, idea lists, and lab notebooks, which were all on different systems.\r\n\r\nI gave up and started just tracking in a single text file and have been using it as my main productivity system for 14 years now. It is so essential to my work now, and has surprisingly scaled with a growing set of responsibilities, that I wanted to share this system. It's been my secret weapon.\r\n\nPrerequisite: A calendar. The one outside tool I use is an online calendar, and I put everything on this calendar, e"
  },
  {
    "title": "Auto-grading decade-old Hacker News discussions with hindsight (karpathy.bearblog.dev)",
    "points": 569,
    "submitter": "__rito__",
    "submit_time": "2025-12-10T17:23:53 1765387433",
    "num_comments": 251,
    "comments_url": "https://news.ycombinator.com/item?id=46220540",
    "comments": [
      "It's fun to read some of these historic comments! A while back I wrote a replay system to better capture how discussions evolved at the time of these historic threads. Here's Karpathy's list from his graded articles, in the replay visualizer:Swift is Open Source\nhttps://hn.unlurker.com/replay?item=10669891Launch of Figma, a collaborative interface design tool\nhttps://hn.unlurker.com/replay?item=10685407Introducing OpenAI\nhttps://hn.unlurker.com/replay?item=10720176The first person to hack the iPhone is building a self-driving car\nhttps://hn.unlurker.com/replay?item=10744206SpaceX launch webcast: Orbcomm-2 Mission [video]\nhttps://hn.unlurker.com/replay?item=10774865At Theranos, Many Strategies and Snags\nhttps://hn.unlurker.com/replay?item=10799261reply",
      "Comment dates on hn frontend are sometimes altered when submissions are merged, do you handle this case properly?reply",
      "It is handled on the Unlurker front page (you will see a little note that says \u201ctime adjusted for second chance\u201d). The replay doesn\u2019t do any adjustment for it, but I think that makes it reflect the reality of when the comments came in since the adjustments are like a temporary bumpreply",
      "I'd love to see sentiment analysis done based on time of day. I'm sure it's largely time zone differences, but I see a large variance in the types of opinions posted to hn in the morning versus the evening and I'd be curious to see it quantified.reply",
      "Yeah, I see this constantly any time Europe is mentioned in a submission. Early European morning/day, regular discussions, but as the European afternoon/evening comes around, you start noticing a lot anti-union sentiment, discussions start to shift into over-regulation, and the typical boring anti-Europe/EU talking points.reply",
      "\u201cRegular\u201d to who? Pro EU sentiment almost only comes from the EU, which is what you\u2019re observing. Pro-US sentiment is relatively mixed (as is anti-US sentiment) in distribution.reply",
      "> Pro EU sentiment almost only comes from the EUSays who? But also, it doesn\u2019t suggest what you imply. I could as easily conclude: \u201cOh wow, the people who actually experience the system like it that much? Awesome!\u201dreply",
      "e.g. how many are cali tech bros vs nyc fintec vs 10am moscow shillbot timereply",
      "I like the \"past\" functionality here, maybe wished there was one for week/month I could scroll back as well.Miss it for reddit as well. Top day/week/month/alltime makes it hard to find top a month in 2018.reply",
      "Okay, your site is a ton of fun. Thank you! :)reply"
    ],
    "link": "https://karpathy.bearblog.dev/auto-grade-hn/",
    "first_paragraph": "Home Blog\n\n\n    10 Dec, 2025\n\n\nTLDR: https://karpathy.ai/hncapsule/Yesterday I stumbled on this HN thread Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now, where Gemini 3 was hallucinating the frontpage of 10 years from now. One of the comments struck me a bit more though - Bjartr linked to the HN frontpage from exactly 10 years ago, i.e. December 2015. I was reading through the discussions of 10 years ago and mentally grading them for prescience when I realized that an LLM might actually be a lot better at this task. I copy pasted one of the article+comment threads manually into ChatGPT 5.1 Thinking and it gave me a beautiful analysis of what people thought + what actually happened in retrospect, even better and significantly more detailed than what I was doing manually. I realized that this task is actually a really good fit for LLMs and I was looking for excuses to vibe code something with the newly released Opus 4.5, so I got to work. I'm going to get all the "
  },
  {
    "title": "EFF launches Age Verification Hub (eff.org)",
    "points": 234,
    "submitter": "iamnothere",
    "submit_time": "2025-12-10T20:35:07 1765398907",
    "num_comments": 209,
    "comments_url": "https://news.ycombinator.com/item?id=46223389",
    "comments": [
      "This keeps coming up and we keep having the same debates about what Age Verification isn't.For the folks in the back row:Age Verification isn't about Kids or Censorship, It's about SurveillanceAge Verification isn't about Kids or Censorship, It's about SurveillanceAge Verification isn't about Kids or Censorship, It's about SurveillanceWithout even reaching for my tinfoil hat, the strategy at work here is clear [0 1 2].  If we have to know that you're not a minor, then we also have to know who you are so we can make any techniques to obfuscate that illegal.  By turning this from \"keep an eye on your kids\" to \"prove you're not a kid\" they've created the conditions to make privacy itself illegal.VPNs are next.  Then PGP.  Then anything else that makes it hard for them to know who you are, what you say, and who you say it to.Please, please don't fall into the trap and start discussing whether or not this is going to be effective to protect kids.  It isn't, and that isn't the point.0 https://www.eff.org/deeplinks/2025/11/lawmakers-want-ban-vpn...1 https://www.techradar.com/vpn/vpn-privacy-security/vpn-usage...2 https://hansard.parliament.uk/Lords/2025-09-15/debates/57714...reply",
      "> If we have to know that you're not a minor, then we also have to know who you areThat is untruereply",
      "Are you aware of any age verification systems that do not have this property?(This includes being robust against law enforcement action, legal or otherwise.)reply",
      "Like many mention in other comments on this post, it's possible to implement using ZKPs.  There are likely other methods that would be effective without compromising privacy.  None of them are part of the Age Verification discussion because kids are not the actual point of Age Verification.When I say \"if we have to know you're not a kid, we have to know who you are\" I'm not stating an actual truth, but the argument as it is playing out politically.reply",
      "> None of them are part of the Age Verification discussion because kids are not the actual point of Age Verification.The EU age verification solution says implementations SHOULD implement[1] their ZKP protocol[2]. Not linking it to the user is stated as an explicit goal:Unlinkability: The goal of the solution is to prevent user profiling and tracking by avoiding linkable transactions. Initially, the solution will rely on batch issuance to protect users from colluding RPs. Zero-Knowledge Proof (ZKP) mechanisms will be considered to offer protection. More details are provided in Section 7. [1]: https://ageverification.dev/av-doc-technical-specification/d...[2]: https://ageverification.dev/av-doc-technical-specification/d...reply",
      "Is there a good explanation of how ZKPs prevent attestation providers (which presumably know your identity) from linking an issued proof back to you if, for example, the website elects to store it? I can wrap my head around RSA and ECC and PKI, but I haven't managed to make sense of this yet.Assuming that's even a goal, of course. The cited paragraph mentions RPs (the websites, from what I understand), but makes no mention of attestation providers.reply",
      "This is, of course, very technical, but here is how it works at a high level.In the non-ZKP presentation, the \"holder\" (phone) sends the credential to the relying party (website), and the RP executes some verification algorithm.  In the ZK presentation, the holder executes the verification algorithm and sends to the RP a proof that the algorithm was executed correctly.The \"proof\" has this magical property that it reveals nothing other than the check passed.  (You will have to take on faith that such proofs exist.)  In particular, if the check was the predicate \"I have a signature by ISSUER on HASH, and SHA256(DOCUMENT)==HASH, and DOCUMENT[\"age_gt_18\"]=TRUE\", anybody looking at the proof cannot infer ISSUER, HASH, DOCUMENT, or HASH, or nothing else really.  \"Cannot infer\" means that the proof is some random object and all HASH, DOCUMENT, ISSUER, etc. that satisfy the predicate are equally likely, assuming that the randomness used in the proof is private to the holder.  Moreover, a generating a proof uses fresh randomness each time, so given two proofs of the same statement, you still cannot tell whether they come from the same ISSUER, HASH, DOCUMENT, ...reply",
      "the more I think about it, the more I feel like I need someone with deep knowledge to explain ZKPs to me.So like, we've got this algorithm that gets sent our way and we run it and that provides kind of a cryptographic hash or whatever.  But if we're running the algorithm ourselves what's to stop us from lying? Where does the 'proof' come from?  What's the check that it's running and why do we inherently trust the source it's checking?reply",
      "I am someone with \"deep knowledge\", but HN is not the proper place for this discussion.  See https://people.cs.georgetown.edu/jthaler/ProofsArgsAndZK.htm... for the gory details.Here is a hopefully simple example of how this ZKP thing may even be possible.  Imagine that you give me a Sudoku puzzle.  I solve it, and then I want to prove to you that I have solved it without telling you the solution.  It sounds impossible, but here is one way to do it.\nI compute the solution.  I randomly scramble the digits 1-9 and I put the scrambled solution in a 9x9 array of lock boxes on a table.  I have the keys to the 81 locks but I am not giving you the key yet.  You randomly ask me to open either 1) one random row chosen by you; 2) one random column chosen by you; 3) one random 3x3 block chosen by you; or 4) the cells corresponding to the original puzzle you posed to me.  In total you have 28 possibilities, and assume that you choose them with equal probability.  You tell me what you want and I open the corresponding lockboxes.  You verify that the opened lock boxes are consistent with me knowing a solution, e.g. all numbers in a row are distinct, the 3x3 block consists of distinct numbers, etc.  If I am cheating, then at least one of your 28 choices will be inconsistent, and you catch me with probability 1/28, so if we repeat this game 1000 times, and I don't know the solution, you will catch me with probability at least 1-(1/28)^1000 which is effectively 1.  However, every time we repeat the game, I pick a different random scrambling of the integers 1-9, so you don't learn anything about the solution.All of ZKP is a fancy way to 1) encode arbitrary computations in this sort of protocol, and 2) amplify the probability of success via clever error-correction tricks.The other thing you need to know is that the protocol I described requires interaction (I lock the boxes and you tell me which ones to open), but there is a way to remove the interaction.  Observe that in the Sudoku game above, all you are doing is flipping random coins and sending them to me.  Of course you cannot let me pick the random coins, but if we agree that the random coins are just the SHA256 hash of what I told you, or something else similarly unpredictable, then you will be convinced of the proof even if the \"coins\" are something that I compute myself by using SHA256.  This is called the \"Fiat-Shamir transformation\".How do we implement the lock boxes?  I tell you SHA256(NONCE, VALUE) where the NONCE is chosen by me.  Given the hash you cannot compute VALUE.  To open the lock box, I tell you NONCE and VALUE, which you believe under the assumption that I cannot find a collision in SHA256.reply",
      "If it's not linked to an identity, why can't a kid use a parent's key?reply"
    ],
    "link": "https://www.eff.org/press/releases/eff-launches-age-verification-hub-resource-against-misguided-laws",
    "first_paragraph": "SAN FRANCISCO\u2014With ill-advised and dangerous age verification laws proliferating across the United States and around the world, creating surveillance and censorship regimes that will be used to harm both youth and adults, the Electronic Frontier Foundation has launched a new resource hub that will sort through the mess and help people fight back.\u00a0To mark the hub's launch, EFF will host a Reddit AMA (\u201cAsk Me Anything\u201d) next week and a free\u00a0livestreamed panel discussion on January 15 highlighting the dangers of these misguided laws.\u00a0\u201cThese restrictive mandates strike at the foundation of the free and open internet,\u201d said EFF Activist Molly Buckley. \u201cWhile they are wrapped in the legitimate concern about children's safety, they operate as tools of censorship, used to block people young and old from viewing or sharing information that the government deems \u2018harmful\u2019 or \u2018offensive.\u2019 They also create surveillance systems that critically undermine online privacy, and chill access to vital onli"
  }
]