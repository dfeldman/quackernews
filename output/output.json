[
  {
    "title": "If you put Apple icons in reverse it looks like someone getting good at design (threads.com)",
    "points": 119,
    "submitter": "lateforwork",
    "submit_time": "2026-01-17T23:47:16 1768693636",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=46663338",
    "comments": [
      "It looks like someone getting good at illustration. Older icons are far better illustrations. However icon design is not just about illustration, it's about clarity and affordances. Icons don't exist in isolation like an illustration, they exist alongside the rest of the UX and other app icons, and being recognisable is important.All that to say, the sweet pot was likely somewhere in the middle of this timeline. The earliest icons aren't recognisable enough as they're too illustrative. The later icons aren't recognisable enough because they're too basic. The middle are pretty, clear from colour, clear from shape, well branded.reply",
      "I spent half a year designing and creating 200+ icons for a custom geospatial mapping app. I really enjoyed the work but it was grueling and tedious, especially the design part. Too many people had too many different opinions on which symbols meant what, which styles clearly conveyed ideas without being too detailed, and many other things that kept wasting my time and causing a lot of rework and inconsistencies. It was literally just me doing the work, so I stopped trying to get consensus and took a few weeks to redesign the entire set and even used color science to inform my design decisions. I created the entire set without external input, then presented it. Sure there was some tweaking here and there, but I believe it turned about to be great and no one really complained in the end. The most important part was that end-users were happy. I used Inkscape and developed a set of scripts to automate the build and had everything in a very organized Git repo.reply",
      "None of the Pages icons are recognisable because almost no one uses Pages. The word icon is just a blue W which is not any more illustrative than an orange pen.reply",
      "I agree. The middle one seems to be the best combination of clarity and simplicity.reply",
      "Between this, and icon-only toolbars and ribbons, I think we're reinventing Chinese, badly. Ideographic characters can often convey meaning succinctly.My vote is to either go back to picture icons, or use Chinese characters with localized pronunciation, so \u8eca or \u8f66 is car, and so on.reply",
      "Chinese is not in any way ideographic unless you are already partially literate.reply",
      "I'm sure design theory says the new ones are better, but the very first one was much clearer for users. Also on the phone I could say \"click on the ink with the pen\".reply",
      "On the phone you can now say \"Command + space, then search pages\"reply",
      "There is no such \"design theory,\" only schools of designreply",
      "I wish this was better understood.reply"
    ],
    "link": "https://www.threads.com/@heliographe.studio/post/DTeOwAykwQ1",
    "first_paragraph": ""
  },
  {
    "title": "A programming language based on grammatical cases of Turkish (github.com/kip-dili)",
    "points": 118,
    "submitter": "nhatcher",
    "submit_time": "2026-01-17T20:44:52 1768682692",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=46661897",
    "comments": [
      "Hi all, Kip's developer here! I was going to wait until we had finished the playground and landing page before posting about the project more, but here's the browser-based playground we have so far (thanks to Alperen Keles) for anyone who wants to play with the language: https://alpaylan.github.io/kip/(The work on JavaScript transpilation just started today and currently doesn't work, but running the language should mostly work, though it probably has bugs, which I'd love to hear about in the repo's issues!)reply",
      "Okay there is an updated web page and playground now: https://kip-dili.github.io/reply",
      "I studied Turkish for a few years and remember thinking it could make an interesting programming language (due to the grammatical/agglutinative features). I was gonna call it \u00c7, but I was never seriously going to make it. Happy to see someone went for it!reply",
      "\"Kip (meaning \"grammatical mood\" in Turkish)\"I'm not sure what a grammatical mood is, so I tried a couple of well known translation services and got: kip == \"mode\".  However big G did also manage \"modal\", \"paradigm\", \"tense\" and \"module\".For my money: \"tense\".  Just to confuse the issue, tense has several meanings in english!  Here I think we are talking about a verbal tense:https://www.bbc.co.uk/bitesize/articles/zh4thbk#zyh2s82Tense can also be synonymous with emotion: dangerous/exciting and also as a measure: tension/tight.reply",
      "In linguistics, tense is a verb conjugation to indicate temporal information, while mood is a conjugation to indicate various kinds of metainformation about the speaker's relationship to the information in the sentence. It's not as common a term as \u2018tense\u2019 when discussing English, because English doesn't conjugate for mood, but it is the standard word for describing some features of Turkish morphology such as evidentiality.Automatic translators, while an impressive and convenient piece of technology, usually focus on providing a plausible gloss in the target language, so typically lose a lot of nuance. For looking up words a dictionary is usually a better bet; for example, Wiktionary has https://en.wiktionary.org/wiki/kip#Turkish with a link to the explanation of the English word as well.reply",
      "> because English doesn't conjugate for moodIt does, but like some other English inflectional patterns the syntax is mostly vestigial.All I ask is that the two of you be polite to each other has be in subjunctive mood; if it were indicative, it would be are instead.Something that I find interesting is that, while conjugating verbs for mood is largely vestigial in English, the more general phenomenon of paying close attention to the relationship between the sentence and reality, the focus that mood expresses, is very much alive. It's just that it's mostly moved out of the inflectional system.reply",
      "It has constructs for a few different moods/modes[1], but no conjugation: the morphology used to form moods is borrowed from other verb forms (in your example, the bare infinitive) that were never (as far as I know!) dedicated mood conjugations.[1]: pedantically they are \u2018modes\u2019 in the linguistic jargon, but often referred to as \u2018moods\u2019 in discussions of English grammar: linguistically a mood is the grammatical morphology used to signify a mode, which English lacks.reply",
      "> It has constructs for a few different moods/modes[1], but no conjugation: the morphology used to form moods is borrowed from other verb forms (in your example, the bare infinitive) that were never (as far as I know!) dedicated mood conjugations.Well, this is mixing an argument about the facts with an argument about the history.On the facts this is a mood expressed by conjugating the verb. It obviously isn't an infinitive form because it's a finite verb. It is identical with the infinitive form, and this is a general rule of English (only observable with this one verb), but there's nothing stopping different forms from being identical, even identical by rule. In Latin the nominative and accusative case of a neuter noun are always identical.",
      "A grammatical mood indicates the modality of the verb, and some languages possess rich inventories of the grammatical moods. They are called differently in different languages, but mood is an established term in English.English has indicative (\u00abgo\u00bb, \u00abis going\u00bb etc), subjunctive / conjunctive / conditional (\u00abwent\u00bb in \u00abas if they went\u00bb), imperative (\u00abgo!\u00bb).German has two conditional moods \u2013 Konjunktiv I and II, for example.Finno-Ugric languages have many more.reply",
      "> English has ... subjunctive / conjunctive / conditional (\u00abwent\u00bb in \u00abas if they went\u00bb)That isn't the English subjunctive.You're correct that this construction expresses the same thing that another language might express by marking a non-indicative mood on the verb, but it would not conventionally be said to use a non-indicative mood. That went is a normal past-tense indicative verb and the modality is expressed by the whole structure of the clause, not just by the inflection of the verb.In linguistics there's a whole set of parallel vocabulary where one set is for grammatical forms and the mirror set is for the semantics usually expressed by those forms. So you have grammatical \"tense\" and semantic \"time\" or grammatical \"mood\" and semantic \"modality\". You got the modality right, but not the mood.Compare the conventional analysis that he will be there tomorrow expresses future time, but is not in future tense because there is no English future tense.reply"
    ],
    "link": "https://github.com/kip-dili/kip",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A programming language based on grammatical cases of Turkish.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Kip (meaning \"grammatical mood\" in Turkish) is an experimental programming language that uses Turkish grammatical cases as part of its type system. It demonstrates how natural language morphology\u2014specifically Turkish noun cases and vowel harmony\u2014can be integrated into programming language design.This is a research/educational project exploring the intersection of linguistics and type theory, not a production programming language.There is also a tutorial in Turkish and a tutorial in English that explains how to write Kip programs.NoteKip is experimental. Expect changes in syntax and behavior over time.For you to get a taste of what Kip looks like, her"
  },
  {
    "title": "ASCII characters are not pixels: a deep dive into ASCII rendering (alexharri.com)",
    "points": 824,
    "submitter": "alexharri",
    "submit_time": "2026-01-17T11:15:26 1768648526",
    "num_comments": 102,
    "comments_url": "https://news.ycombinator.com/item?id=46657122",
    "comments": [
      "Amazing post, I didn\u2019t think this through a lot, but since you are normalizing the vectors and calculating the euclidean distance, you will get the same results using a simple matmul, because euclidean distance over normalized vectors is a linear transform of the cosine distance.Since you are just interested in the ranking, not the actual distance, you could also consider skipping the sqrt. This gives the same ranking, but will be a little faster.reply",
      "It's stuff like this I would have loved to know when I was doing game engine dev in the 90s.reply",
      "I want to do game programming again like it's 1999. No more `npm i` or \"accept all cookies\" :/ rant off :)reply",
      "Go make a game for the Sega Genesis https://mdengine.dev/Or, the GameBoy Advance https://github.com/GValiente/butanoreply",
      "I do enjoy these kinds of write ups, especially when it's about something that might seem so simple on the surface, but in order to get looking great you really have to go in deep.Lucas Pope did a really nice write up on how he developed his dithering system for Return of The Obra Dinn. Recommended if you also enjoyed this blog post.https://forums.tigsource.com/index.php?topic=40832.msg136374...reply",
      "> The image of Saturn was generated with ChatGPT.Wait...wh...why?!?\nOf all the things, actual pictures of the planet Saturn are readily available in the public domain. Why poison the internet with fake images of it?reply",
      "https://www.theverge.com/2023/3/13/23637401/samsung-fake-moo...Are we sure the planets are real?reply",
      "How can planets be real if our eyes aren\u2019t real?reply",
      "> > The image of Saturn was generated with ChatGPT.> Wait...wh...why?!?It has just begun. Wait until nobody bothers using Wikipedia, websites, or even one day forums.This is going to eat everything.And when it's immediate to say something like, \"I need a high contrast image of Saturn of dimensions X by Y, focus on Saturn, oblique angle\" -- that's going to be magic.We'll look at the internet and Google like we look at going to the library and grabbing an encyclopedia off the shelves.The use of calculators didn't kill ingenuity, nor did the switch to the internet. Despite teachers protesting both.Humans will always use the lowest friction thing, and we will never stop reaching for the stars.reply",
      "I\u2019ve been having The Talk with my kids recently. They\u2019ll say \u201cI looked up this question and the answer was X.\u201d And I\u2019ll ask \u201cwas that answer on a credible website, or was it an AI summary?\u201d And then explain, again, that LLMs are great at producing plausible sounding explanations for things, but that you have to ground-truth anything that they tell you if it\u2019s important that it\u2019s correct.reply"
    ],
    "link": "https://alexharri.com/blog/ascii-rendering",
    "first_paragraph": "Recently, I\u2019ve been spending my time building an image-to-ASCII renderer. Below is the result \u2014 try dragging it around, the demo is interactive!One thing I spent a lot of effort on is getting edges looking sharp. Take a look at this rotating cube example:Try opening the \u201csplit\u201d view. Notice how well the characters follow the contour of the square.This renderer works well for animated scenes, like the ones above, but we can also use it to render static images:The image of Saturn was generated with ChatGPT.Then, to get better separation between different colored regions, I also implemented a cel shading-like effect to enhance contrast between edges. Try dragging the contrast slider below:The contrast enhancement makes the separation between different colored regions far clearer. That was key to making the 3D scene above look as good as it does.I put so much focus on sharp edges because they\u2019re an aspect of ASCII rendering that is often overlooked when programmatically rendering images as"
  },
  {
    "title": "Xous Operating System (xous.dev)",
    "points": 69,
    "submitter": "eustoria",
    "submit_time": "2026-01-14T17:29:09 1768411749",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=46619059",
    "comments": [
      "Here's their 39c3 talk about Xous: https://media.ccc.de/v/39c3-xous-a-pure-rust-rethink-of-the-...reply",
      "Interesting, didn't hear from this system so far. Seems to be funded by the EU. Apparently it is written in pure Rust since 2020, and Andrew \"bunnie\" Huang seems to be involved.Is there a PDF version of the book (https://betrusted.io/xous-book/)?reply",
      "There is a single-page version of the book that you can save as a PDF: https://betrusted.io/xous-book/print.htmlreply",
      "Great, thanks.I assume the \"kernel\" makes heavy use of \"unsafe\", because all the infrastructure assumed by Rust is not available. Or how was this solved?reply",
      "From the talk linked above, they went to considerable effort to design a system with a cheap processor which nevertheless contains an mmu, and so most other embedded kernels, which assume the lack of one, are not applicable. So the point of writing in rust is that they can ensure that some of the guarantees of rust are enforced by the hardware. (It's been a while since I watched that talk, so I don't recall exactly which ones). And this is a microkernel, not a monolithic kernel, so they will be using hardware guarantees even between kernel components.reply",
      "It's not really about infrastructure but yes kernels and firmwares have to do a lot of stuff the compiler can't verify as safe, eg writing to a magic memory address you obtained from the datasheet that enables some feature of the chip. And that will need to happen in unsafe code blocks. I wouldn't call that a problem but it is a reality.reply",
      "Are you one of the authors? Concerning the \"infrastructure\": Rust assumes a runtime, the standard library assumes a stack exists, a heap exists, and that main() is called by an OS; in a kernel, none of this is true. And the borrow checker cannot reason about things like e.g. DMA controllers mutating memory the CPU believes it owns, Memory-mapped I/O where a \"read\" has side effects (violating functional purity), context switches that require saving register state to arbitrary memory locations, or interrupt handlers that violate the call stack model. That's what I mean by \"infrastructure\". It's essentially the same issue with every programming language to some degree, but for Rust it is relevant to understand that the \"safety guarantees\" don't apply to all parts of an operating system, even if written in Rust.reply",
      "I have no affiliation, I'm just a commenter.The standard library requires a heap and such, but you can enable the no_std attribute to work in environments where they don't exist. https://docs.rust-embedded.org/book/intro/no-std.htmlRust's safety model only applies to code you write in your program, and there's a lot that's unsafe (cannot be verified by the compiler) about writing a kernel or a firmware, agreed. You could have similar problems when doing FFI as well.reply",
      "Rust assumes a runtime, the standard library assumes a stack exists, a heap\n  exists, and that main() is called by an OS;\n\nWrong.reply",
      "Use of \"unsafe\" is unavoidable. Various pieces of hardware are directly writing into the address space. Concepts of \"ownership\" and \"mutability\" go beyond code semantics.reply"
    ],
    "link": "https://xous.dev/",
    "first_paragraph": "Xous is a microkernel operating system designed for medium embedded systems with clear separation of processes. Nearly everything is implemented in userspace, where message passing forms the basic communications primitive.You can read more about it in the Xous Book.This project is funded through the NGI0 PET Fund, a fund established by NLnet\nwith financial support from the European Commission's Next Generation Internet\nprogramme, under the aegis of DG Communications Networks, Content and Technology\nunder grant agreement No 825310.\u00a9 2022 Xous Team. Some rights reserved."
  },
  {
    "title": "We put Claude Code in Rollercoaster Tycoon (ramp.com)",
    "points": 360,
    "submitter": "iamwil",
    "submit_time": "2026-01-12T14:28:17 1768228097",
    "num_comments": 207,
    "comments_url": "https://news.ycombinator.com/item?id=46588972",
    "comments": [
      "Related:I\u2019ve always found it crazy that my LLM has access to such terrible tools compared to mine.It\u2019s left with grepping for function signatures, sending diffs for patching, and running `cat` to read all the code at once.I however, run an IDE and can run a simple refactoring tool to add a parameter to a function, I can \u201cfollow symbol\u201d to see where something is defined, I can click and get all usages of a function shown at a glance, etc etc.Is anyone working on making it so LLM\u2019s get better tools for actually writing/refactoring code? Or is there some \u201cbitter lesson\u201d-like thing that says effort is always better spent just increasing the context size and slurping up all the code at once?reply",
      "> I however, run an IDE and can run a simple refactoring tool to add a parameter to a function, I can \u201cfollow symbol\u201d to see where something is defined, I can click and get all usages of a function shown at a glance, etc etcI am so surprised that all of the AI tooling mostly revolves around VSC or its forks and that JetBrains seem to not really have done anything revolutionary in the space.With how good their refactoring and code inspection tools are, you\u2019d really think they\u2019d pass of that context information to AI models and that they\u2019d be leaps and bounds ahead.reply",
      "Are you? I'm not surprised at all, considering that the biggest investment juggernaut in AI is also the author of VSC. I wonder what the connection is? ;)reply",
      "Agreed - this seems like a no brainer, surely this is something that is being worked on.reply",
      "Not coding agents but we do a lot of work trying to find the best tools, and the result is always that the simplest possible general tool that can get the job done always beats a suite of complicated tools and rules on how to use them.reply",
      "If you can read fast enough, grepping is probably faster than waiting for a compiler to tell you anything.reply",
      "Faster for worse results, though. Determining the source of a symbol is not as trivial as finding the same piece of text somewhere else, it should also reliably be able to differentiate among them. What better source for that then the compiler itself?reply",
      "Yeah, especially for languages that make heavy use of type inference. There\u2019s nothing you can really grep for most of the time\u2026 to really know \u201cwho\u2019s using this code\u201d you need to know what the compiler knows.An LLM can likely approach compiler-level knowledge just from being smart and understanding what it\u2019s reading, but it costs a lot of context to do this. Giving the LLM access to what the compiler knows as an API seems like it\u2019s a huge area for improvement.reply",
      "This isn\u2019t completely the answer to what you want but skills do open a lot of doors here. Anything you can do on a command line can turn into a skill, after all.reply",
      "Kit looks like a good step in this direction:https://github.com/cased/kitreply"
    ],
    "link": "https://labs.ramp.com/rct",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: ChunkHound, a local-first tool for understanding large codebases (github.com/chunkhound)",
    "points": 46,
    "submitter": "NadavBenItzhak",
    "submit_time": "2026-01-17T21:03:52 1768683832",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=46662078",
    "comments": [
      "you say \"local-first\" but have placed voyage API for embeddings as the default (had to go to the website and dig to find that you can infact use local embedding models). Please fixreply",
      "Might give this a try to experiment if it's really free to use (I'll have to read up on that I guess). The qemu codebase is huge and every contributer seems to solve problems in slightly different ways. Would be nice if this tool could help distill it.reply",
      "Can you please expose the functionality as a self-documenting CLI command with machine readable output? (Or did I misunderstand that MCP isn't the only way to use it?)I am curious to try it but do not want to adopt MCP servers.Telling Claude to call the CLI tool is more efficient.reply",
      "Agree. And to make the CLI usage more effective/efficient, if you can publish a skill that would be excellentreply",
      "Is there a way to have the model inside of codex to make use of chunkhound instead of its \u201cbuilt in\u201d search/explore functionality with rg? Whenever I spin up a new agent using xhigh thinking it spins its wheels for a while to get up to speed \u2014 wondering if chunkhound can make this process faster.reply"
    ],
    "link": "https://github.com/chunkhound/chunkhound",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Local first codebase intelligence\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\n\n\nLocal first codebase intelligence\n\n\n\n\n\nYour AI assistant searches code but doesn't understand it. ChunkHound researches your codebase\u2014extracting architecture, patterns, and institutional knowledge at any scale. Integrates via MCP.Visit chunkhound.github.io for complete guides:Note: Use \"codex-cli\" instead if you prefer Codex. Both work equally well and require no API key.For configuration, IDE setup, and advanced usage, see the documentation.Ideal for:Stop recreating code. Start with deep understanding.MIT\n        Local first codebase intelligence\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Light Mode InFFFFFFlation (willhbr.net)",
    "points": 141,
    "submitter": "Fudgel",
    "submit_time": "2026-01-17T22:19:25 1768688365",
    "num_comments": 99,
    "comments_url": "https://news.ycombinator.com/item?id=46662662",
    "comments": [
      "> My eyes will thank youSometimes I think the most hate for light mode is from people without autobrightness in their displays. Or from those who don\u2019t know how to change it easily.Sure, if I were to constantly blind myself with 10k lux, I would hate white background too.But it isn\u2019t supposed to be like that: make it the same brightness as the surroundings and voila.I\u2019ve never met a person saying they hate books and wish they were white on black.Also with glossy display (like 6k xdr) the only way I can deal with reflections is by always using light mode. Alabaster code theme is my favorite.If you don\u2019t have auto brightness, there are many apps to change it easily via UI or keyboard instead of manual knobs of your monitor \u2014 most of them for the past 10 years support control via hdmi/displayport\u2014I don\u2019t see people complaining \u201cI hate listening to most music because my headphones are always at 90% volume \u2014 every soundtrack should be lounge cafe del mar.\u201d Or \u201cI use this browser extension to make everything 5% loud.\u201dWell, just turn down the volume knob, dummy.reply",
      "Not everybody own $4k monitors, so automatic brightness isn\u2019t always available.Regardless though, due to the design inconsistencies of the system, one screen is too bright that causes to reduce the brightness and another one uses literally 1/1,000,000 contrast difference between tabs to distinguish the active one, so it\u2019s impossible to get a base brightness correct.I\u2019m using a MacBook Pro M4 and as I move around the house, automatic brightness either tries to blind me despite I\u2019ve been in a dark room for a minute, or simply refuses to turn the brightness up when the sun is shining down into the room. It\u2019s certainly designed for a certain environment, but not definitely a home.reply",
      "If it helps, you can disable auto brightness in accessibility settings so that only manual change remainsreply",
      "I use both auto (when available) and manual brightness adjustments, and the environment in which I do most of my computing gets ample natural light.The problem persists, however, because as the linked posts notes light mode is far brighter than it used to be, and now if I crank brightness down low enough to feel comfortable I'm sacrificing contrast and color vividness to such a degree that (for me) it's actively distracting. So, dark mode on high brightness it is.For code editing, I've always tended towards dark themes ever since they became readily available in IDEs in the late 2000s simply because syntax coloration \"pops\" so much more strongly than is possible with a light theme. When I use a light theme for code editing it feels almost like staring at a sheet of undifferentiated text in comparison.reply",
      "Seconding this, light themes cripple syntax highlighting, which in turn makes it far more annoying to quickly scan through code and glean structure. You can make up for this to some degree with text decorations, but, well, with dark schemes you have that too.reply",
      "> because syntax coloration \"pops\" so much more strongly than is possible with a light theme.That\u2019s why I mentioned alabaster: the only thing it highlights is comments and constants.Nowadays I can\u2019t stand \u201cnormal\u201d themes even for a minute: they are like blinking Christmas lights for me, too much distraction.Imaging reading the book where each word has different colors for nouns, verbs, what have you \u2014 nuts! :-)reply",
      "Feels like a difference in mental structures. Without robust syntax coloring, parsing code is considerably more difficult for me. In more human terms it feels kind of like trying to communicate without being able to use adjectives or something.reply",
      "It took a couple of days 10+ years ago to see what the fuss is about (I was an avid \u201cchristmas-lighter\u201d before), and I never came back.Also check this:\nhttps://tonsky.me/blog/syntax-highlighting/reply",
      "This is a pretty awful post, the problem is his example uses a horrible syntax highlighting scheme that makes use of far too few colours and no other text decorations.In a competent highlighting scheme, you have enough differentiation that every distinct type of thing indeed has a different way it pops.reply",
      "99% of vscode themes are like the one he showed. IMO, the best themes do typically have minimal/functional highlights, which results in more text that is the base color."
    ],
    "link": "https://willhbr.net/2025/10/20/light-mode-infffffflation/",
    "first_paragraph": "Back in the day, light mode wasn\u2019t called \u201clight mode\u201d. It was just the way that computers were, we didn\u2019t really think about turning everything light or dark. Sure, some applications were often dark (photo editors, IDEs, terminals) but everything else was light, and that was fine.What we didn\u2019t notice is that light mode has been slowly getting lighter, and I\u2019ve got a graph to prove it. I did what any normal person would do, I downloaded the same (or similar) screenshots from the MacOS Screenshot Library on 512 Pixels. This project would have been much more difficult without a single place to get well-organised screenshots from. I cropped each image so just a representative section of the window was present, here shown with a pinkish rectangle:Then used Pillow to get the average lightness of each cropped image:This ignores any kind of perceived brightness or the tinting that MacOS has been doing for a while based on your wallpaper colour. I could go down a massive tangent trying to wor"
  },
  {
    "title": "The recurring dream of replacing developers (caimito.net)",
    "points": 279,
    "submitter": "glimshe",
    "submit_time": "2026-01-17T14:31:33 1768660293",
    "num_comments": 230,
    "comments_url": "https://news.ycombinator.com/item?id=46658345",
    "comments": [
      "The pattern that gets missed in these discussions: every \"no-code will replace developers\" wave actually creates more developer jobs, not fewer.COBOL was supposed to let managers write programs. VB let business users make apps. Squarespace killed the need for web developers. And now AI.What actually happens: the tooling lowers the barrier to entry, way more people try to build things, and then those same people need actual developers when they hit the edges of what the tool can do. The total surface area of \"stuff that needs building\" keeps expanding.The developers who get displaced are the ones doing purely mechanical work that was already well-specified. But the job of understanding what to build in the first place, or debugging why the automated thing isn't doing what you expected - that's still there. Usually there's more of it.reply",
      "Classic Jevons Paradox - when something gets cheaper the market for it grows. The unit cost shrinks but the number of units bought grows more than this shrinkage.reply",
      "Does that automatically translate into more openings for the people whose full time job is providing that thing? I\u2019m not sure that it does.Historically, it would seem that often lowering the amount of people needed to produce a good is precisely what makes it cheaper.So it\u2019s not hard to imagine a world where AI tools make expert software developers significantly more productive while enabling other workers to use their own little programs and automations on their own jobs.In such a world, the number of \u201clines of code\u201d being used would be much greater that today.But it is not clear to me that the amount of people working full time as \u201csoftware developers\u201c would be larger as well.reply",
      "> Does that automatically translate into more openings for the people whose full time job is providing that thing?Not automatically, no.How it affects employment depends on the shapes of the relevant supply/demand curves, and I don't think those are possible to know well for things like this.For the world as a whole, it should be a very positive thing if creating usable software becomes an order of magnitude cheaper, and millions of smart people become available for other work.reply",
      "I debate this in my head way to much & from each & every perspective.Counter argument - if what you say is true, we will have a lot more custom & personalized software and the tech stacks behind those may be even more complicated than they currently are because we're now wanting to add LLMs that can talk to our APIs. We might also be adding multiple LLMs to our back ends to do things as well. Maybe we're replacing 10 but now someone has to manage that LLM infrastructure as well.My opinion will change by tomorrow but I could see more people building software that are currently experts in other domains. I can also see software engineers focusing more on keeping the new more complicated architecture being built from falling apart & trying to enforce tech standards. Our roles may become more infra & security. Less features, more stability & security.reply",
      "Of course that is true. The nuance here is that software isn\u2019t just getting cheaper but the activity to build it is changing. Instead of writing lines of code you are writing requirements. That shifts who can do the job. The customer might be able to do it themselves. This removes a market, not grows one. I am not saying the market will collapse just be careful applying a blunt theory to such a profound technological shift that isn\u2019t just lowering cost but changing the entire process.reply",
      "You say that like someone that has been coding for so long you have forgotten what it's like to not know how to code.  The customer will have little idea what is even possible and will ask for a product that doesn't solve their actual problem.  AI is amazing at producing answers you previously would have looked up on stack overflow, which is very useful.  It often can type faster that than I can which is also useful.  However, if we are going to see the exponential improvements towards AGI AI boosters talk about we would have already seen the start of it.When LLMs first showed up publicly it was a huge leap forward, and people assumed it would continue improving at the rate they had seen but it hasn't.reply",
      "Exactly. The customer doesn't know what's possible, but increasingly neither do we unless we're staying current at frontier speed.\nAI can type faster and answer Stack Overflow questions. But understanding what's newly possible, what competitors just shipped, what research just dropped... that requires continuous monitoring across arXiv, HN, Reddit, Discord, Twitter.\nThe gap isn't coding ability anymore. It's information asymmetry. Teams with better intelligence infrastructure will outpace teams with better coding skills.\nThat's the shift people are missing.reply",
      ">The customer will have little idea what is even possible and will ask for a product that doesn't solve their actual problem.How do you know that? For tech products most of the users are also technically literate and can easily use Claude Code or whatever tool we are using. They easily tell CC specifically what they need. Unless you create social media apps or bank apps, the customers are pretty tech savvy.reply",
      "One example is programmers who would code physics simulations that run in massive data. You need a decent amount of software engineering skills to maintain software like that but the programmer maybe has a BS in Physics but doesn\u2019t really know the nuances of the actual algorithm being implemented.With AI, probably you don\u2019t need 95% of the programmers who do that job anyway. Physicists who know the algorithm much better can use AI to implement a majority of the system and maybe you can have a software engineer orchestrate the program in the cloud or supercomputer or something but probably not even that.Okay, the idea I was trying to get across before I rambled was that many times the customer knows what they want very well and much better than the software engineer.reply"
    ],
    "link": "https://www.caimito.net/en/blog/2025/12/07/the-recurring-dream-of-replacing-developers.html",
    "first_paragraph": "07.12.2025, By Stephan SchwabEvery decade brings new promises: this time, we'll finally make software development simple enough that we won't need so many developers. From COBOL to AI, the pattern repeats. Business leaders grow frustrated with slow delivery and high costs. Developers feel misunderstood and undervalued. Understanding why this cycle persists for fifty years reveals what both sides need to know about the nature of software work.When Neil Armstrong stepped onto the lunar surface in 1969, the world witnessed what organized human ingenuity could accomplish. Behind that achievement stood Margaret Hamilton and her team, writing Apollo\u2019s guidance software by hand, catching critical errors through careful review, and proving that software could be mission-critical.The Apollo program demonstrated that software development was essential to achieving the impossible. Yet it also revealed something that would frustrate business leaders for decades to come: writing software required s"
  },
  {
    "title": "The Olivetti Company (abortretry.fail)",
    "points": 139,
    "submitter": "rbanffy",
    "submit_time": "2026-01-11T15:33:04 1768145584",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=46576581",
    "comments": [
      "Excellent technical history, but it misses what made Olivetti incomparable: Adriano's human-centric philosophy that business and human culture were inseparable.The article mentions worker housing and urban planning in passing, then moves on. But that was the strategy. Ivrea wasn't welfare\u2014it was integrated design. Factory, housing, schools, public spaces all operating under one coherent philosophy: machines and lives should both be beautiful and functional.Search \"Olivetti negozio\", \"fabbrica\" or \"architettura\"\u2014the retail design and factory architecture show it, decades before Apple. But more importantly, search for Adriano's writing on the Community Movement. He believed you couldn't separate good design from good society. The red typewriter wasn't just aesthetics; it was a statement about human dignity.That's why Olivetti succeeded where technically equivalent competitors didn't. They engineered for humans, not just machines. Beauty, culture, and production were one integrated system.The article's strength\u2014technical rigor and business detail\u2014accidentally proves the weakness: it treats design and culture as separate from engineering. Olivetti proved they're the same thing.(I have a working M10 from 1983. Still remarkable machine\u2014that tiltable screen, the integrated design. They were still building for humans, not just specs.)reply",
      "Its an incredible story and way another time. As my cousin put it while i was last in ivrea: those factory buildings where like spaceships at that time.\nPartialy very bad luck, but with all the nostalgia i think adriano was also partialy a bit dreamy and that ultimately came at a cost.\nOn the other side and what rarely gets mentioned: olivetti had a really good and massive sales crew. And that allowed them to spend money on these things.Ps.Adriano is my biological grandfather.\nPps.i posted the link before, but didnt get much traction.reply",
      "Author here. I\u2019d love to talk to you about your grandfather, Ivrea, and so on if you\u2019re open to it.Admin at the linked domain.reply",
      "Sent you a mailreply",
      "I worked for Olivetti\u2019s Advanced Technology Lab in Cupertino CA in the late 80s. They had some innovative PCs back then.reply",
      "Daaamn... Olivetti.  ,d88b.d88b,\n  88888888888\n  `Y8888888Y'\n    `Y888Y'   \n      `Y'\n\nAn Olivetti PC was an ultimate dream to have in the late 80s and the early 90s for me, in impressionable age of adolescence, prone to the call of tinkering,  hacking and programming. They were the brand, at least in Europe.Such a nice memory :)reply",
      "I worked in IT support and engineering for a UK Olivetti dealer / distributor in the 1980s/90s. As such I had access to all sorts of Olivetti kit in various states of functionality. At one time, my home PC was an Olivetti M280 case with an M380 (386DX) motherboard and EGA display adapter. It had a colour monitor and the ANK 27-102 keyboard - it was a 'top end' hybrid for its time that I'd put together from several non-working machines..I also had a 'faulty' Olivetti inkjet printer that was written off under warranty with a mysterious fault. I eventually managed to fix it by bending the metal paper detector arm so that it slotted properly into the optical sensor - it was a little out of whack and the sensor sometimes couldn't work out whether there was paper in the tray.reply",
      "Somewhat apropos is this excellent video I just watched yesterday where Olivetti's graphics were touched on:https://youtu.be/xNsK_F4JlG4?t=586reply",
      "Olivetti is famous for having bought Acorn, and owning the ARM architecture.They likely think about that missed opportunity deeply in their corporate culture.I don't know the story of how they let that get away.\"Such was the secrecy surrounding the ARM CPU project that when Olivetti were negotiating to take a controlling share of Acorn in 1985, they were not told about the development team until after the negotiations had been finalised...\"Olivetti would eventually relinquish majority control of Acorn in early 1996, selling shares to US and UK investment groups to leave the company with a shareholding in Acorn of around 45%.\"https://en.wikipedia.org/wiki/Acorn_Computersreply",
      "Unfortunately they don't have anymore a corporate culture worth speaking of... These days all you see their brand on is cash registers.reply"
    ],
    "link": "https://www.abortretry.fail/p/the-olivetti-company",
    "first_paragraph": ""
  },
  {
    "title": "Raising money fucked me up (yakkomajuri.com)",
    "points": 114,
    "submitter": "yakkomajuri",
    "submit_time": "2026-01-17T18:29:00 1768674540",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=46660543",
    "comments": [
      "> It's much more comfortable to be the person that \"could be X\" than to be the person that tries to actually do it.Brilliant insight.Reminds of me this, from Theodore Roosevelt's Citizenship in a Republic:> It is not the critic who counts; not the man who points out how the strong man stumbles, or where the doer of deeds could have done them better. The credit belongs to the man who is actually in the arena, whose face is marred by dust and sweat and blood; who strives valiantly; who errs, who comes short again and again, because there is no effort without error and shortcoming; but who does actually strive to do the deeds; who knows great enthusiasms, the great devotions; who spends himself in a worthy cause; who at the best knows in the end the triumph of high achievement, and who at the worst, if he fails, at least fails while daring greatly, so that his place shall never be with those cold and timid souls who neither know victory nor defeat.Good luck, and go get 'em.reply",
      "Expectations that we hold inside of ourselves can be a really difficult echo of identities we tried fantasizing about when growing up and as an adult. We want to do well, we want the approval, we want the validation.The anxiety over expectations can kill you. It\u2019s self abuse - people (investors, bosses, spouses) don\u2019t invest in you for your anxiety driven productivity, they do it because of who you are outside of that worry. It\u2019s hard to replace it if you consider it your motor. Let the desire to do well and good stay, but let the fear of others disappointment go, and the fantasy that we can control those outcomes by squeezing every last drop out of ourselves.reply",
      "Can you separate \"who you are\" from that worry? Seems to me it's a part of you and you wouldn't be you without it, for better and worse.reply",
      "Identities shift over time whether we intend it or not. Who you were at 5, or 10 is not who you are at 20, 30, 40. We all pick up baggage, trinkets, burdens, and experiences.One worries because it was a helpful strategy compared to not worrying, but some (like me very specifically) can get attached to that worry to the detriment of picking up other mechanisms.reply",
      "It's always important to remind one's self that \"who you are\" is simply the story one is attached to. Things like meditation or psilocybin can help bring that to light.reply",
      "A wonderful and personally relevant thing to read.reply",
      "> Then you look around and see \"startup X gets to $1M ARR a month after launch\" and shit like that and I'm feeling terrible about how we're barely growing.Comparison is the thief of joy. I fall into this trap almost weekly. Success stories are incredibly rare and we only see the splash, not the iceberg of failure just beneath the surface.I think about my current business constantly even though on paper we are making enough to keep this thing going forever but it never feels enough.I felt this post and appreciate the honesty.reply",
      "Some feedback from me (not a likely user though):- It was easier to find a link to where you worked at than your repo (https://github.com/skaldlabs/skald?tab=readme-ov-file), you should have linked it visibly- I had no idea what / why I should use it so I looked at the demo video and it didn't seem to solve any particular use case for any particular problem, it was more a ,,config'' video instead of a demo video- From reading the (quite interesting) article it seemed like you are focusing on pivoting instead of iteration speed. Have you tried for example to just query an LLM to build the whole project that you have done? How much time would be to vibe code it?I know that HN is mostly against vibe coding, but if the project could have been created in 1-3 days and you took 3 month, that's a bigger issue than growth itself. In that case the metric that should be looked at is iteration speed instead of just growth (both are super important though!)reply",
      "> \"- It was easier to find a link to where you worked at than your repo (https://github.com/skaldlabs/skald?tab=readme-ov-file), you should have linked it visibly\"Genuinely curious, can I ask why this is relevant to point out? This seems like just a general blog post, about raising money for a startup and personal reflections on it. Why would a link to a github repo be an important part of that?reply",
      "It's just part of both getting feedback and general sales.For engineers it feels too pushy / not genuine, but after spending time / effort on a great non-generated interesting article, inserting a link for people who want to check it out isn't pushy.reply"
    ],
    "link": "https://blog.yakkomajuri.com/blog/raising-money-fucked-me-up",
    "first_paragraph": "January 15, 2026About four months ago I quit my job at Doublepoint and decided to start my own thing.I'd been working on a little project with Pedrique (who would become my co-founder) for a bit over half-a-year and decided I had enough signal to determine he was someone I wanted to start a business with.I was excited about the idea we were working on at the time, but being truly honest about my motivations, I mostly wanted to run my own thing. In a dream world I'd have had the \"idea of my life\" while working at PostHog or Doublepoint and have gone on to build that with maximum conviction but this wasn't the case, so I got tired of waiting for a spark and decided to go out and make it happen, with the idea we were working on being our best bet at the time.Since I'd just quit my job, I had my finances well in order. Thus, my ideal scenario would have been to work on the idea we had the MVP for, try to get it off the ground, and if that didn't work, try something else, then something els"
  },
  {
    "title": "Below the Surface: Archeological Finds from the Amsterdam Noord/Zuid Metro Line (belowthesurface.amsterdam)",
    "points": 60,
    "submitter": "stefanvdw1",
    "submit_time": "2026-01-11T14:36:13 1768142173",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=46576091",
    "comments": [
      "There's an Ericsson GH388 phone I used in 90s!IIRC it was my first mobile.Never used Nokia though it had major market share those days.reply",
      "I love that this includes modern artifacts as well. The nineties mobile phone already looks archaeological by comparison to modern ones.reply",
      "My favourite station is Rokin, because it includes an amazing display of these artifacts (from Roman dishes to Nokia 3310s) in between the escalators that take you to the platform. It's incredible.https://www.reddit.com/r/knolling/comments/e3e86r/at_rokin_m...reply",
      "WTFHTTTMTS ?Who the fuck has the time to make this shit ?reply",
      "The website answers this question directly:> This website is a product of the Department of Archaeology, Monuments and Archaeology (MenA), City of Amsterdam, in cooperation with the Chief Technology Office (CTO), City of Amsterdam.Seems to me like a good, culturally enriching way for a city to spend a bit of time and money.reply",
      "That's exactly what history should be about. Ordinary lives of ordinary people. But it's mostly which King fought with which emperor and slept with which socialite.reply",
      "Depends on the sources, earlier historical writing is definitely like that, whilst more modern writing often has a more nuanced approach.\u201chistoire vue d'en bas et non d'en haut\u201dreply",
      "What's the problem exactly? In the Netherlands we sometimes take the time to make nice things just because it looks nice and/or because we like to commemorate our shared history.reply"
    ],
    "link": "https://belowthesurface.amsterdam/en/vondsten",
    "first_paragraph": ""
  },
  {
    "title": "An Elizabethan mansion's secrets for staying warm (bbc.com)",
    "points": 111,
    "submitter": "Tachyooon",
    "submit_time": "2026-01-17T16:53:24 1768668804",
    "num_comments": 131,
    "comments_url": "https://news.ycombinator.com/item?id=46659550",
    "comments": [
      "The castles and mansions were relatively modern. Most people didn't have \"good\" home design, they had older, practical architecture. Their homes had thin walls, were drafty, and had no chimneys; there was a hole in the roof where the smoke from your fire would go, so your attic was filled with smoke (where you'd smoke meats for winter).You're better served by looking to 19th century lower and middle class architecture. Right before air conditioning, but with relatively modern designs using modern building materials and practices (\"insulation\" (horsehair and newspaper), fireplaces/stoves, corridors with doors to separate cold rooms from hot ones, windows designed to allow cross-breezes, covered porches to provide shade in summer, etc). Right before air conditioning came in, we had pretty much gotten to the peak of design that used natural forms of temperature regulation. Some designs even created mini greenhouses of glass, with half the wall mounted with earth, for thermal regulation as well as solar heating. The only better passive methods invented since then is geothermal.The peak of winter heat management were the pechka, Russian rocket stoves built into literal tons of masonry, for the most thermal mass possible. You'd heat it up once with a small amount of wood and it warms the house the whole day. They were so big you could sleep on top of it.reply",
      "The 19th century was basically the low point of Dutch civilization. People stayed warm because 10 people slept in one room.It was so bad that even rich people had to admit that the country had become an embarrassment.reply",
      "When we lost power for 10 days a few winters back we attempted to use the fire place for heat.  It was a fail.  Post and beam house (large wide open floor plan) with a large transfer from 1st to 2nd floor, and apprently my lack of skill for optimizing heat over beauty in the fireplace, left us without much of a thermal bump.  To this day I swear we were pulling heat out of the chimney faster than we were heating the house; I cooled the house with fire.reply",
      "An open fire is not a particularly warm thing to have unless you\u2019re directly in front of it. Most of the heat goes straight up the flue, and it uses an enormous amount of air to keep burning - it will pull huge volumes from rvertwhere it can. This is why these old buildings didn\u2019t suffer from damp issues - the open fires burning were ventilating them.reply",
      "It's the same problem as those portable AC units: the exhaust (chimney in this case) draws large amounts of air in from outside which is at the wrong temperature (cold in this case).reply",
      "At some point they realised and the newer ones have a dupex air duct so you can keep air pressure evenreply",
      "Huh, just like a balanced flue.reply",
      "If it has a flue or chimney, it isnt really an open fire.  Look at an ancient long house, or farmer's thatched cottage from say 400 years ago. They had a fire on a stone circle on the floor in the middle of the room, and a high roof sometimes with a hole but often not.  It was smoky, but kept everyone warm.reply",
      "It gave people lung cancer, too. Maybe genetic adaptation to that (pretty toxic) environment is why smoking doesn't kill people more quickly.reply",
      "There have been times, with various crises, where I only half considered if indoor plumbing was such a great thing. But that's probably a very old-fashioned New England thing.reply"
    ],
    "link": "https://www.bbc.com/future/article/20260116-an-elizabethan-mansions-secrets-for-staying-warm",
    "first_paragraph": "In a bleak, deadly period of cold weather known as the Little Ice Age, clever Elizabethan designs helped keep a magnificent stately home unusually warm. The house has lessons for how we can heat our homes more efficiently today.England's longest river was usually flowing freely. But on New Year's Eve in 1564, the River Thames was frozen solid, from bank to bank. Bonfires crackled on the stuck-fast surface, oxen roasted on spits, and people danced on the ice. Some accounts say that Queen Elizabeth I even practised archery on the glacial river. This sort of thing wasn't a one off. It had happened before: King Henry VIII and his queen had dashed downriver in a sleigh nearly three decades previously in 1537.These frosty conditions were the result of a climatic plot twist roughly between the 14th and 19th centuries, known today as the Little Ice Age. As well as festivals on the ice, this prolonged cold period brought periods of famine, and frightening unseasonable frosts. Soldiers froze to "
  },
  {
    "title": "M8SBC-486 (Homebrew 486 computer) (maniek86.xyz)",
    "points": 89,
    "submitter": "rasz",
    "submit_time": "2026-01-11T18:58:19 1768157899",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=46578601",
    "comments": [
      "4MB of SRAM would have cost an absolute fortune back in the day.  One of the more overlooked reasons behind the explosion of personal computing power back in the 80s and 90s was the invention and proliferation of DRAM which made it finally affordable for people to have enough memory on the system to use it for more than toy scale projects.reply",
      "4 MB of SRAM in the '80s would have been the main RAM of a supercomputer.We still use SRAM today.  It's what level-1 cache and registers are implemented with - actual flip-flops, can be toggled with one cycle delay.  Supercomputers used to make their entire main memory out of SRAM, effectively the whole thing was L1 cache.The 486 has an on-chip cache - 8 or 16 KB of SRAM.  Very large for the time.Off-chip access to the DRAM involves wait states.  The read or write is stalled until the DRAM enters the appropriate state.  The 486 would also do block reads of 16 bytes at a time to fill an entire cache line.  This is around the time main memory and the CPU became increasingly decoupled.Avoiding all the complexity of managing DRAM is why hobbyists use SRAM these days.  Basically: to avoid cost.  Ironic!reply",
      "And large amounts of L1 cache do in fact cost a fortune today!reply",
      "Is that hard soldered RAM? Very modern!You mentioned something about custom holes. What does that mean?reply",
      "I think, it means that it cannot be mounted in any standard case, like AT (I know, there is no official AT standard formally), ATX, \u00b5ATX or ITX.reply",
      "HN hug?reply",
      "https://web.archive.org/web/20260117185107/https://maniek86....reply",
      "origin server fell overreply"
    ],
    "link": "https://maniek86.xyz/projects/m8sbc_486.php",
    "first_paragraph": "\u00a0[Back to the\u00a0homebrew computers page]The M8SBC-486 is a 486 homebrew computer motherboard made from scratch. From the schematic and PCB to the chipset! It is not based on existing designs, but rather on my experience with my previous experimental 486 homebrew (page about it coming soon!). I started working on it back in August 2025 and I started researching the 486 CPU in April 2025. I initially planned to make it just a 486 homebrew with the ordinary goal of getting it to run Linux and DOOM. However, my design choices made it compatible enough to run other cool stuff!I call it \"kinda PC compatible\" because it has a lot in common with standard older x86 PCs. The main things missing here are the secondary PIC and DMA. However, based on my tests on this board, many programs can work without these. The missing DMA especially removes sound card support. Just see below the compatibility table!GitHub repository of the project:\u00a0https://github.com/maniekx86/M8SBC-486\r\nTheRetroWeb entry (thank"
  },
  {
    "title": "The thing that brought me joy (stephenlewis.me)",
    "points": 61,
    "submitter": "monooso",
    "submit_time": "2026-01-17T18:42:39 1768675359",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=46660663",
    "comments": [
      "You don't have to leave the command line. Claude Code, and other agentic tools like it, make you feel like you've left the command line because they capture the whole terminal and leave you with less agency. There are tools like aider (and my own project runprompt) which let you retain more control in your terminal and in my experience feel much less disempowering, while still giving you a productivity boost.reply",
      "I love this, it resonates so deeply with me. Code is, for me, joy. I spent a little more than an afternoon writing a parser to parse a new ad-hoc file format I created to represent the IDs (class name and ID names) I will use in my CSS, and it was just fun. Sure some AI could probably have written that for me, but for what? So I can dig directly back into complicated actual engineering issues? Where would my breaks be?reply",
      "Ironically I have a somewhat of a different view - I love rubber ducking and tinkering with LLMs. Sometimes they come up with a use case that I would not have thought of, but I would have liked to have maybe 2 weeks later. Other times it is nitpicking  each others' code etc.reply",
      "I think we are presented with a false dichotomy here, as you can use llm tools for menial tasks and code whatever scratches your itch at the same time. For me, I really do not enjoy writing any frontend, html, javascript, whatever; I just want to bring some website I need to light. I focus on other code and that is what brings me joy.reply",
      "> Sure some AI could probably have written that for me, but for what?One reason would be to raise the ceiling of what your project can do within the budget of time and motivation you have. Or, as it often happens, to be able to finish the project at all.reply",
      "I feel similarly. Sounds a bit like other crafts that were later industrialized and (partially) mechanized, like woodworking and carpentry.One can certainly enjoy the laborious handcrafted process of building your own table, and yet go back to a shop that churns out cheap furniture that\u2019s nonetheless useful for many others, and see the value in both.Obviously there\u2019s more degrees of freedom in software, but I\u2019m trying to see it that way to rationalize how I\u2019m feeling with the current state of things.reply",
      "Some people like the making and tinkering with 3D printers, but have no actual projects they want to make with them, nor do they have the skills to use CAD to design them.  On the other side are the people that have no interest in 3D printers, and just use them to implement their ideas.I'm starting to think programming might become the same thing;  people that program will be the people that just like to tinker with code and have no real ideas to implement, while the people that have ideas will use LLMs to implement the code so they can just work on their idea.I've seen the same thing with Linux. There are people that like to tinker with Linux, playing with every setting and every window manager, but don't actually use the computer to DO anything, and then there are people that don't care what the OS is, and are just using the computer as an actual tool to get something done.reply",
      "I think there must be a continuous spectrum between the extremes you describe.reply",
      "I suspect there's a synergy between the two.reply",
      "> It\u2019s not that the agents are now producing flawless code. I spent a good 20 minutes yesterday watching one tie itself in knots trying to write a regex: first in Sed, then in Bash, and finally in Python (six times).This sounds very strange.I'm using Claude (Opus 4.5 via Code) every day and it's very good with regexes, sed, awk and similar bash oneliners.We don't know what the author asked it to do, but this smells like the problem started at least several messages before that.To author's point: code brings me joy. I'm currently learning Zig, for no reason whatsoever other than intellectual challenge and I, subjectively, like the language. I'm writing silly little programs that nobody will ever see. It's fun.Then I switch over to a paid project, and claude[0] another task from my backlog.There's code, and then there's code. You can find joy in some code and absolutely want to avoid coding in something else.[0] code using Claudereply"
    ],
    "link": "https://www.stephenlewis.me/blog/the-thing-that-brought-me-joy/",
    "first_paragraph": ""
  },
  {
    "title": "MIT's Computer Systems Security (2024) (csail.mit.edu)",
    "points": 4,
    "submitter": "barishnamazov",
    "submit_time": "2026-01-18T00:09:43 1768694983",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://css.csail.mit.edu/6.858/2024/",
    "first_paragraph": "\nThe lectures cover a\nbroad overview of systems security\ntogether with a deeper focus on several topics:\nisolation techniques,\nprivilege separation,\ndealing with buggy code,\nnetworked and distributed systems,\nand\nhuman-focused security and privacy.\n\nLinks to notes etc. on future days are copies of materials from last year,\nto give you an idea of what the future will bring.  We will update the\nnotes as the course progresses.  The year of publication for class\nreadings are shown in parentheses.\n\n\n\n\nMondayTuesday\nWednesdayThursday\nFriday\n\n\n \nfeb 5\nFirst day of classes\nfeb 6\nLEC 1: Introduction, threat models (video)\nPreparation:  Optionally read Modern Android exploit\nAssigned: Lab 1: Buffer overflows\nfeb 7\nfeb 8\nLEC 2: OS and VM isolation (video)\nPreparation:  Read about OS and VM isolation (Question)\nfeb 9\n\n \nfeb 12\nfeb 13\nLEC 3: Software fault isolation (video)\nPreparation:  Read about WebAssembly (Question)\nfeb 14\nfeb 15\nLEC 4: Trusted hardware (video)\nPreparation:  Read BitLocker (20"
  },
  {
    "title": "Common misunderstandings about large software companies (philipotoole.com)",
    "points": 66,
    "submitter": "otoolep",
    "submit_time": "2026-01-12T06:38:51 1768199931",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=46584880",
    "comments": [
      "Many of the author's rebuttals hinge on the assumption that everyone in an organisation is acting in its interest first - and not their own, often conflicting, self-interest. As such, they are not particularly convincing.Large organisations absolutely do, as a function of their scale, produce pockets where slackers and incompetents can hide. They'll surround themselves with a web of process, pointless meetings, and substance-free buzzword-heavy documentation/presentations to disguise this fact. Others may become ensnared in this web, and will rightly express the criticisms that the author is attempting to debunk.reply",
      "I don't think I've ever worked at a company where slacking off was the problem. The vast majority of people want to do good work.What I _have_ seen is several companies afflicted by this really strange characteristic of the software development industry: We appear to be the only industry on the planet where it is common to pick leaders (executives) that know nothing about the product or how it's made.You can't run a bridge building company without knowing how to build a bridge. You can't run a law firm without knowing law.You don't need to know all the nitty gritty - big picture is important - but understanding the product _in depth_ is a requirement in any business.reply",
      "Are you in a completely different world than me? Because even the CEO of Boeing is not an engineer. Larry Ellison  The CEO of the biggest bank in my country holds a masters degree in business economics, but nothing related to finance, econometrics or risk management. The CEO of US steel is an accountant. Don't even get me started on the (non)education of some politicians.Understanding the product is often important, but equally often it is something you can delegate to others. It's only the younglings that think intimate knowledge of the product is the hallmark of a great leader, because that is the only thing they themselves bring to the table.reply",
      "> Are you in a completely different world than me? Because even the CEO of Boeing is not an engineer. Larry Ellison The CEO of the biggest bank in my country holds a masters degree in business economics, but nothing related to finance, econometrics or risk management. The CEO of US steel is an accountant.Specifically the CEO is more like the figurehead of the company; this role is to present and \"sell the value\" of the company to investors, important customers and partners. So often it is not too worrysome if the CEO has a different background; sometimes this can even make sense.What should worry one much more is if the leadership layers below come from a very different background than what the company's industry is.reply",
      "I agree fully with your comment, but I wish to point out that Larry Ellison's was a programmer at the time that the company that became Oracle was founded by him and his co-founders.reply",
      "I get the point of his comment but it\u2019s just nonsense\u2026 plenty of good CEOs aren\u2019t SMEs in the field and plenty of bad ones are. the CEO of Boeing is absolutely an engineer - and so was the CEO during most of the years people consider the worst in Boeing\u2019s quality history with the 737 Max (Muilenburg).reply",
      "Knowing how your product works does not actually solve the problem of running a large company.reply",
      "> The vast majority of people want to do good work.The vast majority of people have convinced themselves they\u2019re doing good work. Then reject any suggestion they could do it better (including me).reply",
      "Indeed. Most people who seek employment at big tech do so because of the money, not because of the mission.reply",
      "I read it as saying that even if you solved the incentive misalignments, you would still have very similar annoying symptoms to what people complain about today. So you have to be careful in looking at any particular annoyance to disentangle which aspects of it are inherent complexity to a large company and which are BS. But I already believed that, so I may be steelmanning the article too much.reply"
    ],
    "link": "https://philipotoole.com/common-misunderstandings-about-large-software-companies/",
    "first_paragraph": "\n\t\t\t\t\tPhilip O'Toole\t\t\t\t\n\t\t\t\t\tPhilip O'Toole\t\t\t\tI sometimes read commentary about large software companies and notice a recurring pattern. People correctly identify real characteristics of large organizations, criticize them, but show little appreciation for why those characteristics exist in the first place.This is not an abstract topic for me. I have worked at very large firms \u2013 Nortel and Google, which neatly bookend my career. I have also worked at companies in the 100-1000 person range, and at startups with fewer than ten people. I have seen the same problems from very different vantage points.Some of the most common criticisms are familiar. They are not wrong, exactly. But they are often incomplete.At very large software companies, programming ability, technical expertise, and raw resources are not the limiting factors. Coordination is.Coordination is almost free in a ten-person startup. It is still relatively easy in a forty-person company. In a very large organization, coordina"
  },
  {
    "title": "IRISC: An ARMv7 assembly interpreter and computer architecture simulator (polysoftit.co.uk)",
    "points": 9,
    "submitter": "rtybanana",
    "submit_time": "2026-01-18T00:05:02 1768694702",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://polysoftit.co.uk/irisc-web/",
    "first_paragraph": ""
  },
  {
    "title": "Counterfactual evaluation for recommendation systems (eugeneyan.com)",
    "points": 61,
    "submitter": "kurinikku",
    "submit_time": "2026-01-17T05:20:20 1768627220",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=46655524",
    "comments": [
      "I wish there was a HN for data content. Articles like this are always my favorite ways to learn something new from a domain expert. I work in fraud detection & would like to write something similar!reply",
      "https://datatau.net used to be kinda that\u2026 but it has been dead for a while, and it looks like the spam bots have taken over.reply",
      "I admit this is way over my head, I am still trying to grok it. This seems to require an existing model to start from\u2014-I am not sure how one would arrive at a model from scratch (I guess start from the same weights on all items?)I think the point about A/B testing in production to confirm if a new model is working is really important, but quite important is to also do A/B/Control testing, where Control is random (seeded to the context or user) or no recommendations, which helps not only with A vs B, but helps validate that A or B isn\u2019t performing worse than Control. What percentage of traffic (1% or 5%) goes to Control depends on traffic levels, but also requires convincing to run control.I think one important technique is to pre-aggregate your data on a user-centered or item-centered basis. This can make it much more palatable to collect this data on a massive scale without having to store a log for every event.Contextual bandit is one technique that attempts to deal with confounding factors and bias from actual recommendations. However, I think there\u2019s a major challenge to scale it to large counts of items.I think the quality of collected non-click data is also important\u2014-did the user actually scroll down to see the recommendations or were they served but not looked at? Likewise, I think it\u2019s important to add depth to the \u201cviews\u201d or \u201cclicks\u201d metric\u2014-if something was clicked, how long did the user spend viewing/interacting with the item? Did they click and immediately go back or did they click and look at it for a while? Did they add the item to cart? Or if we are talking about articles, did they spend time reading it? Item interest can be estimated more closely than just views, clicks and purchases. Of course, we know that purchases (or more generally conversion rates) have a direct business value, but, for example, an add to cart is somewhat of a proxy of purchase probability and can enhance the quality of the data used to train (and thus a higher proxy business value).It\u2019s probably impractical to train on control interactions only (and also difficult to keep the same user in control group between visits).The SNIPS normalization technique reminds me of the Mutual Information factor correction when training co-occurrence (or association) models, where Mutual Information rewards items less likely to randomly co-occur.reply",
      "There are a number of different types of counterfactuals;Describe the different types of counterfactuals in statistics: Classical counterfactuals, Pearl's counterfactuals, Quantum counterfactuals, Constructor theory counterfactualsreply"
    ],
    "link": "https://eugeneyan.com/writing/counterfactual-evaluation/",
    "first_paragraph": "\n\n[\n        \n        \n        recsys\neval\nmachinelearning\n        \n    ]\n \u00b7 8 min read\n            \nWhen I first started working on recommendation systems, I thought there was something weird about the way we did offline evaluation. First, we split customer interaction data into training and validation sets. Then, we train our recommenders on the training set before evaluating them on the validation set, usually on metrics such as recall, precision, and NDCG. This is similar to how we evaluate supervised machine learning models and doesn\u2019t seem unusual at first glance.But don\u2019t our recommendations change how customers click or purchase? If customers can only interact with items shown to them, why do we perform offline evaluation on static historical data?It took me a while to put a finger on it but I think this is why it felt weird: We\u2019re treating recommendations as an observational problem when it really is an interventional problem.Problems solved via supervised machine learning are "
  },
  {
    "title": "A New Era for FIRST LEGO League: Inspiring the Next Generation of Learners (firstinspires.org)",
    "points": 3,
    "submitter": "jchin",
    "submit_time": "2026-01-12T18:38:22 1768243102",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://community.firstinspires.org/new-era-first-lego-league-future-edition",
    "first_paragraph": "For\u00a0nearly 30\u00a0years,\u00a0FIRST\u00ae\u00a0LEGO\u00ae\u00a0League has\u00a0helped\u00a0millions of\u00a0children and\u00a0young people\u00a0across 100+ countries\u00a0explore\u00a0the fun\u00a0and creativity\u00a0of STEM through hands-on robotics.\u00a0With support from\u00a0you\u00a0\u2014\u00a0our incredible community\u00a0\u2014\u00a0each\u00a0season brings\u00a0exciting new challenges and\u00a0events\u00a0to hundreds of thousands of participants,\u00a0shaping\u00a0how\u00a0the next generation\u00a0sees\u00a0and experiences\u00a0science, technology, engineering,\u00a0and math.\u00a0\u00a0Many of you have\u00a0witnessed\u00a0this\u00a0impact firsthand and\u00a0shared your desire to reach even more students\u00a0in your communities.\u00a0We\u2019ve\u00a0been\u00a0working on\u00a0ways to\u00a0help make that possible.\u00a0\u00a0Over the past few years,\u00a0we\u2019ve\u00a0taken a close look at our program offerings through surveys and conversations with partners, coaches, and participants around the world. What we heard was clear:\u00a0The needs of our community are evolving, and\u00a0it\u2019s\u00a0time for\u00a0FIRST\u00a0LEGO League to evolve with them.\u00a0We know the best place to reach the next generation is where they already\u00a0learn\u00a0every day\u00a0\u2014\u00a0the\u00a0classroom.\u00a0\u00a0T"
  },
  {
    "title": "There's no single best way to store information (quantamagazine.org)",
    "points": 74,
    "submitter": "7777777phil",
    "submit_time": "2026-01-17T16:17:58 1768666678",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=46659219",
    "comments": [
      "The best way to store information depends on how you intend to use (query) it.The query itself represents information. If you can anticipate 100% of the ways in which you intend to query the information (no surprises), I'd argue there might be an ideal way to store it.reply",
      "This is connected to the equivalence relationship between optimal indexing and optimal AGI. The \"best\" way is optimal for the entire universe of possible queries but has the downside of being profoundly computationally intractable.Requiring perfect knowledge of how information will be used is brittle. It has the major benefit of making the algorithm design problem tractable, which is why we do it.An alternative approach is to exclude large subsets of queries from the universe of answerable queries without enumerating the queries that the system can answer. The goal is to qualitatively reduce the computational intractability of the universal case by pruning it without over-specifying the queries it can answer such as in the traditional indexing case. This is approximately what \"learned indexing\" attempts to do.reply",
      "Yes with the important caveat that a lot of the time people don't have a crystal ball, can't see the far future, don't know if their intents will materialise in practice 12 months down the line and should therefore store information in Postures until that isn't a feasible option any more.A consequence of there being no generally superior storage mechanism is that technologists as a community should have an agreed default standard for storage - which happens to be relational.reply",
      "This is exactly right, and the article is clickbait junk.Given the domain name, I was expecting something about the physics of information storage, and some interesting law of nature.\nInstead, the article is a bad introduction to data structures.reply",
      "You both are affirming the title of the article.\"No single best way\", meaning \"it depends.\"But don't let something like literacy get in the way of a opportunity to engage in meaningless outrage.reply",
      "This line of thought works for storage in isolation, but does not hold up if write speed is a concern.reply",
      "So long as (fast/optimal) real-time access to new data is not a concern, you can introduce compaction to solve both problems.reply",
      "> (fast/optimal) real-time access to new datahttps://en.wikipedia.org/wiki/Optimal_binary_search_tree#Dyn...reply",
      "Speed can always be improved. If a method is too slow, run multiple machines in parralel. Longevity is different as it cannot scale. A million cd burners are together very fast, but the CDs wont last any longer. So the storage method is is the more profound tech problem.reply",
      "as a line of thought, it totally does. you just extend the workload description to include writes. where this get problematic is that the ideal structure for transactional writes is nearly pessimal from a read standpoint. which is why we seem to end up doubling the write overhead - once to remember and once to optimize. or highly write-centric approach like LSMI'd love to be clued in on more interesting architectures that either attempt to optimize both or provide a more continuous tuning knob between themreply"
    ],
    "link": "https://www.quantamagazine.org/why-theres-no-single-best-way-to-store-information-20260116/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesJanuary 16, 2026In data storage, sometimes it\u2019s best to embrace a bit of disorder.Kristina Armitage/Quanta MagazineStaff WriterJanuary 16, 2026Just as there\u2019s no single best way to organize your bookshelf, there\u2019s no one-size-fits-all solution to storing information.Consider the simple situation where you create a new digital file. Your computer needs to rapidly find a place to put it. If you later want to delete it, the machine must quickly find the right bits to erase. Researchers aim to design storage systems, called data structures, that balance the amount of time it takes to add data, the time it takes to later remove it, and the total amount of memory the system needs.To get a feel fo"
  }
]