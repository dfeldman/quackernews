[
  {
    "title": "Mr Tiff (inventingthefuture.ghost.io)",
    "points": 162,
    "submitter": "speckx",
    "submit_time": "2025-11-04T22:57:12 1762297032",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=45816853",
    "comments": [
      "Don't have much to add except to mention again that the magic number for TIF is 42, and it's 42 because of the meaning of 42:https://web.archive.org/web/20210108174645/https://www.adobe...  Bytes 2-3\n  An arbitrary but carefully chosen number (42) that further identifies the file as a TIFF filereply",
      "I checked the TIFF talk page and found comments from:https://en.wikipedia.org/wiki/User:ScarlsenTurns out the answer was on Wikipedia already :).reply",
      "If you had told me an article ostensibly about a file format would have me teary-eyed by the end I wouldn't have believed you. This is beautiful, thank you!reply",
      "Beautiful and moving. Thank you author of the article and thank you Mr TIFFreply",
      "I was not expecting the emotional ending. Really well done.reply",
      "RIP Mr. TIFF. Hoping we continue to document these incredible engineers and their work before it's lost to the sands of time/pits of LLM muck.reply",
      "Pretty amazing investigation work. Very nice to see that credit is being given where due.reply",
      "TIFF indeed -- I recall the floppy disk for Mac mailed from Seattle with the TIFF spec printed on paper. A few weeks later, another graphics editor with TIFF support. I never, ever heard the name Carlsen until today. Thank you for this articlereply",
      "And that\u2019s a wonderful lesson to try searching alternate spellings of names for an oral history.reply",
      "Did a similar deep dive for one of the posters for the cult classic movie Possession (1981). Just giving random phone numbers a call is incredibly effective, lots of people are happy to reminisce about old work and have great stories.reply"
    ],
    "link": "https://inventingthefuture.ghost.io/mr-tiff/",
    "first_paragraph": "For as long as I have published my books, one of my overarching goals was to give credit to those who actually invented the hardware and software that we use. I have spent 10,000+ hours to create an\u00a0accurate record of their work but I'm not complaining. The 'as-close-to-possible' truth of invention by individuals or teams meant identifying the work, educating myself, writing questions, and sending emails. And after that process, I set up a chat because it all gets down to talking to someone on the other side of the world, about something that happened 30 or 40 years ago. If the invention involves a team, I try to interview more than one person, so I can cross-check the facts. Not to call anyone out, it\u2019s just that, given time, we all forget the facts. And everyone adds their personal take. It\u2019s because of that, for example, that I know the English musician Peter Gabriel really did visit Apple's research labs as they tested the Apple Sound Chip, and gave the team his personal approval t"
  },
  {
    "title": "Patching 68K Software \u2013 SimpleText (tinkerdifferent.com)",
    "points": 46,
    "submitter": "mmoogle",
    "submit_time": "2025-11-04T22:59:22 1762297162",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=45816879",
    "comments": [
      "This is beautiful, but the real takeaway should be that even proprietary software you only have binaries for is still mutable. The computer runs the code you want it to run. We always need to maintain that and prevent scenarios where general purpose computers stop being the default.reply",
      "We were always doing this kind of thing on these platforms. This is how we used to hack copy protection out of games.Stepping through, line by line, editing the code and adding JMPs to get around the copy protection code after loading the magic numbers into the register...Happy, happy times.reply"
    ],
    "link": "https://tinkerdifferent.com/threads/patching-68k-software-simpletext.4793/",
    "first_paragraph": ""
  },
  {
    "title": "Apple uses 3D Gaussian splatting for Personas and 3D conversions of photos (cnet.com)",
    "points": 34,
    "submitter": "dmarcos",
    "submit_time": "2025-10-30T15:53:21 1761839601",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=45761433",
    "comments": [
      "This video might help explain 3D Gaussian splatting. \nhttps://www.youtube.com/watch?v=wKgMxrWcW1s\nEssentially, an entirely new graphics pipeline with different fundamental techniques which allow for high performance and fidelity compared to... what we did before(?)\nCool.reply",
      "Not quite, it\u2019s just a way to assign a color value to a point in space (think point clouds) based on photogrammetry. It\u2019s voxels on steroids but still is drawn using the same techniques. It\u2019s the magic of creating the splats that\u2019s interesting.reply",
      "A color value for each point is a good starting place to gain an intuition. Some readers might be interested to know that the color is not constant for each point, but instead dependent on viewing angle. That is part of what allows splats to look realistic. Real objects have some degree of specularity which makes them take on slightly different shades as you move your head.reply",
      "And since we normally see with binocular vision, a stereoscopic view adds another layer of realism you wouldn't normally perceive otherwise. Each eye sees subsurface scattering differently and integrates in your head.reply",
      "The same graphics pipeline is used: rasterization.reply",
      "Rasterization is a very general term. There is a big difference in practice between the traditional rasterization pipeline and splat rasterizersreply",
      "\"Now out of beta\"??Just in time for Vision Pro to go big. Right?reply"
    ],
    "link": "https://www.cnet.com/tech/computing/apple-talks-to-me-about-vision-pro-personas-where-is-our-virtual-presence-headed/",
    "first_paragraph": "\n    Apple's Vision team met me in-headset to chat about how unique telepresence Personas have evolved, and where they're going.\n  That's me standing between Apple's Jeff Norris and Steve Sinclair after a meeting in-headset, discussing Personas while embodying Personas.Buried inside Apple's $3,499 Vision Pro\u00a0VR headset is a feature that continually wows me, but you've probably never heard of it. The feature, called\u00a0Personas, involves two or more users, all wearing Vision Pros, chatting with one another in real time but as virtual replicas.\u00a0Now out of beta, Personas are part of Apple's avatar system for the Vision Pro, creating replicas of yourself via a 3D photo scan.\u00a0Taking a scan of myself isn't a new thing. Some five years ago,\u00a0I tried telepresence with 3D-scanned avatars on Nreal AR glasses with a company called Spatial. I've gotten peeks at Meta's realistic codec avatars. I explored cartoon avatar telepresence with Microsoft in HoloLens. And I've even scanned myself into all sorts"
  },
  {
    "title": "This Day in 1988, the Morris worm infected 10% of the Internet within 24 hours (tomshardware.com)",
    "points": 296,
    "submitter": "canucker2016",
    "submit_time": "2025-11-04T15:23:14 1762269794",
    "num_comments": 143,
    "comments_url": "https://news.ycombinator.com/item?id=45812024",
    "comments": [
      "The 10% number is completely made up. According to Paul Graham, \"I was there when this statistic was cooked up, and this was the recipe: someone guessed that there were about 60,000 computers attached to the Internet, and that the worm might have infected ten percent of them.\"reply",
      "That figure is probably UUCP mostly not live connected hosts. I could be wrong, but 60k hosts that you could telnet to sounds like a lot of ducking hosts back then. I was there too, in my late teens. God bless PG.reply",
      "Yeah and a 'host' back then wasn't a cheap PC or something, they tended to be $30000 workstations or $300000 servers. At tech companies and Universities only, and mostly in the US. 60k sounds like a lot for those days. It grew massively from the early 90s.Even UUCP was still really fringe and those weren't actually connected hosts on tcp/ip. They had their own dialup mail exchange protocol similar to fidonet.reply",
      "Those were the days.  I still remember my fido number.  And I still remember just how painful it was to get uucp working properly.  Ugh.  But my mother had an email address years before any of her contemporaries.  Being a geek was fun then.reply",
      "foo@baz!quux, those were the days.reply",
      "I followed his course 6.5840 on distributed systems (https://pdos.csail.mit.edu/6.824/, YouTube videos at https://youtube.com/playlist?list=PLrw6a1wE39_tb2fErI4-WkMbs...) and completed the labs. One day, out of curiosity, I looked up his name. Then I realized what a legend he is.Great course by the way.reply",
      "His dad was a legend as well, chief scientist in NSA.reply",
      "RTM was my TA at MIT for a CS/systems engineering course. It took the students until we did an assignment about the worm to realize who he was IIRC. The students thought it was very cool, but even then, as a TA covering the assignment, he didn't really talk about it.reply",
      "Would be cool if he adds a session on how to hack distributed system in 1988...reply",
      "In 1988? Just stick random semicolons in things.reply"
    ],
    "link": "https://www.tomshardware.com/tech-industry/cyber-security/on-this-day-in-1988-the-morris-worm-slithered-out-and-sparked-a-new-era-in-cybersecurity-10-percent-of-the-internet-was-infected-within-24-hours",
    "first_paragraph": "The Internet contracted worms a year before the World Wide Web was even a thing.\nWhen you purchase through links on our site, we may earn an affiliate commission. Here\u2019s how it works.\nThis week in 1988, Cornell graduate student Robert Tappan Morris unleashed his eponymous worm upon the Internet. The wave of infections grew to 10% of the entire Internet within 24 hours, causing astronomically expensive damage for the time. However, the pioneering Morris worm malware wasn\u2019t made with malice, says an FBI retrospective on the \u201cprogramming error.\u201d It was designed to gauge the size of the Internet, resulting in a classic case of unintended consequences.Known to be something of a prankster, Morris must have felt some foreboding about releasing his \u2018innocent\u2019 program into the wild. Evidence of this comes from his release method. \u201cHe released it by hacking into an MIT computer from his Cornell terminal in Ithaca, New York,\u201d according to the FBI.The Morris worm was written in C and targeted BSD "
  },
  {
    "title": "Pg_lake: Postgres with Iceberg and data lake access (github.com/snowflake-labs)",
    "points": 271,
    "submitter": "plaur782",
    "submit_time": "2025-11-04T16:12:27 1762272747",
    "num_comments": 78,
    "comments_url": "https://news.ycombinator.com/item?id=45812606",
    "comments": [
      "This is huge!When people ask me what\u2019s missing in the Postgres market, I used to tell them \u201copen source Snowflake.\u201dCrunchy\u2019s Postgres extension is by far the most ahead solution in the market.Huge congrats to Snowflake and the Crunchy team on open sourcing this.reply",
      "Honestly. Just pay snowflake for the amazing DB and ecosystem it is. And then go build cool stuff unless your value add to customers is infra let them handle all that.reply",
      "Sounds great until you're locked into Snowflake - so glad iceberg is becoming the standard, anything is great.The trap you end up in is you have to pay snowflake to access your data, iceberg and other technology help with the walled garden.Not just snowflake, any pay on use provider.(Context - have spent 5+ years working with Snowflake, it's great, have built drivers for various languages, etc).reply",
      "Why not just use Ducklake?[1] That reduces complexity[2] since only DuckDB and PostgreSQL with pg_duckdb are required.[1] https://ducklake.select/[2] DuckLake - The SQL-Powered Lakehouse Format for the Rest of Us by Prof. Hannes M\u00fchleisen: https://www.youtube.com/watch?v=YQEUkFWa69oreply",
      "DuckLake is pretty cool, and we obviously love everything the DuckDB is doing. It's what made pg_lake possible, and what motivated part of our team to step away from Microsoft/Citus.DuckLake can do things that pg_lake cannot do with Iceberg, and DuckDB can do things Postgres absolutely can't (e.g. query data frames). On the other hand, Postgres can do a lot of things that DuckDB cannot do. For instance, it can handle >100k single row inserts/sec.Transactions don't come for free. Embedding the engine in the catalog rather than the catalog in the engine enables transactions across analytical and operational tables. That way you can do a very high rate of writes in a heap table, and transactionally move data into an Iceberg table.Postgres also has a more natural persistence & continuous processing story, so you can set up pg_cron jobs and use PL/pgSQL (with heap tables for bookkeeping) to do orchestration.There's also the interoperability aspect of Iceberg being supported by other query engines.reply",
      "How does this compare to https://www.mooncake.dev/pgmooncake? It seems there are several projects like this now, with each taking a slightly different approach optimized for different use cases?reply",
      "Definitely similar goals, from the Mooncake author:\nhttps://news.ycombinator.com/item?id=43298145I think pg_mooncake is still relatively early stage.There's a degree of maturity to pg_lake resulting from our team's experience working on extensions like Citus, pg_documentdb, pg_cron, and many others in the past.For instance, in pg_lake all SQL features and transactions just work,  the hybrid query engine can delegate different fragments of the query into DuckDB if the whole query cannot be handled, and having a robust DuckDB integration with a single DuckDB instance (rather than 1 per session) in a separate server process helps make it production-ready. It is used in heavy production workloads already.No compromise on Postgres features is especially hard to achieve, but  after a decade of trying to get there with Citus, we knew we had to get that right from day 1.Basically, we could speed run this thing into a comprehensive, production-ready solution. I think others will catch up, but we're not sitting still either. :)reply",
      "FYI the mooncake team was acquired by Databricks so it's basically vendors trying to compete on features now :)reply",
      "> For instance, it can handle >100k single row inserts/sec.DuckLake already has data-inlining for the DuckDB catalog, seems this will be possible once it's supported in the pg catalog.> Postgres also has a more natural persistence & continuous processing story, so you can set up pg_cron jobs and use PL/pgSQL (with heap tables for bookkeeping) to do orchestration.This is true, but it's not clear where I'd use this in practice. e.g. if I need to run a complex ETL job, I probably wouldn't do it in pg_cron.reply",
      "> This is true, but it's not clear where I'd use this in practice. e.g. if I need to run a complex ETL job, I probably wouldn't do it in pg_cron.Think \"tiered storage.\"See the example under https://github.com/Snowflake-Labs/pg_lake/blob/main/docs/ice...:   select cron.schedule('flush-queue', '* * * * *', $$\n     with new_rows as (\n       delete from measurements_staging returning *\n     )\n     insert into measurements select * from new_rows;\n   $$);\n\nThe \"continuous ETL\" process the GP is talking about would be exactly this kind of thing, and just as trivial. (In fact it would be this exact same code, just with your mental model flipped around from \"promoting data from a staging table into a canonical iceberg table\" to \"evicting data from a canonical table into a historical-archive table\".)reply"
    ],
    "link": "https://github.com/Snowflake-Labs/pg_lake",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        pg_lake: Postgres with Iceberg and data lake access\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.pg_lake integrates Iceberg and data lake files into Postgres. With the pg_lake extensions, you can use Postgres as a stand-alone lakehouse system that supports transactions and fast queries on Iceberg tables, and can directly work with raw data files in object stores like S3.At a high level, pg_lake lets you:There are two ways to set up pg_lake:Both approaches include the PostgreSQL extensions, the pgduck_server application and setting up S3-compatible storage.Follow the Docker README to set up and run pg_lake with Docker.Once you\u2019ve built and installed the required components, you can initialize pg_lake inside Postgres.Create all required extensions at once u"
  },
  {
    "title": "Whole Earth Index (wholeearth.info)",
    "points": 141,
    "submitter": "bookofjoe",
    "submit_time": "2025-10-28T15:36:39 1761665799",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=45734259",
    "comments": [
      "I love the Whole Earth Catalog. That era of techno-utopian optimism is so exciting. I'm too young to have experienced more then the tail end of it in the 90s going to computer camp as a kid, but it felt like anything was possible and everything was connected.It is a bit sad to see where we have landed after all that.reply",
      "If you look at the first 10 years of Whole Earth Review, starting in 1985, it's startling to see the similarities to the issues of today.January 1985: Computers as Poison - \"It is not our hand that we put into the computer, it is our attention.\"July 1985: Digital Retouching - \"The end of photography as evidence of anything\"Winter 1985: \"Islam: Beyond the Stereotypes\"Spring 1986: \"Peering into the age of Transparency\" - about space surveillanceSummer 1986: \u201cThis text tries to explain how minds work. How can intelligence emerge from non-intelligence? To answer that, I\u2019ll show that you can build a mind from many little parts, each mindless by itself.\u201dFall 1986: The Fringes of Reason - Strange myths and eccentric scienceWinter 1986: AmerRuss - Joining America and Russia into one countrySummer 1987: What is real & A No-Cash Economy that WorksFall 1987: Doing Drag & Male IdentitySummer 1988: The Far Left & Far Right Converge\nSummer 1988: The Rights of RobotsSummer 1989: Is the body obsoleteSummer 1991: Electronic DemocracyWinter 1991: Questioning TechnologyFall 1992: Artificial Lifereply",
      "> It is a bit sad to see where we have landed after all that.For a comically small amount of money I can listen to any song I want to, read any book I want to, watch any movie/TV show I want to. Then there\u2019s the ad-supported videos and images and text. Then there\u2019s the AIs that I use every day!I\u2019m in awe at how amazing where we have landed at is. Sure some stuff isn\u2019t perfect but what fun is it to be sad about what is pretty cool?reply",
      "Maybe you're too young to remember the kind of vibe and optimism that people rode in the 90s.Felt like everything was going to be better, like we humans were going to be better. More peace, no apartheid, no Soviet union, removing borders between countries in Europe, tech felt like a way to connect us.In fact, I invite you to re read your entire post. You post achievements in conveniences as major milestones for human progress, but...people have never read as little as they do today, never went to so few concerts as today, or the movies and the average adult in US spends less than 4 hours socializing (including both family and friends) per week, that's less than half the quote of the 90s which was already less but not as significantly.reply",
      "I started getting online in around 1996 for whatever that\u2019s worth.> You post achievements in conveniences as major milestones for human progressA careful reader will note that I did not do this.reply",
      "You didn't explicitly call your examples major milestones of human progress but you did use rather trite examples of consumer capitalism as a counter example to my disappointment at the lackluster end game of 20th century techno-futurism.As other commenters have stated the techno-futurist vision that comes out of the Whole Earth Catalog was radically utopian and far grander then \"I get to watch low value consumer media whenever I want.\"reply",
      "I\u2019d say dirt cheap solar panels and CRISPR based vaccines are pretty cool. I\u2019m also quite optimistic about the proliferation of plausible SMR designs. That new concrete that self heals and sequesters carbon is cool too.",
      "Social dislocation, a loneliness epidemic, the breakdown of civil society and of trust in the media, gambling unleashed in everyone's pockets, billions of dollars spent trying to get you addicted to scrolling on your phone... Yes, it's worth bemoaning that.reply",
      "Yeah my mistake you\u2019re right. I\u2019ll go be sad for awhile as penance!reply",
      "Maybe I'm missing some sarcasm here, but it would be worth asking what the consequences of this situation are for the people who actually make all the music/books/films you get to consume for a \"comically small amount of money\".reply"
    ],
    "link": "https://wholeearth.info/",
    "first_paragraph": "Here lies a nearly-complete archive of Whole Earth publications, a series of journals and magazines descended from the Whole Earth Catalog, published by Stewart Brand and the POINT Foundation between 1968 and 2002. They are made available here for scholarship, education, and research purposes.The Whole Earth Catalog was an American counterculture magazine and product catalog published by Stewart Brand several times a year between 1968 and 1972, and occasionally thereafter, until 1998. The magazine featured essays and articles, but was primarily focused on product reviews. The editorial focus was on self-sufficiency, ecology, alternative education, \u201cdo it yourself,\u201d and holism, featuring the slogan \u201caccess to tools.\u201dFounded in 1974 by the staff of the Whole Earth Catalog, CoEvolution Quarterly lasted 10 years as a small circulation magazine whose titular founding idea was coined by zoologist Paul Ehrlich and botanist Peter Raven to account for events that neither of their separate disci"
  },
  {
    "title": "Uncle Sam wants to scan your iris and collect your DNA, citizen or not (theregister.com)",
    "points": 95,
    "submitter": "SanjayMehta",
    "submit_time": "2025-11-04T23:35:27 1762299327",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=45817167",
    "comments": [
      "The problem with these types of technologies is that you will be at the mercy of whoever uses them. It's like chat control, censorship, gun laws, etc. You can't control how they will be leveraged.I lived in California for some time a few years ago, and it was a mess, so I understand people being okay with this type of stuff if it will make them more secure, but it's a very risky slippery slope.The other thing is that with all the data Google has, they can probably uncover everything they need just by paying for Google Ads data :/reply",
      "Hilariously, this is the second Sam that wants to collect everyones iris's for nefarious purposesreply",
      "You can submit a public comment on the proposal to DHS at the link below:https://www.regulations.gov/document/USCIS-2025-0205-0002/co...reply",
      "Did you know that the State of California has a DNA sample from every person born in the state since 1983?  It's required by law for the hospital to collect it and give it to the state.reply",
      "This is a particularly incendiary way of putting this information out there.What is collected and stored is a small blood-spot sample from a heel prick on a newborn. This is used to test for various kinds of conditions that affect newborns.This isn't a full DNA genome sequence or even any data at all, just the blood-spot specimen.Law enforcement does not have automatic access to this sample, but individual samples have been given to law enforcement through court orders or warrants. There isn't a clear SOP for how law enforcement typically gets this information or how often it's given to law enforcement, but there's been proposed legislation to make this more transparent.reply",
      "> This is a particularly incendiary way of putting this information out there.Was it inaccurate?reply",
      "It's about as accurate a Buzzfeed headline, but I guess that's par for the course on the internet these days.It's not a \"DNA sample\" in the way that most people would consider it these days, no more than a used cup would also be called a \"DNA sample\". But to your point, it can still be used for surveillance and tracking.Also, your phrasing is designed to make it seem like a huge overreach, when this act has likely saved millions of lives through early diagnosis of preventable diseases and early intervention on disabilities. I have personally experienced this.So yes, I do think your framing here is inaccurate through omission of key facts.reply",
      "> this act has likely saved millions of lives through early diagnosis of preventable diseases and early intervention on disabilitiesWhy does the state have to collect and keep the sample for that to happen? Why can't it be the private property of the parents, provided to whatever private testing labs are used to do the tests?reply",
      "That seems like a fair criticism. I don't know enough to quantify the benefit of retaining these samples, but I do know that the reason for keeping samples primarily relates to quality control, research, and development of tests.There is a process for people to have the sample destroyed, I also have no idea how easy or how often that is used.reply",
      "the implication was misleading, yes. the implication being that California has database of its citizens' genetic data. when the reality is that CA has a _physical sample_ of blood.reply"
    ],
    "link": "https://www.theregister.com/2025/11/04/dhs_wants_to_collect_biometric_data/",
    "first_paragraph": "If you're filing an immigration form - or helping someone who is - the Feds may soon want to look in your eyes, swab your cheek, and scan your face. The US Department of Homeland Security wants to greatly expand biometric data collection for immigration applications, covering immigrants and even some US citizens tied to those cases.DHS, through its component agency US Citizenship and Immigration Services, on Monday proposed a sweeping expansion of the agency's collection of biometric data. While ostensibly about verifying identities and preventing fraud in immigration benefit applications, the proposed rule goes much further than simply ensuring applicants are who they claim to be.First off, the rule proposes expanding when DHS can collect biometric data from immigration benefit applicants, as \"submission of biometrics is currently only mandatory for certain benefit requests and enforcement actions.\" DHS wants to change that, including by requiring practically everyone an immigrant is "
  },
  {
    "title": "Codemaps: Understand Code, Before You Vibe It (cognition.ai)",
    "points": 190,
    "submitter": "janpio",
    "submit_time": "2025-11-04T17:47:09 1762278429",
    "num_comments": 65,
    "comments_url": "https://news.ycombinator.com/item?id=45813767",
    "comments": [
      "Sounds very cool.I wanted to try this out, so I opened Windsurf for the first time in ages and clicked the \"Upgrade Available\" button, which sent me to: https://windsurf.com/editor/update-linux  Did you install using apt or apt-get? If so...\n  \n  1. Update package lists\n  \n  sudo apt-get update\n  \n  2. Upgrade Windsurf\n  \n  sudo apt-get upgrade windsurf\n\nWhle `apt-get upgrade windsurf` will technically upgrade Windsurf, instructing users to run a command that will attempt to upgrade all packages on their system is nuts when the command is provided in a context that strongly implies it will only upgrade Windsurf and has no warnings or footnotes to the contrary. Good thing I didn't ask Windsurf's agent to ugprade itself for me, I guess.EDIT - I don't want to detract from the topic at hand, however - after upgrading (with `sudo apt-get install --only-upgrade windsurf` :)) and playing around a bit, the Codemaps feature indeed seems very nifty and worth checking out. Good job!reply",
      "So `apt-get upgrade $PACKAGE` has ridiculous semantics that no one would expect, and the actual syntax for upgrading a package is in neither the man page nor the command help.reply",
      "> So `apt-get upgrade $PACKAGE` has ridiculous semantics that no one would expectEspecially not an LLM!reply",
      "hiya! team noticed your comment and agreed - and it is fixed.    - const CodeSnippetTwo = `sudo apt-get upgrade windsurf`;\n    + const CodeSnippetTwo = `sudo apt-get install windsurf`;reply",
      "Did you also generate this with \u201cAI\u201d?reply",
      "https://tenor.com/view/westworld-if-you-cant-tell-does-it-ma...reply",
      "If you couldn't tell your food had been cut with sawdust would it matter to you if you found out?reply",
      "A few things to point out after reading and thinking about this:- Another AI firm building products focused on Fortune 500 scale problems. If you're not at a F500, this tool isn't necessarily a good fit for you, so YMMV.- static analysis tools that produce flowcharts and diagrams like this have existed since antiquity, and I'm not seeing any new real innovation other than \"letting the LLM produce it\".They say it's ZDR, so maybe I don't fully understand what problem they're trying to solve, but in general I don't see the value add for a system like this. Also onboarding isn't necessarily just presenting flow charts and diagrams: one of the biggest things you can do to onboard somebody is level-set and provide them with problem context. You COULD go into a 30 minute diatribe about how \"this is the X service, which talks to the Y service, and ...\" and cover a whiteboard in a sprawling design diagram, or you could just explain to them \"this is the problem we're working on\", using simple, compact analogies where/when applicable. If the codebase is primarily boilerplate patterns, like CRUD, MVC, or Router/Controller/Service/DB, why talk about them? Focus on the deviant patterns your team uses. Focus on the constraints your team faces, and how you take the unbeaten path to navigate those constraints.reply",
      "> static analysis tools that produce flowcharts and diagrams like this have existed since antiquity, and I'm not seeing any new real innovation other than \"letting the LLM produce it\".Inherent limitation of static analysis-only visualization tools is lack of flexibility/judgement on what should and should not be surfaced in the final visualization.The produced visualizations look like machine code themselves. Advantage of having LLMs produce code visualizations is the judgement/common sense on the resolution things should be presented at, so they are intuitive and useful.reply",
      "Although I haven't personally experienced the feeling of \"produced visualizations looking like machine code\", I can appreciate the argument you're making wrt judgment-based resolution scaling.reply"
    ],
    "link": "https://cognition.ai/blog/codemaps",
    "first_paragraph": "Software development only becomes engineering with understanding. Your ability to reason through your most challenging coding tasks is constrained by your mental model of how things work \u2014 in other words, how quickly and how well you onboard to any codebase for solving any problem. However most AI vibe coding tools are aimed at relieving you of that burden by reading \u2192 thinking \u2192 writing the code for you, increasing the separation from you and your code. This is fine for low value, commodity tasks, but absolutely unacceptable for the hard, sensitive, and high value work that defines real engineering.We all need more AI that turns your brain ON, not OFF.Today we are announcing Windsurf Codemaps, which are first-of-its-kind AI-annotated structured maps of your code, powered by SWE-1.5 and Claude Sonnet 4.5. Building on our popular work from DeepWiki and Ask Devin, Codemaps is the next step in hyper-contextualized codebase understanding, grounded in precise code navigation.Every engineeri"
  },
  {
    "title": "BlackRock's Larry Fink: \"Tokenization\", Digital IDs, & Social Credit (thewinepress.substack.com)",
    "points": 30,
    "submitter": "sbuttgereit",
    "submit_time": "2025-11-04T21:39:32 1762292372",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=45816191",
    "comments": [
      "Use cash. Get cash out at the ATM, keep it in your wallet. Spend it at local businesses. Even if you can\u2019t do it all the time do it as much as you can. Start today and stick with it.Otherwise this is what we\u2019ll be stuck with everywhere all the time. There won\u2019t be a choice anymore if you don\u2019t exercise that right. We\u2019re already far down this slippery slope.reply",
      "And advocating for mass individual consistent behavioral change is less than useless. If you want change you need political organization. The sum of public opinion is more influenceable than the sum of everyone's actions. Unfortunately, in the US it's not so simple as \"vote for the party that's against this\" as we only have two and neither are. Which means if you want to be effective you should throw your lot in with an advocacy group. In this case probably the EFF, maybe the ACLU?reply",
      "Many people (not the EFF or ACLU, lol) saw it coming years ago and put in a monumental effort to try to turn to tide, only to be relentlessly repressed and dehumanized by bolsheviks and idiots.reply",
      "cameras + machine learning \ntrackable serialized billsreply",
      "Yeah, people forget bills have a serial code, and if shops were required by law to validate them you could still mostly track all the moneyreply",
      "Or if it was just valuable tracking data for them to have.You don't need a law where there's profit incentives. Rewards programs track plenty.reply",
      "Dude who became powerful by the simplest business model in existence (buying S&P winners with other people's money, selling losers), suddenly gets to set the policy for the rest of the world. Index funds should never be allowed to vote in corporations they own as their business model is just a simple rental of success.reply",
      "You first, Larry. Any functional social credit would have him at \"untouchable\" levels.reply",
      "Hate is a powerful word. But I really hate this people. If you work on these projects, shame on you.reply",
      "What I find funny about this is that cryptocurrency - a supposed way to create a currency independent of bank or government control - laid the foundation for this. Look at all the terminology Larry Fink is throwing around here: tokens, ledger, fractional ownership.Good stuff, thanks guys!reply"
    ],
    "link": "https://thewinepress.substack.com/p/tokenization-blackrocks-larry-fink",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: A CSS-Only Terrain Generator (layoutit.com)",
    "points": 273,
    "submitter": "rofko",
    "submit_time": "2025-11-04T13:58:35 1762264715",
    "num_comments": 75,
    "comments_url": "https://news.ycombinator.com/item?id=45811093",
    "comments": [
      "When I turn off JS, it shows a loader instead of the terrain. Is this really  CSS-Only? I mean it's still a high achievement even with JS, but was expecting it would also work without JS. This one, for example, truly works without JS https://benjaminaster.com/css-minecraft/ .reply",
      "I'm assuming it's the render engine that is in pure CSS. You could display a static map in CSS but things like the tools to modify the terrain definitely need JS.reply",
      "I wanted to check if your assumption is correct but I couldn\u2019t find the source code.Why do you think the renderer is pure css and not e.g. mostly css?reply",
      "The top right button has a \"Download code\" which gives you a .zip file. That .zip file doesn't have any JS in it, and renders the terrain just like in the online editor, except you can turn off JS and it still works.Edit: someone else wrote basically the same an hour ago: https://news.ycombinator.com/item?id=45814791reply",
      "Looks like it\u2019s a \u201c(css-only terrain) generator\u201d - a generator that lets the user create and download a css only terrain.As opposed to a \u201ccss-only (terrain generator)\u201d - a terrain creation studio built with css only.reply",
      "You might not need it using the new :has() and different inputs as modifiers.  Though that's a lot of :has() and probably would kill performance.reply",
      "GP linked an example of a similar project that allowed you to modify the terrain without any JS at allreply",
      "I think what's intended is that the completed and downloaded solution doesn't require any javascript.Build something then hit the Download Code button - that packaged HTML solution doesn't require any javascript to render locally.reply",
      "Yeah, it worked, it seems to be a static rendered html with no interactivity though.reply",
      "Wow this really feels like roller coaster tycoon!!! (I can see lots of people refer to this to their favorite sim game though)Great work!reply"
    ],
    "link": "https://terra.layoutit.com",
    "first_paragraph": ""
  },
  {
    "title": "By the Power of Grayscale (zserge.com)",
    "points": 104,
    "submitter": "surprisetalk",
    "submit_time": "2025-10-31T12:11:03 1761912663",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=45771151",
    "comments": [
      "If you enjoyed this post you may also like the 2024 book foundations of computer vision: https://visionbook.mit.edu/prior hn thread: https://news.ycombinator.com/item?id=44281506i don't have any background in computer vision but enjoyed how the introductory chapter gets right into it illustrating how to build a limited but working simple vision systemreply",
      "For those who don't know, the author is a very prolific dev:https://github.com/zserge?tab=repositories&q=&type=&language...reply",
      "It may come as a surprise to some that a lot of industrial computer vision is done in grayscale. In a lot of industrial CV tasks, the only things that matter are cost, speed, and dynamic range. Every approach we have to making color images compromises on one of those three characteristics.I think this kind of thing might have real, practical use cases in industry if it's fast enough.reply",
      "In some contexts there is no compromise to even make\u2014if you're working in semiconductor manufacturing and using a scanning electron microscope to verify critical dimensions, for example, then the only image data you're going to get out of the SEM is (the equivalent of) grayscale, anyway.reply",
      "Also resolution & uniformityColor makes major compromises physically also, since it seems like the Red, Green and Blue channels are sampling from the same physical location but the actual sensor buckets are offset from each other.reply",
      "Ah, I think you work in the same industry as me, machine vision. I completely agree with you, most applications use grayscale images unless it\u2019s color-based application.Which vision library are you using? I\u2019m using Halcon by MVTec.reply",
      "Appreciate the old school non-AI approach.reply",
      "But have a look at the \"Thresholding\" section. It appears to me that AI would be much better at this operation.reply",
      "It really depends on the application. If the illumination is consistent, such as in many machine vision tasks, traditional thresholding is often the better choice. It\u2019s straightforward, debuggable, and produces consistent, predictable results. On the other hand, in more complex and unpredictable scenes with variable lighting, textures, or object sizes, AI-based thresholding can perform better.That said, I still prefer traditional thresholding in controlled environments because the algorithm is understandable and transparent.Debugging issues in AI systems can be challenging due to their \"black box\" nature. If the AI fails, you might need to analyze the model, adjust training data, or retrain, a process that is neither simple nor guaranteed to succeed. Traditional methods, however, allow for more direct tuning and certainty in their behavior. For consistent, explainable results in controlled settings, they are often the better option.reply",
      "Not to mention performance. So often, the traditional method is the only thing that can keep up with performance requirements without needing massive hardware upgrades.Counter intuitively, I\u2019ve often found that CNNs are worse at thresholding in many circumstances than a simple otsu or adaptive threshold. My usual technique is to use the least complex algorithm and work my way up the ladder only when needed.reply"
    ],
    "link": "https://zserge.com/posts/grayskull/",
    "first_paragraph": "When people talk about computer vision, they usually think of OpenCV or deep neural networks like YOLO. But in most cases, doing computer vision implies understanding of the core algorithms, so you can use or adapt them for your own needs.I wanted to see how far I could go by stripping computer vision down to the bare minimum: only grayscale 8-bit images, no fancy data structures, plain old C, some byte arrays and a single header file. After all, an image is just a rectangle of numbers, right?This post is a guided tour through the algorithms behind Grayskull \u2013 a minimal computer vision library designed for resource-constrained devices.A grayscale pixel is normally represented as a single byte, where 0 means black, 255 means white, and values in between represent various shades of gray.A grayscale image is essentially a 2D array of these pixels, defined by its width and height, but for a simpler memory layout languages such as C often represent it as a 1D array of size width * height:Th"
  },
  {
    "title": "I took all my projects off the cloud, saving thousands of dollars (rameerez.com)",
    "points": 116,
    "submitter": "sebnun",
    "submit_time": "2025-11-04T21:22:15 1762291335",
    "num_comments": 132,
    "comments_url": "https://news.ycombinator.com/item?id=45816041",
    "comments": [
      "I dislike those black and white takes a lot. It's absolutely true that most startups that just run an EC2 instance will save a lot of cash going to Hetzner, Linode, Digital Ocean or whatever. I do host at Hetzner myself and so do a lot of my clients.That being said, the cloud does have a lot of advantages:- You're getting a lot of services readily available. Need offsite backups? A few clicks. Managed database? A few clicks. Multiple AZs? Available in seconds.- You're not paying up-front costs (vs. investing hundreds of dollars for buying server hardware) and everything is available right now [0]- Peak-heavy loads can be a lot cheaper. Mostly irrelevant for you average compute load, but things are quite different if you need to train an LLM- Many services are already certified according to all kinds of standards, which can be very useful depending on your customersAlso, engineering time and time in general can be expensive. If you are a solo entrepreneur or a slow growth company, you have a lot of engineering time for basically free. But in a quick growth or prototyping phase, not to speak of venture funding, things can be quite different. Buying engineering time for >150\u20ac/hour can quickly offset a lot of saving [1].Does this apply to most companies? No. Obviously not. But the cloud is not too expensive - you're paying for stuff you don't need. That's an entirely different kind of error.[0] Compared to the rack hosting setup described in the post. Hetzner, Linode, etc. do provide multiple AZs with dedicated servers.[1] Just to be fair, debugging cloud errors can be time consuming, too, and experienced AWS engineers will not be cheaper. But an RDS instance with solid backups-equivalent will usually not amortize quickly, if you need to pay someone to set it up.reply",
      "You don't actually need any of those things until you no longer have a \"project\", but a business which will allow you to pay for the things you require.You'd be amazed by how far you can get with a home linux box and cloudflare tunnels.reply",
      "On this site, I've seen these kind of takes repeatedly over the past years, so I went ahead and built a little forum that consists of a single Rust binary and SQLite. The binary runs on a Mac Mini in my bedroom with Cloudflare tunnels. I get continuous backups with Litestream, and testing backups is as trivial as running `litestream restore` on my development machine and then running the binary.Despite some pages issuing up to 8 database queries, I haven't seen responses take more than about 4 - 5 ms to generate. Since I have 16 GB of RAM to spare, I just let SQLite mmap the whole the database and store temp tables in RAM. I can further optimize the backend by e.g. replacing Tera with Askama and optimizing the SQL queries, but the easiest win for latency is to just run the binary in a VPS close to my users. However, the current setup works so well that I just see no point to changing what little \"infrastructure\" I've built. The other cool thing is the fact that the backend + litestream uses at most ~64 MB of RAM. Plenty of compute and RAM to spare.It's also neat being able to allocate a few cores on the same machine to run self-hosted GitHub actions, so you can have the same machine doing CI checks, rebuilding the binary, and restarting the service. Turns out the base model M4 is really fast at compiling code compared to just about every single cloud computer I've ever used at previous jobs.reply",
      "Just one of the couple dozen databases we run for our product in the dev environment alone is over 12 TB.How could I not use the cloud?reply",
      "What's your cloud bill?",
      "You can get quite far without that box,\neven, and just use Cloudflare R2 as free static hosting.reply",
      "> A few clicks.Getting through AWS documentation can be fairly time consuming.reply",
      "Figuring out how to do db backups _can_ also be fairly time consuming.There's a question of whether you want to spend time learning AWS or spend time learning your DB's hand-rolled backup options (on top of the question of whether learning AWS's thing even absolves you of understanding your DB's internals anyways!)I do think there's value in \"just\" doing a thing instead of relying on the wrapper. Whether that's easier or not is super context and experience dependent, though.reply",
      "> Figuring out how to do db backups _can_ also be fairly time consuming.apt install automysqlbackup autopostgresqlbackupThough if you have proper filesystem snapshots then they should always see your database as consistent, right?  So you can even skip database tools and just learn to make and download snapshots.reply",
      "Hmmm, I think you have to figure out how to do your database backups anyway as trying to get a restorable backup out of RDS to use on another provider seems to be a difficult task.Backups that are stored with the same provider are good, providing the provider is reliable as a whole.(Currently going through the disaster recovery exercise of, \"What if AWS decided they didn't like us and nuked our account from orbit.\")reply"
    ],
    "link": "https://rameerez.com/send-this-article-to-your-friend-who-still-thinks-the-cloud-is-a-good-idea/",
    "first_paragraph": ""
  },
  {
    "title": "Singing bus horns in West Sumatra (auralarchipelago.com)",
    "points": 48,
    "submitter": "Kaibeezy",
    "submit_time": "2025-10-24T07:54:17 1761292457",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=45692042",
    "comments": [
      "The modern evolution of this lives long on the bus around Indonesia, in the form of telolet.https://en.wikipedia.org/wiki/Om_Telolet_Omreply",
      "Sing me a song, Mr. Kalason man. Sing me a song on a bus.  We'll miss all of those pure-ish tone melodies. Driving your competitors nuts.That was an interesting read. There is a movie called RV, and in that movie there is an RV with a kalason type select-a-melody horn installed.  I'm glad we don't have these distractions in our vehicles, but they would surely be a fun diversion while stuck in traffic.  Can you imagine the cacophony of a congested California freeway, with each vehicle belting out their own melodies on their own kalason?  I can.  No thank you.  But, to dream...reply",
      "was disappointed there was no bus. and he only knows one song and it's really long.reply"
    ],
    "link": "https://www.auralarchipelago.com/auralarchipelago/kalason",
    "first_paragraph": "field recordings from around IndonesiaSound: Kalason oto (often simply \u201ckalason\u201d)Location: Alahan Panjang, Kab. Solok, West SumatraThis post is dedicated to Pak Budahar - a real Minang musical legend who literally spread music across Sumatra, providing sweet solace to his passengers for decades. Next time you honk your horn, I hope you think of him. +++What was the last time you honked your car horn? If it wasn\u2019t a precautionary toot, it was surely out of frustration, if not outright anger. The honk is a scream from within our sealed-in vehicles - \u201cTake heed! There\u2019s a human in here!\u201d But have you ever honked with tenderness, with love, with longing? The tukang kalason of West Sumatra have.\u00a0\u00a0The Minangkabau people of this region are famous for their tradition of marantau, immigrating far and wide in search of a better life (often opening nasi Padang spots wherever they go!) Back in the 1950s, buses journeyed overland carrying migrants from West Sumatra to ports across this massive isla"
  },
  {
    "title": "RISC-V takes first step toward international ISO/IEC standardization (riscv.org)",
    "points": 6,
    "submitter": "jrepinc",
    "submit_time": "2025-10-30T13:30:37 1761831037",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://riscv.org/blog/risc-v-jtc1-pas-submitter/",
    "first_paragraph": "Thank You For Attending RISC-V Summit North America! | Presentations Will Be Available On-demand Shortly | Watch This Space\n\n                                Andrea Gallo                                \n\nAndrea Gallo is CEO of RISC-V International, having joined as Vice President of Technology. Previously, he spent over a decade at Linaro leading datacenter, cloud, mobile, and IoT initiatives, following a fellowship at STMicroelectronics.\nAndrea Gallo is CEO of RISC-V International, having joined as Vice President of Technology. Previously, he spent over a decade at Linaro leading datacenter, cloud, mobile, and IoT initiatives, following a fellowship at STMicroelectronics.RISC-V is an industry standard, like USB or Wi-Fi. The specifications are publicly available under the Creative Commons license and every engineer, wherever they are in the world, can use them to design their products locally, while engaging with the global RISC-V ecosystem.This standard is defined by RISC-V Internatio"
  },
  {
    "title": "Bluetui \u2013 A TUI for managing Bluetooth on Linux (github.com/pythops)",
    "points": 16,
    "submitter": "birdculture",
    "submit_time": "2025-11-04T23:29:31 1762298971",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/pythops/bluetui",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        \ud83d\udedc TUI for managing bluetooth on Linux\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A Linux based OS with bluez installed.NoteYou might need to install nerdfonts for the icons to be displayed correctly.You can download the pre-built binaries from the release page release pageYou can install bluetui from crates.ioYou can install bluetui from the extra repository:You can install bluetui from the lamdness Gentoo Overlay:If you are a user of x-cmd, you can run:Run the following command:This will produce an executable file at target/release/bluetui that you can copy to a directory in your $PATH.Tab: Switch between different sections.j or Down : "
  },
  {
    "title": "Launch HN: Plexe (YC X25) \u2013 Build production-grade ML models from prompts (plexe.ai)",
    "points": 65,
    "submitter": "vaibhavdubey97",
    "submit_time": "2025-11-04T17:07:47 1762276067",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=45813310",
    "comments": [
      "Sounds interesting! I'm trying to train a model but it's still \"processing\" after a bit but fine-tuning takes a while I get it. I'm having trouble understanding how it's inferring schema. I used a sample dataset and yet the sample inference curl uses a blank json?curl -X POST \"XXX/infer\" \\\n-H \"Content-Type: application/json\" \\\n-H \"x-api-key: YOUR_API_KEY\" \\\n-d '{}'How do I know what the inputs/outputs are for one of my models? I see I could have set the response variable manually before training but I was hoping the auto-infer would work.Separately it'd be ideal if when I ask for models that you seem to not be able to train (I asked for an embedding model as a test) the platform would tell me it couldn't do that instead of making me choose a dataset that isn't anything to do with what I asked for.All in all, super cool space, I can't wait to see more!I'm a former YC founder turned investor living in Dogpatch. I'd love to chat more if you're down!reply",
      "Thanks for the great feedback! To your points:1. Depending on your dataset the training could take from 45 mins to a few hours. We do need add an ETA on the build in the UI.2. The input schema is inferred towards the end of the model building process, not right at the start. This is because the final schema depends on the decisions made regarding input features, model architecture etc during the building process. You should see the sample curl update soon, with actual input fields.3. Great point about upfront rejecting builds for types of models we don't yet support. We'll be sure to add this soon!We're in London at the moment, but we'd love to connect with you and/or meet in person next time we're in SF - drop us a note on LinkedIn or something :)reply",
      "Thanks for the great feedback! We've added a `baseline_deployed` status where the agents create an initial baseline and deploy it so you have something to play around with quickly. This is why you're seeing a blank json there. Once your final model is deployed, it creates an input and output schema from the features used for the model build :)reply",
      "The tool gave me advice and code to do what I asked... but when I used the \"export analysis\" it did NOT include the code.  It was simply an overview.It would be more useful for the export to have an option (or by default) to include everything from the session.reply",
      "Thanks for your feedback! The \"export analysis\" functionality is built to enable you to get detailed data insights and get a report generated from the insights. Would you prefer to see the entire chat in your export or would it be helpful for it to simply include code snippets in the same format you received right now?reply",
      "A way to select all (or by Q/A paragraph) for export (e.g. to pdf or how about a .ipynb) would probably be the most useful.  Perhaps as just a plain \"export\" option in addition to an analysis/insights summary.p.s. kudos on the promo code that enable folks to kick the tires with as little friction as possible.reply",
      "Makes sense! We'll be sure to make this available very soon :) Thank you!reply",
      "Amazing! Great work. Congratulations on launch.Few questions:\n1. Can it work with tabular data, images, text and audio?\n2. Data preprocessing code is deployed with the model?\n3. Have you tested use cases when ML model was not needed? For example, you can simply go with average. I'm curious if agent can propose not to use ML in such case.\n4. Do you have agent for model interpretation?\n5. Are you using generic LLM or have your own LLM tuned on ML tasks?reply",
      "Thanks! Great set of questions:1. Tabular data only, for now. Text/images also work if they're in a table, but unfortunately not unstructured text or folders of loose image files. Full support for images, video, audio etc coming sometime in the near future.2. Input pre-processing is deployed in the model endpoint to ensure feature engineering is applied consistently across training and inference. Once a model is built, you can see the inference code in the UI and you'll notice the pre-processing code mirrors the feature engineering code. If you meant something like deploying scheduled batch jobs for feature processing, we don't support that yet, but it's in our plans!3. The agent isn't explicitly instructed to \"push back\" on using ML, but it is instructed to develop a predictor that is as simple and lightweight as possible, including simple baseline heuristics (average, most popular class, etc). Whatever performs best on the test set is selected as the final predictor, and this could just be the baseline heuristic, if none of the models outperform it. I like the idea of explicitly pushing back on developing a model if the use case clearly doesn't call for it!4. Yes, we have a model evaluator agent that runs an extensive battery of tests on the final model to understand things like robustness to missing data, feature importance, biases, etc. You can find all the info in the \"Evaluations\" tab of a built model. I'm guessing this is close to what you meant by \"model interpretation\"?5. A mix of generic and fine-tuned, and we're actively experimenting with the best models to power each of the agents in the workflow. Unsurprisingly, our experience has been that Anthropic's models (Sonnet 4.5 and Haiku 4.5) are best at the \"coding-heavy\" tasks like writing a model's training code, while OpenAI's models seem to work better at more \"analytical\" tasks like reviewing results for logical correctness and writing concise data analysis scripts. Fine-tuning for our specific tasks is, however, an important part of our implementation strategy.Hope this covers all your questions!reply",
      "Thanks a lot! On a side note: big fan of mljar here. When we were initially playing around with using agents for automating ML tasks, we had used problems from the openml's automl benchmark which you had posted about on Reddit for our initial testsreply"
    ],
    "link": "https://www.plexe.ai/",
    "first_paragraph": "Backed byAI Data ScientistAI Data ScientistAI Data Scientist Your Agentic ML Engineering Team  Turn your data into engineered AI solutions.Turn your data into engineered AI solutions.Turn your data into engineered AI solutions.Turn your raw data into engineered AI solutions.Try NowTry NowTry NowTry NowBook a DemoBook a DemoBook a DemoBook a DemoCustom ML ModelsData DashboardsAPI EndpointsBatch JobsFile UploadDatabase ConnectorsCustom ML ModelsData DashboardsAPI EndpointsBatch JobsFile UploadDatabase ConnectorsCustom ML ModelsData DashboardsAPI EndpointsBatch JobsFile UploadDatabase ConnectorsCustom ML ModelsData DashboardsAPI EndpointsBatch JobsFile UploadDatabase ConnectorsHow It WorksFrom Prompt to Production: The Plexe WorkflowGet Instant, Actionable Data InsightsSimply connect your data, Plexe checks quality, and spots the patterns that matter most.Create ModelBuild a custom AI model for your specific needs in a few simple stepsGive me quick insights on ecommerce fraud datasetQuick"
  },
  {
    "title": "Frozen String Literals: Past, Present, Future? (byroot.github.io)",
    "points": 23,
    "submitter": "Bogdanp",
    "submit_time": "2025-10-28T15:08:31 1761664111",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://byroot.github.io/ruby/performance/2025/10/28/string-literals.html",
    "first_paragraph": "\nOct 28, 2025\n      If you are a Rubyist, you\u2019ve likely been writing # frozen_string_literal: true at the top of most of your Ruby\nsource code files, or at the very least, that you\u2019ve seen it in some other projects.Based on informal discussions at conferences and online, it seems that what this magic comment really is about is not always well understood,\nso I figured it would be worth talking about why it\u2019s there, what it does exactly, and what its future might look like.Before we can delve into what makes frozen string literals special, we first need to talk about the Ruby String type,\nbecause it\u2019s quite different from the equivalent type in other popular languages.In the overwhelming majority of popular languages, strings are immutable.\nThat\u2019s the case in Java, JavaScript, Python, PHP, Go, etc.There are a few exceptions, though, like Perl, C++, and of course Ruby:Implementation-wise, they\u2019re just an array of bytes, with an associated encoding to know how these bytes should be interpr"
  },
  {
    "title": "Singapore to cane scammers as billions lost in financial crimes (freemalaysiatoday.com)",
    "points": 37,
    "submitter": "raybb",
    "submit_time": "2025-11-04T20:02:51 1762286571",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=45815279",
    "comments": [
      "I've been in banking for quite some time of my life and hands down, there is no country in the world that makes bankers with let's say questionable skills in risk assessment and decision making more afraid. Millions in fines, maybe more? Zero fucks given. Messing with regulators in Singapore? Not worth it. Wouldn't be surprised if they send or have sent people out to tell the somewhat gory stories of the canings in Singapore.Personally, I don't believe in preventive effects of draconian punishment, but I also don't believe in cokeheads. Being a cokehead in Singapore means risking facing the mandatory death sentence for posession of more than 30g of cocaine, which depending on the habit is a months supply max for some.reply",
      "Singapore is an odd country. The only country, to my knowledge, that had independence thrust upon it without its consent. Extremely prosperous compared to its neighbors. An autocratic, single party state where the government is so popular that they need to rig their elections against themselves to get dissenting voices. One of the most militarized countries (#3 by military spending per capita) in the world, yet their military has barely been used.What would you even call their socioeconomic system? They're not exactly doing neoliberal capitalism, their government is far too involved for that. They're not socialist, they've got free enterprise galore. The autocracy+militarization+heavily meddled with big business thing most resembles fascist states, but without the typical racist scapegoating (on the contrary, they've put a frankly inordinate amount of effort into preventing racial infighting).In most countries \"The country also passed a new law earlier this year that would allow the police to control the bank accounts of individuals who they suspect to be scam targets and limit what transactions they can do.\" would probably set off alarm bells, but it does seem like business as usual in Singapore.reply",
      "> What would you even call their socioeconomic system?Pragmatism-maxxing.> Lee was a stern advocate of pragmatism, stating that he was not \"enamoured with ideology\" but instead with what works. For Lee \"the ultimate test of the value of a political system\" was \"whether it helps that society to establish conditions which improve the standard of living for the majority of its people\". [0]Given what they started off as, and what resources they had available to them, they have succeeded.[0] https://en.wikipedia.org/wiki/Political_positions_of_Lee_Kua...reply",
      "If you haven't, go read \"The Singapore Story\" https://annas-archive.org/md5/6578558e0416e264a39da0448003ec... If you're bored, skip to the Japanese invasion Chapter and then read on. Many unique things happened in Singapore to make Singapore, Singapore.reply",
      ">that they need to rig their elections against themselves to get dissenting voicesI don't believe this is true. If you're talking about Non-Constituency Members of Parliament, they are consolation prizes given to best losers, and there are many things they cannot vote on. Moreover, the ruling party almost never lifts the party whip, i.e. members of the party CANNOT vote against the party line (without being kicked out of the party, which results in them being kicked out of parliament). In other words, since the ruling party already has a majority, any opposing votes literally do not matter.If you aren't talking about the NCMP scheme, then I do not know what you're talking about, as the ruling party does institute policies that are beneficial for the incumbent party.reply",
      "I\u2019ve never been there but whenever I read something about it I get the vibe that they\u2019re an HOA with a military.reply",
      "Their social system is familiar to anyone with an Asian familyreply",
      "> Singapore is an odd countryThe reason you find it odd is because you really can't find another country that the citizen have such a high trust towards the government and let the government do (almost) anything they wanted, yet the government doesn't abuse this power (mostly, at least) and continue focus on long term benefits of the country (rather than short term gains because the political party need to survive the next election in few years time)> One of the most militarized countries (#3 by military spending per capita) in the world, yet their military has barely been used.Ther reason is quite simple: Singapore is a very small country and it is very easily to be invaded. The high military spending is more of a deterent.> What would you even call their socioeconomic system?It is very much a free market capitalism with some state intervention, similar to many other countries. If anything, I would say Singapore is more free market than many western countries due to the fact that the government is very pro-business as the country is heavily rely on foreign businesses to survive.reply",
      "What would you even call their socioeconomic system?Pure authoritarianism.reply",
      "It could really just be the money.reply"
    ],
    "link": "https://www.freemalaysiatoday.com/category/highlight/2025/11/04/singapore-to-cane-scammers-as-billions-lost-in-financial-crimes",
    "first_paragraph": ""
  },
  {
    "title": "What is a manifold? (quantamagazine.org)",
    "points": 330,
    "submitter": "isaacfrond",
    "submit_time": "2025-11-04T09:58:14 1762250294",
    "num_comments": 117,
    "comments_url": "https://news.ycombinator.com/item?id=45809193",
    "comments": [
      "I first learned about manifolds through Introduction to Smooth Manifolds by John M. Lee. The book is dense but beautifully structured, guiding you from basic topology to smooth maps and tangent spaces with clear logic. It demands focus, yet every definition builds toward a deeper picture of how geometry works beneath the surface. Highly recommended.reply",
      "It's truly the best book on Smooth Manifolds, though if you'd like a gentler approach which is still useful, then I suggest Loring Tu's books. Lee's Topological Manifolds book is also very nice. His newest edition of the Riemannian manifolds book requires selective reading or it'll slow you down.reply",
      "What's the relation between the different Lee manifolds? Is it a sequence you're supposed to read in order?reply",
      "Lee taught Intro to Topological Manifolds for one quarter, and then the next two quarters where Intro to Smooth Manifolds. Then Riemannian, then vector bundles, and then complex manifolds.reply",
      "That's a great suggestion. I actually started with Topological Manifolds before moving on to Introduction to Smooth Manifolds and it really helped build a solid foundation.I havent read Loring Tus books before but let me look at them since I have been wanting to revisit the topic with a clearer and more relaxed approach.reply",
      "Tbh, I never quite understood the appeal of John M. Lee's book. It's not bad but I didn't find it great, either, especially (IIRC) in terms of rigor. Meanwhile, the much less well-known \"Manifolds and Differential Geometry\" by Jeffrey M. Lee (yeah, almost the same name) was much better.reply",
      "This is a very informative article about the history of manifolds and their significance. Don\u2019t let the title fool you into this being just a definition.It\u2019s actually much more well written than the majority or articles we usually come across.reply",
      "And they have a RSS feed, although it's a bit tricky to figure out, since the relevant header tag for that is set up incorrectly, pointing to a useless empty \"comments\" feed even from their main page. The actual feed for articles is https://www.quantamagazine.org/feed/reply",
      "Nice find, thank you. Your sleuthing is appreciated.reply",
      "Oh dope. Added to my feedbin!reply"
    ],
    "link": "https://www.quantamagazine.org/what-is-a-manifold-20251103/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesNovember 3, 2025Mark Belan/Quanta MagazineScience Writing FellowNovember 3, 2025Standing in the middle of a field, we can easily forget that we live on a round planet. We\u2019re so small in comparison to the Earth that from our point of view, it looks flat.The world is full of such shapes \u2014 ones that look flat to an ant living on them, even though they might have a more complicated global structure. Mathematicians call these shapes manifolds. Introduced by Bernhard Riemann in the mid-19th century, manifolds transformed how mathematicians think about space. It was no longer just a physical setting for other mathematical objects, but rather an abstract, well-defined object worth studying in its o"
  },
  {
    "title": "NoLongerEvil-Thermostat \u2013 Nest Generation 1 and 2 Firmware (github.com/codykociemba)",
    "points": 307,
    "submitter": "mukti",
    "submit_time": "2025-11-04T17:10:35 1762276235",
    "num_comments": 106,
    "comments_url": "https://news.ycombinator.com/item?id=45813343",
    "comments": [
      "If your boiler supports OpenTherm then get this thermostat controller https://github.com/Alexwijn/SATWeather comp + low load comp + PID which means your room temperature works at the precision range supported by your temperature sensor. In my case, within 0.02 Celsius. Saves energy and makes your house more comfortable. Operated via home assistant.See real time data in Grafanahttps://gasboiler.grafana.net/public-dashboards/8d44381aafa9...Or Emoncmshttps://emoncms.org/app/view?name=MyBoilerIdealLogicH24Opent...reply",
      "I'm very interested in this\u2014 I have a fairly new Vitodens 100 boiler + Ecobee and also a heat pump system with its own thermostat, and I'm frustrated by several elements of this setup:- The Vitodens has like ten stages, but the Ecobee has no way to command them, it's just a binary call to the Taco pump for heat / no heat, with the boiler deciding on its own how hard to push (I guess based on the outside air sensor and maybe time of day?)- The Vitodens is monitoring the return boiler water temperature, but the Ecobee doesn't know anything about that.- None of this is interlinked with the heat pump, so the systems can run on top of each other and end up with the wrong parts of the house overheated or left cold. The heat pump's controller is proprietary but it works with the NetHome Plus app so there is a bridge to get the units on homeassistant.I don't have the spoons right now to try to beat this all into shape, but eventually I'd like to get HA temp monitors in multiple places in the house so that a single central system can make smarter decisions about which system to run and when. For example, in the evening I mostly care about the bedrooms, and the bedrooms are covered by zone 2 of the heat pump, so it would make sense to prioritize the heat pump then and only run the boiler if the heat pump isn't able to keep up; whereas in the daytime if heat is needed, it's probably throughout the house so the boiler should run.reply",
      "Stuff this project tackles is on my \"I'll get to it after I retire\" list - super awesome. Looks like this works for forced air HVAC as well?reply",
      "In theory but the odds of you having an HVAC control board that supports OpenTherm are extremely low.reply",
      "There's also ems-esp which I use on an older Worcester Bosch boiler to set flow temperatures based on the outside temperature (managed by home assistant).reply",
      "Any good multi zone ones for home assistant?reply",
      ">Do NOT use this firmware on any thermostat that is critical for your heating or cooling needs.Also, carefully consider its use with propane or natural gas HVAC units. Many can reach dangerous temperatures very quickly. Many years ago we had a thermostat failure that caused our HVAC to not shut off. While it had an over-heat cut-out, it was for temps above 200F. Because the unit had an oversized blower, it caused our home to reach dangerous temps as we slept, including our kids room which was a good 20F hotter than our bedroom. Luckily we woke up and the kids were okay.reply",
      "That's just a disclaimer. The same could be said of the original ;-)No \"smart\" thermostats for me --- I have a round Honeywell that's been working perfectly for several decades.reply",
      "I'm a little confused, because this looks like you're just swapping one proprietary service (Google) for another (NoLongerEvil).Despite their name, we have no idea if NoLongerEvil is evil or not.  Why should I trust them?  I don't know them at all.  Why will they be immune to the regular economic pressures surrounding any connected online service?  What will stop them from adding tracking or other anti-features?  Even if they are a bunch of saints, what will stop them from selling the service to a company that will not respect my privacy?Google is at least the devil we know, here.I was expecting a fully open source firmware, with a fully open source backend service that people can host themselves if they so choose.(I guess they didn't write their own firmware; they hacked Google's firmware so it redirects traffic from Google's servers to their own.  So I guess in this model, I'd want to see an open source, self-hostable backend service, and a \"build\" process for the hacked firmware to set the API URL to the self-hosted backend.)Edit: looks like they plan to open source the backend and enable self-hosting \"soon\".  Hopefully that comes to pass!reply",
      "> Google is at least the devil we know, here.Google has left these devices essentially completely unusable. You're not trading up Google because Google already abandoned these devices by shutting off the lights. Even if you don't agree with how robust their service is, they're offering you the ability to turn what's effectively e-waste into an operable device.reply"
    ],
    "link": "https://github.com/codykociemba/NoLongerEvil-Thermostat",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Breathe fresh life into your bricked Nest Gen 1 & 2, now with 100% less evil!\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\u26a0\ufe0f WARNING: EXPERIMENTAL SOFTWAREThis project is currently in the experimental/testing phase. Do NOT use this firmware on any thermostat that is critical for your heating or cooling needs. Flashing this firmware may brick your device or cause unexpected behavior. Only proceed if you have a backup thermostat or can afford to have your device non-functional during testing.This directory contains the tools and firmware needed to flash custom firmware to Nest Thermostat devices using the OMAP DFU (Device Firmware Update) interface.This firmware loader uses the OMAP bootloader interface to flash custom bootloader and kernel images to Nest "
  }
]