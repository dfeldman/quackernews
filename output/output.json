[
  {
    "title": "Netflix to Acquire Warner Bros (netflix.com)",
    "points": 1431,
    "submitter": "meetpateltech",
    "submit_time": "2025-12-05T12:21:19 1764937279",
    "num_comments": 1130,
    "comments_url": "https://news.ycombinator.com/item?id=46160315",
    "comments": [
      "Any consolidation like this seems like a negative for consumers. But at least it wasn\u2019t bought by Larry Ellison, as was considered very likely (assuming this merger gets approved, in the current administration you never know).From a Hacker News perspective, I wonder what this means for engineers working on HBO Max. Netflix says they\u2019re keeping the company separate but surely you\u2019d be looking to move them to Netflix backend infrastructure at the very least.reply",
      "> Any consolidation like this seems like a negative for consumersThis is a very common narrative to this news. But coming into this news, I think the most common narrative against streaming was essentially \"There is not enough consolidation.\" People were happy when Netflix was the streaming service, but then everyone pulled their content and have their own (Disney, Paramount, etc.)reply",
      "I want a separation between the streaming platform companies and the content making companies, so that the streaming companies can compete on making a better platform/service and the content companies compete on making better content.I don't want one company that owns everything, I want several companies that are able to license whatever content they want. And ideally the customer can choose between a subscription that includes everything, and paying for content a la carte, or maybe subscriptions that focus on specific kinds of content (scifi/fantasy, stuff for kids, old movies, international, sports, etc.) regardless of what company made it.reply",
      "This is how it worked a decade+ ago, when there was still alpha to be had on providing better streaming service. It was great and we got things like the Netflix Prize and all sorts of content ranking improvements, better CDN platforms, lower latency and less buffering, more content upgraded to HD and 4K. Plus some annoying but clearly effective practices like auto-play of trailers and unrelated shows.Now these are all solved problems, so there is no benefit in trying to compete on making a better platform / service. The only thing left is competing on content.> I want several companies that are able to license whatever content they want. And ideally the customer can choose between a subscription that includes everything, and paying for content a la carte, or maybe subscriptions that focus on specific kinds of contentThis seems like splitting hairs, it's almost exactly what we do have. You can still buy and rent individual shows & movies from Apple and Amazon and other providers. Or you can subscribe to services. The only difference is there is no one big \"subscription that includes everything\", you need 10 different $15 subscriptions to get everything. Again, kind of splitting hairs though. The one big subscription would probably be the same price as everything combined anyway.reply",
      "It is worth noting that the Netflix Prize winner's solution was never meaningfully used, because Netflix pivoted from ranking content based on what you tell them you like to ranking content based on clicks and minutes watched.To say that \"we have solved ranking\" because Netflix decided to measure shallow metrics and addiction is... specious at best. Instead the tech industry (in all media domains, not just streaming video) replaced improving platforms and services in meaningful ways with surveillance and revenue extraction.reply",
      "> ranking content based on clicks and minutes watched.I suspect they just push what they want you to watch, like their own content. Seems that way to me at least, based on their quite shitty \"recommendations\"reply",
      "Why do they care what you watch? I expect they pay a flat fee to license content (if not, how is that policed?) so the marginal cost to them is the same no matter what you watch.I'd guess they push you to their content for the same reason they make that content in the first place: they believe you'll like it and keep watching it.Ad placement is one wrinkle that would incentivize promoting their own content, but I don't get the impression that's big enough to make the difference at the margins.reply",
      "I think they also used their metrics to figure out people liked kevin spacey (whoops) - and created house of cards - which catapulted netflix's production side.https://medium.com/@danial.a/how-netflix-used-data-to-create...reply",
      "> there is no one big \"subscription that includes everything\"You're right, but the switching cost is super easy, and _most_ of the time, these networks aren't putting out new content that I care that much about, so I've found it easiest to just swap services, keeping one subscription active at a time, and then switching again when I've finished watching everything interesting on the next.reply",
      "Exactly. Nothing is really preventing a $200/month aggregator beyond paying a bunch of lawyers and people not wanting to pay that. I know I'll live with some service fragmentation in exchange for not paying for a bunch of stuff I'll maybe watch once in a blue moon. And I'll probably buy some discs for things I really want to see.reply"
    ],
    "link": "https://about.netflix.com/en/news/netflix-to-acquire-warner-bros",
    "first_paragraph": ""
  },
  {
    "title": "Cloudflare outage on December 5, 2025 (cloudflare.com)",
    "points": 545,
    "submitter": "meetpateltech",
    "submit_time": "2025-12-05T15:35:43 1764948943",
    "num_comments": 409,
    "comments_url": "https://news.ycombinator.com/item?id=46162656",
    "comments": [
      "This is architectural problem, the LUA bug, the longer global outage last week, a long list of earlier such outages only uncover the problem with architecture underneath. The original, distributed, decentralized web architecture with heterogeneous endpoints managed by myriad of organisations is much more resistant to this kind of global outages. Homogeneous systems like Cloudflare will continue to cause global outages. Rust won't help, people will always make mistakes, also in Rust. Robust architecture addresses this by not allowing a single mistake to bring down myriad of unrelated services at once.reply",
      "> Homogeneous systems like Cloudflare will continue to cause global outagesBut the distributed system is vulnerable to DDOS.Is there an architectural solution that maintains the advantages of both systems?reply",
      "I\u2019m not sure I share this sentiment.First, let\u2019s set aside the separate question of whether monopolies are bad. They are not good but that\u2019s not the issue here.As to architecture:Cloudflare has had some outages recently. However, what\u2019s their uptime over the longer term? If an individual site took on the infra challenges themselves, would they achieve better? I don\u2019t think so.But there\u2019s a more interesting argument in favour of the status quo.Assuming cloudflare\u2019s uptime is above average, outages affecting everything at once is actually better for the average internet user.It might not be intuitive but think about it.How many Internet services does someone depend on to accomplish something such as their work over a given hour? Maybe 10 directly, and another 100 indirectly? (Make up your own answer, but it\u2019s probably quite a few).If everything goes offline for one hour per year at the same time, then a person is blocked and unproductive for an hour per year.On the other hand, if each service experiences the same hour per year of downtime but at different times, then the person is likely to be blocked for closer to 100 hours per year.It\u2019s not really bad end user experience that every service uses cloudflare. It\u2019s more-so a question of why is cloudflare\u2019s stability seeming to go downhill?And that\u2019s a fair question. Because if their reliability is below average, then the value prop evaporates.reply",
      "> Cloudflare has had some outages recently. However, what\u2019s their uptime over the longer term? If an individual site took on the infra challenges themselves, would they achieve better? I don\u2019t think so.Why is that the only option? Cloudflare could offer solutions that let people run their software themselves, after paying some license fee. Or there could be many companies people use instead, instead of everyone flocking to one because of cargoculting \"You need a CDN like Cloudflare before you launch your startup bro\".reply",
      "All of my company's hosted web sites have way better uptimes and availability than CF but we are utterly tiny in comparison.With only some mild blushing, you could describe us as \"artisanal\" compared to the industrial monstrosities, such as Cloudflare.Time and time again we get these sorts of issues with the massive cloudy chonks and they are largely due to the sort of tribalism that used to be enshrined in the phrase: \"no one ever got fired for buying IBM\".We see the dash to the cloud and the shoddy state of in house corporate IT as a result.  \"We don't need in-house knowledge, we have \"MS copilot 365 office thing\" that looks after itself and now its intelligent - yay \\o/Until I can't, I'm keeping it as artisanal as I can for me and my customers.reply",
      "In other words, the consolidation on Cloudflare and AWS makes the web less stable. I agree.reply",
      "Usually I am allergic to pithy, vaguely dogmatic summaries like this but you're right. We have traded \"some sites are down some of the time\" for \"most sites are down some of the time\". Sure the \"some\" is eliding an order of magnitude or two, but this framing remains directionally correct.reply",
      "Does relying on larger players result in better overall uptime for smaller players? AWS is providing me better uptime than if I assembled something myself because I am less resourced and less talented than that massive team.If so, is it a good or bad trade to have more overall uptime but when things go down it all goes down together?reply",
      "From a societal view it is worse when everything is down at once. Leads to a less resilient society: It is not great if I can't buy essentials from one store because their payment system is down (this happened to one super market chain in Sweden due to a hacker attack some years ago, took weeks to fully fix everything, and then there was that whole Crowdstrike debacle globally more recently).It is far worse if all of the competitors are down at once. To some extent you can and should have a little bit of stock at home (water, food, medicine, ways to stay warm, etc) but not everything is practical to do so with (gasoline for example, which could have knock on effects on delivery of other goods).reply",
      "When only one thing goes down, it's easier to compensate with something else, even for people who are doing critical work but who can't fix IT problems themselves. It means there are ways the non-technical workforce can figure out to keep working, even if the organization doesn't have on-site IT.Also, if you need to switchover to backup systems for everything at once, then either the backup has to be the same for everything and very easily implementable remotely - which to me seems unlikely for specialty systems, like hospital systems, or for the old tech that so many organizations still rely on (and remember the CrowdStrike BSODs that had to be fixed individually and in person and so took forever to fix?) - or you're gonna need a LOT of well-trained IT people, paid to be on standby constantly, if you want to fix the problems quickly, on account of they can't be everywhere at once.If the problems are more spread out over time, then you don't need to have quite so many IT people constantly on standby. Saves a lot of $$$, I'd think.And if problems are smaller and more spread out over time, then an organization can learn how to deal with them regularly, as opposed to potentially beginning to feel and behave as though the problem will never actually happen. And if they DO fuck up their preparedness/response, the consequences are likely less severe.reply"
    ],
    "link": "https://blog.cloudflare.com/5-december-2025-outage/",
    "first_paragraph": ""
  },
  {
    "title": "Adenosine on the common path of rapid antidepressant action: The coffee paradox (kglmeridian.com)",
    "points": 55,
    "submitter": "PaulHoule",
    "submit_time": "2025-12-05T22:10:50 1764972650",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=46168057",
    "comments": [
      "On chronic coffee consumption: \"One meta-analysis found that RR coffee 0.757, RR caffeine 0.721 (12). Another one found RR 0.76, with an optimal protective effect at \u223c400 mL/day (13). In comparison to many drug treatments that have an effect size in this range, this is not a small effect size. A risk reduction of 20 to 25% is quite impressive.\"As if I needed another reason to drink coffee.reply",
      "One thing I've learned over the years is that specifically setting out to enjoy and appreciate something on a daily basis is beneficial to overall satisfaction with life.  And for me, that's my morning cuppa before the rest of the house wakes up.  Is it (just) the coffee or is it (also) the rituals surrounding coffee?reply",
      "I've always associated this sort of life satisfaction & ritual spectrum with Zen \"no-mind\" [^1]Whether it's coffee ritual, or doing dishes there's something pretty magical about the quiet flow state of engaging with the moment[^1]: https://en.wikipedia.org/wiki/No-mindreply",
      "It\u2019s 100% the addiction.It\u2019s ok, me too. At home I\u2019m a 4-6 cup a day drinker. On the go 2-3 Starbucks. I have a serious problem.reply",
      "People act like addiction is a word with an inherent negative connotation, but that's not the case, you can totally be addicted to healthy behavioursreply",
      "That was me too. Turns out I was just self-medicating for adhd. I still skip the meds on the weekend so I can enjoy larger quantities of coffee.reply",
      "I'm not gonna lie, double espresso with ritalin before work is pretty good too. It's the T+2 date which is uncool.reply",
      "Well, that's a bit of an unfair projection; I'm fairly fastidious about keeping my consumption around 2-3 cups a day before 11am and taking occasional tolerance breaks without consequence.  But if you feel like your coffee intake is a problem that you have trouble controlling, maybe cut back.reply",
      "I also enjoy my morning ritual of preparing the grinds and brewing a fresh pot. But I'll be honest, at the end of the day it doesn't really matter where I get it -- brunch at a nice restaurant, Starbucks, McDonalds, a cheap hotel buffet, lukewarm from a flight attendant ... as long as I get it. Sounds healthy, right?! ;)reply",
      "The problem is, most Americans don't drink coffee, they drink sugary mix with coffee flavorreply"
    ],
    "link": "https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/article-10.61373-bm025c.0134.xml",
    "first_paragraph": "Yue, Luo, and colleagues discovered that adenosine signalling is the common underlying mechanism of rapid acting antidepressant therapies, unifying the effects of ketamine, ECT and acute intermittent hypoxia. They use genetically encoded sensors, along with extensive mechanistic dissection, to show that all three induce adenosine surges in mood-regulatory circuits via A1 and A2A receptor activation. The mechanism of action of ketamine primarily involves modulation of mitochondrial metabolism as opposed to NMDA receptor antagonism, thereby presenting the possibility for improvements in derivative products with better therapeutic indices. These outcomes offers a rational framework for gauging therapeutic benefit for depression and raise vexing questions about patterns of caffeine consumption in treatment resistant depression, specifically whether the chronic use has a protective effect or whether the acute use impedes treatment response.As Claude Bernard understood in laying the foundati"
  },
  {
    "title": "Sam Altman's Dirty DRAM Deal (mooreslawisdead.com)",
    "points": 93,
    "submitter": "pabs3",
    "submit_time": "2025-12-06T00:24:55 1764980695",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=46169224",
    "comments": [
      "Moves like this should be illegal.It's becoming increasingly clear that OpenAI is going to get lapped by Google on technical merits. So this is the \"code red\" solution? Supply shenanigans?They are getting beat in the developer market by Anthropic. And getting beat on fundamental tech by Google. This is a company whose ostensible mission is to \"benefit all of humanity\" ...reply",
      "> Moves like this should be illegal.Should be, as in, new legislation should criminalize it?  What's the generalized principle?  Or should be, as in existing law should cover it? And if so, what law / how?reply",
      "Seems like it is, but the question is whether the current Justice Department will do anything about it.reply",
      "> Seems like it isDo you have a citation for what law is being violated? Or just vibes?reply",
      "Market manipulation is a crime under the Securities Exchange Act of 1934.  You can't buy things to influence the price or the market, only to use or resell.https://en.wikipedia.org/wiki/Market_manipulationreply",
      "The law you refer to applies only to markets for securities. RAM is very clearly not a security, it fails the Howey test.",
      "Do you think OpenAI plans to trade the semiconductor market? This would only apply in that scenario.reply",
      "No, they want DRAM to be expensive to give them a competitive advantage over their competitors.",
      "That'd probably make more sense if there wasn't also 50 other tech companies buying up RAM for the same reason (a sudden huge spike in demand due to AI taking off).reply",
      "They mean to resell them in a different form: as part of their PaaS or SaaS. Per the article, OpenAI is just hoarding the wafers, not purchasing the final product.reply"
    ],
    "link": "https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal",
    "first_paragraph": "HomeVideosPodcastsArticlesGPU ChartMerchandiseSupport Us!More...Written by Tom of Moore\u2019s Law Is DeadSpecial Assistance by KarbinCry & kari-no-sugataBased on this Video: https://youtu.be/BORRBce5TGwAt the beginning of November, I ordered a 32GB DDR5 kit for pairing with a Minisforum BD790i X3D motherboard, and three weeks later those very same sticks of DDR5 are now listed for a staggering $330\u2013 a 156% increase in price from less than a month ago! At this rate, it seems likely that by Christmas, that DDR5 kit alone could be worth more than the entire Zen 4 X3D platform I planned to pair it with! How could this happen, and more specifically \u2013 how could this happen THIS quickly? Well, buckle up! I am about to tell you the story of Sam Altman\u2019s Dirty DRAM Deal, or: How the AI bubble, panic, and unpreparedness stole Christmas...But before I dive in, let me make it clear that my RAM kit\u2019s 156% jump in price isn\u2019t a fluke or some extreme example of what's going on right now. Nope, and in fac"
  },
  {
    "title": "Gemini 3 Pro: the frontier of vision AI (blog.google)",
    "points": 332,
    "submitter": "xnx",
    "submit_time": "2025-12-05T16:15:10 1764951310",
    "num_comments": 171,
    "comments_url": "https://news.ycombinator.com/item?id=46163308",
    "comments": [
      "WellIt is the first model to get partial-credit on an LLM image test I have. Which is counting the legs of a dog. Specifically, a dog with 5 legs. This is a wild test, because LLMs get really pushy and insistent that the dog only has 4 legs.In fact GPT5 wrote an edge detection script to see where \"golden dog feet\" met \"bright green grass\" to prove to me that there were only 4 legs. The script found 5, and GPT-5 then said it was a bug, and adjusted the script sensitivity so it only located 4, lol.Anyway, Gemini 3, while still being unable to count the legs first try, did identify \"male anatomy\" (it's own words) also visible in the picture. The 5th leg was approximately where you could expect a well endowed dog to have a \"5th leg\".That aside though, I still wouldn't call it particularly impressive.As a note, Meta's image slicer correctly highlighted all 5 legs without a hitch. Maybe not quite a transformer, but interesting that it could properly interpret \"dog leg\" and ID them. Also the dog with many legs (I have a few of them) all had there extra legs added by nano-banana.reply",
      "I just tried to get Gemini to produce an image of a dog with 5 legs to test this out, and it really struggled with that. It either made a normal dog, or turned the tail into a weird appendage.Then I asked both Gemini and Grok to count the legs, both kept saying 4.Gemini just refused to consider it was actually wrong.Grok seemed to have an existential crisis when I told it it was wrong, becoming convinced that I had given it an elaborate riddle. After thinking for an additional 2.5 minutes, it concluded:\n\"Oh, I see now\u2014upon closer inspection, this is that famous optical illusion photo of a \"headless\" dog. It's actually a three-legged dog (due to an amputation), with its head turned all the way back to lick its side, which creates the bizarre perspective making it look decapitated at first glance. So, you're right; the dog has 3 legs.\"You're right, this is a good test. Right when I'm starting to feel LLMs are intelligent.reply",
      "An interesting test in this vein that I read about in a comment on here is generating a 13 hour clock\u2014I tried just about every prompting trick and clever strategy I could come up with across many image models with no success. I think there's so much training data of 12 hour clocks that just clobbers the instructions entirely. It'll make a regular clock that skips from 11 to 13, or a regular clock with a plaque saying \"13 hour clock\" underneath, but I haven't gotten an actual 13 hour clock yet.reply",
      "Right you are. It can do 26 hours just fine, but appears completely incapable when the layout would be too close to a normal clock.https://gemini.google.com/share/b3b68deaa6e6I thought giving it a setting would help, but just skip that first response to see what I mean.reply",
      "If you want to see something rather amusing - instead of using the LLM aspect of Gemini 3.0 Pro, feed a five-legged dog directly into Nano Banana Pro and give it an editing task that requires an intrinsic understanding of the unusual anatomy.  Place sneakers on all of its legs.\n\nIt'll get this correct a surprising number of times (tested with BFL Flux2 Pro, and NB Pro).https://imgur.com/a/wXQskhLreply",
      "I had no trouble getting it to generate an image of a five-legged dog first try, but I really was surprised at how badly it failed in telling me the number of legs when I asked it in a new context, showing it that image. It wrote a long defense of its reasoning and when pressed, made up demonstrably false excuses of why it might be getting the wrong answer while still maintaining the wrong answer.reply",
      "Yeah it gave me the 5-legged dog on the 4th or 5th try.reply",
      "Its not that they aren\u2019t intelligent its that they have been RL\u2019d like crazy to not do thatIts rather like as humans we are RL\u2019d like crazy to be grossed out if we view a picture of a handsome man and beautiful woman kissing (after we are told they are brother and sister) -Ie we all have trained biases - that we are told to follow and trained on - human art is about subverting those expectationsreply",
      "Why should I assume that a failure that looks like a model just doing fairly simple pattern matching \"this is dog, dogs don't have 5 legs, anything else is irrelevant\" vs more sophisticated feature counting of a concrete instance of an entity is RL vs just a prediction failure due to training data not containing a 5-legged dog and an inability to go outside-of-distribution?RL has been used extensively in other areas - such as coding - to improve model behavior on out-of-distribution stuff, so I'm somewhat skeptical of handwaving away a critique of a model's sophistication by saying here it's RL's fault that it isn't doing well out-of-distribution.If we don't start from a position of anthropomorphizing the model into a \"reasoning\" entity (and instead have our prior be \"it is a black box that has been extensively trained to try to mimic logical reasoning\") then the result seems to be \"here is a case where it can't mimic reasoning well\", which seems like a very realistic conclusion.reply",
      "I have the same problem, people are trying so badly to come up with reasoning for it when there's just nothing like that there. It was trained on it and it finds stuff it was trained to find, if you go out of the training it gets lost, we expect it to get lost.reply"
    ],
    "link": "https://blog.google/technology/developers/gemini-3-pro-vision/",
    "first_paragraph": "Dec 05, 2025\n          Gemini 3 Pro delivers state-of-the-art performance across document, spatial, screen and video understanding.\n        \nGemini 3 Pro is Google's most capable multimodal model that delivers state-of-the-art performance across document, spatial, screen and video understanding. You can use it for complex visual reasoning, document processing, and understanding spatial relationships. Check out the developer documentation or play with the model in Google AI Studio to get started.\nGemini 3 Pro is Google's most capable multimodal model that delivers state-of-the-art performance across document, spatial, screen and video understanding. You can use it for complex visual reasoning, document processing, and understanding spatial relationships. Check out the developer documentation or play with the model in Google AI Studio to get started.Your browser does not support the audio element.Gemini 3 Pro represents a generational leap from simple recognition to true visual and spati"
  },
  {
    "title": "Leaving Intel (brendangregg.com)",
    "points": 82,
    "submitter": "speckx",
    "submit_time": "2025-12-05T21:27:04 1764970024",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=46167552",
    "comments": [
      "Hats off to Brendan!reply",
      "Congratulations. A fulfilling life.reply",
      "I'm guessing he'll land at one of the big frontier model companies. I'm surprised he stayed at Intel as long as he did, they are dying fast.reply",
      "Intel losing great people at high speed. Not the first, not the last.reply",
      "In the photo of him on his last day [0], there's a cassette deck on his desk.That could be something mundane, but I'd like to believe something crazy happens if you yell at it [1]...[0] https://www.brendangregg.com/blog/images/2025/brendanoffice2...[1] https://www.youtube.com/watch?v=tDacjrSCeq4reply",
      "> cassette deck on his deskGreybeard reporting for duty: https://en.wikipedia.org/wiki/Commodore_Datasettereply",
      "Extra slash in the urlreply",
      "Terrible news from Intel, this guy seems like the best performance engineer on the planetreply",
      "Where do you think he's going next? OpenAI? Google? Just saving 1% on inference could probably justify his salary 100foldreply",
      "I\u2019m wonder how much longer Intel will be around. It seems to be dying a slow death like Kodak or IBM at this point.reply"
    ],
    "link": "https://www.brendangregg.com/blog//2025-12-05/leaving-intel.html",
    "first_paragraph": "Brendan's site:05 Dec 2025I've resigned from Intel and accepted a new opportunity. If you are an Intel employee, you might have seen my fairly long email that summarized what I did in my 3.5 years. Much of this is public:It's still early days for AI flame graphs. Right now when I browse CPU performance case studies on the Internet, I'll often see a CPU flame graph as part of the analysis. We're a long way from that kind of adoption for GPUs (and it doesn't help that our open source version is Intel only), but I think as GPU code becomes more complex, with more layers, the need for AI flame graphs will keep increasing.I also supported cloud computing, participating in 110 customer meetings, and created a company-wide strategy to win back the cloud with 33 specific recommendations, in collaboration with others across 6 organizations. It is some of my best work and features a visual map of interactions between all 19 relevant teams, described by Intel long-timers as the first time they ha"
  },
  {
    "title": "Perpetual Futures (bitsaboutmoney.com)",
    "points": 52,
    "submitter": "sirodoht",
    "submit_time": "2025-12-05T21:23:03 1764969783",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=46167500",
    "comments": [
      "It's striking how much the crypto world depends on trust in other parties. The whole point of crypto was supposed to be that it was \"trustless\". But it's not set up that way. All these crypto derivatives are not set up as contracts on a blockchain, with assets locked up until the derivatives settle. They're book entries with some weakly regulated exchange in Outer Nowhere.reply",
      "The people who want trustless decentralization and the people who want leveraged gambling and the people who want KYC-free international money transfer may be different people. The only problem with Liberty Reserve was that it got shut down; if a \"decentralied\" fig leaf can allow it to operate... let there be \"decentralization\".reply",
      "That's not true with decentralised exchanges like hyperliquid, no?reply",
      "Hyperliquid and similar exchanges aren't decentralized. That is their long term goal but they are very far from achieving it.The few actual decentralized exchanges are too slow and expensive.reply",
      "> HyperCore includes fully onchain perpetual futures and spot order books. Every order, cancel, trade, and liquidation happens transparently with one-block finality inherited from HyperBFT. HyperCore currently supports 200k orders / second, with throughput constantly improving as the node software is further optimized.Key part:> fully onchain perpetual futures and spot order booksreply",
      "I mean, as soon as synchronisation is required in any system, block chain, distributed SAAS, even Peer to Peer sharing, decentralisation fails hardThat's one of the sticking points I have with the /idea/ of the technologyreply",
      "This comment makes sweeping generalizations.reply",
      "This is a common place in any thread about cryptocurrencies on HN unfortunately... I could be convinced of my own message also being a sweeping generalization if anyone can point out a single post where top comments aren't doing exactly this when it comes to this topic, even the technical ones.reply",
      "By now crypto-in-practice has violated so many of its supposed founding principles that it's tired and cliche to point it out.It was supposed to be limited in supply unlike fiat, and yet Tether underpins the whole thing and they print that out of thin air all the time. It was supposed to be decentralized, but in practice a few big exchanges control all the transactions and a few big mining pools control all the minting. It was supposed to be \"code is law\", and yet if you find a big exploit on smart contracts it'll be unwound later on and the cops will still show up for you. And as you say, it was supposed to be trustless, but counterparty risk is everywhere.And it turns out nobody cares, because to a first approximation nobody is in crypto for the libertarian principles. It is all about number go up; always has been, always will be. It's not even worth pointing out anymore.reply",
      "> It was supposed to be limited in supply unlike fiat, and yet Tether underpins the whole thing and they print that out of thin air all the time.This is a joke right? Tether (USDT) is pegged to the dollar... and there is not really a limit to the USD printing machine, nobody ever claimed a stablecoin would have a limited supply. It's literally the main critique of the fiat system levied by crypto proponents.The only asset which has made and still hold promises of not increasing its supply over its limit set through its consensus code is Bitcoin. And it is nowhere close to ever change... as a matter of fact if it changed, most people wouldn't call that fork Bitcoin.reply"
    ],
    "link": "https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/",
    "first_paragraph": "Programming note: Bits about Money is supported by our readers. I generally forecast about one issue a month, and haven't kept that pace that this year. As a result, I'm working on about 3-4 for December.Much financial innovation is in the ultimate service of the real economy. Then, we have our friends in crypto, who occasionally do intellectually interesting things which do not have a locus in the real economy. One of those things is perpetual futures (hereafter, perps), which I find fascinating and worthy of study, the same way that a virologist just loves geeking out about furin cleavage sites.You may have read a lot about stablecoins recently. I may write about them (again; see past BAM issue) in the future, as there has in recent years been some uptake of them for payments. But it is useful to understand that a plurality of stablecoins collateralize perps. Some observers are occasionally strategic in whether they acknowledge this, but for payments use cases, it does not require a "
  },
  {
    "title": "Idempotency Keys for Exactly-Once Processing (morling.dev)",
    "points": 84,
    "submitter": "defly",
    "submit_time": "2025-12-01T12:07:33 1764590853",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=46106411",
    "comments": [
      "I like to use uuid5 for this. It produces unique keys in a given namespace (defined by a uuid) but also takes an input key and produces identical output ID for the same input key.This has a number of nice properties:1. You don\u2019t need to store keys in any special way. Just make them a unique column of your db and the db will detect duplicates for you (and you can provide logic to handle as required, eg ignoring if other input fields are the same, raising an error if a message has the same idempotent key but different fields).2. You can reliably generate new downstream keys from an incoming key without the need for coordination between consumers, getting an identical output key for a given input key regardless of consumer.3. In the event of a replayed message it\u2019s fine to republish downstream events because the system is now deterministic for a given input, so you\u2019ll get identical output (including generated messages) for identical input, and generating duplicate outputs is not an issue because this will be detected and ignored by downstream consumers.4. This parallelises well because consumers are deterministic and don\u2019t require any coordination except by db transaction.reply",
      "How is this different/better than something like using a SHA256 of the input key?Edit: Just looked it up... looks like this is basically what a uuid5 is, just a hash(salt+string)reply",
      "This doesn't sound good at all. It's quite reasonable in many applications to want to send the same message twice: e.g \"Customer A buys N units of Product X\".If you try to disambiguate those messages using, say, a timestamp or a unique transaction ID, you're back where you started: how do you avoid collisions of those fields? Better if you used a random UUIDv4 in the first place.reply",
      "I recently started using uuidv5 for ID generation based on a composite key. This allows a more diverse key set for partitioning by UUIDreply",
      "This was my exact solution in the late 1990's that I formulated using a uid algorithm I created when confronted with a growing payment processing load issue that centralized hardware at the time could not handle. MsSQL could not process the ever increasing load yet the firehose of real-time payments transaction volume could not be turned off so an interim parallel solution involving microservices to walk everything over to Oracle was devised using this technique. Everything old is new again as the patterns and cycles ebb and flow.reply",
      "Huh. Interesting solution! I've always thought the only way to make an API idempotent was to not expose \"adding\" endpoints. That is, instead of exposing a endpoint \"addvalue(n)\" you would have setvalue(n)\". Any adding that might be needed is then left as an exercise for the client.Which obviously has it's own set of tradeoffs.reply",
      "This article glosses over the hardest bit and bike sheds too much over keys.> Critically, these two things must happen atomically, typically by wrapping them in a database transaction. Either the message gets processed and its idempotency key gets persisted. Or, the transaction gets rolled back and no changes are applied at all.How do you do that when the processing isn\u2019t persisted to the same database? IE. what if the side effect is outside the transaction?You can\u2019t atomically rollback the transaction and external side effects.If you could use a distributed database transaction already, then you don\u2019t need idempotent keys at all. The transaction itself is the guaranteereply",
      "The practical answer is you use a combination of queries and compensating actions to resemble idempotency with the external service. Some people additionally constrain things to be a linear sequence of actions/effects, and call this pattern Sagas. It's sort of a bastardized distributed transaction that lets you handle a lot of real world use cases without getting into the complexity of true distributed transactions.reply",
      "I'm not sure if TFA implies this (it uses too much of his personal jargon for me to understand everything, and it's Friday) but consider this solution based on his transaction log section: you should use the same database that persists the idempotency key to persist the message, and then consume the messages from the CDC/outbox-style. Meaning, the database simply acts as an intermediate machine that dedupes the flow of messages. Assuming you're allowed to make the producer wait.reply",
      "The external side-effects also need to support idempotency keys, which you propagate. Then you use something like a message queue to drive the process to completion.reply"
    ],
    "link": "https://www.morling.dev/blog/on-idempotency-keys/",
    "first_paragraph": "In distributed systems, there\u2019s a common understanding that it is not possible to guarantee exactly-once delivery of messages.\nWhat is possible though is exactly-once processing. By adding a unique idempotency key to each message, you can enable consumers to recognize and ignore duplicate messages, i.e. messages which they have received and successfully processed before.Now, how does this work exactly? When receiving a message, a consumer takes the message\u2019s idempotency key and compares it to the keys of the messages which it already has processed. If it has seen the key before, the incoming message is a duplicate and can be ignored. Otherwise, the consumer goes on to process the message, for instance by storing the message itself, or a view derived from it, in some kind of database.In addition, it stores the idempotency key of the message. Critically, these two things must happen atomically, typically by wrapping them in a database transaction. Either the message gets processed and it"
  },
  {
    "title": "Fizz Buzz in CSS (susam.net)",
    "points": 61,
    "submitter": "froober",
    "submit_time": "2025-12-05T20:18:22 1764965902",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=46166708",
    "comments": [
      "145 using P instead of li.<style>\np{counter-increment:n}\np:not(:nth-child(5n)):before{content:counter(n)}\np:nth-child(3n):before{content:\"Fizz\"}\np:nth-child(5n):after{content:\"Buzz\"}\n</style><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p>reply",
      "im not sure how you counted that as 145, but here's 137 for the css<style>p{--n:counter(n);counter-increment:n;&:before{content:var(--n)};&:nth-child(5n){--n:\"\";&:after{content:\"Buzz\"}}&:nth-child(3n){--n:\"Fizz\"</style><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p>reply",
      "A shorter solution is possible with an ordered list (<ol>) if we're willing to ignore the untidy output:  li:nth-child(3n), li:nth-child(5n) { list-style: none }\n  li:nth-child(3n)::before { content: \"Fizz\" }\n  li:nth-child(5n)::after { content: \"Buzz\" }\n\nExample: https://susam.net/code/web/css-fizz-buzz-ol.html  $ curl -sS https://susam.net/code/web/css-fizz-buzz-ol.html | sed -n '/none/,/after/p' |  tr -d '[:space:]' \n  li:nth-child(3n),li:nth-child(5n){list-style:none}li:nth-child(3n)::before{content:\"Fizz\"}li:nth-child(5n)::after{content:\"Buzz\"}\n  $ curl -sS https://susam.net/code/web/css-fizz-buzz-ol.html | sed -n '/none/,/after/p' |  tr -d '[:space:]' | wc -c\n  129\n\nBut I don't quite like how misaligned the numbers and the words look in this version.  Correcting that would call for extra code that would cancel out the characters saved.reply",
      "list-style-position: inside;reply",
      "Yes!  However, like I mentioned in my previous comment, corrections like this cancel out the number of bytes saved with the <ol>-based solution.I mean, the solution in the original post is 152 characters long.The <ol> based solution is 129 characters long.  Shorter but uglier.If we add your correction, we get neater output, which is nice, but it comes at the cost of 30 additional characters in the minified code thereby making the solution 159 characters long.  li { list-style-position: inside }\n  li:nth-child(3n), li:nth-child(5n) { list-style: none }\n  li:nth-child(3n)::before { content: \"Fizz\" }\n  li:nth-child(5n)::after { content: \"Buzz\" }reply",
      "104\n:nth-child(3n){list-style:\"Fizz\"}:nth-child(5n){list-style:\"Buzz\"}:nth-child(15n){list-style:\"FizzBuzz\"}data:text/html,<style>:nth-child(3n){list-style:\"Fizz\"}:nth-child(5n){list-style:\"Buzz\"}:nth-child(15n){list-style:\"FizzBuzz\"}</style><ol id=o><script>o.innerHTML='<li>'.repeat(99)</script>reply",
      "103 :nth-child(3n){list-style:\"Fizz\"}:nth-child(5n){list-style:\"Buzz\"}:nth-child(15n){list-style:\"FizzBuzz\"reply",
      "98 :nth-child(5n){list-style:\"\"}:nth-child(3n){list-style:\"Fizz\"}:nth-child(5n)::after{content:\"Buzz\"reply",
      "95 :nth-child(5n){list-style:}:nth-child(3n){list-style:\"Fizz\"}:nth-child(5n)::after{content:\"Buzzreply",
      "68 :nth-child(3n){list-style:\"Fizz\"}:nth-child(5n)::after{content:\"Buzzreply"
    ],
    "link": "https://susam.net/fizz-buzz-in-css.html",
    "first_paragraph": "\n  What is the smallest CSS we can write to produce the Fizz Buzz\n  sequence?  One could of course do this with no CSS at all, simply by\n  placing the entire sequence as plain text in the HTML body.  So to\n  make the problem precise and keep it interesting, we require that\n  every number and word that appears in the output must come directly\n  from the CSS.  Placing any part of the output numbers or words\n  outside the stylesheet or using JavaScript is not allowed.  With\n  this constraint, I think it can be done in four lines of CSS as\n  shown below:\n\n  Here is a complete working example:\n  css-fizz-buzz.html.\n\n  I am neither a web developer nor a code-golfer.  Seasoned\n  code-golfers looking for a challenge can probably shrink this\n  solution further.  However, such wizards are also likely to scoff at\n  any mention of counting lines of code, since CSS can be collapsed\n  into a single line.  The number of characters is probably more\n  meaningful.  The code can also be minified slightly"
  },
  {
    "title": "Patterns for Defensive Programming in Rust (corrode.dev)",
    "points": 203,
    "submitter": "PaulHoule",
    "submit_time": "2025-12-05T16:34:25 1764952465",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=46163609",
    "comments": [
      "Good article, but one (very minor) nit I have is with the PizzaOrder example.    struct PizzaOrder {\n        size: PizzaSize,\n        toppings: Vec<Topping>,\n        crust_type: CrustType,\n        ordered_at: SystemTime,\n    }\n\nThe problem they want to address is partial equality when you want to compare orders but ignoring the ordered_at timestamp. To me, the problem is throwing too many unrelated concerns into one struct. Ideally instead of using destructuring to compare only the specific fields you care about, you'd decompose this into two structs:    #[derive(PartialEq, Eq)]\n    struct PizzaDetails {\n        size: PizzaSize,\n        toppings: Vec<Topping>,\n        crust_type: CrustType,\n        \u2026 // additional fields\n    }\n\n    #[derive(Eq)]\n    struct PizzaOrder {\n        details: PizzaDetails,\n        ordered_at: SystemTime,\n    }\n\n    impl PartialEq for PizzaOrder {\n        fn eq(&self, rhs: &Self) -> bool { \n            self.details == rhs.details\n        }\n    }\n\nI get that this is a toy example meant to illustrate the point; there are certainly more complex cases where there's no clean boundary to split your struct across. But this should be the first tool you reach for.reply",
      "You have a good point there, that is better. But it is still, well honestly, wrong. Two orders ordered at different times are just not the same order, and using a typeclass approach to say that they most definitely are is going to bite you in the back seat.PartialEq and Eq for PizzaDetails is good. If there is a business function that computes whether or not someone orders the same thing, then that should start by projecting the details.reply",
      "I do agree that implementing PartialEq on orders in this way is a bad fit. But it is a synthetic example to make a point, so I tried to keep it in the spirit of the original article (while ironically picking nits in the same vein myself).reply",
      "Yeah, I immediately twitched when I saw the PartialEq implementation. Somebody is going to write code which finds the \"correct\" order and ends up allowing someone to order the same pizza but get yours, while you have to wait for it to be made and cooked again.It's not difficult to write the predicate same_details_as() and then it's obvious to reviewers if that's what we meant and discourages weird ad-hoc code which might stop working when the PizzaDetails is redefined.reply",
      "You can solve this in the general case by implementing the typeclass for the coarser equality relation over an ad-hoc wrapper newtype.reply",
      "Well it isn't a good call. This is the kind of code that OOP makes people write.reply",
      "Decomposing things just to have different equality notions doesn't generalize.How would you decompose a character string so that you could have a case-insensitive versus sensitive comparison?:)reply",
      "Indexing into arrays and vectors is really wise to avoid.The same day Cloudflare had its unwrap fiasco, I found a bug in my code because of a slice that in certain cases went past the end of a vector. Switched it to use iterators and will definitely be more careful with slices and array indexes in the future.reply",
      "Funny, it's really the same thing, why Rust people say we should abandon C.  Meanwhile in C, it is also common to hand out handle instead of indices precisely due to this problem.reply",
      "It's pretty similar, but writing `for item in container { item.do_it() }` is a lot less error prone than the C equivalent. The ha-ha-but-serious take is that once you get that snippet to compile, there's almost nothing you could ever do to break it without also making the compiler scream at you.reply"
    ],
    "link": "https://corrode.dev/blog/defensive-programming/",
    "first_paragraph": "I have a hobby.Whenever I see the comment // this should never happen in code, I try to find out the exact conditions under which it could happen.\nAnd in 90% of cases, I find a way to do just that.\nMore often than not, the developer just hasn\u2019t considered all edge cases or future code changes.In fact, the reason why I like this comment so much is that it often marks the exact spot where strong guarantees fall apart.\nOften, violating implicit invariants that aren\u2019t enforced by the compiler are the root cause.Yes, the compiler prevents memory safety issues, and the standard library is best-in-class.\nBut even the standard library has its warts and bugs in business logic can still happen.All we can work with are hard-learned patterns to write more defensive Rust code, learned throughout years of shipping Rust code to production.\nI\u2019m not talking about design patterns here, but rather small idioms, which are rarely documented, but make a big difference in the overall code quality.Here\u2019s some"
  },
  {
    "title": "Most technical problems are people problems (joeschrag.com)",
    "points": 320,
    "submitter": "mooreds",
    "submit_time": "2025-12-05T13:07:59 1764940079",
    "num_comments": 239,
    "comments_url": "https://news.ycombinator.com/item?id=46160773",
    "comments": [
      "And most people problems are communication problems. Engineers aren't engaged with the product vision or the customer base, and are allowed to silo themselves. Product doesn't see the point of engineers being engaged and feed the engineering team like an in-house outsourcing shop. Sales and CS fail to understand the cost of their promises to individual customers to the timelines of features they're hungry for from the product plan. Goals and metrics for success fail to align. And thus everyone rows in their own direction.The solution usually isn't \"better people.\" It's engaging people on the same goals and making sure each of them knows how their part fits with the others. It's also recognizing when hard stuff is worth doing. Yeah you've got a module with 15 years of tech debt that you didn't create, and no-one on the team is confident in touching anymore. Unlike acne, it won't get better if you don't pick at it. Build out what that tech debt is costing the company and the risk it creates. Balance that against other goals, and find a plan that pays it down at the right time and the right speed.reply",
      "This is why I built out a Shadow Sessions program for our internal tooling teams at my BigCo.The users are right there, go make friends. Learn what they're doing day to day. And how it fits into the larger picture.These sessions are lightweight, and auto schedule every three weeks with no required action items and people come out of it amazed every time, lots of little bugs have been fixed, and connections are being made.The culture of not engaging with the end users when they're so readily available is an odd one to me. And you can really get to say 80% of macro picture understanding and user experience design fundamentals with a fairly low lift.To do this I created a sign up form and an auto scheduler that interacts with the Slack API. The scheduling and getting folk on board is the hardest part. Also finding time if you do things outside the product road map.reply",
      "100% this. Go and spend time with the people using your software. Even better, use it yourself.One of the companies I\u2019ve worked for did food delivery, and in food delivery during Christmas week everybody works operations - either you\u2019re out in a van with one of the regular drivers helping them carry orders that are three times larger than any other week, or you\u2019re handling phone calls and emails to fix whatever problems arise. Either way without fail January every year would see a flurry of low effort/high value updates to the software those parts of the business used. Anything from changing the order of some interactions to fit the flow of dropping a delivery to putting our phone number in the header of every admin page.Absolutely nothing beats going out there and doing the job to discover where the tools you\u2019re responsible for fall over. Bonus points if you can do it at the most stressful time of year when if anything is going to fail it probably will.reply",
      "Not using it themselves is why my managment at various companies wouldn't let anyone do sensible things.Companies that sell to other companies .... don't care about the users. It's one bunch of managers sleezing up to another to make a sale. Whether the product is good to use doesn't matter to them because none of them use it.A \"good\" company wouldn't allow this to happen but it happens often enough.Another bad smell is when developers themselves never use the whole product and simply work on their little bit.reply",
      "Yep, exactly, and amazing.And it's such a blind spot in the industry that the people most able to build and estimate features and software are left to be the least equipped to see through the end user's eyes.As such, when you encourage user oriented engineers, these common and often low effort issues can be avoided at the outset which improves velocity organizationally and results in better software and user experiences for projects now and in the future.reply",
      "A bit more heavyweight, but we implemented a rotation program when I was managing an internal tools team at a previous company. We'd trade an engineer from our team with an engineer from a feature team for a quarter.The amount of improvements to our collective understandings was super valuable. Feature devs got to help fix problems with their tools more directly (while also learning that it's not always as straightforward as it may seem), and we brought back much stronger insights into the experience of actually using our tools day-to-day.reply",
      "I think it\u2019s because companies don\u2019t incentivize people listening to each other. Management doesn\u2019t listen to the underlings and the underlings have to compete to get noticed.I have only a few people with whom I can discuss something in depth without anybody pushing an agenda. With most people it\u2019s just about pushing through what you want to do.I am just going through a bunch of sessions where a director has engaged consultants to change our stuff to use a new platform. Nobody who works on the system thinks it makes sense but it can\u2019t be stopped because of the director and a few yes men. Nobody listens.reply",
      "Makes me think of something my dad and I both talked about with our time in the military. He was Army and I was Navy. But when the ability to promote is tied with ranking against your peers, if you really want to game the system, you essentially sabotage your peers. Which is the exact opposite you want in the military or really any organization. You want to foster a, rising tide lifts all boats with getting the work done. But it hard when your performance evaluations are the complete opposite of that, and I have seen people do it.I got qualified on our equipment quick and was in a position where I was training my peers who I was ranked against. If I were an asshole, I would have trained them poorly and drug it out. I didn't, but someone who is goal oriented to climb through the ranks as fast a possible, it is a logical action that I could have taken.reply",
      "> If I were an asshole, I would have trained them poorly and drug it out.That's of course the obvious way this goes wrong. Bad intentions. The much more insidious version is that you could have just been a terrible teachers, maybe you suck at training your peers, and you don't know.The end result is the same. You look like the only person who gets it amongst the riff-raff, but in this case you don't even have a choice. The system has produced a poor outcome not because anybody abused it, but because it was a bad system.reply",
      "\"Better people\" solves a lot! But definitely not everything. But a lot!reply"
    ],
    "link": "https://blog.joeschrag.com/2023/11/most-technical-problems-are-really.html",
    "first_paragraph": "\u00a0I once worked at a company which had an enormous amount of technical debt - millions of lines of code, no unit tests, based on frameworks that were well over a decade out of date.\u00a0 On one specific project, we had a market need to get some Windows-only modules running on Linux, and rather than\u00a0cross-compiling, another team had simply copied & pasted a few hundred thousand lines of code, swapping Windows-specific components for Linux-specific.For the non-technical reader, this is an enormous problem because now two versions of the code exist.\u00a0 So, all features & bug fixes must be solved in two separate codebases that will grow apart over time.\u00a0 When I heard about this, a\u00a0young & naive version of me set out to fix the situation....Tech debt projects are always a hard sell to management, because even if everything goes flawlessly, the code just does roughly what it did before.\u00a0 This project was no exception, and the optics weren't great.\u00a0 I did as many engineers do and \"ignored the politi"
  },
  {
    "title": "Extra Instructions of the 65XX Series CPU (ffd2.com)",
    "points": 6,
    "submitter": "embedding-shape",
    "submit_time": "2025-12-06T00:38:50 1764981530",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "http://www.ffd2.com/fridge/docs/6502-NMOS.extra.opcodes",
    "first_paragraph": ""
  },
  {
    "title": "I'm Peter Roberts, immigration attorney who does work for YC and startups. AMA",
    "points": 164,
    "submitter": "proberts",
    "submit_time": "2025-12-05T16:04:20 1764950660",
    "num_comments": 207,
    "comments_url": "https://news.ycombinator.com/item?id=46163121",
    "comments": [
      "Hi Peter, thanks for the AMA!I work for an American company and I am based in Europe. I visit the US for work every now and then. I heard a lot of horror stories regarding border entries. If I am ever in a situation where the border police asks for access to my personal phone and pin code, what are my options? Can I refuse and what happens then?reply",
      "You are within your rights to say no but if you say no, almost certainly CBP will assume that you are hiding something and deny you admission.reply",
      "Can they deny you admission when you are a US citizen?reply",
      "They can not. Neither US Citizens or Green Card Holders can be denied entry.Sources: https://www.aclu.org/know-your-rights/what-do-when-encounter...https://www.aclunc.org/our-work/know-your-rights/know-your-r...reply",
      "A country can not deny entry to its own citizens.They can immediately arrest you, however.reply",
      "But not for not giving them access to your phone.reply",
      "In America, Europe, etc.reply",
      "They are not legally entitled to deny you entry.That doesn't mean they can't deny you entry. It means you might win a court case some day.ICE cannot legally arrest people who are citizens for no reason, and yet they have done exactly that 30% of the time by their own admission.\"Knowing your rights\" is meaningless if the public chooses to vote for people who don't care about those rights, and celebrate when you do not get your rights.It doesn't matter what the paper says, it matters what CBP feels like doing, and what their management lets them get away with. The constitution is just a magic circle we all agree to play in, and isn't real if enough people disregard it.If the border agent doesn't want you to come into the country, you are fucked. Nobody's job is to get between that agent and you and ensure the border agent follows the law on the paper, and the border agent will not go to jail or even lose their job for completely ignoring the law.reply",
      "> If the border agent doesn't want you to come into the country, you are fucked.You are seriously inconvenienced, but assuming your paperwork is in order, you will be allowed into the US.  This isn't just against US law, it's a violation of international law to render a person stateless.This ignores the real point, which is that while you cannot be refused entry to the United States, you can be arrested at the border.  ICE these days has mastered the art of making people's detainment so uncomfortable that even those with a right to be in this country end up deciding to leave.reply",
      "yes sure you can come into america, straight into a holding cell until you hand over your pins/passwords or go back home.reply"
    ],
    "link": "item?id=46163121",
    "first_paragraph": ""
  },
  {
    "title": "Frank Gehry has died (bbc.co.uk)",
    "points": 123,
    "submitter": "ksajadi",
    "submit_time": "2025-12-05T21:31:40 1764970300",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=46167621",
    "comments": [
      "From 2002: \"Frank Gehry No Longer Allowed To Make Sandwiches For Grandkids\":https://theonion.com/frank-gehry-no-longer-allowed-to-make-s...(just a picture, no story).reply",
      "I grew up a few blocks from his funky Santa Monica house [1], passed by it all the time. When you\u2019re a kid you typically see wild new things like that as just normal because you have no context for how unusual they are. His house defied that perspective; even as a kid you understand that being wrapped in oddly angled chain link fences and corrugated metal is just... different. It's an unanswered question, a loose thread, a thing you can't unknow.I don't particularly like the house - it's meant to be challenging not beautiful - but with perspective I see now there aren't many creations out there that achieve existence in eternal confusion like it does for me. I see his other works like Bilbao [2] and Disney Hall as refinements on the concept with the added dimension of beauty. They're not quite as memorable, but I think do a great job exploring the frontier of beauty and befuddlement.[1] https://en.wikipedia.org/wiki/Gehry_Residence[2] especially the aerial perspective https://en.wikipedia.org/wiki/Guggenheim_Museum_Bilbao#/medi...reply",
      "The MoPoP in seattle also carries his aesthetic, I would say it's funky, not beautifulreply",
      "I saw him speak about that house and at that time he was having a really hard time living in the suburban mindset. He wanted to offend.I\u2019m jealous that you knew it so well and as just another house.reply",
      "I don't have much to say about the focus of your comment, but I do want to talk about this:\"When you\u2019re a kid you typically see wild new things like that as just normal because you have no context for how unusual they are.\"NOT TRUE! I remember then (and even now) looking at unique things in awe and amazement, rather than something normal or ordinary.Just what I think :)reply",
      "He also designed a Facebook\u2019s office in Menlo Park. The roof was literally a park, seemingly blending with the bay and you could go for a nice nature stroll mid-day by just going up a flight of stairs. \nhttps://arquitecturaviva.com/works/facebook-campus-in-menlo-...reply",
      "I worked in this building. It was terrible. Low light, completely open office, people walking around you all the time, extremely noisy, pretty ugly (the roof-top garden was the exception). My team expensed noise cancelling headphones because it was so loud.MPK 22 was also designed by Gehry Partners, which was a massive improvement on the inside, but outside is still kinda terrible in my opinion: https://www.truebeck.com/project/facebook-mpk-22/reply",
      "Not surprising to hear. I mean Gehry has always been more flair than quality. His studio has probably weakest execution from all of the star architects. But it's a great brand i guess thats why you hire Gehry.reply",
      "I mean, having been in that building a few times, and working on the other side of the street, it's pretty clear the reason that building is such a disaster is that the architects did what the clients asked for. I like to give Gehry the benefit of the doubt, maybe that's cause he guest starred on Arthur. But you can only tell the client they're dumb and their building will suck to be in so many times before you just go ahead and let them have their hellscape.The roof was pretty nice though.reply",
      "Same. Echo chamber hell. I appreciated the modernness of the interior as a design nerd, though it was uncomfortable as a primary desk for all the reasons you\u2019ve said. Never mind the never ending flood of visitors up and down the walkways.The roof was the main reprieve about the entire environment, wonderfully maintained and honestly a blessing to escape the main campus.Nonetheless. Frank is a legend, very fortunate to have been able to been able to experience his work on a daily basis.reply"
    ],
    "link": "https://www.bbc.co.uk/news/articles/c5y2p22z9gno",
    "first_paragraph": "Frank Gehry, one of the most influential architects of the last century, has died aged 96.Gehry was acclaimed for his avant garde, experimental style of architecture. His titanium-covered design of the Guggenheim Museum in Bilbao, Spain, catapulted him to fame in 1997. He built his daring reputation years before that when he redesigned his own home in Santa Monica, California, using materials like chain-link fencing, plywood and corrugated steel.HIs death was confirmed by his chief of staff Meaghan Lloyd. He is survived by two daughters from his first marriage, Leslie and Brina; his wife, Berta Isabel Aguilera, and their two sons, Alejandro and Samuel, The Guggenheim Museum Bilbao, one of Gehry's most famous worksBorn in Toronto in 1929, Gehry moved to Los Angeles as a teenager to study architecture at the University of Southern California before completing further study at  the Harvard Graduate School of Design in 1956 and 1957.After starting his own firm, he broke from the traditiona"
  },
  {
    "title": "Show HN: HCB Mobile \u2013\u00a0financial app built by 17 y/o, processing $6M/month (hackclub.com)",
    "points": 102,
    "submitter": "mohamad08",
    "submit_time": "2025-12-03T04:20:44 1764735644",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=46130260",
    "comments": [
      "HCB is an amazing Rails 8 app. It is the Rails app that is processing $6M/month.https://github.com/hackclub/hcbExcellent work on the mobile app though I would wonder, since HCB runs on Hotwire, why it was not written as a Hotwire Native app which would leverage the existing Rails Hotwire app and not require a complete rewrite?reply",
      "The OP built the React Native mobile app - not the entire platform / company. Some folks commenting like they built the company. Just a point of clarification.Great work! Keep building OP!reply",
      "The OP title seems a bit misleading  notwithstanding this caveat.reply",
      "I am surprised you managed to get those entitlements at all!Did it help to be a non-profit?reply",
      "That's awesome, and impressive you were able to build that. As an angel investor, my first question would be: how do you deal with financial fraud? Like users exploiting your app for money laundering via donations then spending... Any system that lets money get in and out is eventually used as a channel by launderers.reply",
      "This is very helpful to the community. Great work.reply",
      "What is this page of transactions for?\nhttps://hcb.hackclub.com/hq/transactionsI get that you want to be \"open\", but is everyone involved in these transactions ok with them being shared? \nEven if they are, this doesn't seem like a good idea security wise. I see partial account numbers and other IDs/numbers that I assume you'd prefer not be public, regardless of how insensitive they may seem now.EXPENSIFY, INC. VALIDATION XXXXXX5987 THE HACK FOUNDATION\n +$0.89FRONTING $10,000 TO CHRIS WALKER FOR GITHUB GRANTS MADE FROM PERSONAL ACCOUNT\n -$10,000.00CHECK TO LACHLAN CAMPBELL\n +$800.00Transfer to Emma's Earnings\n -$1,923.08reply",
      "Not just for hack club - but transactions for another organization that is using their software is public. https://hcb.hackclub.com/reboot/transactions?page=13Not sure if all the organizations using their software know this.reply",
      "They have this page for reporting: https://github.com/hackclub/hcb/blob/main/SECURITY.mdreply",
      "Please look at this @mohamad08The numbers and amounts used for account validations and adding it to be able to pull or push money . Should not be shown public..reply"
    ],
    "link": "https://hackclub.com/fiscal-sponsorship/mobile/",
    "first_paragraph": "I\u2019m Mohamad, a 17-year-old from the SF Bay Area, and I just shipped the official mobile app for HCB.If you haven't heard of it, HCB is the financial backbone for over 6,500 teenager-led nonprofits, clubs, and hackathons. We provide 501(c)(3) nonprofit status, access to a bank account, a donation collection platform, and debit cards for thousands of young people trying to do good in their communities.HCB is currently processing an average of $6 million per month (over $80M in its lifetime).1 For the last year, I\u2019ve led the project to build the first-ever mobile app for this entire community.The entire project is open source on GitHub (we'd love a \u2b50\ufe0f!).These teenagers are running run robotics teams, hackathons, and nonprofit projects that improve their community. They need a way to manage their organization's finances from their pocket.\nWith HCB Mobile, they'll be able to:When I started working on this app, I wanted to build in native code like SwiftUI for iOS and Kotlin/Jetpack Compose "
  },
  {
    "title": "Tides are weirder than you think (signoregalilei.com)",
    "points": 65,
    "submitter": "surprisetalk",
    "submit_time": "2025-12-01T20:14:53 1764620093",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=46112560",
    "comments": [
      "You may have seen diagrams of the tidal force of the Moon on the earth (like this one: https://www.oc.nps.edu/nom/day1/tide_force_diagram.gif).Intuitively you would think that the tide is being formed because the Moon is \"lifting up\" the water at the point closest to the Moon.  But this contribution is actually very miniscule to the tidal effect.  Instead the bulk of the tides are produced about 45 degrees away where the tidal force is parallel to the Earth's surface.  This has the effect of dragging the water closer to the tidal bulge.reply",
      "> Kelvin\u2019s machine automates the second half of that task. As the pulleys spin, they pull on a common chain by the correct amount for each of the calculated components. A year\u2019s worth of tidal tables can be put together in half an hour, if you know the components. Even better, you can \u201cguess and check\u201d the components by comparing your machine\u2019s output to past records, and adjusting the pulleys until you get something that works correctly.I didn't know they already had machine learning and model fitting algorithms in the 1800s, but here we are...reply",
      "https://xkcd.com/1838reply",
      "https://www.youtube.com/watch?v=AxC770lpSLw shows one of the old tide prediction mechanical computers briefly mentioned in this article.  It is effectively doing an inverse Fourier Transform, summing all the various 30+ sinusoids that affect the tides.reply",
      "https://en.wikipedia.org/wiki/Tide-predicting_machineBasically, a summation of sinusoids.reply",
      "We have a \"King Tide\" today in SoCal where the local swing is +7/-1.5. Get to see normally hidden tidepools and a bunch of cobbles...reply",
      "I know this is unrelated to the actual content, but I have such a visceral reaction to any headline in the \"x is different than you think\"... how do you know what I think? I am sure many people who read this will be experts on tides, and the title is completely wrong.For me, the worst are posts about scale and things I won't need, like \"You don't need kafka\" or \"your data isn't actually big data\" or \"don't horizontally scale, just get a bigger server\"I get that I am not the target audience and there are people for whom those statements are true, but I am running Kafka clusters with data from 10s of thousands of servers, I absolutely can't move that to a single machine.I wish they would phrase it as \"Tides are weirder than most people think\", although that probably doesn't drive as much engagement.reply",
      "Because if someone says \"one\" it sounds affected.reply",
      "It is property of English language where \"you\" is used in place of \"one\" very often. This is particularly common in American English which has less formality to it; less Frenchiness. No 'on' etc. Everyone is 'tu'.It is language quirk, but you can probably use LLM to replace HN headlines like this. Pretty cheap and one will no longer have visceral reaction that one does not wish.reply",
      "Nice article!Any talk of tide prediction should always mention xtide:https://flaterco.com/xtide/I've used it with great accuracy in a number of locations around the world.Another one of those free software packages that's been meticulously maintained by one person for decades...reply"
    ],
    "link": "https://signoregalilei.com/2025/11/12/tides-are-weirder-than-you-think/",
    "first_paragraph": "Let's Explore!BlogVideosAbout\n\n\n\n\n\n\n\n \n\t\t\t\t\t\t\t\tSubscribe\t\t\t\t\t\t\t\nOur world relies on the sea more than ever: 80% of goods traded worldwide move by ship.1 Today\u2019s mariners take it for granted that they can get an accurate chart of the tides for any location on Earth. This would not have been possible without the work of countless scientists through history. The first workable solution, Lord Kelvin\u2019s tide-predicting machines, came in the 1870s. They were complex masses of gears and pulleys that were the most advanced mechanical computers of their day:\u00a0Why this complexity? Ancient Greek philosophers had already deduced that the Moon caused the tides. Isaac Newton determined the Moon\u2019s gravity was responsible in the 1680s, and Pierre-Simon Laplace produced a more refined theory in the 1770s incorporating the Earth\u2019s rotation and landmasses. But Laplace\u2019s equations were very challenging to actually solve for any given location \u2013 hence the machines. Let\u2019s go through the different layers that "
  },
  {
    "title": "The missing standard library for multithreading in JavaScript (github.com/w4g1)",
    "points": 31,
    "submitter": "W4G1",
    "submit_time": "2025-12-05T21:09:11 1764968951",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=46167349",
    "comments": [
      "I like this, but unfortunately it doesn't solve one annoying problem: lexical scope doesn't work and it will fail in an unexpected way.If you reference something lexically, your code fails at runtime. Want to use an import? You have to use import() inside the closure you pass to spawn(). Typescript doesn't know this. Your language server doesn't know this. Access a variable that shadows a built in global? Now you're accessing the built in global.The only way this could even be addressed is by having a full on parser. Even then you can't guarantee things will work.I think the only \"fix\" is for JS to introduce a new syntax to have a function that can't access lexical scope, returning a value that either extends a subclass of Function or has a cheeky symbol set on it. At least then, it'll fail at compile time.reply",
      "I\u2019d love a way to be able to specify that sort of thing. I wrote a little server-side JSX rendering layer, and event handlers were serialized to strings, and so they had similar restrictions.reply",
      "This looks great. If it works as well as the readme suggests, this\u2019ll let me reach for Bun in some of the scenarios where I currently reach for Go. Typescript has become my favorite language, but the lack of efficient multithreading is sometimes a deal breaker.reply",
      "This seems very much worth a look!(I suspect, to paraphrase Greenspun's rule, any sufficiently complicated app using Web Workers contains an ad hoc, informally-specified, bug-ridden, slow implementation of half of this library...)reply",
      "This is cool! Hope we can get multi-threaded wasm some time soon.reply"
    ],
    "link": "https://github.com/W4G1/multithreading",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        The missing standard library for multithreading in JavaScript (Works in Node.js, Deno, Bun, Web browser)\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\nMultithreading is a TypeScript library that brings robust, Rust-inspired concurrency primitives to the JavaScript ecosystem. It provides a thread-pool architecture, strict memory safety semantics, and synchronization primitives like Mutexes, Read-Write Locks, and Condition Variables.This library is designed to abstract away the complexity of managing WebWorkers, serialization, and SharedArrayBuffer complexities, allowing developers to write multi-threaded code that looks and feels like standard asynchronous JavaScript.JavaScript is traditionally single-threaded. To achieve true parallelism, this library u"
  },
  {
    "title": "Framework Sponsors CachyOS (cachyos.org)",
    "points": 138,
    "submitter": "d3Xt3r",
    "submit_time": "2025-12-05T20:03:21 1764965001",
    "num_comments": 115,
    "comments_url": "https://news.ycombinator.com/item?id=46166536",
    "comments": [
      "Very interesting that Valve and Framework seem to be throwing their eggs in the Arch basket over Debian/Ubuntu. When I got my first computer, I installed Ubuntu because it was dominant. Maybe it still is for the average Linux downloader, but why are the Hardware companies more into Arch?reply",
      "> over Debian/UbuntuAnd over Fedora/RHEL. If I had to guess, it could be that new entrants find it easier to submit changes to Arch Linux packages [1]. ChromeOS also steered away from Debian-based distributions, choosing a Gentoo base.[1] https://gitlab.archlinux.org/archlinux/packaging/packagesreply",
      "They're not though. They're supporting debian and bazzite which is fedora based and have worked with fedora extensively. See https://frame.work/de/en/blog/framework-sponsorshipsreply",
      "I'd think it's because they're introducing updates to address issues w/ the hardware quickly and want a rolling-release distro so users can get the updates faster.reply",
      "Debian testing is about as stable as it gets while also being a rolling distribution. The promotion of package updates from unstable to testing does not take that long either depending on the severity. I would venture a guess that there is more to it.reply",
      "Testing doesn't get timely security updates. Arch is more like Sid anyway.reply",
      "If only Arch supported Arm.reply",
      "I run Arch Linux on my M1, is that not arm?reply",
      "No, you run an Arch derivative.> Arch Linux is an independently developed, x86-64 general-purpose GNU/Linux distribution that strives to provide the latest stable versions of most software by following a rolling release model.- https://wiki.archlinux.org/title/Arch_Linux> This page complements the Installation guide with instructions specific to Apple Macs. The Arch installation image supports Apple Macs with Intel processors, but neither PowerPC nor Apple Silicon processors.(emphasis mine)- https://wiki.archlinux.org/title/Mac(FWIW, I understand that there is benefit to good coverage of a narrower scope, but I do wish Arch would fold https://archlinuxarm.org/ into the main project and be officially multi-arch, but that is not the world we live in.)reply",
      "Arch package manager here, there is ongoing work behind the scenes to support multiple architectures (aarch64, riscv, etc), but as our volunteers (myself included) are doing this in our free time, progress is up in the air.reply"
    ],
    "link": "https://discuss.cachyos.org/t/framework-sponsorship-for-cachyos/19376",
    "first_paragraph": "Hey CachyOS Community,We have some massive news to share today. Framework, the company behind the modular and repairable laptop revolution, is now sponsoring CachyOS.For an open-source project like ours, finding hardware partners who genuinely care about Linux is rare. Framework has not only provided us with a Framework Laptop 16 to help us optimize our kernel and packages on modern hardware, but they have also committed to a $250 monthly donation.While we are still a community-driven project, this contribution amounts to about 10% of our total monthly donations. Every bit of support like this helps stabilize our infrastructure and fuels our ultimate goal: eventually working on CachyOS full-time to bring you the fastest, most optimized Linux experience possible.Please go show them some love and check out their blog post regarding further sponsorships:We make a number of sponsorships each year in the form of both monetary donations and product donations.\u00a0We're sharing a list of our spon"
  },
  {
    "title": "Why we built Lightpanda in Zig (lightpanda.io)",
    "points": 162,
    "submitter": "ashvardanian",
    "submit_time": "2025-12-05T18:29:50 1764959390",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=46165249",
    "comments": [
      "> Zig particularly shines: comptime metaprogramming, explicit memory allocators, and best-in-class C interoperability. Not to mention the ongoing work on compilation timesThe D programming language shines:comptime: https://dlang.org/spec/function.html#interpretationmetaprogramming: https://dlang.org/spec/template.html#function-templatesexplicit memory allocators: these are easily made, there's nothing special about them, I use them all the timebest-in-class C interoperability: Nothing beats D's ImportC, where you can import a .c file as if it were a module. You can even use ImportC to translate your C code to D! https://dlang.org/spec/importc.htmlPerformance: same as C and C++reply",
      "Why D sees low adoption?reply",
      "We could do a better job at marketingreply",
      "Years ago, when I initially picked up Rust, I loved it. It does a lot of things right. At the same time, though, I knew there was a possibility of it going wrong in two opposite directions:1. Developers balked at being required to take on the cognitive load required to allow GC-less memory management2. Developers wore their ability to take on that cognitive load as a badge of honor, despite it not being in their best interestI eventually came to the decision to stop developing in Rust, despite its popularity. It is really cool that its creators pulled it off. It was quite an achievement, given how different it was when it came out. I think that if I had to implement a critical library I would consider using Rust for it, but as a general programming language I want something that allows me to focus my mental facilities on the complexities of the actual problem domain, and I felt that it was too often too difficult to do that with Rust.reply",
      "It's not quite a fully formed argument, but I'm coming to the view that Rust mostly requires less cognitive load than other languages. I'm coming at this from the perspective of \"cognitive load\" meaning, roughly \"the measure of the number of things you need to keep in working memory\". Rust is no doubt difficult to learn, there are many concepts and a lot of syntax, but when you grasp it cognitive load is actually lower. Rust encodes so much more about the program in text than peer languages so there are fewer things to keep in your head. One good example of this is pointer lifetimes in Zig and C which you have to keep in your head, whereas in Rust you don't.My own appreciation for Rust is rooted in humility. I know I'm an overgrown monkey prone to all kinds of mistakes. I appreciate Rust for helping me avoid that side of mereply",
      "The mentality around lifetimes is different in Zig if you are using it for the correct types of problems.For example, a command line utility. In a CLI tool you typically don't free memory. You just allocate and exit and let the OS clean up memory.Historically compilers were all like this, they didn't free memory, they just compiled a single file and then exited! This ended up being a problem when compilers moved more into a service model (constant compilation in the background, needing to do whole program optimization, loading into memory and being called on demand to compile snippets, etc), but for certain problem classes, not worrying about memory safety is just fine.Zig makes it easy to create an allocator, use it, then just free up all the memory in that region.Right tool for the job and all that.reply",
      "I've been having an absolutely great time with Rust's bumpalo crate, which works very similarly. The lifetime protection still works great, and it's actually a lot more permissive than normal Rust, since it's the same lifetime everywhere.The sad exception is obviously that Rust's std collections are not built on top of it, and neither is almost anything else.But nevertheless, I think this means it's not a Zig vs Rust thing, it's a Zig stdlib vs Rust stdlib thing, and Rust's stdlib can be replaced via #[no_std]. In the far future, it's likely someone will make a Zig-like stdlib for Rust too, with a &dyn Allocator inside collections.reply",
      "> In the far future, it's likely someone will make a Zig-like stdlib for Rust too, with a &dyn Allocator inside collections.This exists in the nightly edition of Rust, but is unlikely to become a feature in its current form because the alternative of \"Storages\" seems to be a lot more flexible and to have broader applicability.reply",
      "I'm not convinced that you can't borrow check in zig...   (disclaimer, i'm working on compile time memory safety for zig)reply",
      "I had no idea you were working on Zig dnautics.If you were to add borrow checking to Zig, it would make it much easier to justify using it at my current workplace.reply"
    ],
    "link": "https://lightpanda.io/blog/posts/why-we-built-lightpanda-in-zig",
    "first_paragraph": "Because We're Not Smart Enough for C++ or RustTo be honest, when I began working on Lightpanda, I chose Zig because I\u2019m not smart enough to build a big project in C++ or Rust.I like simple languages. I like Zig for the same reasons I like Go, C, and the KISS principle. Not just because I believe in this philosophy, but because I\u2019m not capable of handling complicated abstractions at scale.Before Lightpanda, I was doing a lot of Go. But building a web browser from scratch requires a low-level systems programming language to ensure great performance, so Go wasn\u2019t an option. And for a project like this, I wanted more safety and modern tooling than C.Our requirements were performance, simplicity, and modern tooling. Zig seemed like the perfect balance: simpler than C++ and Rust, top-tier performance, and better tooling and safety than C.As we built the first iterations of the browser and dug deeper into the language, we came to appreciate features where Zig particularly shines: comptime met"
  },
  {
    "title": "Making RSS More Fun (matduggan.com)",
    "points": 178,
    "submitter": "salmon",
    "submit_time": "2025-12-05T13:00:28 1764939628",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=46160698",
    "comments": [
      "> I rarely want to read all of a websites content from beginning to endI get the impression this person is using RSS reader wrong. Or is there really a culture of people you are using RSS like a youtube-channel, consuming everything from beginning to end? For me the purpose of RSS is to get the newest headlines, choose the interesting articles and skip the rest. This means there is a limited list of items to check each day, and a finishing line.> The whole appeal of TikTok, for those who haven't wasted hours of their lives on it, is that I get served content based on an algorithm that determines what I might think is useful or fun.But TikTok is even worse. It's an endless stream of content, pressuring you constantly, always pushing you on the \"just one more\"-train. How is that even better? This all reads more like this person should use a readlater-list, not a different RSS reader.reply",
      "To praise TikTok it has a highly effective recommendation engine precisely because it is showing you one piece of content at a time and registering your engagement on that.YouTube's interface gives people a feeling of agency because it tempts you with 10 or so videos on the side and you can choose one,  it also means YouTube does not get information about the 9 you didn't click,  maybe you would have liked 5 of them and hated 4 of them but it can at best guess about that.  I read about negative sampling in the recommender literature to address this issue and never felt I understood it or believed in it -- the literature clearly indicates that it sorta-kinda works but I think it does not work very well.So far as hating on algorithmic feeds it is not the algorithms themselves that are bad but how they are chosen.  If there is any characteristic of the content that can be quantified or evaluated a feed can be designed to privilege that.  A feed could be designed to be highly prosocial,  calming and such or designed to irritate you as much as possible.  It's possible that people get bored with the first.My own reader works like TikTok in that it shows one content piece of the time but it is basically the stuff that I submit to HN and it is scientific papers and articles about LLMs and programming languages and social psychology and political science and sports and and advanced manufacturing and biotech and such.  You might say my world view is unusual or something but it is certainly not mindless lowest common denominator stuff or outrage (e.g. to be fair I post a few things to HN because YOShInOn thinks they are spicy -- YOShInOn has a model that can predict if y'all are going to comment on an article or not and I felt it was a problem that my comments/submission ratio was low before I had YOShInOn)reply",
      "> To praise TikTok it has a highly effective recommendation engine precisely because it is showing you one piece of content at a time and registering your engagement on that.I'm a bit divided on TikToks efficiency. It's a well working doom-scrooling-machine, better than any other platform, but from my personal experience, it's not actually that good at recommending the content I actually want. And I think it's largely because it has the wrong focus, namely the attention. High attention-content is not always what I want and need, but TikTok has barely any way to realize this, exactly because of how It works.> YouTube's interface gives people a feeling of agency because it tempts you with 10 or so videos on the sideInteresting, never used that side-thing.> it also means YouTube does not get information about the 9 you didn't click,Yes, and that's OK. The not-clicked entries can still give me relevant information. And yes, the system can't act on this, but that's the whole point of RSS Readers, to make your own choice, on the spot, and switch it constantly as necessary. No system can react to this. \"Smart\" algorithmic solutions are doomed to stay mediocre because of this.reply",
      "Well...Personally I can't stand TikTok or Youtube Shorts or the videos on Instagram.  I just can't stand the meaningless motion to get attention,  it makes my skin crawl, it makes the bottom drop out of my stomach,  etc.  One time YT Shorts showed me an AI generation video of a pretty girl transforming into a fox on America's got talent, which is a good choice for me but then I got saturation videos of Chinese girls transforming into just about everything on AGT with the same music and reaction shots and it was more than I could use and not looking cool anymore but rather like AI slop.  That said,  I enjoy classic YouTube with relish.My RSS reader gives recommendations based on explicit up/down and it has an AUC of maybe 0.78 or so,  I saw a paper where TikTok is getting 0.83 so I feel like I'm doing OK.I haven't done anything to change it in the last year except increase the number of random articles it inserts a little because making the recs worse actually can make them better,  see [1]  TikTok is famous for doing this.  I think I could tune it up so for a given batch it could have a target \"thumbs up\" percentage or something more systematic but really I am very happy with the recs so it is not clear to me what \"better\" really is.There is the problem with it that the system has a lot of latency which does not really matter for articles on most subjects because news about software or science or political science or engineering is usually OK if it is delayed a few days or a few weeks but it is a problem with sports where you really look like a dumbass if you post about something that happened on week 2 during week 4.  It's a toughie though because I'd have to rework the thing to take out latency in 5+ stages of the system and then think systematically how to balance \"urgent\" vs \"interesting\" so I don't face the problem that urgent but interesting sports articles don't crowd other things out.  [2][1] https://en.wikipedia.org/wiki/Multi-armed_bandit[2] personally I don't mind the old articles for myself because I'm a weird kind of sports fan.  Two years ago I used to follow the NFL but since I started doing sports photography I might go to 5 games on one weekend and if I am doing that the NFL is a lot less interesting than,  say,  Arknights so I am a little embarrassed to say I have no idea how the Bills are doing this year.  But if I'm going to post sports articles to Bluesky or something it's a problem.reply",
      "> I get the impression this person is using RSS reader wrong. Or is there really a culture of people you are using RSS like a youtube-channel, consuming everything from beginning to end? For me the purpose of RSS is to get the newest headlines, choose the interesting articles and skip the rest. This means there is a limited list of items to check each day, and a finishing line.Why would the author's use be the wrong one? And why should YouTube be different, in principle? (Maybe you are using YouTube wrong...)I think at some point there was a shift in the way we consume online content, from \"I'll read whatever is up now\" to \"I have my list of things to catch up with\". RSS is older, so it is natural to connect it with the older way of consuming content. But there is no reason we can't do the same with YouTube channels, for example.reply",
      "RSS has been traditionally used like an email client rather than a streaming service. You don't read every email, some go straight to spam or the trash bin. RSS is a time saver, not a time waster.I can see that some feeds, like serializartions or low-volume/high quality content, is desirable to be consumed in its entirety, but the 80/20 principle seems to also apply to RSS feeds too in general. Specially if your RSS list reaches double digits.reply",
      "A bit weird to make blanket statements about a tool like that. Some people read all emails, some don\u2019t. Just like some people only subscribe to people\u2019s personal blogs and want to read all of them.Some might want to use it as a news aggregator and quickly browse through headlines. There no right or wrong usage of an RSS reader or \u201ctraditional usage\u201d.reply",
      "As RSS was being widespread around 2010, this is what most people said they were using it like, at least in my experience. It was the time when we still didn't have great spam filters, and people were used to receive and discard many emails without reading them.RSS was also frequently compared to discussion forums, where you also want to efficiently ignore non-relevant content. RSS gave us the power to ignore the budding information overload.reply",
      "A common setup was to have a folder hierarchy similar to email. Blogs were in folders organized by topic using whatever approach you felt best. You'd then dip into parts of the hierarchy. There often wasn't an aggregated feed that you could use but you could see a list of all items per blog. Each blog would then be highlighted or show a count when there was new content.I said blog instead of feed because social networks had a focus on the single scrolling feed as a list of content aggregated from different authors. Some RSS clients embraced this to a degree, but it didn't start out that way. Twitter was the first social network I really used in 2007 to follow bloggers I subscribed to, and it took a while to adjust to this firehose of interspersed content. That wasn't an uncommon sentiment from devs.reply",
      "So what? It's not a democratic vote to decide what way is the right/wrong way to use RSS. Do as you please, it's a simple usable protocol that basically allows for different use cases.reply"
    ],
    "link": "https://matduggan.com/making-rss-more-fun/",
    "first_paragraph": "It's JSON all the way downI don't like RSS readers. I know, this is blasphemous especially on a website where I'm actively encouraging you to subscribe through RSS. As someone writing stuff, RSS is great for me. I don't have to think about it, the requests are pretty light weight, I don't need to think about your personal data or what client you are using. So as a protocol RSS is great, no notes. However as something I'm going to consume, it's frankly a giant chore. I feel pressured by RSS readers, where there is this endlessly growing backlog of things I haven't read. I rarely want to read all of a websites content from beginning to end, instead I like to jump between them. I also don't really care if the content is chronological, like an old post about something interesting isn't less compelling to me than a newer post. What I want, as a user experience, is something akin to TikTok. The whole appeal of TikTok, for those who haven't wasted hours of their lives on it, is that I get ser"
  }
]