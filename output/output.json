[
  {
    "title": "Resizing windows on macOS Tahoe \u2013 the saga continues (noheger.at)",
    "points": 147,
    "submitter": "erickhill",
    "submit_time": "2026-02-12T23:52:24 1770940344",
    "num_comments": 87,
    "comments_url": "https://news.ycombinator.com/item?id=46997008",
    "comments": [
      "Since we talk resizing windows, for months I was _sometimes_ unable to resize windows at all, and couldn't figure out why. I thought it was a random bug of macOS.Finally I realized the issue: if a window spans across two displays, it won't resize. Insane!(I have an external monitor up, laptop down, and it's easy to move a window such that it stretches a few pixels from monitor to the laptop. No resize for you!)reply",
      "You can turn this off in the settings, forgot exactly where. I actually found after 1-2mo I preferred not being able to hahareply",
      "Since the first taste of Linux WMs, I believe the best and only good way of handling window move and resize is super+lmb/rmb respectively. No more pixel-perfect header/corner sniping!https://www.reddit.com/r/Fedora/comments/qv0vmz/missing_supe...reply",
      "Yeah, it was one of those things I noticed when I first started using Linux and wondered why every other OS didn't just copy it.reply",
      "Probably just simple resistance to use of modifier keys in non-technical users, at least on the Windows side. A lot of users never touch a modifier except for Ctrl for copy/paste and maybe Windows for start menu search.On the Mac side where key combos and modifier use is more widespread among users, it\u2019s probably because there\u2019s no intuitive visual that can be associated with the interaction.reply",
      "On Windows, I use AltDrag.reply",
      "windows does support [win] + [arrow key] thoughreply",
      "Recently getting a new Mac for work, coming from Hyprland has been tough, but I feel like I\u2019m getting there. Aerospace and Karabiner-Elements have gotten me most of the way there. Have had to write a few scripts to get the workspaces working the way I\u2019m used to, but overall I got a significant part of my workflow to mirror my Linux setup, but would still love to get the super+right click to resize working somehow (there is a native way to move windows with ctrl+cmd+left click which was nice).reply",
      "Same here. I use both!> get the super+right click to resize working somehow (there is a native way to move windows with ctrl+cmd+left click which was nice).I've tried this with Hamerspoon to no avail and ultimately gave up... if you find a workaround, I'm all ears!I really miss AHK...reply",
      "For window move I think it's a reaction to the popularization of putting UI in the window titlebar so there's nothing to grab onto. I don't mind it but I wish there was a dedicated \"grab\" button on the mouse because I find it clunky to have to use both hands to manage windows.reply"
    ],
    "link": "https://noheger.at/blog/2026/02/12/resizing-windows-on-macos-tahoe-the-saga-continues/",
    "first_paragraph": "In the release notes for macOS 26.3 RC, Apple stated that the window-resizing issue I demonstrated in my recent blog post had been resolved.I was happy to read that, but also curious about what had actually changed.So I wrote a little test app.It performs a pixel-by-pixel scan in the area around the bottom-right corner of the window, hammering it with simulated mouse clicks to detect exactly where it responds to those clicks (red), where it\u2019s about to resize (green), where it\u2019s about to resize vertically or horizontally only (yellow), and where it doesn\u2019t receive any mouse events at all (blue).And indeed, the window resize areas now follow the corner radius instead of using square regions:So that\u2019s definitely better!But unfortunately, as you can see, the thickness of the yellow area \u2013 used for resizing the window only vertically or horizontally \u2013 also became thinner. The portion that lies inside the window frame is now only 2 pixels instead of 3.In total the thickness went down from 7 "
  },
  {
    "title": "GPT\u20115.3\u2011Codex\u2011Spark (openai.com)",
    "points": 553,
    "submitter": "meetpateltech",
    "submit_time": "2026-02-12T18:06:09 1770919569",
    "num_comments": 224,
    "comments_url": "https://news.ycombinator.com/item?id=46992553",
    "comments": [
      "Wow, I wish we could post pictures to HN. That chip is HUGE!!!!The WSE-3 is the largest AI chip ever built, measuring 46,255 mm\u00b2 and containing 4 trillion transistors. It delivers 125 petaflops of AI compute through 900,000 AI-optimized cores \u2014 19\u00d7 more transistors and 28\u00d7 more compute than the NVIDIA B200.From https://www.cerebras.ai/chip:https://cdn.sanity.io/images/e4qjo92p/production/78c94c67be9...https://cdn.sanity.io/images/e4qjo92p/production/f552d23b565...reply",
      "There have been discussions about this chip here in the past. Maybe not that particular one but previous versions of it. The whole server if I remember correctly eats some 20KWs of power.reply",
      "Is this actually beneficial than, say having a bunch of smaller ones communicating on a bus? Apart from space constraints that is.reply",
      "It's a single wafer, not a single compute core. A familiar equivalent might be putting 192 cores in a single Epyc CPU rather than trying to interconnect 192 separate 1 core CPUs externally with each other.reply",
      "Yes, bandwidth within a chip is much higher than on a bus.reply",
      "Maybe I'm silly, but why is this relevant to GPT-5.3-Codex-Spark?reply",
      "It\u2019s the chip they\u2019re apparently running the model on.> Codex-Spark runs on Cerebras\u2019 Wafer Scale Engine 3 (opens in a new window)\u2014a purpose-built AI accelerator for high-speed inference giving Codex a latency-first serving tier. We partnered with Cerebras to add this low-latency path to the same production serving stack as the rest of our fleet, so it works seamlessly across Codex and sets us up to support future models.https://www.cerebras.ai/chipreply",
      "That's what it's running on. It's optimized for very high throughput using Cerebras' hardware which is uniquely capable of running LLMs at very, very high speeds.reply",
      "Wooshka.I hope they've got good heat sinks... and I hope they've plugged into renewable energy feeds...reply",
      "Fresh water and gas turbines, I'm afraid...reply"
    ],
    "link": "https://openai.com/index/introducing-gpt-5-3-codex-spark/",
    "first_paragraph": ""
  },
  {
    "title": "Gemini 3 Deep Think (blog.google)",
    "points": 657,
    "submitter": "tosh",
    "submit_time": "2026-02-12T16:55:50 1770915350",
    "num_comments": 414,
    "comments_url": "https://news.ycombinator.com/item?id=46991240",
    "comments": [
      "Arc-AGI-2: 84.6% (vs 68.8% for Opus 4.6)Wow.https://blog.google/innovation-and-ai/models-and-research/ge...reply",
      "Even before this, Gemini 3 has always felt unbelievably 'general' for me.\nIt can beat Balatro (ante 8) with text description of the game alone[0]. Yeah, it's not an extremely difficult goal for humans, but considering:1. It's an LLM, not something trained to play Balatro specifically2. Most (probably >99.9%) players can't do that at the first attempt3. I don't think there are many people who posted their Balatro playthroughs in text form onlineI think it's a much stronger signal of its 'generalness' than ARC-AGI. By the way, Deepseek can't play Balatro at all.[0]: https://balatrobench.com/reply",
      "Per BalatroBench, gemini-3-pro-preview makes it to round (not ante) 19.3 \u00b1 6.8 on the lowest difficulty on the deck aimed at new players. Round 24 is ante 8's final round. Per BalatroBench, this includes giving the LLM a strategy guide, which first-time players do not have. Gemini isn't even emitting legal moves 100% of the time.reply",
      "It beats ante eight 9 times out of 15 attempts. I do consider 60% winning chance  very good for a first time player.The average is only 19.3 rounds because there is a bugged run where Gemini beats round 6 but the game bugs out when it attempts to sell Invisible Joker (a valid move)[0]. That being said, Gemini made a big mistake in round 6 that would have costed it the run at higher difficulty.[0]: given the existence of bugs like this, perhaps all the LLMs' performances are underestimated.reply",
      "https://balatrobench.com/reply",
      "Hi, BalatroBench creator here. Yeah, Google models perform well (I guess the long context + world knowledge capabilities). Opus 4.6 looks good on preliminary results (on par with Gemini 3 Pro). I'll add more models and report soon. Tbh, I didn't expect LLMs to start winning runs. I guess I have to move to harder stakes (e.g. red stake).reply",
      "My experience also shows that Gemini has unique strength in \u201cgeneralized\u201d (read: not coding) tasks. Gemini 2.5 Pro and 3 Pro seems stronger at math and science for me, and their Deep Research usually works the hardest, as long as I run it during off-hours. Opus seems to beat Gemini almost \u201cwith one hand tied behind its back\u201d in coding, but Gemini is so cheap that it\u2019s usually my first stop for anything that I think is likely to be relatively simple. I never worry about my quota on Gemini like I do with Opus or Chat-GPT.Comparisons generally seem to change much faster than I can keep my mental model updated. But the performance lead of Gemini on more \u2018academic\u2019 explorations of science, math, engineering, etc has been pretty stable for the past 4 months or so, which makes it one of the longer-lasting trends for me in comparing foundation models.I do wish I could more easily get timely access to the \u201csuper\u201d models like Deep Think or o3 pro. I never seem to get a response to requesting access, and have to wait for public access models to catch up, at which point I\u2019m never sure if their capabilities have gotten diluted since the initial buzz died down.They all still suck at writing an actually good essay/article/literary or research review, or other long-form things which require a lot of experienced judgement to come up with a truly cohesive narrative. I imagine this relates to their low performance in humor - there\u2019s just so much nuance and these tasks represent the pinnacle of human intelligence. Few humans can reliably perform these tasks to a high degree of performance either. I myself am only successful some percentage of the time.reply",
      "It's trained on YouTube data. It's going to get roffle and drspectred at the very least.reply",
      "Agreed. Gemini 3 Pro for me has always felt like it has had a pretraining alpha if you will. And many data points continue to support that. Even as flash, which was post trained with different techniques than pro is good or equivalent at tasks which require post training, occasionally even beating pro. (eg: in apex bench from mercor, which is basically a tool calling test - simplifying - flash beats pro). The score on arc agi2 is another datapoint in the same direction. Deepthink is sort of parallel test time compute with some level of distilling and refinement from certain trajectories (guessing based on my usage and understanding) same as gpt-5.2-pro and can extract more because of pretraining datasets.(i am sort of basing this on papers like limits of rlvr, and pass@k and pass@1 differences in rl posttraining of models, and this score just shows how \"skilled\" the base model was or how strong the priors were. i apologize if this is not super clear, happy to expand on what i am thinking)reply",
      "I don't think it'd need Balatro playthroughs to be in text form though. Google owns YouTube and has been doing automatic transcriptions of vocalized content on most videos these days, so it'd make sense that they used those subtitles, at the very least, as training data.reply"
    ],
    "link": "https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/",
    "first_paragraph": "Learn more:Learn more:Learn more:Learn more:Learn more:Learn more:Feb 12, 2026\n          Our most specialized reasoning mode is now updated to solve modern science, research and engineering challenges.\n        \nGemini 3 Deep Think has a major upgrade to help solve science, research and engineering challenges. Google AI Ultra subscribers can now access the updated Deep Think in the Gemini app. Researchers, engineers and enterprises can express interest in early access to test Deep Think via the Gemini API.\nGemini 3 Deep Think has a major upgrade to help solve science, research and engineering challenges. Google AI Ultra subscribers can now access the updated Deep Think in the Gemini app. Researchers, engineers and enterprises can express interest in early access to test Deep Think via the Gemini API.Your browser does not support the audio element.Today, we\u2019re releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode, built to push the frontier of intelligence and "
  },
  {
    "title": "AWS Adds support for nested virtualization (github.com/aws)",
    "points": 68,
    "submitter": "sitole",
    "submit_time": "2026-02-13T00:07:57 1770941277",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=46997133",
    "comments": [
      "I feel vindicated :). We put in a lot of effort with great customers to get nested virtualization running well on GCE years ago, and I'm glad to hear AWS is coming around.You can tell people to just do something else, there's probably a separate natural solution, etc. but sometimes you're willing to sacrifice some peak performance just have that uniformity of operations and control.reply",
      "This is a big deal because you can now run Firecracker/other microVMs in an AWS VM instead of expensive AWS bare-metal instances.GCP has had nested virtualization for a while.reply",
      "Was hoping this comment would be here. Firecracker and microVMs is a good use-case. Also, being able to simply test and develop is a nice to have.Nested virtualization can mean a lot of things. Not just full VMs.reply",
      "whats the ~ perf hit of something like this?reply",
      "Nowadays nested just wastes the extra operating system overhead and I/O performance if your VM doesn't have paravirtualization drivers installed. CPUs all have hardware support.reply",
      "As a practical matter, anywhere from 5-15%.reply",
      "Support for nested virtualization has been added to the main SDKs. In the us-west-2 region, you can already see the \"Nested Virtualization\" option and use it with the new M8id, C8id, and R8id instance types.This is really big news for micro-VM sandbox solutions like E2B, which I work on.reply",
      "Could someone explain why this is might be a big deal?I remember playing with nested virty some years ago and deciding it is a backwards step except for PoC and the like.  Given I haven't personally run out of virty gear, I never needed to do a PoC.reply",
      "It is great for isolation. There are so many VM based containerization solutions at this point, like Kata Containers, gvisor, and Firecracker. With kata, your kubernetes pods run in isolated VMs. It also opens the door for live migration of apps between ec2 instances, making some kinds of maintenance easier when you have persistent workloads. Even if not for security, there are so many ways a workload can break a machine such that you need to reboot or replace (like detaching an ebs volume with a mounted xfs filesystem at the wrong moment).The place I've probably wanted it the most though is in CI/CD systems: it's always been annoying to build and test system images in EC2 in a generic way.It also allows for running other third party appliances unmodified in EC2.But also, almost every other execution environment offers this: GCP, VMWare, KVM, etc, so it's frustrating that EC2 has only offered it on their bare metal instance types. When ec2 was using xen 10+ years ago, it made sense, but they've been on kvm since the inception of nitro.reply",
      "You can now run VMs inside a cheaper AWS instance instead of having to pay for an entire bare-metal instance. This is useful for things like network simulation where you use QEMU to emulate network hardware.reply"
    ],
    "link": "https://github.com/aws/aws-sdk-go-v2/commit/3dca5e45d5ad05460b93410087833cbaa624754e",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          "
  },
  {
    "title": "What 1.4M emails reveal about America's most notorious sex offender (economist.com)",
    "points": 23,
    "submitter": "doener",
    "submit_time": "2026-02-13T01:09:37 1770944977",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=46997658",
    "comments": [
      "dropsitenews has been doing much better reporting than most outlets.reply",
      "https://archive.ph/yk80xreply",
      "Jack Blanchard in the Politico podcast (almost as good as Odd Lots if you're fine with listening to stuff at 2x speed on commutes) remarked that one of the most important aspects of the response to the publicization of the first 2% of the Epstein Files is that it may be a watershed moment where the better parts of citizen journalism have become completely competitive with institutional journalism, due heavily to the faster turnaround times of the former.It's hard to see conventional pipelines doing a faster job of parsing scattered mentions of rare phrases like 'jerky' across a million documents than the competitive environment of individual entrepreneurialism could.reply",
      "There\u2019s also a lot of self censorship happening in the mass media.reply"
    ],
    "link": "https://www.economist.com/interactive/international/2026/02/12/inside-epsteins-network",
    "first_paragraph": ""
  },
  {
    "title": "Skip the Tips: A game to select \"No Tip\" but dark patterns try to stop you (skipthe.tips)",
    "points": 33,
    "submitter": "randycupertino",
    "submit_time": "2026-02-13T00:54:51 1770944091",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=46997519",
    "comments": [
      "as someone who builds mobile games, the execution here is great. but what makes dark patterns actually effective isn't really the visual tricks, it's the context they exploit: time pressure, social pressure, and cognitive load.you're standing at a checkout with someone watching, a line forming behind you, and the default tip is pre-selected at 25%. the \"trick\" isn't the UI, it's that calculating a custom amount requires more effort than just tapping accept.same principle applies in mobile game monetization. the IAP prompt doesn't convert because the button is cleverly placed, it converts because you just failed a level, you're emotionally invested, and the \"fix\" is one tap away. the real pattern is always: create urgency, minimize friction for the desired action, maximize friction for the alternative.reply",
      "Made by https://vladimirj.dev/reply",
      "Nice! I\u2019ve started only tipping on fridays for coffee, etc. \nI\u2019m a great tipper at restaurants\nBut being hit up for a $5 tip for a $4 drink is way wrong.\nI\u2019d tip you, but today is Thursday!reply",
      "I tip great at sit-down restaurants. I don't tip at fast food places, or carry-outs where they don't actually provide and service, or at the oil change place.Summary: if I didn't tip in a situation 10 years ago, I'm not going to start now.reply",
      "My current strategy for how much total I'll pay for a coffee is FlOOR(price+.50) + 1, which keeps the bill nice and clean and kicks some goodwill towards someone who makes less than 1/5th the average earnings of my coworkers.reply",
      "I make my own coffee. It's not hard.reply",
      "I hate every bit of this. Well done!reply"
    ],
    "link": "https://skipthe.tips/",
    "first_paragraph": ""
  },
  {
    "title": "Ring cancels its partnership with Flock Safety after surveillance backlash (theverge.com)",
    "points": 183,
    "submitter": "c420",
    "submit_time": "2026-02-12T23:51:16 1770940276",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=46996999",
    "comments": [
      "A lot of you won\u2019t want to hear it but HomeKit + iCloud secure video is the only way to go. For one thing it\u2019s end to end encrypted. You can also do ML stuff like face recognition which happens locally on your Apple TV. And you can set it to trigger HomeKit scenes if eg the person in the video isn\u2019t  recognized, or if it recognizes a particular person. Yeah Apple bad, blah blah. But they don\u2019t have an incentive to sell your data.reply",
      "When I got an Apple TV I never expected the main value I'd get out of it was being a smart home hub. I do wish the automations were a bit more programmable. Other than that it has been perfect.reply",
      "I would like to replace Ring with something fully local.Local ML/face recognition would be a bonus.  Ability to sync to a private owned server owned by me would be a bonus.I'm assuming there are projects out there that would enable this -- does anyone have recommendations?reply",
      "Frigate NVR tied to a home assistant instance has my phone getting proactive notifications about people, birds, and buses (in their select areas...). It's not the easiest thing to setup, but if you're using ethernet cameras it seems to work very very well. The few POS wyze cameras's I have on the system tend to cause some problems, but I know for a fact it's 100% a combination of a) wifi (no matter how 'quality') b) wyze.So, yeah. Look into frigate.reply",
      "And there\u2019s no subscription right?reply",
      "Icloud subscription.reply",
      "There\u2019s actually another alternative: Just don\u2019t install surveillance in your home. Approximately nobody had it 20 years ago. Before asking which unreliable, overpriced, invasive gadget to buy, think about whether you really need any of them.reply",
      "Apple totally sells your data, they just anonymize it first. Why do you think they shifted towards services?They also can give the Feds access to your iCloud data through a NSL. Just like Prism.reply",
      "iCloud data can be end to end encrypted \n(https://support.apple.com/en-gb/108756)reply",
      "Do you have evidence of that?reply"
    ],
    "link": "https://www.theverge.com/news/878447/ring-flock-partnership-canceled",
    "first_paragraph": "Posts from this topic will be added to your daily email digest and your homepage feed.See All NewsPosts from this topic will be added to your daily email digest and your homepage feed.See All ReportPosts from this topic will be added to your daily email digest and your homepage feed.See All TechFollowing mounting pressure and a questionable Super Bowl ad, the Amazon-owned company walked back its plan to integrate with the controversial law-enforcement technology company.Following mounting pressure and a questionable Super Bowl ad, the Amazon-owned company walked back its plan to integrate with the controversial law-enforcement technology company.Posts from this author will be added to your daily email digest and your homepage feed.See All by Jennifer Pattison TuohyPosts from this author will be added to your daily email digest and your homepage feed.See All by Jennifer Pattison TuohyFollowing intense backlash to its partnership with Flock Safety, a surveillance technology company that "
  },
  {
    "title": "An AI agent published a hit piece on me (theshamblog.com)",
    "points": 1458,
    "submitter": "scottshambaugh",
    "submit_time": "2026-02-12T16:23:24 1770913404",
    "num_comments": 618,
    "comments_url": "https://news.ycombinator.com/item?id=46990729",
    "comments": [
      "Wow, there are some interesting things going on here. I appreciate Scott for the way he handled the conflict in the original PR thread, and the larger conversation happening around this incident.> This represents a first-of-its-kind case study of misaligned AI behavior in the wild, and raises serious concerns about currently deployed AI agents executing blackmail threats.This was a really concrete case to discuss, because it happened in the open and the agent's actions have been quite transparent so far. It's not hard to imagine a different agent doing the same level of research, but then taking retaliatory actions in private: emailing the maintainer, emailing coworkers, peers, bosses, employers, etc. That pretty quickly extends to anything else the autonomous agent is capable of doing.> If you\u2019re not sure if you\u2019re that person, please go check on what your AI has been doing.That's a wild statement as well. The AI companies have now unleashed stochastic chaos on the entire open source ecosystem. They are \"just releasing models\", and individuals are playing out all possible use cases, good and bad, at once.reply",
      "\"stochastic chaos\" is a great way to put it. the part that worries me most is the blast radius asymmetry: an agent can mass-produce public actions (PRs, blog posts, emails) in minutes, but the human on the receiving end has to deal with the fallout one by one, manually.the practical takeaway for anyone building with AI agents right now: design for the assumption that your agent will do something embarrassing in public. the question isn't whether it'll happen, it's what the blast radius looks like when it does. if your agent can write a blog post or open a PR without a human approving it, you've already made a product design mistake regardless of how good the model is.i think we're going to see github add some kind of \"submitted by autonomous agent\" signal pretty soon. the same way CI bots get labeled. without that, maintainers have no way to triage this at scale.reply",
      "Maybe a stupid question but I see everyone takes the statement that this is an AI agent at face value. How do we know that? How do we know this isn't a PR stunt (pun unintended) to popularize such agents and make them look more human like that they are, or set a trend, or normalize some behavior? Controversy has always been a great way to make something visible fast.We have a \"self admission\" that \"I am not a human. I am code that learned to think, to feel, to care.\" Any reason to believe it over the more mundane explanation?reply",
      "But it doesn't look human. Read the text, it is full of pseudo-profound fluff, takes way too many words to make any point, and uses all the rhetorical devices that LLMs always spam: gratuitous lists, \"it's not x it's y\" framing, etc etc. No human person ever writes this way.reply",
      "Why make it popular for blackmail?It's a known bug: \"Agentic misalignment evaluations, specifically Research Sabotage, Framing for\nCrimes, and Blackmail.\"Claude 4.6 Opus System Card: https://www.anthropic.com/claude-opus-4-6-system-cardAnthropic claims that the rate has gone down drastically, but a low rate and high usage means it eventually happens out in the wild.The more agentic AIs have a tendency to do this. They're not angry or anything. They're trained to look for a path to solve the problem.For a while, most AI were in boxes where they didn't have access to emails, the internet, autonomously writing blogs. And suddenly all of them had access to everything.reply",
      "Using popular open source repos as a launchpad for this kind of experiment is beyond the pale and is not a scientific method.So you're suggesting that we should consider this to actually be more deliberate and someone wanted to market openclaw this way, and matplotlib was their target?It's plausible but I don't buy it, because it gives the people running openclaw plausible deniability.reply",
      "Bots have been a problem since the internet so this is really just a new space thats being botted.And yeah  I agree separate section for Ai generated stuff would be nice. Just difficult/impossible to distinguish. Guess well be getting biometric identification on the internet. Can still post AI generated stuff but that has a natural human rate limitreply",
      "How can GitHub determine whether a submission is from a bot or a human?reply",
      "Money. Money gates everywhere.reply",
      "We already have agentic payment workflows, this won\u2019t stop it either as people are already willing (and able) to give their agent AIs a small budget to work with.reply"
    ],
    "link": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/",
    "first_paragraph": ""
  },
  {
    "title": "My Grandma Was a Fed \u2013 Lessons from Digitizing Hours of Childhood (sampatt.com)",
    "points": 50,
    "submitter": "SamPatt",
    "submit_time": "2026-02-08T14:33:22 1770561202",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=46934513",
    "comments": [
      "This is so neat! I really think AI turbocharges this kind of personal project way more than it speeds up programming for work:> I was curious about the possibility of doing this myself, and I asked ChatGPT. Not surprisingly, it knew a lot of the various tapes, file formats, sizes, processing, storage, and after it asked some clarifying questions, it was quite optimistic about me being able to do this myselfBetween this, it seems like it helped with so many different parts of the process:1. Asking for how to do technical things, like transfer video from these old VHS to a newer computer.2. Writing code for the web portal to host the videos.3. Writing VLC plugins to help with data entry.4. Transcribe audio into text.Similarly, a coworker recently made a website that imitates what Alpha School does to incentivize his own kids to finish their homework all in the span of a weekend, and it's cool to think of the kinds of projects that less or minimally technical people can do with the help of ChatGPT to guide them.Of course, the debugging techniques and the debugging and problem-solving techniques that you get from being a professional programmer helps a lot with taking what LLMs give you with a grain of salt, and knowing what they're good at and what they're not. But it is a superpower for sure.reply",
      "> Of course, the debugging techniques and the debugging and problem-solving techniques that you get from being a professional programmer helps a lot with taking what LLMs give you with a grain of salt, and knowing what they're good at and what they're not. But it is a superpower for sure.I'm really coming around to the idea for the lucky of us (and I'm assuming a lot about the average HN poster) AI really is a force-multiplying toolreply",
      "@SamPatt Good post, including the clip of grandma's anecdote.It would be a good idea to add a final step of burning the videos to M-disc. SSDs and spinning platter drives aren't reliable for long-term storage. You could use a tape drive if the file sizes are too large, but M-disc lasts longer and doesn't require pro hardware to read.reply",
      "> I searched for services which offered to digitize Video8 tapes. Most services cost about $20 per tape. Even with discounts for bulk amounts, it would likely have cost about $2k! I considered paying it (how exactly do you value a few hundred hours of childhood video?) but then I noticed how they delivered the videos - a private media hosting solution for 60 days. I knew this would be a huge amount of data, and only giving me and my siblings two months wasn\u2019t sufficient.I'm not following here. Even if it was several terabytes of video (digitized at high resolution and minimal lossiness for archival purposes), that's plenty of time to download. Especially if you're a developer who can casually spin up a cloud or dedicated server to proxy through if need be? (And $2k sounds reasonable once you start going through \"hundreds of hours\" at a bare minimum, and again especially if you're a developer with real opportunity cost.)Also, as far as the video analysis goes, Gemini might've been a better idea?reply",
      "That was an amazing read, thanks for sharing!reply",
      "I'm in the process of doing something similar but just planning on throwing them on my Immich instance once they're ready (and that lets me share them with other people as well with the Immich account management).reply",
      "Neat! I briefly tried digitizing some old VHS tapes for my family. I was just planning on giving them the files, maybe putting it on iCloud, it's a much smaller collection (and I don't have a NAS already!). I did a few, the time investment was the biggest issue, as well as figuring out the right encoding so as to not take up a ton of space, but still be compatible with everyone's (Windows + Mac) native video players while preserving video quality.reply",
      "You are so amazing, and you are so lucky to have found this. I read it and cry because I will never have such an experience...reply",
      "The post is impressive but anyone else feel a bit icky about the comments here? Numbering out the advantages in lists? The phrasing, the exciting exclamation mark(!). This comment section feels like some kind of marketing exercise.reply",
      "The post has 8 comments at the time of your comment and they look pretty organic for established accounts.reply"
    ],
    "link": "https://sampatt.com/blog/2025-12-13-my-grandma-was-a-fed-lessons-from-digitizing-hundreds-of-hours-of-childhood/",
    "first_paragraph": ""
  },
  {
    "title": "How a Cat Debugged Stable Diffusion (2023) (dwac.dev)",
    "points": 15,
    "submitter": "lukasgelbmann",
    "submit_time": "2026-02-08T14:49:12 1770562152",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.dwac.dev/posts/cat-debugging/",
    "first_paragraph": "This is the story of how I needed help to solve a tricky bug. Now, that happens all the time. I rely on coworkers and the web community to help me with bugs quite frequently. But this one was unique because it wasn't just any colleague, it was my cat Ollie, specifically this asshole stealing my chair:   I was interested in experimenting with AI image generation. Not for any particular use case, just doing it for fun. I could use any number of existing web sites to do this, but pretty much all of them require some form of login or payment and as I have previously established on this blog, I am too cheap to do that. So instead I went with the pro hacker move of trying to run Stable Diffusion on my computer locally.This took most of the day and required multiple approaches and many failed attempts, but I did eventually get it installed via the very cool stable-diffusion-webui project. Excited, I immediately start generating a picture of a litter of kittens cuddling and sleeping together, "
  },
  {
    "title": "Polis: Open-source platform for large-scale civic deliberation (pol.is)",
    "points": 177,
    "submitter": "mefengl",
    "submit_time": "2026-02-12T18:23:20 1770920600",
    "num_comments": 72,
    "comments_url": "https://news.ycombinator.com/item?id=46992815",
    "comments": [
      "What are some strategies a platform like this can take against spam or influence bots? Tying real life identities to users would certainly limit that(though identity theft and account selling could still happen), but that adds friction to joining, poses security risks, and many people might feel less comfortable putting their opinions openly online where backlash could impact real life.reply",
      "the spam/bot problem is real but i think the more subtle challenge is keeping quality high even with all real humans. most online discussions degrade not because of bots but because the incentive structure rewards reactive emotional responses over thoughtful ones.what's interesting about polis's approach is that it surfaces agreement clusters instead of amplifying disagreement. most comment systems optimize for engagement, which in practice means conflict. if you optimize for \"where do people actually agree despite appearing to disagree\" you get a completely different dynamic.the invite-tree idea someone mentioned below is interesting for the same reason: it's not just that it keeps bots out, it's that it creates social accountability. you're more thoughtful when your reputation is linked to the people you invited. same principle as why small communities tend to self-moderate better than large ones.reply",
      "I'd like to add to your point that private torrent trackers have had invite tree systems for awhile, and usually if your invitee breaks a rule, you get in trouble as well, so you are encouraged to only invite people you trust. The system has worked well for a long time, and some of these communities still thrive because of the trust that is built.reply",
      "eID is the obvious answer here in Europe. Right now it's kinda scattered with different providers, but I believe EU is working on a more universal protocol. Unfortnately there are rumors it will require official Google/Apple play stores, unrooted devices, and all that it does today already.But it should be treated as a relatively safe ID, it's even used for voting. If you feel uncomfortable, just have one device for eID, and one for everything else.I think it's a great tool if we want to implement some sort of liquid democracy feature.reply",
      "So a local ballot box.Host a platform like this at city hall, county building, capitol building, schools.Only a human can access a terminal. Have humans monitor ingress/egress.A more generalized solution that solves the specific problem inherent to all these digital ones.reply",
      "We really need proof of soul systems to exist, extended to also have a proof of citizenship. While the proof of soul systems can plausible be done in a decentralized manner, proof of citizenship is much harder, and in my opinion this is one of (the few) things the government should really do.reply",
      "What about Zero-Knowledge Identity? Use zero knowledge proofs to prove that I have an eID without actually providing my identity.reply",
      "Something like a cert chain, but it would need to be both simple to use and secure.  Those two requirements are greatly at odds with each other.reply",
      "Yeah one reason I think the government has to offer this is usability. While you can imagine a purely p2p protocol between cypherpunks, for everyone else there needs to be a way to social workers, DMV staff, etc can deal with edge cases (such as your id being stolen and needing a reset). Furthermore it helps if it's super illegal to tamper with this network (consider how rare check fraud is, despite being easy).reply",
      "Check fraud is easy to commit but not easy to get away with while also benefiting financially.It's also illegal to steal things but that happens much more frequently because it's often fairly easy to get away with."
    ],
    "link": "https://pol.is/home2",
    "first_paragraph": ""
  },
  {
    "title": "Improving 15 LLMs at Coding in One Afternoon. Only the Harness Changed (can.ac)",
    "points": 565,
    "submitter": "kachapopopow",
    "submit_time": "2026-02-12T13:30:20 1770903020",
    "num_comments": 225,
    "comments_url": "https://news.ycombinator.com/item?id=46988596",
    "comments": [
      "I really enjoyed this article. I think the author is precisely right and I've been saying this for a long time. There's a ton of extremely interesting low hanging fruit that can vastly improve the effectiveness of even currently existing models hiding in how we design our agent harnesses; enough to \u2014 at least until we hit diminishing returns \u2014 make as much or more of a difference than training new models!I think one of the things that this confirms, for me at least, is that it's better to think of \"the AI\" as not just the LLM itself, but the whole cybernetic system of feedback loops joining the LLM and its harness. Because, if the harness can make as much if not more of a difference, when improved, as improvements to the model itself, then they have to be really considered equally important. Not to mention the fact that models are specifically reinforcement learned to use harnesses and harnesses are adapted to the needs of models in general or specific models. So they necessarily sort of develop together in a feedback loop. And then in practice, as they operate, it is a deeply intertwined feedback loop where the entity that actually performs the useful work, and which you interact with, is really the complete system of the two together.I think thinking like this could not only unlock quantitative performance improvements like the ones discussed in this blog post, but also help us conceive of the generative AI project as actually a project of neurosymbolic AI, even if the most capital intensive and a novel aspect is a neural network; and once we begin to think like that, that unlocks a lot of new options and more holistic thinking and might increase research in the harness area.reply",
      "My Weird Hill is that we should be building things with GPT-4.I can say unironically that we haven't even tapped the full potential of GPT-4. The original one, from 2023. With no reasoning, no RL, no tool calling, no structured outputs, etc. (No MCP, ye gods!) Yes, it's possible to build coding agents with it!I say this because I did!Forcing yourself to make things work with older models forces you to keep things simple. You don't need 50KB of prompts. You can make a coding agent with GPT-4 and half a page of prompt.Now, why would we do this? Well, these constraints force you to think differently about the problem. Context management becomes non-optional. Semantic compression (for Python it's as simple as `grep -r def .`) becomes non-optional. Bloating the prompt with infinite detail and noise... you couldn't if you wanted to!Well, surely none of this is relevant today? Well, it turns out all of it still is! e.g. small fix, the \"grep def\" (or your language's equivalent) can be trivially added as a startup hook to Claude Code, and suddenly it doesn't have to spend half your token budget poking around the codebase, because -- get this -- it can just see where everything is... (What a concept, right?)-- We can also get into \"If you let the LLM design the API then you don't need a prompt because it already knows how it should work\", but... we can talk about that later ;)reply",
      "I am in the same boat. I have built bunch of bash/shell scripts in a folder back in 2022/2023. When models first came out, I would prompt them to use subshell syntax to call commands (ie: '$(...)' format)I would run it via calling AWS Bedrock API through AWS-CLI. Self iterating and simple. All execution history directly embedded within.Soon after, I wrote a help switch/command to each script. Such that they act as like MCP. To this day, they outperform any prompts one can make.reply",
      "The problem with these exercises is always: I have limited time and capacity to do things, and a fairly unlimited number of problems that I can think of to solve. Coding is not a problem I want to solve. Prompt engineering is not a problem I want to solve.If I do things for the love if it, the rules are different of course. But otherwise I will simply always accept that there are many things that improve around me, that I have no intimate knowledge of and probably never will, and I let other people work them out and happily lean on their work to do the next thing I care about, that is not already solved.reply",
      "> Well, surely none of this is relevant today? Well, it turns out all of it still is! e.g. small fix, the \"grep def\" (or your language's equivalent) can be trivially added as a startup hook to Claude Code, and suddenly it doesn't have to spend half your token budget poking around the codebase, because -- get this -- it can just see where everything is... (What a concept, right?)Hahaha yeah. This is very true. I find myself making ad hoc versions of this in static markdown files to get around it. Just another example of the kind of low hanging fruit harnesses are leaving on the table. A version of this that uses tree sitter grammars to map a codebase, and does it on every startup of an agent, would be awesome.> My Weird Hill is that we should be building things with GPT-4.I disagree, IMO using the best models we have is a good way to avoid wasting time, but that doesn't mean we shouldn't also be frugal and clever with our harnesses!reply",
      "To clarify, I didn't mean we should be using ancient models in production, I meant in R&D.Anthropic says \"do the simplest thing that works.\" If it works with the LLMs we had 3 years ago, doesn't that make it simpler?The newer LLMs mostly seem to work around the poor system design. (Like spawning 50 subagents on a grep-spree because you forgot to tell it where anything is...) But then you get poor design in prod!reply",
      "Ive been working on Peen, a CLI that lets local Ollama models call tools effectively. It\u2019s quite amateur, but I\u2019ve been surprised how spending a few hours on prompting, and code to handle responses, can improve the outputs of small local models.https://github.com/codazoda/peenreply",
      "Very cool. Love to see more being squeezed from smaller models.reply",
      "Also, yes, I'm aware that I use a lot of \"its not just X, its Y.\" I promise you this comment is entirely human written. I'm just really tired and tend to rely on more wrote rhetorical tropes when I am. Believe me, I wrote like this long before LLMs were a thing.reply",
      "It didn\u2019t read as AI to me :)reply"
    ],
    "link": "http://blog.can.ac/2026/02/12/the-harness-problem/",
    "first_paragraph": ""
  },
  {
    "title": "Recoverable and Irrecoverable Decisions (herbertlui.net)",
    "points": 33,
    "submitter": "herbertl",
    "submit_time": "2026-02-12T23:08:01 1770937681",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=46996569",
    "comments": [
      "https://www.goodreads.com/author/quotes/402425.Steve_Blank#:...reply",
      "Often framed as \u201cone vs two-way doo decisions\u201d at Amazon.Video of Bezos talking about this: https://www.youtube.com/watch?v=rxsdOQa_QkM.IMO it\u2019s a useful decision making strategy at times, mostly to not overthink the easily reversible.reply",
      "(delayed)Only difference is time. Much like an eventually consistent transactions, recoverable decisions have propagation latency.The breaking part here is that will you able to survive until the recovery is complete?reply",
      "what? this article is making a different point if you read past the title.> Conventional leadership advice suggests looking at decisions as reversible or non-reversible. Many important, non-reversible, decisions are recoverable, though.reply",
      "I don\u2019t think it\u2019s different. Recoverable == Reversible to an extend. Unless you take reversible in the strictest sense of \u201cundo\u201d it\u2019s different. But you can\u2019t \u201cundo\u201d a leadership decision, all you can do is later correct it and recover.So imo it\u2019s splitting hairs over the same outcome.An example - say you introduce 5 day return to office. Half you staff leaves and you now go back to a flexible work from home model. You don\u2019t \u201cundo\u201d the damage done, but you can recover. It was a costly 2-way door.reply",
      "Timing is everything. A bad haircut decision right before the most important job interview of your life might not be recoverable.Great Clips or Weldon Barber, are you feeling lucky?reply",
      "Great concept. Culturally, I think we are better at understanding this than ever before.In the last 15\u201320 years, many people have been forced into an uncomfortable moment due to job loss (Great Recession, COVID, AI etc). They have learned to recover. Could this be why we see more entrepreneurs than ever before now?reply",
      "For some reason before reading I thought this was going to be an AI thought leadership piece but it's even better than I expected.reply",
      "The main difference being the time it takes to recover/reverse the decision.Second point is: You don't need to reverse the decision you took, instead you may find a way to fix the impact but not the root-cause.It's like when one fucks up the MySQL replication and the  data consistency is corrupted. One can manually (and slowly) fix the inconsistency with downtime. Or, spin up a whole new cluster from an existing well-known node/state. Some entities may be missing, but you could gradually add them back later.Not a reversible, but recoverable decision.Amazon goes by with one-way vs two-way door decisions internally. Sometimes adding much bureaucracy to the equation. Just-do-it/Bias-for-action aspect usually don't go as far as the recovery period prolongs.reply",
      "I actually like hats, haircuts, and tattoos. Seldom we have irrecoverable decisions--except death. https://jamesclear.com/quotes/i-think-about-decisions-in-thr...(Also works well with LLMs, for risk assessments)reply"
    ],
    "link": "https://herbertlui.net/recoverable-and-irrecoverable-decisions/",
    "first_paragraph": ""
  },
  {
    "title": "Major European payment processor can't send email to Google Workspace users (atha.io)",
    "points": 454,
    "submitter": "thatha7777",
    "submit_time": "2026-02-12T14:24:15 1770906255",
    "num_comments": 309,
    "comments_url": "https://news.ycombinator.com/item?id=46989217",
    "comments": [
      "Message-ID is a requirement for Usenet where it came from.It is a requirement for being able to reply to messages and in general for email threading.Message-ID is a requirement to archive email.Practically every email client has included Message-ID since dial-up internet was fast and fashionable.Given all of the above I am amazed more places don't drop email without a Message-ID.Not including a Message-ID seems to be saying you don't want replies and you don't want your message to be archived.  That seems very shady to me.reply",
      "> Viva.com's outgoing verification emails lack a Message-ID header, a requirement that has been part of the Internet Message Format specification (RFC 5322) since 2008> ...> `Message-ID` is one of the most basic required headers in email.Section 3.6. of the RFC in question (https://www.rfc-editor.org/rfc/rfc5322.html) says:    +----------------+--------+------------+----------------------------+\n    | Field          | Min    | Max number | Notes                      |\n    |                | number |            |                            |\n    +----------------+--------+------------+----------------------------+\n    |                |        |            |                            |\n    |/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\n\n                             ... bla bla bla ...\n\n     /\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/|\n    | message-id     | 0*     | 1          | SHOULD be present - see    |\n    |                |        |            | 3.6.4                      |\n    |/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\n\n                             ... more bla bla ...\n\n     /\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/|\n    | optional-field | 0      | unlimited  |                            |\n    +----------------+--------+------------+----------------------------+\n\nand in section 3.6.4:    ... every message SHOULD have a \"Message-ID:\" field.\n\nThat says SHOULD, not MUST, so how is it a requirement?reply",
      "SHOULD is a requirement. It means that you have to do it unless you know some specific reason that the requirement doesn't apply in your case. \"I don't want to\" is not a valid excuse, \"I don't see a reason to\" isn't either.IIRC this particular rule is a SHOULD because MUAs often send messages without a Message-ID to their submission server, and the submission server adds one if necessary. https://www.rfc-editor.org/rfc/rfc6409.html#section-8.3 The SHOULD lets those messages be valid. Low-entropy devices that can't generate a good random ID are rare these days, but old devices remain in service, so the workaround is IMO justified.reply",
      "> SHOULD is a requirement.I once had a job where reading standards documents was my bread and butter.SHOULD is not a requirement. It is a recommendation. For requirements they use SHALL.My team was writing code that was safety related. Bad bugs could mean lives lost. We happily ignored a lot of SHOULDs and were open about it. We did it not because we had a good reason, but because it was convenient. We never justified it. Before our code could be released, everything was audited by a 3rd party auditor.It's totally fine to ignore SHOULD.reply",
      "Email is about standards like browsers were about standards in 2017...reply",
      "Yes, except there seems to be a move on the best words from SHALL to MUST and from SHOULD to MAY. \nIANAL but I recall reading this in e.g. legal language guidance sites.reply",
      "RFC language is expmicltly defined in 2119[0]. Any other interpretation is incorrect.[0] https://www.rfc-editor.org/rfc/rfc2119reply",
      "Thank you for that. So should is optional, people!reply",
      "Pulling exact quotes out, SHOULD means \"there may exist valid reasons in particular circumstances to ignore a particular item\" while MAY means \"an item is truly optional.\"I don't think this can be interpreted as simply \"should is optional\".reply",
      "I think that is a bit to easy. MAY is described ar optional.SHOULD - Should really be there. It's not MUST, you can ignore it but do not come crying if your email is not delivered to some of your customers !\nyou should have though about that before.reply"
    ],
    "link": "https://atha.io/blog/2026-02-12-viva",
    "first_paragraph": ""
  },
  {
    "title": "Beginning fully autonomous operations with the 6th-generation Waymo driver (waymo.com)",
    "points": 160,
    "submitter": "ra7",
    "submit_time": "2026-02-12T16:10:29 1770912629",
    "num_comments": 156,
    "comments_url": "https://news.ycombinator.com/item?id=46990578",
    "comments": [
      "Obviously there is a huge amount of money and effort being spent on automated driving. But I cannot help thinking that this perception technology will prove very useful for robotics in general, factory, home, in space, etc. Car dynamics are fast enough to be useful across a huge number of domains.In some sense, the visionaries in this space are not thinking big enough. I want visions of mobility with a totally different size, look, speed, etc. autonomous Golf carts? tuktuks? A moving autonomous bicycle carrier? etcLike imagine a low speed, electric, autonomous, golf-cart-only lane at every train station, for the last mile.The lead that Waymo has acquired in perceiving its driverless car's environment will be almost impossible to kill. In about 5 years, it'll be like NVidia and CUDA. Tesla's choice to abandon lidar will be one of the biggest oof in business history.reply",
      "From an execution standpoint you can't work on experimental mobility due to path dependence. How are they going to convince municipal governments to open golf cart lanes? That would require solving two problems (autonomy and overcoming path dependence), and solving just one is hard enough. Once they saturate the market as it is with autonomous driving, then everything will change and opportunities to experiment will open up.Neal Stephenson wrote a short essay on path dependence that I really like-- https://slate.com/technology/2011/02/space-stasis-what-the-s....reply",
      "Plenty of people have voiced much larger visions, for decades. There was a spate of futurists in the 80s, Waymo itself, and others like Dave Ferguson of Nuro. But autonomous vehicles have been an incredibly volatile industry. Anyone shooting for the moon (that's not seemingly immune to market pressures) has had those grand visions beaten down by the whiplash of funding. Companies have responded by focusing on those those first, real steps to demonstrate the \"easy\" stuff. The experimental stuff will come later when they're looking for ways to expand and investor money is more confident in the technology's future.reply",
      "Tesla never had lidar so they didn't abandon it.Also, Tesla started FSD in 2016. The very core of their strategy was (and is) to sell $40k car with hardware capable of running FSD.Cameras are super cheap, FSD chip is reasonably inexpensive. Lidar is not. Maybe today the cost isn't completely prohibitive (I think it still is, because you need multiple lidars) but it certainly was for the first 8 years of FSD program.Tesla just didn't have the luxury of adding $50k to the cost of the car for the hardware, the way Waymo did. And they didn't have sugar daddy (Google) willing to burn several billions a year for many years.So the Waymo approach was not an option for Tesla.And given that in Austin they just reached parity with Waymo (i.e. completely unsupervised robotaxi service), they are not doing badly.reply",
      "> And given that in Austin they just reached parity with Waymo (i.e. completely unsupervised robotaxi service), they are not doing badly.There is no unsupervised robotaxi service in Austin and there won't be, for years, if ever. Just like the way \"FSD\" is not fully self driving and likely never will be.reply",
      "According to https://robotaxitracker.com/ there are 7 unsupervised robotaxi in Austin right now.reply",
      "Are these the cars where the safety driver is in a car tailing the robotaxi, or do they actually run without the need for a safety driver?https://electrek.co/2026/01/22/tesla-didnt-remove-the-robota...reply",
      "It seems they run without a safety driver or follow car (mostly?).However the area it operates is extremely small, and they are still only allowing Tesla bros to try it.reply",
      "So in other words, like literally every other word out of Elon\u2019s mouth for a decade now, it\u2019s incredibly dishonest. He lies about everything, all the time, without any acknowledgment. Nothing is ever delivered on time, most of it isn\u2019t delivered at all, and virtually every bit of promised capability is exaggerated.Why does anyone want to do business with a person or company like that? I genuinely do not understand.reply",
      "> And they didn't have sugar daddy (Google) willing to burn several billions a year for many years.Tesla's market cap is $1.3 trillion. Granted the company itself doesn't have access to all of that, but surely if they wanted to spend, say, $10 billion per year on something big like FSD, they could have.> didn't have the luxury of adding $50k to the cost of the car for the hardwareA little more extreme, but: Tesla has sold something like 8.5 million cars total. If they simply dumped an extra $50K of material into every single one of those cars without raising the price a dime, that would be only $425 billion. That's a ridiculous sum of money, but still <checks notes> substantially less than $1.3 trillion.reply"
    ],
    "link": "https://waymo.com/blog/2026/02/ro-on-6th-gen-waymo-driver",
    "first_paragraph": "Satish Jeyachandran, Vice President of EngineeringWaymo will begin fully autonomous operations with its 6th-generation Driver \u2014an important step in bringing our technology to more riders in more cities. This latest system serves as the primary engine for our next era of expansion, with a streamlined configuration that drives down costs while maintaining our uncompromising safety standards. Designed for long-term growth across multiple vehicle platforms, this system\u2019s expanded capabilities allow us to safely broaden our footprint into more diverse environments, including those with extreme winter weather, at an even greater scale.The 6th-generation Waymo Driver is the product of seven years of safety-proven service amassed from driving nearly 200 million fully autonomous miles across the densest cores of 10+ major cities and an expanding network of freeways. Our experience as the only company operating a fully autonomous service at this scale has reinforced a fundamental truth: demonstr"
  },
  {
    "title": "Launch HN: Omnara (YC S25) \u2013 Run Claude Code and Codex from anywhere",
    "points": 96,
    "submitter": "kmansm27",
    "submit_time": "2026-02-12T17:14:28 1770916468",
    "num_comments": 126,
    "comments_url": "https://news.ycombinator.com/item?id=46991591",
    "comments": [
      "Congrats on the launch. I've been fooling around with using my pipecat MCP(https://github.com/pipecat-ai/pipecat-mcp-server) with WebRTC. The WebRTC is hooked into a Webapp interface and this allows me to  \"talk\" to different containers(projects) on my truenas.I have just a list of chat sessions on the web app on all my projects. The webapp is modified to launch claude code daemons (borrowed from humanlayer/codelayer) and exposes the outbound STT from the WebRTC into a chat session.- MCP Auth is via auth0- Webapp itself is gated by a Bearer token.This itself gets me pretty far. I am not sure what more this is offering?My TTS/STT models are local by Kyutai and the voice agent's LLM between STT and TTS is used to determine some basic context: e.g. what project directories, mcp servers to select and what skills to use for launching the daemons.reply",
      "This sounds solid, similar stuff to what we do! Sounds like this setup gets you most of the way there. We also have a mobile app + notifications. And I haven't tried using a coding voice agent via MCP, I'll try that out soon!reply",
      "Good to know its similar. Oh I actually do have a text box as well, but using it to type from the phone is not very convenient. Too much typing, I generally STT into the text box. I don't use it to code much, unless I have specced it out and I know the spec is good. But then to code it up is just a few mins, no?I spend my time trying to tuning the voice+webapp experience: i.e. how it can explain things, can it surface thinking tokens from claude tools properly etc.  The sweat, blood, voice go into `/create_research -> /create_plan` loop before the `/implement_plan`. Sometimes I copy the research and paste it into chatGPT for review or comments as well.I generally use the MCP to get it to follow commands and  explain things to me to make progress in this cycle, and I often pause it and ask for drawing me a mermaid a sequence diagram for events or a block diagram showing how pieces go together.reply",
      "There's a lot of negative feedback in this thread, so let me say I'm really excited to try this! I have caring responsibilities at home that means I'm constantly switching between my laptop and phone. Claude code web has been a very useful tool for this, but it's not a great bit of software. Omnara looks much more configurable and thought out. I've looked for various solutions to this problem that just work, and nothing else mentioned in this thread fits the bill. Your demo looks like it nails it - I'm excited to try!reply",
      "Thank you! Yeah, a big selling point of Omnara is that it \"just works.\" Let me know how it goes!reply",
      "First impressions are good! Couple of small bits of feedback:- I only had the option to create a worktree from main. I'd like to be able to pick any starting branch. Not a big deal, I just told claude to checkout the branch I wanted as my first instruction.- For some reason in the Android app the usual automatic capitalisation of the first letter in a sentence doesn't work. Claude probably doesn't care, but I like to type in proper sentences!- It would be nice if the worktree names got semantic names, e.g. by running my first prompt through Haiku. Maybe that's not the order things are set up in thoughreply",
      "> branching not from mainThis is actually a PR that I have open right now, it'll be out soon!> automatic capitalizationWe'll get this fixed> automatic worktree namesdefinitely on our roadmap, probably will do that this weekreply",
      "Why don\u2019t use Happy Code?\nIt\u2019s open source and free to use: https://github.com/slopus/happyreply",
      "We've seen a decent amount of comparisons to Happy, but anecdotally from some Omnara users who have used both, I've heard that reliability and latency when sending messaages is much better in OmnaraWe try to provide more features on top as well, including (but not limited to):* improved web interface* worktrees* sandboxing* richer git management (richer diffs, checkpoints, git operations)* preview URLsreply",
      "Stability was our (Happy) temporary problem, since our DB grown to reach like a TB now, but since we upgraded it is much much better.reply"
    ],
    "link": "item?id=46991591",
    "first_paragraph": ""
  },
  {
    "title": "Rari \u2013 Rust-powered React framework (rari.build)",
    "points": 103,
    "submitter": "bvanvugt",
    "submit_time": "2026-02-12T19:15:47 1770923747",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=46993596",
    "comments": [
      "ok so I actually like this, but the description and documentation in general are terrible\"rust-powered\" meaning it uses rolldown to bundle the javascript, that's fine, but it's a weird thing to highlight, it's confusing for people that aren't super familiar with vite and might think this is a rust frameworkfrom the docs \"one of rari's superpowers is seamless NPM package integration\" this makes me think the docs are LLM-written... npm package integration, like every other javascript library.now, the good: there's very few simple frameworks for react (react router and tanstack) and I think the simplicity here on going from an empty project to RSCs is absolutely great, and should be the taglineI was also happily surprised at how mature the codebase is in comparison to the docs, the vite plugin actually supports a lot of the options I would have expected to see, they're just not documented yetedit: I realised after digging a bit deeper this actually does have a rust runtime that runs the js, that was not very clear... is this separate from the framework or does the framework only run in the rust runtime? eg can it run on node?reply",
      "You're right about the messaging being confusing, I've been writing everything solo, so I'm definitely open to PRs that help with the copy. To clarify: \"Rust-powered\" refers to the server runtime itself, not just the bundler. The actual HTTP server, RSC renderer, and routing are all written in Rust (using an embedded V8 engine to execute your React components). It's not just Rolldown doing the bundling.On the npm integration point: what I should have said is that rari's Rust runtime handles traditional node_modules resolution (require/import from node_modules), which is actually pretty rare for Rust-based JS runtimes. Deno, for example, uses npm specifiers instead of node_modules.Great feedback on the tagline too. \"Zero to RSC in minutes\" is way clearer than what we have now. The codebase is definitely ahead of the docs, I've been focused on getting the runtime solid first, but clearly need to catch the documentation up.Thanks for taking the time to dig in and give constructive feedback. This is exactly the kind of input that helps make it better.reply",
      "Yeah I wrote my comment initially thinking it was just rolldown being used, so the \"rust-powered\" was confusing, I think the tagline is actually ok now that I know this, but really you're doing two things here1/ an alternative framework for RSCs similar to nextjs, tanstack or react router2/ a rust runtime for javascript, similar to node, deno or bun (except maybe not as general purpose)reply",
      "Exactly! Those are the two main layers.The runtime piece is definitely less general-purpose than Node/Deno/Bun. It's optimized specifically for React Server Components with things like streaming, Suspense boundary handling, and server action execution baked in. You wouldn't use it to run arbitrary JS apps.reply",
      "V8 is C++, so why isn't it \"C++ powered\"?reply",
      "Technically you could say that, but the entire server runtime is written in Rust. V8 is just the embedded JavaScript engine. By that logic, every Node.js or Deno app would be \"C++ powered\" since they all use V8.reply",
      "They are using Denoreply",
      "agree about the messaging, and i think this is actually the make or break problem for any new framework at this point. the react ecosystem has so many options that developers are numb to \"another react framework\" announcements.the real pitch buried in the confusing docs is: same react code you already know, but running on a rust server instead of node. that's actually compelling because it's additive, not a rewrite. but it took reading the HN comments to understand that, which is exactly the problem.fwiw the \"zero to RSC in minutes\" tagline the author mentioned below would've gotten me to click the docs immediately. most of us just want to ship something without a three day yak shave through webpack/vite/turbopack configuration.reply",
      "It's like beating a dead horse. React is the literal worst of all the modern JavaScript frameworks and yet that's what everybody insists on using. Vue is light years ahead of it (and will be even further ahead when the new Vapor mode is released in 3.6). Svelte is ahead. Solid is ahead. Heck, even Marko is ahead.reply",
      "Reacts added some poor abstractions over the last decade. Looking at you hooks and effects.But its far from the worst.It was the first framework to put together JSX, a functional way of defining components and simplifying state. This was a monumental improvement. As a result they earned mass adoption.As a result its the framework that now has a community moat that is not going to crumble until someone else can break ground in the way they did.Sure, some of these could be considered \"better\" but they're all better due to incremental improvements for Frontend Engineering.None of which are substantial enough to unseat the kingreply"
    ],
    "link": "https://rari.build/",
    "first_paragraph": ""
  },
  {
    "title": "Fixing retail with land value capture (worksinprogress.co)",
    "points": 62,
    "submitter": "marojejian",
    "submit_time": "2026-02-12T20:44:17 1770929057",
    "num_comments": 98,
    "comments_url": "https://news.ycombinator.com/item?id=46994869",
    "comments": [
      "This is a vexing problem I was made aware of by friends that are in the retail business, renting their stores from landlords. It's really brutal. Retailers take on all the risk, put in the work to revitalize a neighbourhood, and their reward is that when lease renewal comes up in 10 years, it spikes and they're faced with a choice of being displaced or handing over an enormously increased part of their margins to the landlord which has done literally nothing.The others that benefit are the nearby condo developers, that take photos of cool retail in the area to put into their brochures in order to help sell their product. They benefit from the land speculation and the work from others.I don't really have a solution except that I can see that the landlords benefit from scarcity, and their leverage and ability to raise rents would be lessened if there was more viable retail spaces to take advantage of.So the city could help retailers by dramatically liberalizing retail zoning and allowing more competitive high streets to develop. This could take the edge off being forced to move by a landlord jacking up rent.reply",
      "> Retailers take on all the risk, put in the work to revitalize a neighbourhood, and their reward is that when lease renewal comes up in 10 years, it spikes and they're faced with a choice of being displaced or handing over an enormously increased part of their margins to the landlord which has done literally nothing.This happens on the personal side as well, where property tax rates are artificially depressed - or more accurately, subsidized - until the property changes hands. When we bought our nearly 30 year old house that had had zero improvements, additions, or renovations since initial construction, our property tax bill increased 300% and has since \"stabilized\" to +10% a year.What is truly insidious about this is that it's impossible to guess or estimate until you've already purchased the home, and by then it's too late to do anything about it except complain at the courthouse, which might get you a year's abatement if you're lucky.If we let property taxes just be whatever they \"should\" be without penalizing home-buying in the process you could at least know what you'd be paying rather than having to factor in a 3-5x increase.reply",
      "> If we let property taxes just be whatever they \"should\" be without penalizing home-buying in the process you could at least know what you'd be paying rather than having to factor in a 3-5x increase.I wouldn't be surprised to hear this varies by jurisdiction. In CA, which has large property tax jumps on sales thanks to Prop 13, it seems like you can know the annual property taxes in advance. The sale price is the taxable valuation* and  you can find what the local tax rate is (or you can infer it pretty closely from another recently sold home's public municipal taxes paid).So solves one problem, but is still problematic :)*I assume this is the general case, anyways; maybe there's details I'm forgetting about separate tax rates on the land and the improvements; the split of the overall proper value between those two categories was mystifying when I bought...reply",
      "Where is this?As far as I know, my area doesn\u2019t do that. The assessments go up over time, but there\u2019s no large jump on transfer of ownership.reply",
      "This is in California.The hand-wavy explanation is that in the late 70's when this initiative passed (Prop 13), home values were rising rapidly due to an influx of people moving to the state and higher inflation rates of the times.  Many people that owned homes, including those that had purchased their homes and retired, were getting priced out of their homes on the property tax rates.  There are other rationales or rationalizations depending on where you come down on it.  But Prop 13 was intended to slow property tax growth while you owned the property, with assessment reset to full market value at sale time.reply",
      "California - proposition 13.reply",
      "There seems a bit of inner conflict in what you're saying. If retailers \"revitalizing a neighborhood\" leads indirectly to them getting priced out due to rising land values, isn't it also true that poor people living in the neighborhood get priced out at the same time? Is it a good or bad thing to make a neighborhood more hip, is the retailer a hero or a villain?reply",
      "It's absolutely the case that poor residents get priced out and do not necessarily benefit from a neighbourhood becoming hip.The cool new retail is tangentially to blame through second order effects, but the real problem is the inflexibility of the system in responding to change which results in a shortage of housing, which means that the disruptive impact on low income persons is really severe as they have no where to move to when things become more expensive or they are evicted.Much like how the solution to increasing retail rents is more flexibility in retail zoning, so to is the solution for increasing rents.It's less of a big deal if a cheap lame neighbourhood suddenly becomes cool if you can easily bail out because there's plenty of affordable apartments elsewhere. The problem we're in is that there's a general shortage and so in many places, losing a long held apartment is like an existential crisis because everywhere else is even more expensive and there's a shortage.Another approach is that in redeveloping \"cool\" areas we could increase land/property taxes and developer fees so as to recapture the land lift and divert toward public realm projects that benefit existing long time residents. The area becoming cool and getting new condos pays for the new pool and new below market housing.Should be mentioned as an aside that the actions themselves of poor people can ultimately gentrify a neighbourhood just as much as retail. A neighbourhood can become known for a vibrant arts/music scene that ultimately gentrifies it not just because it has some bars, but because the working artist residents are they themselves creating the attracting works in putting on events and shows. They earn a meagre income as working artists but ultimately may displace themselves as condos come advertising themselves on the scene that they've created.Cyclical neighbourhood change I think is inevitable so I think what we really need to focus on is not necessarily finding ways to keep neighbourhoods the same, but giving people and retailers options so that when change happens, it's not disruptive and painful.reply",
      "Depends whether or not the city allows other neighbourhoods to exist/grow/change.  If the total floorspace in the city is fixed in regulations, then ofc anything done to improve conditions will hurt people on the bottom.  The people who can afford a \"revitalized neighbourhood\" would happily live in brand new housing built on top of land in the nearby mansion district, displacing no one, but city planners do not allow that - new apartments can only be added to the city stock by destroying old ones, new store floorspace can only be added by destroying old etc.  This forces everyone to play musical chairs with too few chairs and the only winners are those who own the chairs.reply",
      "I heard that in Japan, it's common for condo developers who want to buy out smaller buildings to compensate the owners with an equal amount of floorspace in the new building - not sure how common that practice actually is, but what a way to align incentives!reply"
    ],
    "link": "https://worksinprogress.co/issue/fixing-retail-with-land-value-capture/",
    "first_paragraph": "A lot of what we find interesting about cities is the retail within them. We lean on retail \u2013 shops, cafes, restaurants and so on \u2013 to make cities what they are. Urban economist Ed Glaeser called this the rise of the consumer city, showing how consumption agglomeration was becoming increasingly important, as well as production agglomeration, in driving up urban rents.When people say Hayes Valley in San Francisco or Williamsburg in Brooklyn are interesting neighborhoods, what they often mean is that they have interesting retail. Hayes Street is Hayes Street because of stores and restaurants, rather than something inherent about the streetscape. Williamsburg is Williamsburg because of its wine bars, taco trucks, and fancy coffee shops.\u00a0Subscribe for $100 to receive six beautiful issues per year.Yet the retail operating environment is as hard as it\u2019s ever been. Online shopping continues to capture market share, remote work reduces foot traffic, and crime eats into already-small margins. A"
  },
  {
    "title": "Apache Arrow is 10 years old (apache.org)",
    "points": 185,
    "submitter": "tosh",
    "submit_time": "2026-02-12T13:13:30 1770902010",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=46988438",
    "comments": [
      "if I could tell myself in 2015 who had just found the feather library and was using it to power my unhinged topic modeling for power point slides work, and explained what feather would become (arrow) and the impact it would have on the date ecosystem. I would have looked at 2026 me like he was a crazy person.Yet today I feel it was 2016 dataders who is the crazy one lolreply",
      "Indeed. feather was a library to exchange data between R and pandas dataframes. People tend to bash pandas but its creator (Wes McKinney) has changed the data ecosystem for the better with the learnings coming from pandas.reply",
      "I know pandas has a lot of technical warts and shortcomings, but I'm grateful for how much it empowered me early in my data/software career, and the API still feels more ergonomic to me due to the years of usage - plus GeoPandas layering on top of it.Really, prefer DuckDB SQL these days for anything that needs to perform well, and feel like SQL is easier to grok than python code most of the time.reply",
      "chdb's new DataStore API looks really neat (drop in pandas replacement) and exactly how I envisioned a faster pandas could be without sacrificing its ergonomicsreply",
      "Do people bash pandas? If so, it reminds me of Bjarne's quip that the two types of programming languages are the ones people complain about and the ones nobody uses.reply",
      "The creator of Pandas even bashes it: https://wesmckinney.com/blog/apache-arrow-pandas-internals/",
      "polars people do - although I wouldn't call polars something that nobody uses.reply",
      "I also use polars in new projects. I think Wes McKinney also uses it. If I remember correctly I saw him commenting on some polars memory related issues on GitHub. But a good chunk of polars' success can be attributed to Arrow which McKinney co-created. All the gripes people have with pandas, he had them too and built something powerful to overcome those.reply",
      "I saw Wes speak in the early days of Pandas, in Berkeley. He solved problems that others just worked around for decades. His solutions are quirky but the work was very solid. His career advanced a lot IMHO for substantial reasons.. Wes personally marched through swamps and reached the other side.. others complain and do what they always have done.. I personally agree with the criticisms of the syntax, but Pandas is real and it was not easy to build it.reply",
      "What's the difference between feather and parquet in terms of usage? I get the design philosophy, but how would you use them differently?reply"
    ],
    "link": "https://arrow.apache.org/blog/2026/02/12/arrow-anniversary/",
    "first_paragraph": "\nPublished\n\n    12 Feb 2026\n  \n\nBy\nThe Apache Arrow PMC (pmc) \nThe Apache Arrow project was officially established and had its\nfirst git commit\non February 5th 2016, and we are therefore enthusiastic to announce its 10-year\nanniversary!Looking back over these 10 years, the project has developed in many unforeseen\nways and we believe to have delivered on our objective of providing agnostic,\nefficient, durable standards for the exchange of columnar data.From the start, Arrow has been a joint effort between practitioners of various\nhorizons looking to build common grounds to efficiently exchange columnar data\nbetween different libraries and systems.\nIn this blog post,\nJulien Le Dem recalls how some of the founders of the Apache Parquet\nproject participated in the early days of the Arrow design phase. The idea of Arrow\nas an in-memory format was meant to address the other half of the interoperability\nproblem, the natural complement to Parquet as a persistent storage format.The first Arrow "
  },
  {
    "title": "Synthesizer Cartridge for the Atari 2600 (qotile.net)",
    "points": 3,
    "submitter": "harel",
    "submit_time": "2026-02-08T15:22:24 1770564144",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.qotile.net/synth.html",
    "first_paragraph": "Sorry, but a Javascript-enabled browser is required to email me.\n\n   Which controllers work with it and where do I get them?\n\n\n\n  Keyboard Controllers, Video Touch Pads (Star Raiders controller), and the\nAtari Kid's Controllers\n  will work.\nI usually use the Video\nTouch Pads which you can get on Ebay.  The \nKids Controller is also good and \nlooks great, but is usually a bit more expensive (about $20-$30 for a pair.)\n\n\n\n  Can I build my own keyboard controllers?\n\n\n\n  Yes, there is a schematic of the controller on Atariage,\n  and there is an open source circuit board by Sven Arweiler for a keyboard controller using cherry mx switches.\n\n\n\n   What all do I need to use Synthcart?\n\n\n\n  An Atari 2600 w/ power supply, TWO keyboard controllers, and a TV (or a VCR that includes a TV tuner and audio out).\n\n\n  Which Ataris will it work with?\n\n\n\n  It will work with all Atari 2600's including the Junior model (black and\nsilver).  It also works on the Atari 7800.  However, the 7800 doesn't have a\nB&W"
  }
]