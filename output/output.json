[
  {
    "title": "Apache ECharts (apache.org)",
    "points": 758,
    "submitter": "tomtomistaken",
    "submit_time": "2025-04-08T17:23:29 1744133009",
    "num_comments": 145,
    "comments_url": "https://news.ycombinator.com/item?id=43624220",
    "comments": [
      "We've tested almost every visualization library under the sun when building Briefer (https://briefer.cloud) and I can confidently say that Apache ECharts is the best.The main issues with other libraries is that they're either:(a) ugly\n(b) difficult to use (i.e. having to do things imperatively)\n(c) not flexible enoughApache ECharts solve these 3 problems. It's pretty by default, it allows us to mount/calculate the declarative spec for the graphs in the back-end and then only send the desired spec to the front-end so it can render, and it's also extremely flexible to the point we can support everything that traditional BI tools can do.We've never had to extend the lib to do anything new, everything we need is already there.Glad to see this great piece of work on top of HN.\n \nreply",
      "Did you compare to vega/vega lite? Curious to hear how they compared!\n \nreply",
      "I've used both, and while I think Vega has it's uses, it's not nearly as web developer friendly. Frontend engineers want a clear delineation between logic, composition and styling. By combining everything into a JSON document, you sacrifice that developer experience while introducing a lot of bespoke approaches.That said, I absolutely love the idea that a blob of JSON living in my database contains everything I need for my visualization. The reality is that not enough other people are willing to put in the effort to learn that syntax, making it somewhat of a selfish tech choice.\n \nreply",
      "I'll toss some props to `go-echarts` [1], which allows you to declare charts with Golang types and it all gets bound to JSON automagically by Golang's JSON marshaller.  I've used it for many projects and whenever there's an issue/PR, the maintainer responds quickly.It's fun to Go-embed JavaScript functions and SQL queries, for this weird blend of data, SQL, Go and Javascript.  Here's a Golang example that pulls data from a DuckDB and creates a baked-in candlestick chart file with JavaScript tooltips. [2][1] https://github.com/go-echarts/go-echarts[2] https://github.com/NimbleMarkets/dbn-duckduck-goose/blob/mai...\n \nreply",
      "This is so sick thank you for sharing. I do a lot of Go + DuckDB stuff. I\u2019ve done some janky JS / html/template stuff for charting so this will be fun to play with\n \nreply",
      "The only down side would be having to program in golang.\n \nreply",
      "After many trials with other libraries, my team settled on Apache ECharts last year, and we do not regret it: excellent documentation, performant, highly configurable yet easy to use, and supporting all the chart types we need (bars, stacked bars, maps, zoomable/scrollable time series, and scatter plots).\n \nreply",
      "how is it compared to ag-grid chart?\n \nreply",
      "We did not evaluate libraries that have a paid plan\n \nreply",
      "What about Vega?\n \nreply"
    ],
    "link": "https://echarts.apache.org/en/index.html",
    "first_paragraph": "Please visit the official Apache ECharts Website atApache ECharts provides more than 20 chart types available out of the box, along with a dozen components, and each of them can be arbitrarily combined to use.Easily switch between Canvas and SVG rendering. Progressive rendering and stream loading make it possible to render 10 million data in realtime.Manage data through datasets, which support data transforms like filtering, clustering, and regression to help analyze multi-dimensional analysis of the same data.The default design follows visualization principles, supports responsive design. Flexible configurations make it easy to customize.The active open source community ensures the healthy development of the project and contributes a wealth of third-party extensions.Automatically generated chart descriptions and decal patterns help users with disabilities understand the content and the stories behind the charts.You are welcomed to cite the following paper whenever you use ECharts in y"
  },
  {
    "title": "PostgreSQL Full-Text Search: Fast When Done Right (Debunking the Slow Myth) (vectorchord.ai)",
    "points": 44,
    "submitter": "VoVAllen",
    "submit_time": "2025-04-09T00:00:15 1744156815",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43627646",
    "comments": [
      "> Mistake #1: Calculating tsvector On-the-Fly (Major issue)I'm shocked that the original post being referred to made this mistake. I recently implemented Postgres FTS in a personal project, and did so by just reading the Postgres documentation on FTS following the instructions. The docs lead you through the process of creating the base unoptimized case, and then optimising it, explaining the purpose of each step and why it's faster. It's really clear that is what it's doing, and I could only assume that someone making this mistake is either doing so to intentionally misrepresent Postgres FTS, or because they haven't read the basic documentation.\n \nreply",
      "This is not my area of expertise so take this with a grain of salt, but my initial instinct was to question why you would need to store the tsvector both in the table and in the index (because the tsvector values will in fact be stored losslessly in a GIN index).The PG docs make it clear that this only affects row rechecks, so this would only affect performance on matching rows when you need to verify information not stored in the index, e.g. queries with weighted text or queries against a lossy GiST index. It's going to be use-case dependent but I would check if your queries need this before using up the additional disk space.\n \nreply",
      "Off topic but this kind of content marketing is excellent for any startup that tries to get its name out compared with a well-known competitor, like it is the case here with ParadeDB.\n \nreply"
    ],
    "link": "https://blog.vectorchord.ai/postgresql-full-text-search-fast-when-done-right-debunking-the-slow-myth",
    "first_paragraph": ""
  },
  {
    "title": "Obituary for Cyc (yuxi-liu-wired.github.io)",
    "points": 204,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-08T19:13:50 1744139630",
    "num_comments": 92,
    "comments_url": "https://news.ycombinator.com/item?id=43625474",
    "comments": [
      "I would argue that Lenat was at least directionally correct in understanding that sheer volume of data (in Cyc's case, rules and facts) was the key in eventually achieving useful intelligence. I have to confess that I once criticized the Cyc project for creating an ever-larger pile of sh*t and expecting a pony to emerge, but that's sort of what has happened with LLMs.\n \nreply",
      "https://ai-2027.com/ postulates that a good enough LLM will rewrite itself using rules and facts... sci-fi, but so is chatting with a matrix multiplication.\n \nreply",
      "How will the rules and facts be connected? By some discrete relationship?This stuff only works for math, and is the basis for the bitter lesson\n \nreply",
      "I doubt it. The human mind is a probabilistic computer, at every level. There\u2019s no set definition for what a chair is. It\u2019s fuzzy. Some things are obviously in the category, and some are at the periphery of it. (Eg is a stool a chair? Is a log next to a campfire a chair? How about a tree stump in the woods? Etc). This kind of fuzzy reasoning is the rule, not the exception when it comes to human intuition.There\u2019s no way to use \u201crules and facts\u201d to express concepts like \u201cchair\u201d or \u201cgrass\u201d, or \u201cface\u201d or \u201cjustice\u201d or really anything. Any project trying to use deterministic symbolic logic to represent the world fundamentally misunderstands cognition.\n \nreply",
      "> There\u2019s no way to use \u201crules and facts\u201d to express concepts like \u201cchair\u201d or \u201cgrass\u201d, or \u201cface\u201d or \u201cjustice\u201d or really anything. Any project trying to use deterministic symbolic logic to represent the world fundamentally misunderstands cognition.Are you sure?  In terms of theoretical foundations for AGI, AIXI is probabilistic but godel-machines are proof based and I think they'd meet criteria for deterministic / symbolic.  Non-monotonic and temporal logics also exist, where chairness exists as a concept that might be revoked if 2 or more legs are missing.   If you really want to get technical then by allowing logics with continuous time and changing discrete truth values, then you can probably manufacture a fuzzy logic where time isn't considered but truth/certainty values are continuous.  Your ideas about logic might be too simple, it's more than just Aristotle\n \nreply",
      "That is not what is suggested.\nLlm still fuzzy mess, but supervisor / self editing is rules based\n \nreply",
      "> There\u2019s no set definition for what a chair is.Sure there is: a chair is anything upon which I can comfortably sit without breaking it.\n \nreply",
      "I find this very amusing. In philosophy of science some 20+ years ago I had a wonderful prof who went through 3(?) periods of thought. He laid out this argument, followed by the arguments seen below in this thread in various ways, in a systematic way where he convinced you that one way of thinking was correct, you took the midterm, then the next day he would lead with \"everything you know is wrong, here's why.\". It was beautiful.He noted that this evolution of thought continued on until people generally argued that concepts/definitions that let you do meaningful things (your definition of meaningful, doesn't really matter what it is), are the way to go. The punchline at the very end, which happened to be the last thing I regurgitated on my last undergraduate exam, was him saying something along the lines of \"Science, it beats hanging out in malls.\"All this to say that if we read a little philosophy of science, that was done a long time ago (way before the class I took), things would make more sense.\n \nreply",
      "I have definitely broken chairs upon sitting in them, which someone else could have sat in just fine. So it's unclear why something particular to me would change the chair-ness of an object.Similarly, I've sat in some very uncomfortable chairs. In fact, I'd say the average chair is not a particularly comfortable one.\n \nreply",
      "For a micro-moment before giving in it was a chair, then it broke. Now its no longer a chair. Its a broken chair.\n \nreply"
    ],
    "link": "https://yuxi-liu-wired.github.io/essays/posts/cyc/",
    "first_paragraph": "Yuxi Liu April 1, 2025April 8, 2025The legendary Cyc project, Douglas Lenat\u2019s 40-year quest to build artificial general intelligence by scaling symbolic logic, has failed. Based on extensive archival research, this essay brings to light its secret history so that it may be widely known.Lenat\u2019s journey began with his PhD work on automated mathematical discovery through heuristic search. He observed that such systems initially make promising discoveries but quickly \u201crun out of steam\u201d as they exhaust their initial pool of heuristic rules. His follow-up system EURISKO, famous for winning tournament competitions by finding unconventional tactics, faced similar limitations. These experiences convinced Lenat that true AI needed a vast foundation of common sense knowledge to avoid intellectual exhaustion.In 1985, he launched Cyc to manually encode millions of facts and rules about common sense, predicting that once this \u201cknowledge pump\u201d was primed, the system would begin true machine learning "
  },
  {
    "title": "Brazil's government-run payments system has become dominant (economist.com)",
    "points": 425,
    "submitter": "jcartw",
    "submit_time": "2025-04-08T10:59:26 1744109966",
    "num_comments": 506,
    "comments_url": "https://news.ycombinator.com/item?id=43620279",
    "comments": [
      "I've been living in Brazil for the last 20 years.Pix revolutionised the way we transact in Brazil. I've used Pix to pay for things that cost only cents, and I have a friend who bought her house using Pix.  The system just works for any transfer amount. And it's so easy to use.Its speed is truly baffling, and so is its reliability. Never have I failed to make a Pix payment because of downtime. I never cease to be amazed by how fast money arrives in my Brazilian account when I make a withdrawal directly from my EUR wallet on Wise. I receive a push notification from my Brazilian bank before Wise finishes running the animation of confirmation of withdrawal. It's like magic.And it's so widespread that nowadays I don't even question whether someone accepts Pix. When I get in a taxi, no matter how old the driver is, it's certain that they take (and prefer) Pix.I've even had homeless people ask me for Pix instead of change on multiple occasions.Cryptocurrencies don't stand a chance.\n \nreply",
      "> I receive a push notification from my Brazilian bank before Wise finishes running the animation of confirmation of withdrawal. It's like magic.After I had to add a special animation for one email system so that user was sure that \"the core functionality of encrypting\" was indeed working (it took milliseconds in reality), your experience doesn't surprise me that much. But, in my \"IoT\" system we have a mix of devices. Our service can handle most requests in sub millisecond, but some devices (gprs) need at least minimum 1 second (20sec is still within time limit) to respond only because of slow connectivity.  And then I have a parking ticket machines where you press button, wait 2 seconds, it beeps, then after 2sec it changes screen to \"printing ticket\", then after 2s you get the ticket, where everything can be a local action (free ticket without payment). Technology is wild.\n \nreply",
      "The parking ticket machine might make things deliberately slow because the printer needs to warm up or something.Maybe it needs up to 5 seconds to warm up if it's in deep sleep, so splitting this into three 2s periods provides the least frustrating user experience.As soon as you need to deal with real hardware things always start to get complicated.\n \nreply",
      "More likely it's warming up the mobile comms state machine, without checking if it's actually needed. Unlike mobile phones which try to keep their data connection somewhat live, IoT things often drop back to the lowest state to save power (and possibly SIM cost)https://www.sharetechnote.com/html/Handbook_UMTS_RrcStateCha...\n \nreply",
      "The cell providers also get really opinionated about how much / how often your IoT device talks to the cell towers when they seek to approve your device.\n \nreply",
      "And programmed on BASIC Stamp on some godforsaken discontinued hardware. :)\n \nreply",
      "More likely it was written by some cheap interns and requires getting unique ticket id from server for \"controlling\" purposes. Then there is one part time employee (met him, small talked a little) who goes from car to car with terminal and checks if those tickets are valid. I have some experience with gprs systems here, so probable flow:- press button- gprs roundtrip about button press with \"no payment, free ticket\" (2s)- machine shows \"printing ticket\", asks server what to print (aka the idiotic unnecessary step)- gprs roundtrip (2s)- printer warmup? (?s)- prints ticket> to save power (and possibly SIM cost)Nope, costs per sim are monthly per card, until you hit the data limit, then per MB. Those machines typically have enough power to keep connection alive.\n \nreply",
      "More likely a parking machine needs to be accessible to all users, and some people get confused when technology works too fast.\n \nreply",
      "Perhaps if you get confused by fast things you shouldn't be driving?\n \nreply",
      "Perhaps if you're driving, the things around you need to give you time to react to other things around you. Fewer things are more frustrating than getting honked at because you pressed a button, then got distracted by a car pulling up which you needed to look at to be aware of, then missed the printer asking if you want a receipt, and then having to press another button to talk to someone to ask for a reprint which, of course, holds up the line of cars growing behind you while someone gets paged to come to the kiosk.\n \nreply"
    ],
    "link": "https://www.economist.com/the-americas/2025/04/03/brazils-government-run-payments-system-has-become-dominant",
    "first_paragraph": ""
  },
  {
    "title": "How Netflix Accurately Attributes eBPF Flow Logs (netflixtechblog.com)",
    "points": 100,
    "submitter": "simplesort",
    "submit_time": "2025-04-08T18:21:49 1744136509",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=43624888",
    "comments": [
      "I wonder how much of Netflix infra is on AWS. Feels like building a castle on someone else's kingdom at that scale; in light of the Prime Video investment, and I guess twitch too.\n \nreply",
      "At Coroot, we solve the same problem, but in a slightly different way. The traffic source is always a container (Kubernetes pod, systemd slice, etc.). The destination is initially identified as an IP:PORT pair, which, in the case of Kubernetes services, is often not the final destination. To address this, our agent also determines the actual destination by accessing the conntrack table at the eBPF level. Then, at the UI level, we match the actual destination with metadata about TCP listening sockets, effectively converting raw connections into container-to-container communications.The agent repo: https://github.com/coroot/coroot-node-agent\n \nreply",
      "https://retina.sh/ is a similar open source tool for Kubernetes.It's early and has some bugs but seems promising.\n \nreply",
      "Question to the Netflix folks: I saw a lot of in-house developed tools being quoted, do you guys have service mesh like linkerd ?Have you guys evaluated vendors like Kentik?I would love to get more insight into what do you guys actually do with flow logs? for example if I store 1 TB of flow logs, what value can I actually derive from them that justify the cost of collection, processing, and storage.\n \nreply",
      "I think Netflix does use an Envoy-based Service Mesh [1], and they roll their own control plane.https://netflixtechblog.com/zero-configuration-service-mesh-...\n \nreply",
      "If the goal of gathering and attributing VPC flows is to have a workload granularity flow logs, then imho gathering mesh level logs is more direct and atraight forward approach, because mesh(and workload orchestrator) are uniquely qualified to know when workload A is running on a host X and is trying to connect to workload B.Looking at Envoy access logs for example is more straightforward and simple aplroach, than running distributed ebpf and memory intensive large spark streaming job\n \nreply",
      "The blog post mentioned that \"The eBPF flow logs provide a comprehensive view of service topology and network health across Netflix\u2019s extensive microservices fleet, regardless of the programming language, RPC mechanism, or application-layer protocol used by individual workloads.\"Service mesh may have restrictions on the network protocols and may not cover all network traffic (like connections to Kafka and databases).\n \nreply",
      "Maybe Im missing something but can\u2019t you run workloads in separate network namespaces and then attach a bpf probe to the veth interface in the namespace? At that point you know all flows on that veth are from a specific workload as long as you keep track of what is running in which network namespaces?I wonder if it is possible with ipv6 to never (or you roll through the addresses so reuse is temporally distant) re use addresses which removes the problems with staleness and false attribution.\n \nreply",
      "I think thats pretty reasonable tbf and probably at a more 'simpler' scale and i use simple loosely because Netflix\u2019s container runtime is Titus, which is more bare metal oriented than, say, Kubernetes. It doesn\u2019t always isolate workloads as cleanly in separate netns per container, especially for network optimisation purposes like IPv6-to-IPv4 sharing.\"I wonder if it is possible with ipv6 to never... re use addresses which removes the problems with staleness and false attribution.\"Most VPCs (also AWS) don\u2019t currently support \"true\" IPv6 scaleout behavior. Buttt!! if IPs were truly immutable and unique per workload, attribution becomes trivial. It\u2019s just not yet realistic... maybe something to explore with the lads?\n \nreply",
      "so they didn't want to pay for AWS CloudWatch [1]; decided to roll their in-house network flow log collection; and had to re-implement attribution?i wonder how many hundreds of thousands of dollars network flow logs cost them; obviously at some point it is going to be cheaper to re-implement monitoring in-house.[1]: https://youtu.be/8C9xNVYbCVk?feature=shared&t=1685\n \nreply"
    ],
    "link": "https://netflixtechblog.com/how-netflix-accurately-attributes-ebpf-flow-logs-afe6d644a3bc",
    "first_paragraph": ""
  },
  {
    "title": "Tailscale has raised $160M (tailscale.com)",
    "points": 399,
    "submitter": "louis-paul",
    "submit_time": "2025-04-08T10:36:07 1744108567",
    "num_comments": 184,
    "comments_url": "https://news.ycombinator.com/item?id=43620141",
    "comments": [
      "I'm a fan of TS and have been a paying customer for work infra for almost a year now. It really is well put together and easy to use, but I do run up against some issues/complaints when diving deep that I hope they can work out:* The pricing tiers and included features by tier penalizes you in frustrating ways. The base plan is a reasonable $6/user/m, but if you want to use ACLs to control anything in a workable way, it jumps 3x to $18/u/m. Better solutions are available for that kind of money, and I shudder to imagine what the next tier ('call us') costs.* Subnet routing broke on Ubuntu (maybe other distros) recently, and there were no alerts, communication from TS, or TS tools to pinpoint/figure out what was going on. I stumbled on a solution (install subnet router on a Windows box), and from there I searched and found others with that issue. Lost half a day in emergency mode over that!* Better tooling to determine why it's falling back to DERP instead of direct for remote clients. DERP relays should be an absolute last resort to provide connectivity for Business-plan-level customers (very slow), and the way TS works just assumes any connectivity is fine.Overall, the simplicity and abstraction of complex VPN networking is wonderful, but if you have issues or advanced needs, you are immediately thrust into the low-level UDP/NAT/STUN world you were trying to avoid. At that point, you're better off using a traditional VPN (WG, OpenVPN, or heaven forbid, IPSec), because it ends up being more straightforward (not easier) without the abstractions and easy-button stuff.\n \nreply",
      "When I saw the new round, I was instantly worried about change in direction that will most likely come with this, and effectively drive away regular users from a tool that seems universally loved.Similar sentiment can be seen in the discussion from three years ago [1] when they raised $100M.[1] https://news.ycombinator.com/item?id=31259950\n \nreply",
      "When they raised the 100M three years ago, I'm pretty sure they said they didn't need it and were saving it for a rainy day (or words to that effect), always seemed very odd at the time. Two q's for anyone who cares to speculate: have they burnt the original investment already? And if not, why would they need more funding? AFAICS there's no real competition in the market place for their product today, the only thing I can conceive is that they have a secret 'tailscale 2' project in the wings which is massively developer or capital intensive. Let's hope it is nothing related to AI band wagoning :-)\n \nreply",
      "Hm OK well thinking out loud, $100M / 3 is $33M / year?I don't know much about Tailscale, nor about how much it costs to run a company, but I thought it was mostly a software company?I would imagine that salaries are the main cost, and revenue could cover salaries?  (seems like they have a solid model - https://tailscale.com/pricing)I'm sure they have some cloud fees, but I thought it was mostly \"control plane\" and not data plane, so it should be cheap?I could be massively misunderstanding what Tailscale is ...Did the product change a lot in the last 3 years?\n \nreply",
      "You're not wrong to think Tailscale is primarily a software company, and yes, salaries are a big part of any software company's costs.  But it's definitely more complex than just payroll.A few other things:1. Go-to-market costsEven with Tailscale's amazing product-led growth, you eventually hit a ceiling.  Scaling into enterprise means real sales and marketing spend\u2014think field sales, events, paid acquisition, content, partnerships, etc. These aren't trivial line items.2. Enterprise sales motionSelling to large orgs is a different beast.  Longer cycles, custom security reviews, procurement bureaucracy... it all requires dedicated teams.  Those teams cost money and take time to ramp.3. Product and infraThough Tailscale uses a control-plane-only model (which helps with infra cost), there's still significant R&D investment.  As the product footprint grows (ACLs, policy routing, audit logging, device management), you need more engineers, PMs, designers, QA, support.  Growth adds complexity.4. Strategic betsCompanies at this stage often use capital to fund moonshots (like rethinking what secure networking looks like when identity is the core primitive instead of IP addresses).  I don't know how they're thinking about it, but it may mean building new standards on top of the duct-taped 1980s-era networking stack the modern Internet still runs on.  It's not just product evolution, it's protocol-level reinvention.  That kind of standardization and stewardship takes a lot of time and a lot of dollars.$160M is a big number.  But scaling a category-defining infrastructure company isn't cheap and it's about more than just paying engineers.\n \nreply",
      "At least tailscale funnel isn't control-plane-only, unless I'm totally misunderstanding something\n \nreply",
      "[flagged]",
      "I can confirm that kenrose is an actual human being :-)\n \nreply",
      "Can likewise confirm dblohm7 is a real human too :)\n \nreply",
      "> I don't know much about Tailscale, nor about how much it costs to run a company$33m/year is only 33 fully loaded software developers including all overhead like HR and managers and office space, and also a cloud hosting bill.33 really isn't that many.\n \nreply"
    ],
    "link": "https://tailscale.com/blog/series-c",
    "first_paragraph": "Tailscale has raised $160 million USD ($230 million CAD) in our Series C, led by Accel with participation from CRV, Insight Partners, Heavybit, and Uncork Capital. Existing angel investor George Kurtz - CEO of Crowdstrike is also included in this round, as well as Anthony Casalena - CEO of Squarespace, who joins as a new investor for Series C.There\u2019s a lot packed into that sentence. But the real question is \u2014 why should you care?When we started Tailscale in 2019, we weren't even sure we wanted to be a venture-backed company. We just wanted to fix networking. Or, more specifically, make networking disappear \u2014 reduce the number of times anyone had to think about NAT traversal or VPN configurations ever again.That might sound simple, but it wasn\u2019t. Here we are, six years later, and millions of people rely on Tailscale every day, connecting their homelabs, their apps, their companies, their AI workloads. Some use it because they love networking and want better tools. Many use it because th"
  },
  {
    "title": "Solving a \u201cLayton Puzzle\u201d with Prolog (buttondown.com/hillelwayne)",
    "points": 53,
    "submitter": "Tomte",
    "submit_time": "2025-04-08T19:11:41 1744139501",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=43625452",
    "comments": [
      "Don't understand why the article uses SWI's constraint libs when the problem is easily solved using pure ISO Prolog with code readily linked from the article even ie Pablo's solution at [2].Just paste that code into [1] and append the line (or place it at the start, doesn't matter)    :- initialization(colin_score(X)).\n\nto tell Prolog which top-level goal to solve and hit Execute to see the solution in your browser.[1]: https://quantumprolog.sgml.net/browser-demo/browser-demo.htm...[2]: https://morepablo.com/2010/09/some-professor-layton-prolog.h...\n \nreply",
      "Very fun post!  If folks haven't seen it, Knuth's latest release looks at constraint satisfaction.  Really fun discussion on the relations between different ways to model this sort of problem.  Happy to add this book to my list!I would also challenge the author to consider puzzles a bit more.  Sprinkling fun into the topics goes a long way.  Specifically, do both!  Talk about how you can reframe a \"real world\" problem in terms of some puzzles we may have played as kids.  Invite us to play more as adults.\n \nreply",
      "if anyone wants a \"human\" solution1) there are 4 questions that everyone answered the same way (let's say this earned everyone A points)2) in the rest of the questions, 7-point and 5-point students gave opposite answersthat means that 7-A (rest of 7-point student's correct answers) equals to 5-(4-A) (rest of 5-point student's incorrect answers)7-A = 1+A => A=3That means 3-point student scored 3 points together with everyone else, and answered rest of the questions wrongFrom this it's trivial to find the hidden score and why there are 4 possible answer keys\n \nreply",
      "A puzzle from a game in this series https://en.wikipedia.org/wiki/Professor_Layton\n \nreply",
      "Related: https://news.ycombinator.com/item?id=35623625 (2023) \"Why Did Prolog Lose Steam (2010)\"Anecdotally, some years ago the Zebra Puzzle [1] made the rounds in my team. Two people solved it: myself, a young intern, who mapped out the constraints as a physical puzzle that I was able to solve visually, and a more seasoned colleague who used Prolog.[1] https://en.wikipedia.org/wiki/Zebra_Puzzle\n \nreply",
      "I once used Sentient[0] to solve a similar puzzle in a different game that I think made a puzzle that required a constraint solver as a joke on the player. I'm a bit saddened to see that the repo hasn't been updated in 6 years, and a node update broke the binary installed on my computer, I find it a much more ergonomic environment than Prolog, hopefully someone else will pick up the mantle.[0]: https://sentient-lang.org/\n \nreply",
      "Doing the puzzle with \u201cpencil and paper\u201d logic is actually quite approachable and fun! I recommend it. Hint: you don\u2019t need to run constraint satisfaction! There are some insightful shortcuts to be made\n \nreply",
      "The puzzle is easy enough to solve by brute force, but it seems like rather a lot to solve by hand for a very junior-targeted game.Heuristics could reduce trial-and-error to a reasonable search space, but is there a purely deductive way to solve this by hand?\n \nreply",
      "With the 4 common answers (all 4 people answered them the same) we know that no more than 3 of them can be correct (because Lisa scored 3 points). We also know at least one must be correct (otherwise Mary can't score 7).Examine what Mary and Dan have in common besides those 4... Nothing. They disagreed on each of the remaining 6 answers.We can break this down into three cases, either 1, 2, or 3 of the common answers are correct:1 - Impossible. Mary gets 6 of the remaining correct, Dan gets 4 of the 6 remaining correct, but they have none in common so this doesn't work.2 - Impossible. Mary gets 5 of the remaining correct, Dan gets 3 of the remaining correct, but again their answers disagree so they cannot share a common answer out of the 6 remaining.3. Mary needs 4 of the remaining 6 and Dan needs 2, this is feasible.At this point you can ignore the 4 common ones other than to say Colin has at least a score of 3.Since we now know that everything outside those common ones are incorrect for Lisa, cross everything off that Lisa and Colin share of the 6 non-common answers. There are only 3 that disagree with Lisa so they must be correct (because everything Lisa answered here is wrong). This gives Colin a final score of 6, three in common with everyone and three from disagreeing with Lisa.The reason there are 4 keys in Hillel's solution is actually kind of funny, they don't matter. Those 4 keys only disagree on which of the 4 common answers are incorrect. They agree everywhere else.EDIT: Presentation and some typos\n \nreply",
      "I'm more of a visual person when it comes to puzzles like these so here's my take:        1 2 3 4 5 6 7 8 9 10\n  Mary  B B A B A B B A B B   7\n  Dan   B A A A B A B A A A   5\n  Lisa  B A A A B B B A B A   3\n  Colin B B A A A B B A A A   ?\n\nFirst I remove the answers that everyone agreed on. We know that one of these 4 answers is wrong because of Lisa.        1 2 3 4 5 6 7 8 9 10\n  Mary  _ B _ B A B _ _ B B   7\n  Dan   _ A _ A B A _ _ A A   5\n  Lisa  _ A _ A B B _ _ B A   3\n  Colin _ B _ A A B _ _ A A   ?\n\nNext we can assume anything matching Lisa's remaining answers are wrong, so I will put an x for those. These we 100% know are wrong answers.        1 2 3 4 5 6 7 8 9 10\n  Mary  _ B _ B A x _ _ x B   7\n  Dan   _ x _ x x A _ _ A x   5\n  Lisa  _ x _ x x x _ _ x x   3\n  Colin _ B _ x A x _ _ A x   ?\n\nIf you count both the remaining answers and the blanks, you'll see they equal to their score + 1. That 1 being that unknown of the 4 original blank columns where everyone agreed.So the answer for Colin would by 6 because he has 7 remaining answers.\n \nreply"
    ],
    "link": "https://buttondown.com/hillelwayne/archive/a48fce5b-8a05-4302-b620-9b26f057f145/",
    "first_paragraph": "I have a lot in the works for the this month's Logic for Programmers release. Among other things, I'm completely rewriting the chapter on Logic Programming Languages. I originally showcased the paradigm with puzzle solvers, like eight queens or four-coloring. Lots of other demos do this too! It takes creativity and insight for humans to solve them, so a program doing it feels magical. But I'm trying to write a book about practical techniques and I want everything I talk about to be useful. So in v0.9 I'll be replacing these examples with a couple of new programs that might get people thinking that Prolog could help them in their day-to-day work.On the other hand, for a newsletter, showcasing a puzzle solver is pretty cool. And recently I stumbled into this post by my friend Pablo Meier, where he solves a videogame puzzle with Prolog:1Summary for the text-only readers: We have a test with 10 true/false questions (denoted a/b) and four student attempts. Given the scores of the first thre"
  },
  {
    "title": "Decomposing factorial of 300K as the product of 300K factors larger than 100K (gus-massa.blogspot.com)",
    "points": 60,
    "submitter": "gus_massa",
    "submit_time": "2025-04-08T18:28:06 1744136886",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43624977",
    "comments": [
      "A mathy construction like in the article is probably important for the full conjecture, but isn't this concrete case just an instance of the bin-covering problem? Your discrete items are the log of each prime factor (included according to its multiplicity), set the lower threshold to log(100k), and if you get any solution with 300k or more factors, you can redistribute the extra factors arbitrarily.\n \nreply",
      "Tao agrees with you: https://terrytao.wordpress.com/2025/03/26/decomposing-a-fact...\n \nreply",
      "In the same thread Tao commented https://terrytao.wordpress.com/2025/03/26/decomposing-a-fact... which shows work from Andrew Sutherland that got the 100k limit after about a day.As impressed as I am with this solution, it didn't get to be the first to solve the problem.\n \nreply",
      "HN thread for the Tao piece https://news.ycombinator.com/item?id=43506238\n \nreply"
    ],
    "link": "http://gus-massa.blogspot.com/2025/04/decomposing-factorial-of-300k-as.html",
    "first_paragraph": "\n\n\nA few days ago, Terence Tao proposed a challenge to decompose the 300K! as the product of 300K factors larger than 100K. A smaller example is decomposing 10! as the product of 10 factor greater or equal than 3.\u00a0 10! = 1 * 2 * 3 * 4 * 5 * 6 * 7 * 8 * 9 * 10\u00a0 10! = 3 * 3 * 4 * 4 * 4 * 5 * 5 * 6 * 6 * 7He was able to show a decomposition of 300K! as the product of 300K factors larger than only 90K, and proposed a method to try to use larger numbers. This is part of an attempt to prove a conjecture, so the complete problem is more general, but let\u00b4s try to solve this case.We will fix N=300K that is the case analyzed by Tao in the post. The idea by Tao is to start with a odd number B that is a product of 300K odds numbers larger than 100K, and attempt to fix the difference. One important point is that 300! is even, so the idea is to get try to use the 2 to help in this task.He defines the B-heavy primes that are the primes that appear more time in B than in N!=300!, and the N!-heavy prim"
  },
  {
    "title": "How to Recognize Woodpeckers by Their Drumming Sounds (allaboutbirds.org)",
    "points": 56,
    "submitter": "jamesriso",
    "submit_time": "2025-04-08T20:00:22 1744142422",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=43625864",
    "comments": [
      "This reminds me of how it's possible to decode prairie dog communication into literal 'words' that specify location of possible threats (lookup 'Slobodchikoff prarie dogs').  It's remarkable. Only made possible by the curious\u2013albeit eccentric\u2013human sitting in nature and listening in true analog.And, on the topic of tapping, I imagine even the cadence of our keystrokes can be used to construct meaningful browser fingerprints. We are always emitting so many artefacts that can be used to construct rich identities. It's a bit terrifying from a surveillence perspective but also very satisfying to create order from noise.\n \nreply",
      "I'll have to dig it up (maybe if I get time tomorrow I'll try), but I've seen a couple research papers where they wrote software that got was pretty effective at decoding peoples passwords by listening to them type. Between different keys sounding slightly different, the timing between keystrokes, and an individual's personal typing patterns, it's not even all that difficult. So yes, that sort of thing has definitely been done.\n \nreply",
      "Not listed is the red-bellied woodpecker. I've got one of them that drums on my gutters just outside my home office window every day. Multiple times a day. Fast, evenly spaced drumming with no variation or fall-off. Lasts 1-3 seconds. Maybe not quite as fast as the flicker, but close.I thought he was putting holes in my house for a while until I figured out what he was doing. I have a lot of flickers around too, but don't hear them drumming very often.\n \nreply",
      "Yeah, we got these red-bellied wodpeckers here, knocking on the metal top of the poles of the electricity lines. Since the main inlet is connect to a wall in our bed room, they wake us up early in the morning by their drumming, resonationg through the electricity lines from near and far.It have spent hours, half aslep, pondering what that sound could be, it took quite a while before I found the origin!\n \nreply",
      "If you put a suet cage out, they'll usually go for that and leave your house alone.I used to joke that they'll let you know when they're out of suet, by hammering your gutters to wake you up at 6am.\n \nreply",
      "It's likely that they're drumming on the gutter because the metal is loud. Drumming is both a way to get at food by digging under the bark and a way to signal for territory+mating. The signaling is the main reason that the drumming patterns are distinct!\n \nreply",
      "Amusingly, it wasn't until I put the feeder out (with suet and a bunch of other seed) that he started drumming. It wasn't right away; there was about a year or so where the red-bellied just came for the food. There were several different males and females back then. Now, I'm pretty sure it's just him. I've read that they can drum like this in part to mark territory, so maybe he's just trying to keep the food for himself. He still has to duke it out with all the other birds though. Can be pretty entertaining.And fortunately, I'm usually up by 4 or 5 am anyway so he's never woken me up, but yes, he's banging away really early.\n \nreply",
      "Is there a guide how to spot them? I live near a massive forest and I always hear them but never managed to actually see one. The sound is just coming from all over the place.\n \nreply",
      "It might sound silly, but just close your eyes and listen. Your brain is very good at localizing sounds. Turn to see if the sound direction moves or becomes more distinguishable. Tilting your head or moving a few steps in any direction can help in some environments.You'll develop an ear for it the more you practice.\n \nreply",
      "I loved hearing then in Hampstead Woods in North London, and also the trees along the New River (artificial canal intended to bring fresh water into the city, built in Tudor times)  - but it was quite difficult to see the little buggers. I did have a spotted one come to our bird table in Lincoln UK a some years ago, and my little brother who lives near Grantham quite often sees them.Lovely birds.\n \nreply"
    ],
    "link": "https://www.allaboutbirds.org/news/how-to-recognize-woodpeckers-by-their-drumming-sounds/",
    "first_paragraph": ""
  },
  {
    "title": "Analytic Combinatorics \u2013 A Worked Example (grossack.site)",
    "points": 72,
    "submitter": "mathgenius",
    "submit_time": "2025-04-08T17:29:29 1744133369",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=43624293",
    "comments": [
      "This is only tangentially related, but one thing that I am still kind of hopeful about is analytic combinatorics will free us from the tyranny of asymptotic analysis.I suppose this is kind of a hot take, and in some ways less relevant than it was (say) 10 years ago, but I believe the theoretical CS community has spent a lot of time analyzing the performance of various algorithms over the years and kind of pointedly not inventing algorithms which accomplish some result at all, even if it is only known to be computable in a pathologically inefficient way. This means a lot of breakthroughs that could have been TCS breakthroughs have been invented, usually worse, by other communities.I am not the only one who thinks so, here[1] is an obscure talk where Michael Mitzenmacher (a well-known CS theory prof at Harvard) makes more or less this specific complaint.One of the nice things about Flajolet/Sedgewick[2] (mentioned in this post) is that it gives a nice set of combinators for (at least it seems to me, in theory) precisely enumerating how many \"steps\" an algorithm would take given some input. I optimistically imagine a world where we replace the relatively non-specific asymptotic bounds of an algorithm with a very specific quantification of the work an algorithm will take. And that this in turn would free TCS to focus on things that are more germane to the field as a whole.With that all said I'm open to the argument that TCS has fundamentally changed and this is no longer such a big issue. But perusing the various TCS conferences I sense it isn't.[1]: https://www.youtube.com/watch?v=p3anjSAnKBo[2]: https://algo.inria.fr/flajolet/Publications/book.pdf\n \nreply",
      "> One of the nice things about Flajolet/Sedgewick[2] (mentioned in this post) is that it gives a nice set of combinators for (at least it seems to me, in theory) precisely enumerating how many \"steps\" an algorithm would take given some input. I optimistically imagine a world where we replace the relatively non-specific asymptotic bounds of an algorithm with a very specific quantification of the work an algorithm will take. And that this in turn would free TCS to focus on things that are more germane to the field as a whole.Check out the Art of Computer Programming, by Knuth. He writes all of the algorithms in a hypothetical machine code called MIX (MMIX in later editions). He does go through algorithmic analysis to the degree you describe, showing exactly how many cycles a particular routine may take to complete, based on different variables. This is actually fairly complex even for simple programs. Consider the simple case of computing the maximum in a list:    let current_max := 0\n    for x in array_of_numbers {\n        if x > current_max {\n            current_max = x;\n        }\n    }\n    return current_max;\n\n\nAnyone can tell you this runs in O(N) time. But exactly how many cycles would this take? Ignoring the architectural details, you would need to know how often the condition \"x > current_max\" is true. If the list of numbers is in ascending order, this will be true every time, if it is in descending order it will only be true once. The difference in the number of cycles between those two cases is significant. I believe Knuth works through this example, and shows that, for a randomly-ordered array, this would be true around log_2(n) times.\n \nreply",
      "I actually have read a chunk of the relevant TAOCP, but didn't mention it because the comment was already kind of long. I remarked to a friend the other day that it's kind of funny that we've a little bit come full circle on asymptotic analysis in that we are now counting FLOPs, and it is not a little bit like what Knuth does here. :)\n \nreply",
      "I don't think it's controversial to say that asymptotic analysis has flaws: the conclusions you draw from it only hold in the limit of larger inputs, and sometims \"larger\" means \"larger than anything you'd be able to run it on.\" Perhaps as Moore's law dies we'll be increasingly able to talk more about specific problem sizes in a way that won't become obsolete immediately.I suppose my question is why you think TCS people would do this analysis and development better than non-TCS people. Once you leave the warm cocoon of big-O, the actual practical value of an algorithm depends hugely on specific hardware details. Similarly, once you stop dealing with worst-case or naive average-case complexity, you have to try and define a data distribution relevant for specific real-world problems. My (relatively uninformed) sense is that the skill set required to, say, implement transformer attention customizing to the specific hierarchical memory layout of NVIDIA datacenter GPUs, or evaluate evolutionary optimization algorithms on a specific real-world problem domain, isn't necessarily something you gain in TCS itself.When you can connect theory to the real world, it's fantastic, but my sense is that such connections are often desired and rarely found. At the very least, I'd expect that to often be a response to applied CS and not coming first from TCS: it's observed empirically that the simplex algorithm works well in practice, and then that encourages people to revisit the asymptotic analysis and refine it. I'd worry that TCS work trying to project onto applications from the blackboard would lead to less rigorous presentations and a lot of work that's only good on paper.\n \nreply",
      "Average-case complexity can be a fickle beast. As you say, the simplex algorithm for LP is great in practice, so it's rarely problematic to use. But meanwhile, people also say, \"Modern SAT/SMT solvers are great, they can solve huge problems!\" Yet when I try using one, I usually run into exponential runtimes very quickly, especially for unsatisfiable instances.Overall, it's annoying to tell whether an NP-hard problem is always really hard, or if ~all practical instances can be solved with a clever heuristic. It doesn't help that most problems receive little attention (e.g., to find solvable special cases) after being labeled NP-hard.\n \nreply",
      "> most problems receive little attention (e.g., to find solvable special cases) after being labeled NP-hard.Since I know quite some people who exactly work on this kind of problem of finding special classes that can be solved in polynomial time, my impression is of course different.But I think it can be said that if some NP-hard problem is very important in practice and there is no easy way to to get around this problem (i.e. it will also be practically relevant in, say, 15 years), the problem will for sure get a lot more attention.This is also the reason why some NP-hard problems are much more researched than others.\n \nreply",
      "Yeah, perhaps I was a bit unfair, it's just that the problems that have gotten good results never seem to be the ones I need! C'est la vie, I suppose. (In particular, I've been working with recognizing small formal languages from samples, which has usually NP-hard, but has a surprising number of solvable cases. But my impression is that most modern work has gone into various forms of probabilistic grammars, which aren't really what I'm looking for.)Sometimes it's also helpful to look into approximation algorithms, e.g., a good LLL implementation can work wonders for certain problems. But heaven forbid someone obtains an inapproximability result for your problem, then you're really in trouble.\n \nreply",
      "> But heaven forbid someone obtains an inapproximability result for your problem, then you're really in trouble.This is not (necessarily) true:For example, there exists a great approximation algorithm (Goemans-Williamson algorithm) for MAXCUT in graphs with non-negative edge weights.On the other hand, when negative weights do occur, one can show (unless P=NP) that there exists no polynomial-time approximation algorithm for which the approximation guarantee is a constant factor times the optimal solution.But since the Goemans-Williamson algorithm is a great algorithm (if the Unique Games Conjecture holds, and P != NP, it has the best approximation guarantee that any approximation algorithm for MAXCUT with non-negative weights can get in polynomial time) nobody \"forbids\" you to use it in situations where also negative edge weights can occur. You will loose the approximation goodness guarentee, but in practice, this algorithm nevertheless gives good results in this situation, just not certified good results.\n \nreply",
      "I just meant that there are lots of problems where I think TCS could have contributed but didn't, because the relevant analysis was not acceptable at FOCS or SODA (or whatever). A good example is the original transformers paper, which is vastly over-complicated relative to (say) a later treatment[1] by Ruslan Salakhutdinov's lab, which shows that attention is \"just\" plain-old Nadaraya-Watson kernel smoothing\u2014which if you don't know is a weighted average of points covered in elementary grad stats.I'm not saying it was TCS people would be \"better\" at discovering this or anything like that, I'm just saying that the opportunity for contribution from TCS people is very high, and because the fields are not well-integrated you often have to wait years to uncover what ML concepts \"really\" are. I think working together would benefit both ML and TCS![1]: https://arxiv.org/pdf/1908.11775\n \nreply",
      "Coincidentally I just did an asymptotic complexity analysis yesterday (something I rarely do).  It seemed right since it's by the book but I wasn't sure.  After running the extensive benchmarks on the algorithm, I was so happy to find the results matched the asymptotic prediction.  The lesson is verify, verify, and always verify.[1] Algorithm, https://github.com/williamw520/toposort/blob/master/Algorith...[2] Benchmarks, https://github.com/williamw520/toposort/blob/master/README.m...\n \nreply"
    ],
    "link": "https://grossack.site/2025/04/08/analytic-combinatorics-example.html",
    "first_paragraph": "Math/Music. She/They.Another day, another blog post that starts with \n\u201cI was on mse the other day\u2026\u201d. This time, someone asked \nan interesting question amounting to \u201chow many unordered rooted \nternary trees with $n$ \nnodes are there, up to isomorphism?\u201d. I\u2019m a sucker for these kinds of \ncombinatorial problems, and after finding a generating function solution \nI wanted to push myself to get an asymptotic approximation using \nFlajolet\u2013Sedgewick style analytic combinatorics! I\u2019ve never actually \ndone this before, so I learned a lot, and I want to share some of the things \nI learned \u2013 especially how to do this stuff in sage!Now, you might be thinking \u2013 didn\u2019t you write a very similar blog post \nthree years ago? Yes. Yes I did. Did I also completely forget what \nwas in that post? Yes. Yes I did, haha. For some reason I was getting it mixed \nup with this other post from even more years ago, which isn\u2019t nearly \nas relevant. Thankfully it didn\u2019t matter much, \nsince I\u2019m fairly sure what I wanted"
  },
  {
    "title": "Better typography with text-wrap pretty (webkit.org)",
    "points": 176,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-08T15:10:29 1744125029",
    "num_comments": 81,
    "comments_url": "https://news.ycombinator.com/item?id=43622703",
    "comments": [
      "I find myself laughing at \"Many developers are understandably concerned about the performance of text-wrap: pretty.\"  I just can't bring myself to believe there is a meaningfully sized group of developers that have considered the performance of text-wrapping.\n \nreply",
      "Text wrapping is actually a difficult optimization problem. That's part of the reason LaTeX has such good text wrapping -- it can spend serious CPU cycles on the problem because it doesn't do it in real time.\n \nreply",
      "But with modern hardware, running the dynamic programming solution to this optimization problem takes a trivial amount of cycles* compared to rendering your typical React webapp.* for most webpages. Of course you can come up with giant ebooks or other lengthy content for which this will be more challenging.\n \nreply",
      "Lest we forget, TeX is almost 50 years old now, so what constitutes \"serious CPU cycles\" has to be understood in the context of hardware available at the time.\n \nreply",
      "You aren't wrong; but I stand by my claim.  For one, plenty of things are actually difficult optimization problems that people don't give any passing thought to.But, more importantly, the amount of cycles that would be needed to text-wrap most websites is effectively zero.  Most websites are simply not typesetting the volumes of text that would be needed for this to be a concern.Happy to be shown I'm flat wrong on that.  What sites are you envisioning this will take a lot of time for?\n \nreply",
      "> But, more importantly, the amount of cycles that would be needed to text-wrap most websites is effectively zero.I've measured this, and no, it's not. What you're missing is the complexities of typesetting Unicode and OpenType, where GSUB/GPOS tables, bidi, ruby text, etc. combine to make typesetting quite complex and expensive. HarfBuzz is 290,000 lines of code for a reason. Typesetting Latin-only text in Times New Roman is quick, sure, but that doesn't cut it nowadays.\n \nreply",
      "Apologies, the additional cycles to do justified text is effectively zero compared to the rest of the stack for most sites.  Clearly, it is work, so not actually zero.  And, yes, proper text handling is huge.I would wager you can find scenarios where it is a large number.  My question is if there are sites people use?Seriously taken, these would all be reasons not to do many of the things Unicode does.  And yet here we are.That all said, if you have measurements, please share.  Happy to be proven wrong.",
      "With the current state of Websites and how much resources they waste any text wrapping is probably not an issue at all. :)I hardly can open any website w/o some anti-bot check burning my CPU to the ground for 1/2 minute or something (if it doesn't manage to entirely crash my Firefox in the process like cloudflare). I rather would wait for 0.2s text wrapping than that, that's for sure. :)\n \nreply",
      "Any page with dynamic text. If the calculation takes a moderate amount of time, that will accumulate if the page layout reflows a lot.\n \nreply",
      "Only if the entire text has to be optimized as a whole?  Which, most dynamic text sites do not have to do this.  Most dynamic sites will be a series of individual \"card\" like things that could be justified internally, but are not justified with regard to anything else on the page.\n \nreply"
    ],
    "link": "https://webkit.org/blog/16547/better-typography-with-text-wrap-pretty/",
    "first_paragraph": "Apr 8, 2025by Jen SimmonsSupport for text-wrap: pretty just shipped in Safari Technology Preview, bringing an unprecedented level of polish to typography on the web. Let\u2019s take a look at what the WebKit version of pretty does \u2014 it\u2019s probably a lot more than you expect. Then, we\u2019ll compare it to balance and the other text-wrap values to better understand when to use which one.Ideas of what makes for \u201cgood\u201d typography are deeply rooted in eras when type was set by hand using metal, wood, or ink. Typesetters took great care when deciding if a word should go on the end of one line, the beginning of the next, or be broken with a hyphen. Their efforts improved comprehension, reduced eye-strain, and simply made the reading experience more pleasant. While beauty can be subjective, with disagreements about what\u2019s \u201cbetter\u201d, there are also strongly-held typographic traditions around the globe, representing various languages and scripts. These traditions carry people\u2019s culture from one generation "
  },
  {
    "title": "Show HN: Coroot \u2013 eBPF-based, open source observability with actionable insights (github.com/coroot)",
    "points": 89,
    "submitter": "openWrangler",
    "submit_time": "2025-04-08T16:49:40 1744130980",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=43623820",
    "comments": [
      "Can it parse Zeek logs to identify long-running TCP connections and/or identify user attempts to access a DNS blocked domain?\n \nreply",
      "I took a cursory look and I like what I see \u2013 the service maps are really good, I love the level of detail. I will say, one thing I'm looking for with this kind of software, to maximise value, is structured logging support, and from what I could see, each log line just has the raw payload currently. Is that something you have on your roadmap?\n \nreply",
      "In addition to raw logs, Coroot can extract recurring patterns to generate log-based metrics [1].We also plan to convert structured logs into OpenTelemetry attributes [2].[1] https://demo.coroot.com/p/tbuzvelk/applications/default:Depl...\n[2] https://github.com/coroot/coroot/issues/490\n \nreply",
      "This is somewhat off topic, but are there any common uses for eBPF outside of observability/monitoring? Or is that kind of its whole thing?\n \nreply",
      "I already have Opentelemetry traces and logs going to Clickhouse with the Clickhouse otel exporter.Can i use Coroot to show my existing data, without it taking control of my DDL?\n \nreply",
      "Initially, we relied on the ClickHouse OTEL exporter and its schema, but for performance optimization, we decided to modify our ClickHouse schema, and they are no longer compatible :(\n \nreply",
      "Bummer, it'd be awesome if i could point it at data i already have, even if that meant a reduced feature set.\n \nreply",
      "We're on sentry today, but have been waiting for a fully OSS solution like this.\n \nreply",
      "(I'm a co-founder). At Coroot, we're strong believers in open source, especially when it comes to observability. Agents often require significant privileges, and the cost of switching solutions is high, so being open source is the only way to provide real guarantees for businesses.\n \nreply",
      "What's the data transformation story; for ML on metrics?\n \nreply"
    ],
    "link": "https://github.com/coroot/coroot",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Coroot is an open-source APM & Observability tool, a DataDog and NewRelic alternative. Metrics, logs, traces, continuous profiling, and SLO-based alerting, supercharged with predefined dashboards and inspections.\n      \n\n\nCollecting metrics, logs, and traces alone doesn't make your applications observable.\nCoroot turns that data into actionable insights for you!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can run Coroot as a Docker container or deploy it into any Kubernetes cluster.\nCheck out the Installation guide.The Coroot documentation is available at docs.coroot.com/docs.A live demo of Coroot is available at demo.coroot.comTo start contributing, check out our Contributing Guide.Coroot is licensed under the Apache License, Version 2.0.\n        Coroot is an open-source APM & Observability tool, a DataDog and NewRelic alternative. Metrics, logs, traces, c"
  },
  {
    "title": "Thank HN: The puzzle game I posted here 6 weeks ago got licensed by The Atlantic (theatlantic.com)",
    "points": 699,
    "submitter": "brgross",
    "submit_time": "2025-04-08T15:11:26 1744125086",
    "num_comments": 138,
    "comments_url": "https://news.ycombinator.com/item?id=43622719",
    "comments": [
      "I posted Bracket City to HN on February 24th and the game went live yesterday on The Atlantic (!)The game will stay free to play (and not require logging in). Also, I'm still making all the puzzles!HN provided the first real infusion of players that weren't my mom's friends. So thanks everyone.FWIW The Atlantic's team is amazing and got this live exactly 2 weeks from when we signed the deal.This happened quick and I feel very lucky. The HN community of solvers keeps me honest with much helpful technical and editorial feedback. I love it all -- here or at mayor@bracket.cityT[Tom who befriended a volleyball] HNPS my original post! https://news.ycombinator.com/item?id=43160542\n \nreply",
      "That's awesome, congrats! I had a lot of fun solving today's puzzle.One minor bit of feedback/request: maybe I'm too spoiled by code editors, but it would be nice to have a visual aid for identifying matching brackets -- maybe colorizing matching pairs (\"rainbow brackets\"), and/or a click-to-highlight  feature that highlights the entire contents of a pair of braces for you. I felt like I was spending a lot of time trying to count bracket pairs, which made it hard to keep track of where I was in the puzzle and was less interesting than trying to solve the wordplay.\n \nreply",
      "If the game never has more than three nested levels, you could use [square], then {curly}, then <angle> brakest. You could even do a fourth level with (parenthetical) brackets, but that would mean you couldn't use parenthesis in clues.\n \nreply",
      "Nice work - congratulations!  ...and, yes - I had to paste the text of today's game into vi so I could use the bracket matching to untangle the clues... :)Also, I would make it more obvious which clues are eligible for solving at the moment rather than penalizing us for not being able to discern which ones are.\n \nreply",
      "Agreed about the matching brackets, I had sent that suggestion to mayor@ a couple weeks ago, so maybe once this craziness settles down...\n \nreply",
      "Yes!  Please!\n \nreply",
      "Seconded. This would be super useful.Amazing game!\n \nreply",
      "Congrats! My only feedback is that it's irritating to be counted \"wrong\" for naming a correct answer whose clue hasn't been simplified completely yet.\n \nreply",
      "I would add that the answer detection logic should probably get beefed up a bit as well. When I solved today's puzzle, it counted \"race car\" as a wrong answer when it expected \"racecar\". It should accept both forms of a compound word (also \"racecar\" isn't a word but that's more minor).\n \nreply",
      "But \"race car\" with a space isn't a palindrome.\n \nreply"
    ],
    "link": "https://www.theatlantic.com/games/bracket-city/",
    "first_paragraph": ""
  },
  {
    "title": "No elephants: Breakthroughs in image generation (oneusefulthing.org)",
    "points": 353,
    "submitter": "Kerrick",
    "submit_time": "2025-04-05T03:51:51 1743825111",
    "num_comments": 263,
    "comments_url": "https://news.ycombinator.com/item?id=43590569",
    "comments": [
      "This is a before/after moment for image generation. A simple example is the background images on a ton of (mediocre) music youtube channels. They almost all use AI generated images that are full of nonsense the closer you look. Jazz channels will feature coffee shops with garbled text on the menu and furniture blending together. I bet all of that disappears over the next few months.On another note, and perhaps others are feeling similarly, but I am finding myself surprised at how little use I have for this stuff, LLMs included. If, ten years ago, you told me I would have access to tools like this, I'm sure I would have responded with a never ending stream of ideas and excitement. But now that they're here, I just sort of poke at it for a minute and carry on with my day.Maybe it's the unreliability on all fronts, I don't know. I ask a lot of programming questions and appreciate some of the autocomplete in vscode, but I know I'm not anywhere close to taking full advantage of what these systems can do.\n \nreply",
      "I love using LLMs to generate pictures. I'd call myself rather creative, but absolutely useless in any artistic craft. Now, I can just describe any image I can imagine and get 90% accurate results, which is good enough for the presentations I hold, online pet projects (created a squirrel-themed online math-learning game for which I previously would have needed a designer to create squirrel highschool themed imagery) and memes. For many, many websites this is going to be good enough.\n \nreply",
      "> For many, many websites this is going to be good enough.It was largely a solved problem though. Companies did not seem to have an issue with using stock photos. My current company's website is full of them.For business use cases, those galleries were already so extensive before AI image generation, that what you wanted was almost always there. They seemingly looked at people's search queries, and added images to match previously failed queries. Even things you wouldn't think would have a photo like \"man in business suit jump kicking a guy while screaming\", have plenty of results.\n \nreply",
      "AI is mediocre at a lot of things, but it makes a damn fine upgrade from stock photos. This is the art that\u2019s going to get replaced by this tech, shitty low effort stuff. Images where you just need a picture of X because people are expecting a picture.It\u2019s the same with code. I don\u2019t think software engineers will really be replaced, but small web dev agencies have a good reason to be nervous. Why would you pay someone to make a website for your restaurant when 3-5 prompts will get you there?\n \nreply",
      "Really? What stock service would have a selection of squirrels in a high school setting doing various math or other subject related things?To think any/all combined stock services would be the end all is just unrealistic. Sure, someone one might have settled on something just because they got tired of scrolling (much like streaming video services), that does not mean they are happy with their selection. Just happy to be done.Now, with generativeAI, they can have squirrels doing anything in any setting they can describe. If they don't like it, they can just tweak the description until they are happy. It's an obvious plus for them.I never drank the kool-aid to be all gung-ho on this boom/fad, but I'm not going to be so obstinate that I refuse to accept some people find it quite useful. May someone make all the squirrel attending highschool generative art they want, but you can't tell me some stock place is good 'nuff for everything.\n \nreply",
      "I searched Shutterstock for squirrels doing math. Here's a squirrel doing math: https://www.shutterstock.com/image-vector/pensive-squirrel-d...Yes, it's obvious that if your use case is obscure enough, or you need a ton of unique images, they won't work, which is why I said \"largely a solved problem\".\n \nreply",
      "My problem with finding enjoyment in this is the same problem I have when using cheat codes in games:  the doing part is the fun part, getting to the end or just permutations of the end gets really boring.\n \nreply",
      "Trying to draw a squirrel when you have no artistic talents or experience is not the fun part.I've produced my own music recordings in the past and I've hired musicians to play the instruments that I cannot. Having exasperated recording engineers watch my 5,000th take on a drum fill that I absolutely cannot play is not the fun part. Sitting behind the glass and watching my vision come to life from a really good drummer is absolutely the fun part.\n \nreply",
      "> Sitting behind the glass and watching my vision come to life from a really good drummer is absolutely the fun part.Is having the ai spit out idea after idea fun in the same way for you?\n \nreply",
      ">I love using LLMs to generate pictures. I'd call myself rather creative, but absolutely useless in any artistic craft. Now, I can just describe any image I can imagine and get 90% accurate resultsMay I ask what you use? I'm not yet even a paid subscriber to any of the models, because my company offer a corporate internal subscription chatbot and code integration that works well enough for what I've been doing so far but has no image generation.I have tried image generation on the free tier but run out of free use before I get anyway pleasing.What do you pay for?\n \nreply"
    ],
    "link": "https://www.oneusefulthing.org/p/no-elephants-breakthroughs-in-image",
    "first_paragraph": ""
  },
  {
    "title": "An Overwhelmingly Negative and Demoralizing Force (aftermath.site)",
    "points": 261,
    "submitter": "Doches",
    "submit_time": "2025-04-08T09:22:23 1744104143",
    "num_comments": 226,
    "comments_url": "https://news.ycombinator.com/item?id=43619759",
    "comments": [
      "Had a funny conversation with a friend of mine recently who told me about how he's in the middle of his yearly review cycle, and management is strongly encouraging him and his team to make greater use of AI tools. He works in biomedical lab research and has absolutely no use for LLMs, but everyone on his team had a great time using the corporate language model to help write amusing resignation letters as various personalities, pirate resignation, dinosaur resignation etc. I dont think anyone actually quit, but what a great way to absolutely nuke team moral!\n \nreply",
      "I've been getting the same thing at my company. Honestly no idea what is driving it other than hype. But it somehow feels different than the usual hype; so prescribed, as though coordinated by some unseen party. Almost like every out of touch business person had a meeting where they agreed they would all push AI for no reason. Can't put my finger on it.\n \nreply",
      "Is because unlike prior hype cycles, this one is super easy for an MBA to point at and sort of see a way to integrate it.Prior hype, like block chain are more abstract, therefore less useful to people who understand managing but not the actual work.\n \nreply",
      "Shame that management is deciding that listening to marketing is more important than the craftsmen they push it on.\n \nreply",
      "I\u2019ve always been the kind of developer that aims to have more red lines than green ones in my diffs. I like writing libraries so we can create hundreds of integration tests declaratively. I\u2019m the kind of developer that disappears for two days and comes back with a 10x speedup because I found two loop variables that should be switched.There is no place for me in this environment. I\u2019d not that I couldn\u2019t use the tools to make so much code, it\u2019s that AI use makes the metric for success speed-to-production. The solution to bad code is more code. AI will never produce a deletion. Publish or perish has come for us and it\u2019s sad. It makes me feel old just like my Python programming made the mainframe people feel old. I wonder what will make the AI developers feel old\u2026\n \nreply",
      "AI can definitely produce a deletion. In fact, I commonly use AI to do this. Copy some code and prompt the AI to make the code simpler or more concise. The output will usually be fewer lines of code.Unless you meant that AI won\u2019t remove entire features from the code. But AI can do that too if you prompt it to. I think the bigger issue is that companies don\u2019t put enough value on removing things and only focus on adding new features. That\u2019s not a problem with AI though.\n \nreply",
      "I messed around with Copilot for a while and this is one of the things that actually really impressed me. It was very good at taking a messy block of code, and simplifying it by removing unnecessary stuff, sometimes reducing it to a one line lambda. Very helpful!\n \nreply",
      "> sometimes reducing it to a one line lambda.Please don't do this :)  Readable code is better than clever code!\n \nreply",
      "Especially \"clever\" code that is AI generated!At least with human-written clever code you can trust that somebody understood it at one point but the idea of trusting AI generated code that is \"clever\" makes my skin crawl\n \nreply",
      "Also, the ways in which a (sane) human will screw-up tend to follow internal logic that other humans have learned to predict, recognize, or understand.\n \nreply"
    ],
    "link": "https://aftermath.site/ai-video-game-development-art-vibe-coding-midjourney",
    "first_paragraph": "'I have had conversations about AI in a professional context that make me want to walk into the sea'7:12 PM EDT on April 7, 2025We\u2019re a few years into a supposed artificial intelligence revolution, which could and should have been about reducing mundane tasks and freeing everyone up to do more interesting things with their time. Instead, thanks to the bloodthirsty nature of modern capitalism and an ideological crusade being waged by the tech industry, we\u2019re now facing a world where many people\u2019s livelihoods\u2013like video game developers\u2013are under direct threat.These tumultuous times are of course being reported on everywhere you look, including on this very website, but one area I\u2019ve been curious about recently aren\u2019t the broader moral and legal battles, but what the struggle looks like for the average dev who is now having to encounter AI in their workplace.For this piece, I spoke with a number of people working in the video game industry or very close to it, including artists, game desi"
  },
  {
    "title": "Ask HN: Do you still use search engines?",
    "points": 173,
    "submitter": "davidkuennen",
    "submit_time": "2025-04-08T09:23:18 1744104198",
    "num_comments": 381,
    "comments_url": "https://news.ycombinator.com/item?id=43619768",
    "comments": [
      "It depends on what I'm looking for. If I have a specific thing that I'm just looking for an answer on, then I typically will use ChatGPT. Most of my google searches are either navigational, things i know Google will return more quickly than ChatGPT (\"how old is this actor\", \"when was xx player drafted\") or when I'm interested in browsing results (looking for recipes for borscht, I want to see a few different recipes).\n \nreply",
      "Search is primarily a portal - you know a particular resource exists, you just don't know its exact URL.You hear about this new programming language called \"Frob\", and you assume it must have a website. So you google \"Frob language\". You hear that there was a plane crash in DC, and assume (CNN/AP/your_favorite_news_site) has almost certainly written an article about it. You google \"DC plane crash.\"LLMs aren't ever going to replace search for that use case, simply because they're never going to be as convenient.Where LLMs will take over from search is when it comes to open-ended research - where you don't know in advance where you're going or what you're going to find. I don't really have frequent use cases of this sort, but depending on your occupation it might revolutionize your daily work.\n \nreply",
      "IMO an example of a good use case for an LLM, which would be otherwise very hard to search for, is clarifying vague technical concepts.Just yesterday I was trying to remember the name of a vague concept I\u2019d forgotten, with my overall question being:\u201cIs there a technical term in biology for the equilibrium that occurs between plant species producing defensive toxins, and toxin resistance in the insect species that feed on those plants, whereby the plant species never has enough evolutionary pressure to increase it\u2019s toxin load enough to kill off the insect that is adapting to it\u201dAfter fruitless searching around because I didn\u2019t have the right things to look for, putting the above in ChatGPT gave an instant reply of exactly what I was looking for:\u201cYes, the phenomenon you're describing is often referred to as evolutionary arms race or coevolutionary arms race.\u201d\n \nreply",
      "While I do like LLMs for these tasks, unfortunately this one failed you but was a near enough miss that you couldn't see it. What you were really looking for is the Red Queen problem/hypothesis/race, named after a quote from Through the Looking Glass, with the Queen explaining to Alice: \"Now, here, you see, it takes all the running you can do, to keep in the same place.\" In particular, the Red Queen term is specifically the equilibrium you inquired about, where relative fitness is unchanging, rather than the more general concept of an evolutionary arms race in which there can be winners and losers. The terms 'evolutionary equilibrium' and 'evolutionary steady state' are also used to capture the idea of the equilibrium, rather than just of competition.Evolutionary arms race is somewhat tautological; an arms race is the description of the selective pressure applied by other species on evolution of the species in question. (There are other, abiotic sources of selective pressures, e.g. climate change on evolutionary timescales, so while 'evolution' at least carries a broader meaning, 'arms race' adds nothing that wasn't already there.)That said, using your exact query on deepseek r1 and claude sonnet 3.7 both did include red queen in their answers, along with other related concepts like tit for tat escalation.\n \nreply",
      "This is an incorrect response.Firstly, \"Evolutionary Arms Race\" is not tautological, it is a specific term of art in evolutionary biology.Secondly, \"evolutionary arms race\" is a correct answer, it is the general case of which the Red Queen hypothesis is a special case. I do agree with you that OP described a Red Queen case, though I would hesitate to say it was because of \"equilibrium\"; many species in Red Queen situations have in fact gone extinct.https://en.wikipedia.org/wiki/Evolutionary_arms_racehttps://en.wikipedia.org/wiki/Red_Queen_hypothesis\n \nreply",
      "Same. This is one of the few uses for LLMs that I actually find useful and that I trust.They\u2019re very helpful for helping me ask more refined questions by getting the terminology correct.\n \nreply",
      "Synthesizing what would be multiple searches into one prompt is where they can be really useful.For example: Take the ingredient list of a cosmetic or other product that could be 30-40 different molecules and ask ChatGPT to list out what each of them is and if any have potential issues.You can then verify what it returns via search.\n \nreply",
      "Agreed. I'm increasingly using ChatGPT to research topics. In that way, I can refine my question, drill down, ask for alternatives, supply my own supplementary information, etc.I think of AI as an intelligent search engine / assistant and, outside of simple questions with one very specific answer, it just crushes search engines.\n \nreply",
      "that sounds like a really great example of..... searching through vector embedding. I don't think the LLM part was technically necessary.\n \nreply",
      "Okay, so how does the average person search through vector embedding? I would like to try this out.\n \nreply"
    ],
    "link": "item?id=43619768",
    "first_paragraph": ""
  },
  {
    "title": "Intelligence Evolved at Least Twice in Vertebrate Animals (quantamagazine.org)",
    "points": 188,
    "submitter": "rbanffy",
    "submit_time": "2025-04-08T08:36:23 1744101383",
    "num_comments": 153,
    "comments_url": "https://news.ycombinator.com/item?id=43619548",
    "comments": [
      "Articles like these are tricky. It's an obvious clickbaity thing. Humans knew birds are smart since way before science decided to call itself science.I think the text plays more on hammering the \"nothing makes sense in biology except for the light of evolution\" thing than on the roots of intelligence.The purpose and definition of intelligence have always been a critical point in evolutionary biology.No mention of the foxp2 gene and the peculiarities of both human and bird variants? Seems like this would open a point for an opposite conclusion (there is a common root if you consider language part of what constitutes intelligence).In the sixties, birds were girls, cats were boys, and everyone was kind of an asshole. Why should I trust any kind of research that started back then? :) If we're gonna be weirdly anacronistic, let's at least be clear about it. I am more of a 2025 person.\n \nreply",
      "It's interesting to think of how bird intelligence is related to their perspective. Perching high in branches and taking to the skies allows them to see a large overview of the many activities of other life forms. They can manage to get relatively safe vantage points and just watch. The better they get at predicting what the low animals on the surface are doing, the more opportunities that they have to sneak in and sneak out safely to get a meal. Being stuck on the surface as a mammal means a more immediate, limited-scope, fight-or-flight reaction dominates daily activities, versus a game-board view of many interactions.Bird intelligence makes a lot more sense in that context.\n \nreply",
      "> The better they get at predicting what the low animals on the surface are doing, the more opportunities that they have to sneak in and sneak out safely to get a mealThe most compelling explanation for bird intelligence I\u2019ve read[1] argues that it all stems from social needs. Birds, you see, form lifelong pairs. But they constantly cheat on each other. Keeping track of this cheating behavior, deceiving each other, hide their actions, predict what other birds know, understanding who will and who won\u2019t rat them out to their partner, that\u2019s why the intelligence developed. Then once you have intelligence, it proves useful for all sorts of things.Many species of bird also use this advanced ability to keep track of who knows what for food. They\u2019ll hide a stash for winter and find it all later. But it\u2019s easier to remember where your friend hid theirs than to get your own. So a whole arms race of deception developed.[1] The Genius of Birds https://www.jenniferackermanauthor.com/genius-ofbirds\n \nreply",
      "Funny, I've read the same thing about intelligence, particularly trainability, in both rats and dogs. It's driven by a social aspect. The existence of a peer group necessitates imagination and theory of mind: you have to be able to think about what someone else is thinking about. From there you can have thoughts like \"That big monkey wants me to do this thing that we do sometimes and has indicated that they'll give me a thing I like if I do it.\"\n \nreply",
      "Maybe.  But at least in mammals, visual information processing is a very expensive operation that involves coordinated activity across  many cortical areas.  Vision being such a central sensory modality for birds, I do wonder if it was a strong driver for the evolution of their brains.Edit: don't mean to imply a contradiction with the social interaction hypothesis -- needless to say there can be multiple factors that drive evolution in the same direction...\n \nreply",
      "I just want to agree with you wholeheartedly that there are certainly multiple independent factors driving intelligence. After all, one of the most asocial groups one can imagine, the octopodes, are also at the forefront of animal intelligence (and to further your theory, more of their brains are dedicated to visual processing than we see in humans)\n \nreply",
      "I wonder if there is any kind of bias of perception. If we agree with this point, this probably means bankers are much more intelligent than engineers, considering the former profession has to communicate with hundreds, maybe thousands of clients throughout their career life, while engineers mostly communicate with machines -- they do communicate with their colleagues but you can see the vast gap between the two.Maybe there are two types of intelligence -- versus humans and versus nature.\n \nreply",
      "The obnoxious pro-engineering equivalent of your statement is to say that engineers are more intelligent because they are held accountable to a higher standard of objective truth, one that is judged through the cold eyes of physics and math rather than the rosy glasses of a strategically cultivated in-group.It's probably wrong to directly compare these two types of specialization. However, we do have an interesting social experiment going on: China's bureaucracy leans towards engineering backgrounds while the USA bureaucracy leans towards legal backgrounds. You can see this in the strategies pursued by each side: China pulls large and small levers to acquire hard power (in the sense of manufacturing capacity, not just guns) while the USA has historically been better at pulling large and small levers to acquire soft power (and even though tension from the Triffin Dilemma is peaking again, that's still probably a fair assessment). The next decade will probably see a showdown that supports or repudiates the \"engineer primacy\" vs \"lawyer primacy\" narratives on the level of international strategy, even though both will obviously still exist and have primacy within their respective niches. Interesting times.\n \nreply",
      "But a banker and an engineer are 2 individual members of the same species. Evolutionary pressure to develop a specific type of intelligence doesn't apply.But yes, there are of course many different kinds of intelligence.\n \nreply",
      ">If we agree with this point, this probably means bankers are much more intelligent than engineers, considering the former profession has to communicate with hundreds, maybe thousands of clients throughout their career life, while engineers mostly communicate with machines -- they do communicate with their colleagues but you can see the vast gap between the two.I don't think anything I said about social vs asocial species applies to two members of a a single social species. I feel like this is one of those intuitive leaps that serves as a great reminder that intuitive leaps aren't usually good science.\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/intelligence-evolved-at-least-twice-in-vertebrate-animals-20250407/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesApril 7, 2025Did the neural circuits that support intelligence evolve once in vertebrates, or independently in birds and mammals?Samantha Mash for Quanta MagazineStaff WriterApril 7, 2025Humans tend to put our own intelligence on a pedestal. Our brains can do math, employ logic, explore abstractions and think critically. But we can\u2019t claim a monopoly on thought. Among a variety of nonhuman species known to display intelligent behavior, birds have been shown time and again to have advanced cognitive abilities. Ravens plan for the future, crows count and use tools, cockatoos open and pillage booby-trapped garbage cans, and chickadees keep track of tens of thousands of seeds cached across a la"
  },
  {
    "title": "The Treachery of Image Files (2020) (beyondloom.com)",
    "points": 37,
    "submitter": "appleorchard46",
    "submit_time": "2025-04-06T19:02:58 1743966178",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43604015",
    "comments": [
      "Discussion at the time (113 points, 30 comments) https://news.ycombinator.com/item?id=24408509\n \nreply",
      "I have not read the article, but on the general theme, has anyone else noticed that sometimes the image in a tweet that you've liked, replied to or RTd will silently get replaced by a completely different image?\n \nreply"
    ],
    "link": "http://beyondloom.com/blog/images.html",
    "first_paragraph": "I have recently come into possession of a series of exquisite miniatures which I pray are worthy of your esteemed attention. While my employers are familiar with your unusual tastes, they also appreciate your desire for privacy- this showing was arranged with the utmost discretion, I assure you.To the untrained eye, the pieces might appear remarkably similar. Each canvas is a digitally-reproduced composition measuring ten pixels in height and ten pixels in width, illuminated in a strikingly intense blue.To an, ahem, avid collector such as yourself, it is no doubt obvious that each print possesses unique qualia, as expounded upon by the artist\u2019s extensive footnotes. Please, take as long as you need\u2026In this piece, the artist used a carefully selected vintage of the Macintosh operating system. The desktop wallpaper color was customized to consist entirely of the desired blue, and then the Preview application was employed to take a screenshot and perform the necessary trimming. Tragically,"
  },
  {
    "title": "Reflections on the Mirror Stage (lareviewofbooks.org)",
    "points": 6,
    "submitter": "HR01",
    "submit_time": "2025-04-06T17:28:23 1743960503",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://lareviewofbooks.org/blog/essays/reflections-mirror-stage/",
    "first_paragraph": ""
  },
  {
    "title": "The Greatest Motorcycle Photo (life.com)",
    "points": 102,
    "submitter": "keepamovin",
    "submit_time": "2025-04-05T17:41:35 1743874895",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=43595165",
    "comments": [
      "I beg to differ. This picture of Emile Leray, who disassembled his own broken car in the desert and built a motorcycle out of it is profoundly better.https://thekneeslider.com/images/2022/01/leray-citroen-motor...\n \nreply",
      "From Wikipedia:> He was stranded twenty miles from the nearest settlement, with only enough food and water to last ten days. To survive, Leray used parts of his broken-down car to build a motorcycle, and twelve days after the accident was able to drive it to a village 20 miles away.I admire his ingenuity, but I would have probably just walked.\n \nreply",
      "Why spend three days doing a one-off task when you can spend 10 days automating it?\n \nreply",
      "https://xkcd.com/530/\n \nreply",
      "Did he know the next settlement was only 20 miles away?\n \nreply",
      "The settlement was 20 miles away, but that doesn't mean he only drove 20 miles, or that he knew which direction the settlement was in!\n \nreply",
      "Yeah, walking 20 miles, desert or not, is a far better plan.\n \nreply",
      "Figuring out how to carry enough stuff might be a problem, but making a sling or primitive backpack from the upholstery should be doable with a knife.\n \nreply",
      "3-4 Mph is a reasonable walking speed, so 20 miles is around 6-7 hours. Not saying it would be pleasant, but certainly seems doable.\n \nreply",
      "In the desert, you often really don't want to be walking midday, but if the moon is out doing 20 miles in a night isn't too bad, and doing it split over two days is fine. 5 or 6 liters of water plus some food would be plenty, depending on what you have available to carry that ~15 pounds splitting into two days may be more comfortable. Either way, infinitely less risky than building a motorcycle.\n \nreply"
    ],
    "link": "https://www.life.com/arts-entertainment/the-greatest-motorcycle-photo-ever/",
    "first_paragraph": "The Greatest Motorcycle Photo EverRollie Free getting ready to break the motorcycle speed record on the Bonneville Salt Flats in Utah, 1948.Rollie Free, laying horizontally on his bike to reduce wind resistance, broke the world\u2019s speed record for a motorcycle at the Bonneville Salt Flats in Utah, September 13, 1948.eter Stackpole/Life Picture Collection/ShutterstockNot only did Rollie Free set the world speed record for a motorcycle back in 1948\u2014he looked darn good doing it.The key to setting the record for Free was cutting down on wind resistance. So when the 47-year-old accelerated his Vincent HRD Black Shadow, he positioned his body to be as horizontal as it could. Also, he wore only swim trunks as he whipped across the hard pack of the Bonneville Salt Flats. His plan worked to perfection, setting a record of 150.313 miles per hour. The AMA Motorcycle Hall of Fame calls the picture of Free\u2019s record-setting ride \u201cone of the most famous photos in the history of the sport.\u201d LIFE staff "
  }
]