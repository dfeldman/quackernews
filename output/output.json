[
  {
    "title": "Apple's MLX adding CUDA support (github.com/ml-explore)",
    "points": 153,
    "submitter": "nsagent",
    "submit_time": "2025-07-14T21:40:30 1752529230",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=44565668",
    "comments": [
      "It's coming from zcbenz who created Electron among others https://zcbenz.com/ Nice.reply",
      "If you're going \"wait, no Apple platform has first-party CUDA support!\", note that this set of patches also adds support for \"Linux [platforms] with CUDA 12 and SM 7.0 (Volta) and up\".https://ml-explore.github.io/mlx/build/html/install.htmlreply",
      "How does this work when one of the key features of MLX is using a unified memory architecture? (see bullets on repo readme: https://github.com/ml-explore/mlx )I would think that bringing that to all UMA APUs (of any vendor) would be interesting, but discreet GPU's definitely would need a different approach?edit: reading the PR comments, it appears that CUDA supports a UMA API directly, and will transparently copy as needed.reply",
      "I wonder how much this is a result of Strix Halo. I had a fairly standard stipend for a work computer that I didn't end up using for a while so I recently cashed it in on the EVO-X2 and fuck me sideways: that thing is easily competitive with the mid-range znver5 EPYC machines I run substitors on. It mops the floor with any mere-mortal EC2 or GCE instance, like maybe some r1337.xxxxlarge.metal.metal or something has an edge, but the z1d.metal and the c6.2xlarge or whatever type stuff (fast cores, good NIC, table stakes), blows them away. And those things are 3-10K a month with heavy provisioned IOPS. This thing has real NVME and it cost 1800.I haven't done much local inference on it, but various YouTubers are starting to call the DGX Spark overkill / overpriced next to Strix Halo. The catch of course is ROCm isn't there yet (they're seeming serious now though, matter of time).Flawless CUDA on Apple gear would make it really tempting in a way that isn't true with Strix so cheap and good.reply",
      "For the uninitiated, Strix Halo is the same as the AMD Ryzen AI Max+ 395 which will be in the Framework Desktop and is starting to show up in some mini PCs as well.The memory bandwidth on that thing is 200GB/s. That's great compared to most other consumer-level x86 platforms, but quite far off of an Nvidia GPU (a 5090 has 1792GB/s, dunno about the pro level cards) or even Apple's best (M3 Ultra has 800GB/s).It certainly seems like a great value. But for memory bandwidth intensive applications like LLMs, it is just barely entering the realm of \"good enough\".reply",
      "Apple is just being stupid, handicapping their own hardware so they can sell the fixed one next year or the year afterThis is time tested Apple strategy is now undermining their AI strategy and potential competitivenesstl;dr they could have done 1600GB/sreply",
      "> The catch of course is ROCm isn't there yet (they're seeming serious now though, matter of time).Competitive AMD GPU neural compute has been any day now for at least 10 years.reply",
      "The inference side is fine, nowadays. llama.cpp has had a GPU-agnostic Vulkan backend for a while, it's the training side that tends to be a sticking point for consumer GPUs.reply",
      "It\u2019s pretty explicitly targeting cloud cluster training in the PR description.reply",
      "how is it vs m4 mac mini?reply"
    ],
    "link": "https://github.com/ml-explore/mlx/pull/1983",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\nHave a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.\n  By clicking \u201cSign up for GitHub\u201d, you agree to our terms of service and\n  privacy statement. We\u2019ll occasionally send you account related emails.\n    Already on GitHub?\n    Sign in\n    to your account\n   There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.This PR is an ongoing effort to add a CUDA backend to MLX, very little things work now but you can run the tutorial example already.To build and test:For development I usually use:Only tested on a Ubuntu 22.04 with CUDA 11.6, in theory other environments can also work but there"
  },
  {
    "title": "LIGO detects most massive black hole merger to date (caltech.edu)",
    "points": 176,
    "submitter": "Eduard",
    "submit_time": "2025-07-14T20:06:51 1752523611",
    "num_comments": 85,
    "comments_url": "https://news.ycombinator.com/item?id=44564656",
    "comments": [
      ">  the 225-solar-mass black hole was created by the coalescence of black holes each approximately 100 and 140 times the mass of the Sun.Does this mean that 15 solar masses were converted into energy? Because that's a LOT of energy.reply",
      "Yes. Black hole mergers are the highest energy events in the universe in terms of watts.reply",
      "Yes! And still, gravity is so weak that that immense amount of energy translates to just a relative contraction of less than 10^-20, or about a hair's width in the distance from the Earth to the Moon.reply",
      "Do we know how far this event was from earth? Wouldn't that distance be the determiner of what the relative contraction observed on earth would be?reply",
      "estimated distance of 2.2 Gpc\nper https://en.wikipedia.org/wiki/GW231123reply",
      "That's how fast the millennium falcon goesreply",
      "At 10 times the Schwarzschild radius Space literally stretches and contracts by 10-100%reply",
      "I was disappointed to learn that it would require billions of solar masses of energy from a black hole merger to be able to ride the gravitational wave starting at a distance of a few Schwarzschild radii. It seems like riding a plasma jet might be better.(Just planning my next trip.)reply",
      "Let\u2019s see \u2014 the Tsar Bomba nuclear weapon released the equivalent of converting about 2.3 kg of matter into energy (1).One solar mass is about 2 x 10^30 kg, so round numbers this event released the same as 10^31 Tsar Bombas, which is \u2026 a lot of energy? That number is too big to be a good intuition pump.Let\u2019s try again: over the course of its entire lifetime of about 10 billion years, the sun will release about 0.034% of its mass as energy (2). So one solar mass of energy is about 3000 solar-lifetime-outputs.So this event has released about as much energy as 45,000 suns over their entire lifetime. I\u2019m not sure how much of the energy was released in the final few seconds of merger, but probably most of it? So\u2026 that\u2019s a lot of energy.(1) https://faculty.etsu.edu/gardnerr/einstein/e_mc2.htm(2) https://solar-center.stanford.edu/FAQ/Qshrink.htmlreply",
      "Assuming your 0.034% figure is correct, then one solar mass is equivalent to 2941 lifetimes of a sun's output, not 30. So 15 solar masses would be more like 44115 solar-lifetimes.reply"
    ],
    "link": "https://www.caltech.edu/about/news/ligo-detects-most-massive-black-hole-merger-to-date",
    "first_paragraph": ""
  },
  {
    "title": "RFC: PHP license update (php.net)",
    "points": 133,
    "submitter": "josephwegner",
    "submit_time": "2025-07-14T21:37:27 1752529047",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=44565647",
    "comments": [
      "Beautifull, everything regarding PHP licensing and its history in one place, no marketing or AI generated bs in sight - love it ;)reply",
      "AI generated bs doesn\u2019t add anything new. In fact bs has always existed! So there is nothing to see :)reply",
      "The background:https://wiki.php.net/rfc/php_license_update#backgroundreply",
      "Dang if someone wants to become an expert in software licensing and modifications, this is a page to read.It's sold to us as non-news, which is good. No change for contributors, no change for end users, rights wise.reply",
      "Last time I heard about a non-news update that required no changes or recertification, we learned about 787MAX and MCAS.reply",
      "Let us hope nobody is writing their aircraft stabilizer trim control software in PHP.reply",
      "Well that is rather obvious.  I doubt PHP has RTOS type guarantees built in.Funny you should mention stabilizer control (I don't think that is an aeronautic term).  I recently visited the Battle of Britain Memorial Flight hanger at RAF Conningsby.  It turns out that the Hurricane and Spitfire had unusual (by today's standards but normal for the times) ways of applying trim to control surfaces.One of them - you glue a piece of string on top of an aileron and on the other you smack it with a hammer to bend it (that must be the Spitfire) and then you test it out and keep fettling until the job is done.Well, that's roll sorted out, I'm not sure what trim for the other two axes (pitch, yaw) involves.  Probably knicker elastic.reply",
      "Nothing special about that, here is the factory set trim tab on the p-47.https://www.youtube.com/watch?v=VxWKOHPPNlM&t=298reply",
      "it'll be alright as long as you're not receiving the trim updates as part of a search query using parse_str, otherwise, you might be susceptible to script kiddies.reply",
      "It seems like the only clauses being removed are those that protect PHP and Zend trademarks.  Other than that, it's just unifying the two projects under a single license.--Basically, these two clauses (first from PHP, second from Zend) are removed:The name \u201cPHP\u201d must not be used to endorse or promote products derived from this software without prior written permission. For written permission, please contact group@php.net.The names \u201cZend\u201d and \u201cZend Engine\u201d must not be used to endorse or promote products derived from this software without prior permission from Zend Technologies Ltd. For written permission, please contact license@zend.com.And replaced with:Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.--Then the following three terms (4-6) are removed from PHP:4. Products derived from this software may not be called \u201cPHP\u201d, nor may \u201cPHP\u201d appear in their name, without prior written permission from group@php.net. You may indicate that your software works in conjunction with PHP by saying \u201cFoo for PHP\u201d instead of calling it \u201cPHP Foo\u201d or \u201cphpfoo\u201d5. The PHP Group may publish revised and/or new versions of the license from time to time. Each version will be given a distinguishing version number. Once covered code has been published under a particular version of the license, you may always continue to use it under the terms of that version. You may also choose to use such covered code under the terms of any subsequent version of the license published by the PHP Group. No one other than the PHP Group has the right to modify the terms applicable to covered code created under this License.6. Redistributions of any form whatsoever must retain the following acknowledgment: \u201cThis product includes PHP software, freely available from http://www.php.net/software/\u201d.--And the following three terms (4-6) are removed from Zend:4. Zend Technologies Ltd. may publish revised and/or new versions of the license from time to time. Each version will be given a distinguishing version number. Once covered code has been published under a particular version of the license, you may always continue to use it under the terms of that version. You may also choose to use such covered code under the terms of any subsequent version of the license published by Zend Technologies Ltd. No one other than Zend Technologies Ltd. has the right to modify the terms applicable to covered code created under this License.5. Redistributions of any form whatsoever must retain the following acknowledgment: \"This product includes the Zend Engine, freely available at http://www.zend.com\"6. All advertising materials mentioning features or use of this software must display the following acknowledgment: \"The Zend Engine is freely available at http://www.zend.com\"reply"
    ],
    "link": "https://wiki.php.net/rfc/php_license_update",
    "first_paragraph": "\nPHP has a long history of confusion, concerns, and disagreements regarding its custom open source license, and the Zend Engine License, which covers the sources in the Zend/ directory, adds to this confusion and additionally complicates matters, since it is not an Open Source Initiative Approved License. This RFC proposes a pragmatic simplification to the PHP license that alleviates this confusion, preserves the copyrights owned by all PHP contributors, and grants users the same rights as the original licenses. The proposed license to accomplish this is the Modified BSD License, often referred to as the 3-clause BSD license.\n\nThis proposal addresses a longstanding issue within the open source community by publishing new versions of the PHP License and the Zend Engine License. The Modified BSD License is adopted as the PHP License, version 4, and as the Zend Engine License, version 3.\n\nThe Modified BSD License is sometimes referred to as the \u201cNew,\u201d \u201cRevised,\u201d or \u201c3-clause\u201d BSD License."
  },
  {
    "title": "Kiro:\u00a0A new agentic IDE (kiro.dev)",
    "points": 684,
    "submitter": "QuinnyPig",
    "submit_time": "2025-07-14T14:24:40 1752503080",
    "num_comments": 309,
    "comments_url": "https://news.ycombinator.com/item?id=44560662",
    "comments": [
      "Important details from the FAQ, emphasis mine:> For users who access Kiro with Pro or Pro+ tiers once they are available, your content is not used to train any underlying foundation models (FMs). AWS might collect and use client-side telemetry and usage metrics for service improvement purposes. You can opt out of this data collection by adjusting your settings in the IDE. For the Kiro Free tier and during preview, your content, including code snippets, conversations, and file contents open in the IDE, unless explicitly opted out, may be used to enhance and improve the quality of FMs. Your content will not be used if you use the opt-out mechanism described in the documentation. If you have an Amazon Q Developer Pro subscription and access Kiro through your AWS account with the Amazon Q Developer Pro subscription, then Kiro will not use your content for service improvement. For more information, see Service Improvement.https://kiro.dev/faq/reply",
      "To opt out of sharing your telemetry data in Kiro, use this procedure:1. Open Settings in Kiro.2. Switch to the User sub-tab.3. Choose Application, and from the drop-down choose Telemetry and Content.4. In the Telemetry and Content drop-down field, select Disabled to disable all product telemetry and user data collection.source: https://kiro.dev/docs/reference/privacy-and-security/#opt-ou...reply",
      "Is there a way to confirm this works or do we just have to trust that settings will be honored?reply",
      "You could place some unique strings in your code, and test it to see if they appear as completions in future foundation models? Maybe?I am nowhere near being a lawyer, but I believe the promise would be more legally binding, and more likely to be adhered to, if money was exchanged. Maybe?The \"Amazon Q Developer Pro\" sub they mention appears to be very inexpensive. https://aws.amazon.com/q/pricing/reply",
      "This brings up a tangential question for me.Clearly, companies view the context fed to these tools as valuable. And it certainly has value in the abstract, as information about how they're being used or could be improved.But is it really useful as training data? Sure, some new codebases might be fed in... but after that, the way context works and the way people are \"vibe coding\", 95% of the novelty being input is just the output of previous LLMs.While the utility of synthetic data proves that context collapse is not inevitable, it does seem to be a real concern... and I can say definitively based on my own experience that the _median_ quality of LLM-generated code is much worse than the _median_ quality of human-generated code. Especially since this would include all the code that was rejected during the development process.Without substantial post-processing to filter out the bad input code, I question how valuable the context from coding agents is for training data. Again, it's probably quite useful for other things.reply",
      "I suspect the product telemetry would be more useful - things like success of interaction vs requiring subsequent editing, success from tool use, success from context & prompt tuning parameters would be for valuable to the product than just feeding more bits into the core model.reply",
      "There is company, maybe even a YC company, which I saw posting about wanting to pay people for private repos that died on the vine, and were never released as products. I believe they were asking for pre-2022 code to avoid LLM taint. This was to be used as training data.This is all a fuzzy memory, I could have multiple details wrong.reply",
      "Hello folks! I've been working on Kiro for nearly a year now. Happy to chat about some of the things that make it unique in the IDE space. We've added a few powerful things that I think make it a bit different from other similar AI editors.In specific, I'm really proud of \"spec driven development\", which is based on the internal processes that software development teams at Amazon use to build very large technical projects. Kiro can take your basic \"vibe coding\" prompt, and expand it into deep technical requirements, a design document (with diagrams), and a task list to break down large projects into smaller, more realistic chunks of work.I've had a ton of fun not just working on Kiro, but also coding with Kiro. I've also published a sample project I built while working on Kiro. It's a fairly extensive codebase for an infinite crafting game, almost 95% AI coded, thanks to the power of Kiro: https://github.com/kirodotdev/spirit-of-kiroreply",
      "> It's a fairly extensive codebase for an infinite crafting game, almost 95% AI coded, thanks to the power of Kiro: https://github.com/kirodotdev/spirit-of-kiroThis, along with the \"CHALLENGE.md\" and \"ROADMAP.md\" document, is an incredibly cool way to show off your project and to give people a playground to use to try it out. The game idea itself is pretty interesting too.It would be awesome if I ... didn't have to deal with AWS to use it. I guess maybe that might be a good use case for agentic coding: \"Hey, Kiro - can you make this thing just use a local database and my Anthropic API key?\"Complaining aside though, I think that's just such a cool framework for a demo. Nice idea.reply",
      "Thanks a lot! I plan to fork the project and make a generic version that runs entirely locally using your GPU to do everything. My early tests ran pretty well on NVIDIA 5070. So that's next on my project list to open source in my free time. The only thing more fun that building an AI agent, is using it to build your own ideas!reply"
    ],
    "link": "https://kiro.dev/blog/introducing-kiro/",
    "first_paragraph": "A new agentic IDE that works alongside you from prototype to productionNikhil SwaminathanProduct LeadDeepak SinghVP DevEx & Agents"
  },
  {
    "title": "Protecting My Attention at the Dopamine Carnival (amirsharif.com)",
    "points": 6,
    "submitter": "overload119",
    "submit_time": "2025-07-15T00:34:40 1752539680",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.amirsharif.com/protecting-my-attention-at-the-dopamine-carnival",
    "first_paragraph": "What the hell is going on with our brains? It seems like the algorithms have already taken over and the scientific literature is catching up with the actual impact technology is having.Here are some of the more surprising results I\u2019ve read:What I\u2019m doing:PS. They call it centaur guardrails because it\u2019s AI on the bottom, human on the top. Nice.PSS. I stumbled on this elegant box you put phones into and it blocks all radio communications. You can also buy a dupe on Amazon without the blocking features and just a lock instead."
  },
  {
    "title": "Dog Walk: Blender Studio's official game project (blenderstudio.itch.io)",
    "points": 61,
    "submitter": "doener",
    "submit_time": "2025-07-14T21:33:16 1752528796",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=44565603",
    "comments": [
      "Not their first time around the block! https://apricot.blender.org/It's nice that the free game engine options are so much richer now than they were in 2008; if memory serves they had trouble implementing Go Frankie fully in the blender game engine, so they made one version in BGE and another in Crystal Space.Now you can just use Godot.reply",
      "Is apricot any good? I happen to love 3d platformers, but the trailer was not encouraging.reply",
      "This looks great. Just a note though that this is \"free as in beer\". If you want the source code you'd need to login and pay, it seems.https://studio.blender.org/projects/dogwalk/gallery/?asset=8...reply",
      "It's free as in freedom!> The license of our sources is a bit muddled. We'll try to clear that up asap. The full production repository is CC-BY since it mostly includes the original art assets. The source code of the game is GPLv3 since since [sic] that makes more sense for the code base of the project.They just aren't distributing the source for free, it seems, but you are free to redistribute it however you'd like.reply",
      "They are distributing for free. For free, they are distributing a compiled version of the game which I have no source to, and no license to creative derivative works of, or to perform or display publicly, and so on.That thing, which they call Dogwalk, and are distributing for free, is clearly not open source.The other thing, which they probably also call dogwalk, and they'll give you if you pay them presumably is open source (or maybe the more accurate term is \"free software\" since the source isn't publicly available - i.e. open), but that doesn't make the download on the page linked by HN open source.reply",
      "> They just aren't distributing the source for free, it seems, but you are free to redistribute it however you'd like.Yes, that was my point. I will know the license when I see it in the distributed code :)reply",
      "But it's still open source!https://www.gnu.org/licenses/gpl-faq.html> If I distribute GPLed software for a fee, am I required to also make it available to the public without a charge?> No. However, if someone pays your fee and gets a copy, the GPL gives them the freedom to release it to the public, with or without a fee. For example, someone could pay your fee, and then put her copy on a web site for the general public.reply",
      "Can't unzip on MacOSreply",
      "Earlier: https://news.ycombinator.com/item?id=44554680reply"
    ],
    "link": "https://blenderstudio.itch.io/dogwalk",
    "first_paragraph": "A downloadable game for Windows, macOS, and LinuxBlender Studio's official game project is a short casual interactive  story.  Play  a big, adorable dog traversing through winter woods and help out a   little kid decorate a snowman with  colorful items hidden in the   environment.You are let loose to roam camping grounds, forest paths, idyllic creeks and a frozen pond in this miniature open world.Guide or drag around your little kid owner that you have in tow. Help each other out, be a menace or be a good boy.\u00a0Dive straight in and have the game react to your play-style and choices. There are no fail states. Only player driven moments. Traverse an environment made of real-life paper crafted models, scanned and recreated to be played with. Brought to you by the Blender Studio as the new free and creative commons \"Open Project\". Made with, and available as free and open-source software.\u00a0The project was used to test and improve both Blender and the Godot Game Engine.\u00a0Find all the source fi"
  },
  {
    "title": "DEWLine Museum \u2013 The Distant Early Warning Radar Line (dewlinemuseum.com)",
    "points": 31,
    "submitter": "reaperducer",
    "submit_time": "2025-07-14T22:28:08 1752532088",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44566034",
    "comments": [
      "They could really build geodesic domes in those days. Most of the abandoned domes are intact, after half a century, unmaintained, in an Arctic climate. They're aluminum frames with Fiberglas panels.Geodesic domes were taken over by the \"natural materials\" people in the 1960s and 1970s. This doesn't work. Geodesic domes need standard manufactured components built to tight tolerances. Then they just bolt together. Domes built with wood and shingles do not work very well.[1]Google proposed to build a big geodesic dome for their HQ in Mountain View. It probably would have been better than what they did build, which looks like some kind of sports arena.[1] https://www.domerama.com/dome-basics/domebook-1-2/reply",
      "Reminds me of when we used to drive past a Pinetree Line station every summer on the way to visit my grandparents.reply",
      "Got to play around on a White Alice (?) station near Homer, Alaska maybe 40 years ago or so. It was an abandoned station on Ohlson Mountain (https://en.wikipedia.org/wiki/Ohlson_Mountain_Air_Force_Stat...).There was a huge dish pointing straight up. A friend and I walked around on the dish. There was a very small compartment more or less where the elevation axis was. The slightly creepy feeling I might get stuck in it kept me from going in but my friend did.Another large structure was likely a transmitter. A large surface with a grid of smaller antennas covering one side.Most cool to me though were the rooms with  6 foot high panels with all manner of analog meters, switches, lights.... Nothing worked of course, most everything was smashed. I wish now that I had brought some tools and removed as many of the components as I could.My overall impression was a kind of wonderment that so much money and effort would be expended by the U.S. government to watch for Soviet aircraft/missiles. So much equipment built, foundations poured, cinder blocks stacked...And then I suppose sophisticated satellites made it all obsolete.reply",
      "Eventual replacement:* https://en.wikipedia.org/wiki/North_Warning_SystemAn upgrade was recently announced with a collaboration with Australia:* https://www.cbc.ca/news/canada/north/canada-early-warning-de...* https://en.wikipedia.org/wiki/Jindalee_Operational_Radar_Net...reply"
    ],
    "link": "https://dewlinemuseum.com/",
    "first_paragraph": "DEWLine Museum - HOMEIt only took 32 months to build the DEWLine. Only those associated with this massive construction project know the extent of the difficulties involved, the hardships endured, and the intense effort required to build this surveillance system in so short a time. The radar consoles at all of the DEWLine's 33 stations across the Arctic were manned 24 hours a day, 365 days a year, for 36 years, without fail. The operation and maintenance of the equipment and the site itself was a constant challenge.Thousands upon thousands of 55-gallon fuel drums scattered across the Arctic  tundra. Open dumps full of debris. Hazardous waste left in the open. Vehicles left to rust away in the Arctic wilderness. How could this have happened? Why did it happen?Here are over forty YouTube videos about to the DEWLine. Some are long and some short, but all will be of interest to visitors seeking more information on the DEWLine. So, go get your popcorn and enjoy the movies.We are using Flickr"
  },
  {
    "title": "NeuralOS: An operating system powered by neural networks (neural-os.com)",
    "points": 85,
    "submitter": "yuntian",
    "submit_time": "2025-07-14T19:54:26 1752522866",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=44564531",
    "comments": [
      "Thanks everyone for trying out NeuralOS, and apologies for the frustrating user experience!I coded up the demo myself and didn't anticipate how disruptive the intermittent warning messages about waiting users would become. The demo is quite resource-intensive: each session currently requires its own H100 GPU, and I'm already using a dispatcher-worker setup with 8 parallel workers. Unfortunately, demand exceeded my setup, causing significant lag and I had to limit sessions to 60 more seconds when others are waiting. Additionally, the underlying diffusion model itself is slow to run, resulting in a frame rate typically below 2 fps, further compounded by network bottlenecks.As for model capabilities, NeuralOS is indeed quite limited at this point (as acknowledged in my paper abstract). That's why the demo interactions shown in my tweet were minimal (opening Firefox, typing a URL).Overall, this is meant as a proof-of-concept demonstrating the potential of generative, neural-network-powered GUIs. It's fully open-source, and I hope others can help improve it going forward!Thanks again for the honest feedback.reply",
      "N\u01d0 h\u0103o, x\u00ece x\u00ece Yuntian!\nI read the readme and paper but haven\u2019t played around much yet. I find this fascinating and I don\u2019t care much about poor \u201cexperience\u201d because intuitively I feel this idea couldn\u2019t produce something as reliable and flexible as a real OS anyway. I see you talked about inability to install new software and my reaction was \u201cwell obviously\u201d, because surely it will be at least as limited as the training data, while a real OS provides lots of software of great complexity which is seldom used.Could you talk about your hopes for the future on this project? What are your thoughts on having a more simplified interface which could combine inputs in a more abstract way, or are you only interested in simulating a traditional OS?Thanks again.PS the waiting time while firefox \u201cloads\u201d made me laugh. I presume this is also simulated.reply",
      "Thanks for your comment! I completely agree that currently NeuralOS is far from being as reliable as a real OS. The Firefox loading time is indeed a funny artifact of the neural model simulating delay in real OS.However, my real dream behind this project is to blur the boundaries across applications, not just simulate traditional OS interactions. For example, imagine converting a movie we're watching directly into an interactive video game, or instantly changing the interface of an app (like Signal) to something we prefer (like Facebook Messenger) on the fly.Of course, the current training data severely limits what's achievable today. But looking forward, I envision combining techniques from controllable text generation (such as Zhiting Hu's \"Toward Controlled Generation of Text\" paper) or synthesizing new interaction data to achieve greater and customization. I believe this is a promising path toward creating truly generative and personalized interfaces.Thanks again for your interest!reply",
      "Maybe put the warning below the UI, so it doesn't cause the layout to change?reply",
      "Good idea. I'll update when no one is using it, don't want to cause further interruptions...reply",
      "I tried to use this but the lag made it impossible to even click on an icon. On top of that, a message that other people were waiting popped up intermittently, pushing the emulation down the page, away from the mouse pointer. I'm not sure what sort of experience you're aiming for, but this probably isn't it.reply",
      "I didn't get to do much. Had a hard time clicking on Firefox and then getting to the nav bar and type in \"Hackernews\". Boy was that wild watching it type. Those definitely weren't letters. Then it tried to translate the page for me into Finish and weirdly the \"I'm not a robot\" box would appear, disappear, and then I'd see the title of some paper. I never actually made it to the Google results...It's an interesting project. I'll totally accept \"for fun\" or \"because\" but I'm interested in the why. Even if just a very narrow thing, is there any benefits we would get from using a ML based OS? I mean it is definitely cool and that has merit in its own right, but people talk about Neural OSs and I just don't \"get it\"reply",
      "This brings personal nostalgia to when I was very young and made an \"OS\" in PowerPoint using links between slides, animations, and the embedded internet explorer object. Similarly, I'm not sure I see any practical use in this. Still it's a really fascinating conceptual demonstration of networks understanding intent in the complex state-machine that is a graphical user interface.reply",
      "I did a similar thing when I was younger, except with Batch.reply",
      "I'm glad I wasn't the only one who did this, except for me, I used Microsoft Frontpage.reply"
    ],
    "link": "https://neural-os.com/",
    "first_paragraph": "\n\n                    Project Code: anonymous.4open.science/r/neural-os\n                \n"
  },
  {
    "title": "Doge Denizen Marko Elez Leaked API Key for XAI (krebsonsecurity.com)",
    "points": 13,
    "submitter": "todsacerdoti",
    "submit_time": "2025-07-15T01:24:45 1752542685",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44567008",
    "comments": [
      "This was the \"normalize Indian-hate\" guy.reply",
      "> \u201cIf a developer can\u2019t keep an API key private, it raises questions about how they\u2019re handling far more sensitive government information behind closed doors,\u201dIt raises additional questions. Plenty of questions already unanswered. Seems likely it's been a shitshow.reply"
    ],
    "link": "https://krebsonsecurity.com/2025/07/doge-denizen-marko-elez-leaked-api-key-for-xai/",
    "first_paragraph": "Marko Elez, a 25-year-old employee at Elon Musk\u2019s Department of Government Efficiency (DOGE), has been granted access to sensitive databases at the U.S. Social Security Administration, the Treasury and Justice departments, and the Department of Homeland Security. So it should fill all Americans with a deep sense of confidence to learn that Mr. Elez over the weekend inadvertently published a private key that allowed anyone to interact directly with more than four dozen large language models (LLMs) developed by Musk\u2019s artificial intelligence company xAI.Image: Shutterstock, @sdx15.On July 13, Mr. Elez committed a code script to GitHub called \u201cagent.py\u201d that included a private application programming interface (API) key for xAI. The inclusion of the private key was first flagged by GitGuardian, a company that specializes in detecting and remediating exposed secrets in public and proprietary environments. GitGuardian\u2019s systems constantly scan GitHub and other code repositories for exposed "
  },
  {
    "title": "Context Rot: How increasing input tokens impacts LLM performance (trychroma.com)",
    "points": 88,
    "submitter": "kellyhongsn",
    "submit_time": "2025-07-14T19:25:15 1752521115",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=44564248",
    "comments": [
      "I've definitely noticed this anecdotally.Especially with Gemini Pro when providing long form textual references, providing many documents in a single context windows gives worse answers than having it summarize documents first, ask a question about the summary only, then provide the full text of the sub-documents on request (rag style or just simple agent loop).Similarly I've personally noticed that Claude Code with Opus or Sonnet gets worse the more compactions happen, it's unclear to me whether it's just the summary gets worse, or if its the context window having a higher percentage of less relevant data, but even clearing the context and asking it to re-read the relevant files (even if they were mentioned and summarized in the compaction) gives better results.reply",
      "Gemini loses coherence and reasoning ability well before the chat hits the context limitations, and according to this report, it is the best model on several dimensions.Long story short: Context engineering is still king, RAG is not deadreply",
      "Yep, it can decohere really badly with bigger context. It's not only context related though. Sometimes it can lose focus early on in a way that is impossible to get it back on track.reply",
      "RAG was never going away, the people who say that are the same types who say software engineers will be totally replaced with AI.LLMs will need RAG one way or another, you can hide it from the user, but it still must be there.reply",
      "Yep. The easiest way to tell someone has no experience with LLMs is if they say \u201cRAG is dead\u201dreply",
      "> someone has no experience with LLMsThats 99% of coders. No need to gatekeep.reply",
      "I feel like the optimal coding agent would do this automatically - collect and (sometimes) summarize the required parts of code, MCP responses, repo maps etc., then combine the results into a new message in a new 'chat' that would contain all the required parts and nothing else. It's basically what I already do with aider, and I feel the performance (in situations with a lot of context) is way better than any agentic / more automated workflow I've tried so far, but it is a lot of work.reply",
      "Have you tried NotebookLM which basically does this as an app on the bg (chunking and summarising many docs) and you can -chat- with the full corpus using RAGreply",
      "This effect is well known but not well documented so far, so great job here.It's actually even more significant than it's possible to benchmark easily (though I'm glad this paper has done so.)Truly useful LLM applications live at the boundaries of what the model can do. That is, attending to some aspect of the context that might be several logical \"hops\" away from the actual question or task.I suspect that the context rot problem gets much worse for these more complex tasks... in fact, exponentially so for each logical \"hop\" which is required to answer successfully. Each hop compounds the \"attention difficulty\" which is increased by long/distracting contexts.reply",
      "Is this due to lack of specific long-context training, or is it more limitations of encoding or similar?I've noticed this issue as well with smaller local models that have relatively long contexts, say a 8B model with 128k context.I imagined they performed special recall training for these long context models, but the results seem... not so great.reply"
    ],
    "link": "https://research.trychroma.com/context-rot",
    "first_paragraph": "Claude Sonnet 4, GPT-4.1, Qwen3-32B, and Gemini 2.5 Flash on Repeated Words TaskRecent developments in LLMs show a trend toward longer context windows, with the input token count of the latest models reaching the millions. Because these models achieve near-perfect scores on widely adopted benchmarks like Needle in a Haystack (NIAH) [1], it\u2019s often assumed that their performance is uniform across long-context tasks.However, NIAH is fundamentally a simple retrieval task, in which a known sentence (the \u201cneedle\u201d) is placed in a long document of unrelated text (the \u201chaystack\u201d), and the model is prompted to retrieve it. While scalable, this benchmark typically assesses direct lexical matching, which may not be representative of flexible, semantically oriented tasks.Example Needle in a Haystack (NIAH) SetupWe extend the standard NIAH task, to investigate model behavior in previously underexplored settings. We examine the effects of needles with semantic, rather than direct lexical matches, as"
  },
  {
    "title": "I Solved the Century-Old Mystery of a Miraculous Shipwreck Survivor (thewalrus.ca)",
    "points": 15,
    "submitter": "Thevet",
    "submit_time": "2025-07-12T22:24:57 1752359097",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44545695",
    "comments": [
      "Its amazing how much and how little things have changed when it comes to media.  Good reminder to always be skeptical about sensationalism.reply",
      "If you liked this story, you might like the game Return of the Obra Dinn, which is kinda just this but for ~60 different people on a fictional ship.reply",
      "Oceanliner Designs has a great recreation of this accident: https://youtu.be/-9ZLZ8hiA5Y?si=ElcaIqEQhTHsElkM...and of the last 10 minutes of this accident: https://youtu.be/N5CxSRsiUys?si=wS42xVXUb5Awb95Ureply",
      "Tldr: 'Davidson stripped off his nightshirt and swam away from the ship. The suction took him down, and when he came up, he swam into a frenzied crowd. \u201cThey tramped me under three times before I got through them. I swam on a little farther, but the water was fearfully cold, and I was out of practice swimming,\u201d he said.Davidson was picked up by a lifeboat and taken to the _Storstad_, which survived the collision.'The article was apparently edited to increase prolixity.reply",
      "I thought the background was interesting and helpful to knowreply"
    ],
    "link": "https://thewalrus.ca/empress-of-ireland-survivor-mystery/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Bedrock \u2013 An 8-bit computing system for running programs anywhere (benbridle.com)",
    "points": 75,
    "submitter": "benbridle",
    "submit_time": "2025-07-10T22:20:18 1752186018",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44526322",
    "comments": [
      "This is the latest in a very honourable tradition. My first encounter with it was with Martin Richards's BCPL system in 1972. The compiler generated a hypothetical ISA called OCODE, from which backends generated pretty good native code for Titan-2 and System/360, among others. One of those backends generated INTCODE, which was an extremely reduced ISA, for which an interpreter could be easily written (I wrote one in Fortran). Richards also provided the BCPL compiler and runtime library in INTCODE, so you could quickly have BCPL running interpretively. Then you could use this interpretive version to bootstrap a native-code backend implementation. Put this all together, and you now have a very easy compiler port.Wirth's Pascal-P compiler of 1974(?) used the same idea, also in aid of a highly portable compiler. I have never been able to find out whether this was an independent invention, or whether Wirth was influenced by Richards's work.Of course, the JVM and CLR are descendents of this, but they build a very complex structure on the basic idea. Writing an implementation of one of these virtual machines is not for the faint of heart.So I think Bedrock can be very useful as a compiler target, if nothing else. However, I must agree with some of the other commenters that the 64KiB address space makes it very much of a niche tool. Come up with a 32-bit variant that's not much more complicated, and I think you have a winner.reply",
      "Wouldn't the 32-bit variant just be WebAssembly?reply",
      "Regarding the 64kB limit: I notice that an implementation can provide the programmer an optional memory block of up to 64MB, IIUC:https://benbridle.com/projects/bedrock/user-manual/memory-de...reply",
      "I'm not steeped in computer science, so please pardon me if the following are dumb questions.> Programs written for Bedrock can run on any computer system, so long as a Bedrock emulator has been implemented for that system.Isn't that true of any program? As long as the language that the program is written in is implemented on the system, any (valid?) program in that language will run on that system?reply",
      "Based on the OP, I think the idea is that it's very easy to port this emulator to a new system.reply",
      "I made a bedrock onion of death: https://paste.pictures/FgqbwUTCY8.pngCouldn't have done it without youreply",
      "Love this! Takes me back to the literal 8-bit computers of the 80s when it was much easier to learn to program with, for example, BASIC built into the operating system.reply",
      "I have not delved to deep in the code, but is there any functional differences it has over Java other than the size ?Presumably Java would also be pretty tiny if we wrote it in bytecode instead of higher lever Java.reply",
      "The Java bytecode instruction set actually has a quite complicated specification: https://docs.oracle.com/javase/specs/jvms/se8/html/Which means implementations also have to be correspondingly complicated. You have to handle quite a few different primitive data types each with their own opcodes, class hierarchies, method resolution (including overloading), a \"constant pool\" per class, garbage collection, exception handling, ...I would expect a minimal JVM that can actually run real code generated by a Java compiler to require at least 10x as much code as a minimal Bedrock VM, and probably closer to 100x.reply",
      "This is fantastic! As someone who's used PICO-8 in after-school STEM enrichment classes (and has evaluated uxn), one of the frustrations that my students have always had is easy I/O and persisting state -- for saving/loading game progress and settings, of course. The clipboard and registry devices seem like a good fit.I hope you stick with this!reply"
    ],
    "link": "https://benbridle.com/projects/bedrock.html",
    "first_paragraph": "Bedrock is a compact and portable 8-bit computer system, designed to last forever. Click here to jump straight to the live demos.Bedrock is a computer system that makes it easy to write useful programs that will last forever. The system is small and quick to learn, with only 32 instructions and 12 devices to remember.Bedrock isn\u2019t a real computer system that you can pick up and hold in your hands. It\u2019s a specification that describes an interface for any kind of computing device, allowing you to write programs that will run on any device without having to worry about the peculiarities of the underlying hardware.Programs written for Bedrock can run on any computer system, so long as a Bedrock emulator has been implemented for that system. The emulator acts as a thin translation layer between the program and the system, and is designed to be easy to implement on any computer, console, or handheld, no matter how old or limited. The core system can be implemented in a few hours, and the 12 "
  },
  {
    "title": "SQLite async connection pool for high-performance (github.com/slaily)",
    "points": 55,
    "submitter": "slaily",
    "submit_time": "2025-07-11T10:26:32 1752229592",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=44530518",
    "comments": [
      "This is strange on so many levels.SQLite does not even do network I/O.How does sharing a connection (and transaction scope) in an asyncio environment even work? Won\u2019t you still need a connection per asyncio context?Does sqlite_open really take long compared to the inevitable contention for the write lock you\u2019ll see when you have many concurrent contexts?Does sqlite_open even register in comparison with the overhead of the python interpreter?What is an asyncio SQLite connection anyways? Isn\u2019t it just a regular one that gets hucked into a separate thread?reply",
      "If you're talking to a 100KB SQLite database file this kind of thing is likely unnecessary, just opening and closing a connection for each query is probably fine.If you're querying a multi-GB SQLite database there are things like per-connection caches that may benefit from a connection pool.> What is an asyncio SQLite connection anyways? Isn\u2019t it just a regular one that gets hucked into a separate thread?Basically yes - aiosqlite works by opening each connection in a dedicated thread and then sending async queries to it and waiting for a response that gets sent to a Future.https://github.com/omnilib/aiosqlite/blob/895fd9183b43cecce8...reply",
      "That's even crazier - so you're using asyncio because you have a ton of slow network-bound stuff - but for your database access you are running every sqlite connection in it's own thread and just managing those threads via the asyncio event loop?reply",
      "Thread pooling for databases, whether network based, or disk based, is common. A lot of times it will be baked into your client, so the fact that you think it\u2019s crazy means you\u2019ve only dealt with clients that did this for you.For really large data sets, you can query and wait a few minutes before getting a result. Do you really want to await that?reply",
      "This is a common paradigm for blocking APIs (e.g. the sqlite driver)reply",
      "What is crazy about that?reply",
      "Of course I don't know what the parent is thinking, but my thought is: why can't it be entirely event loop driven? What are the threads adding here?(I don't know anything about that project and this isn't meant as a criticism of its design or a challenge - cos I'd probably lose :-) )reply",
      "Cause the sqlite-lib that python ships isn't async, and sqlite itself usually doesn't give an async API.reply",
      "Python's asyncio is single threaded. If you didn't send them into a different thread, the entire event loop would block, and it would degenerate to a fully synchronous single threaded program with additional overhead.reply",
      "> If you're querying a multi-GB SQLite databaseIn which case SQLite is probably the wrong tool for the job, and you should be using Postgres or MySQL that is actually designed from the ground up for lots of concurrent connections.SQLite is amazing. I love SQLite. But I love it for single-user single-machine scenarios. Not multi-user. Not over a network.reply"
    ],
    "link": "https://github.com/slaily/aiosqlitepool",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \ud83d\udee1\ufe0fA resilient, high-performance asynchronous connection pool layer for SQLite, designed for efficient and scalable database operations.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\n\n\n\n\n\naiosqlitepool is a high-performance connection pool for asyncio SQLite applications. By managing a pool of reusable database connections, it eliminates connection overhead and delivers significant performance gains.Important: aiosqlitepool is not a SQLite database driver.It's a performance-boosting layer that works with an asyncio driver like aiosqlite, not as a replacement for it.aiosqlitepool in three points:aiosqlitepool requires the aiosqlite driver to be installed as a peer dependency.Install with your preferred package manager:pipuvPoetryYou must provide a conn"
  },
  {
    "title": "Replicube: 3D shader puzzle game, online demo (replicube.xyz)",
    "points": 85,
    "submitter": "inktype",
    "submit_time": "2025-07-11T18:00:01 1752256801",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44535202",
    "comments": [
      "Man, that's a fantastic way of making me interested in the game. I'd heard of it before, but up until seeing this I figured I'd have to spend money and hop onto my PC (where I play games, as opposed to my work laptop) to check it out.Now, 15 minutes after clicking the link, I've tried the game out, had a fun time, and ... just might have to buy it.I'm impressed that this sort of thing was possible with Godot too. Very cool.reply",
      "related discussion:Replicube: A puzzle game about writing code to create shapes (https://news.ycombinator.com/item?id=43979916)reply",
      "I think today's answer is actually incorrect. Or at least the reference animation has a hitch where it shows all red for frames 12 and 13. if it shows 2 purples for frame 13 then the animation is smoother and actually the math is much simpler.reply",
      "Very fun! Not sure if it's a me issue, but the music kept getting static-y in the browser version for me. Maybe something to look into.reply",
      "It's an issue with Godot on the web unfortunately, when you're dropping frames the audio starts clipping and crackling. Judging by the other comment, the lua integration must be doing some heavy work.reply",
      "I found that if I remove the number lines or position the display straight on to an axis, that the crackling drops considerably.reply",
      "Same for me, when the code is not correct, the music is much slower and very crackly. Once the code gives the correct solution, the music speeds up and the crackles go away.Also agreed, very fun!reply",
      "Hard to use on a mobile with the keyboard popping over the text editor, but looks like lots of fun. Wish there was a mobile app version.reply",
      "Nice!On the leaderboard I'd like to see code size vs cycles in a 2D plot with the Pareto front highlighted.reply",
      "Note the \"What is Replicube?\" and \"Introductory Puzzles\" button on the bottom, which might be easy to miss.reply"
    ],
    "link": "https://replicube.xyz/staging/",
    "first_paragraph": ""
  },
  {
    "title": "Cognition (Devin AI) to Acquire Windsurf (cognition.ai)",
    "points": 361,
    "submitter": "alazsengul",
    "submit_time": "2025-07-14T18:07:15 1752516435",
    "num_comments": 281,
    "comments_url": "https://news.ycombinator.com/item?id=44563324",
    "comments": [
      "I think the amount of turmoil around these deals is giving more weight to the possibility that we\u2019re in a massive bubble thats quite divorced from any kind of fundamentals. Sooner or later the bubbles gonna burst.reply",
      "> divorced from any kind of fundamentalsAnthropic ARR went $1B -> $4B in the first half of this year. They're getting my $200 a month and it's easily the best money I spend. There's definitely something there.reply",
      "\"Sooner or later the bubble's gonna burst\" and \"There's definitely something there\" aren't mutually exclusive - in fact they often go together.It makes me perhaps a little sad to say that \"I'm showing my age\" by bringing up the .com boom/bust, but this feels exactly the same. The late 90s/early 00s were the dawn of the consumer Internet, and all of that tech vastly changed global society and brought you companies like Google and Amazon. It also brought you Pets.com, Webvan, and the bajillion other companies chronicled in \"Fucked Company\".You mention Anthropic, which I think is in a good a position as any to be one of the winners. I'm much less convinced about tons of the others. Look at Cursor - they were a first moving leader, but I know tons of people (myself included) who have cancelled their subscription because there are now better options.reply",
      "> It makes me perhaps a little sad to say that \"I'm showing my age\"Please don't say stuff like that.As a 20-something who was in diapers during the dot-com boom, I really appreciate your insight. Thanks for sticking around on HN!reply",
      "I genuinely don't understand what value Cursor itself brings. It's like a wrapper for some APIs, right? As far as I can tell there's like four actual AI firms in the world and everyone else is trying to whitelabel. It reminds me of the hosting industry in the early 2000s.reply",
      "It's a very well done wrapper that improves your coding productivity a lot.reply",
      "The problem is that they have no moat and the underlying provider can easily cut them out.reply",
      "> I genuinely don't understand what value Cursor itself brings. It's like a wrapper for some APIs, right?By similar token Windows is mostly a wrapper around Intel and AMD and now Qualcomm CPUs. Cursor/Windsurf add a lot of useful functionality. So much so so that Microsoft GitHub Copilot is losing marketshare to these guys.reply",
      "what're you finding better than cursor now?reply",
      "Claude Code with Pro, Max100, or Max200 subscriptions. Works with any IDE including none.For the time being, nothing comes close, at least for me.reply"
    ],
    "link": "https://cognition.ai/blog/windsurf",
    "first_paragraph": "Cognition has signed a definitive agreement to acquire Windsurf, the agentic IDE.We\u2019re excited to share that Cognition has signed a definitive agreement to acquire Windsurf, the agentic IDE.The acquisition includes Windsurf\u2019s IP, product, trademark and brand, and strong business. Above all, it includes Windsurf\u2019s world-class people, some of the best talent in our industry, whom we\u2019re privileged to welcome to our team.In the immediate term, the Windsurf team will continue to operate as they have been, and we will remain focused on our work of accelerating your engineering with Devin. Over the coming months, we\u2019ll be investing heavily in integrating Windsurf\u2019s capabilities and unique IP into Cognition\u2019s products.With this deal, we\u2019re doubling down on our mission of building the future of software engineering.Below is the note I sent to the Cognition team this morning:Team,As discussed during our all-hands, we are acquiring Windsurf. We have now signed a definitive agreement and we couldn"
  },
  {
    "title": "Anthropic, Google, OpenAI and XAI Granted Up to $200M from Defense Department (cnbc.com)",
    "points": 122,
    "submitter": "ChrisArchitect",
    "submit_time": "2025-07-14T21:16:19 1752527779",
    "num_comments": 81,
    "comments_url": "https://news.ycombinator.com/item?id=44565416",
    "comments": [
      "This money should be going to companies that need 200M.For 200M Google will open an account, send an email that says:You're account is ready, there is $40m left on the retainer. We can code up some email template for 40M if you want.reply",
      "or not spent by the government?\nI mean, unless this is for some really specific thing that really needs a push, I think there's sort of enough money flowing this way already, today. (5 years ago, again a different story)reply",
      "Payback for the presidential library gifts.  The Defense Department doesn't need one hallucinating chatbot let alone four...reply",
      "This actually makes sense because in the meantime Meta is ditching the open-source (open-weights) direction.Before the national security narrative took over, the main argument was about \"safe\" AI, where releasing models as open weights was considered \"not safe.\" Now that no major US AI players release premium open-weights models, the \"safety\" narrative isn't needed anymore\u2014so cooperating with the US military is feasible again.reply",
      "Are Amazon and Meta the ones losing out the most here, in terms of the companies building foundational models?Probably more understandable for Meta, since they've been leaving the B2B space since Workplace has been sunset. Amazon losing out on this is pretty rough for AWS though.reply",
      "Is Amazon trying to build a competitive foundation model? From what I can see AWS is instead focused on hosting and re-licensing Claude, Cohere, DeepSeek and others via Bedrock. And it's pretty likely that a large chunk of this $200M will anyways go to AWS. So I'd hardly call them a loser here.reply",
      "Amazon has a number of foundation models under the name Amazon Nova, which they claimed were SOTA on release but I haven't heard much at all about them since.reply",
      "They are not good...reply",
      "Aka the \"sell gold pans during a gold rush\" strategy.AFAIK AWS are pushing pretty hard with GovCloud these days.reply",
      "I think that would be power components like transformers for the grid.reply"
    ],
    "link": "https://www.cnbc.com/2025/07/14/anthropic-google-openai-xai-granted-up-to-200-million-from-dod.html",
    "first_paragraph": ""
  },
  {
    "title": "Building Modular Rails Applications: A Deep Dive into Rails Engines (panasiti.me)",
    "points": 127,
    "submitter": "giovapanasiti",
    "submit_time": "2025-07-14T15:30:31 1752507031",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=44561354",
    "comments": [
      "One of the reasons microservice architecture originally became popular was to break apart monolithic applications. In many cases, I bet a big driver was a lack of separation of concerns, and a more modular design was desired. There are many ways to put up walls in software to help make software more modular and self-contained. Rails engines are a good way to make more a rails app more modular. The number of times I've seen microservices created for the purpose of modularity (not scaling concerns), and the complexity that has brought has really soured me on microservices.reply",
      "This is exactly my experience. Most of the time people go to microservices for the wrong reason and they will regret that for yearsreply",
      "Different sections of an app can use different databases, if the bottleneck is in the database.Different routes can be served by different servers, if the bottleneck is in CPU usage.Different async tasks can run on different task runner services, if the problem is tasks competing with each other.Different test suites can run for different sections of the app, if the problem is with tests taking too long to run.Github and others even allow specific subfolders to be \"owned\" by different teams.What else is there? Even slowness of compilation and/or initialization can be alleviated, depending on the language or framework.reply",
      "I think the point is that all of that adds complexity that is often unnecessary - a premature optimization if you will. It's like a hammer, and everything looks like a nail to a lot of people.reply",
      "GP isn\u2019t oppositional, they listed runtime constructs that all run off a single monolith. The point being you don\u2019t need so-called microservices for flexibility in the production environment.reply",
      "I've built numerous systems on AWS Lambda over the last 10 years, and have never once regretted it. YMMV.reply",
      "Ive regretted 99% of the services Ive built in AWS lambda over the years. Everytime it gets more complex than a couple hundred lines of code over a few lambas I start to think \u201cif this were just one service, development, deployments, cicd, testing, storage would all be simpler\u201d.reply",
      "My deployments to Lambda are extremely simple. All I do is hit save in VSCode and the Lambda is updated. Change the env to prod and it deploys instantly to prod.There's tools that make it easy, I'm still using a tool I built 10 years ago. Very little has changed except the addition of layers, which are also pretty easy and automatically handled in my dev tool.All the Lambdas I write also run locally, and testing isn't an issue.The only gripe I have with Lambda is when they deprecate older nodejs versions, and I am forced to update some of my Lambdas to run on current nodejs, which then leads to refactoring due to node module incompatibilities in some specific situations. But those are really nodejs problems and not so much Lambda problems, and it does get me to keep my apps updated.YMMV.reply",
      "> One of the reasons microservice architecture originally became popular was to break apart monolithic applications.I feel like the emphasis was on autoscaling parts of the app independently. (It\u2019s telling that this has been forgotten and now we only remember it as \u201csplitting up the app\u201d.)reply",
      "I use multiple services for resilience. Example: With multiple services that have clear separation of concerns, you can debug and fix your processing layer without stopping the collection layer. You can update a distributor while workers wait and vice versa. This way I never have downtime anxiety. No regrets.reply"
    ],
    "link": "https://www.panasiti.me/blog/modular-rails-applications-rails-engines-active-storage-dashboard/",
    "first_paragraph": "I\u2019ve been building Rails applications for the last 10 years on a daily base and almost all of them use active storage now. Users are uploading files and then the questions start rolling in from the team and they are always the same:\u201cHow much storage are we actually using?\u201d\n\u201cCan we see which files aren\u2019t attached to anything anymore?\u201d\n\u201cWhat types of files are users uploading the most?\u201d\n\u201cIs there a way to browse through all our stored files?\u201dI usually open the Rails console, write a few queries, and get the answers for the team or for the stakeholders. But you know this isn\u2019t sustainable. What I need is a proper dashboard, something visual, something that non-technical team members can use, something that doesn\u2019t require SSH access to production servers.This is exactly the problem I faced, and it led me down a fascinating journey into the world of Rails engines, ultimately resulting in the creation of Active Storage Dashboard, a mountable Rails engine that provides a modern interface for"
  },
  {
    "title": "Cidco MailStation as a Z80 Development Platform (2019) (jcs.org)",
    "points": 46,
    "submitter": "robin_reala",
    "submit_time": "2025-07-14T18:11:25 1752516685",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44563364",
    "comments": [
      "I think this was posted here because of the question on Retrocomputing Stackexchange: \u201cWhat was the last commercial Z80-based computer sold?\u201d (https://retrocomputing.stackexchange.com/a/31883/11579)reply",
      "https://en.wikipedia.org/wiki/S1_MP3_player used a Z80 SoC, and at least from a quick search, appears that they're still in production.reply",
      "I love that this site has an Easter egg if left idle long enough.reply",
      "How much room is there for a custom PCB? I'm a 6502 guy so I would like to keep the case but put something there with my favorite CPU.reply",
      "I've learned Z80 and 8051 a decade or two ago, and then forgot everything. Honestly both were easy to pick up, but I assume you're opinionated and/or an expert?Anything in particular that you like about the 6502?reply",
      "I think people like the way the 6502 wires up to peripherals.  Myself I think the Z80 is much better because it has enough registers and addressing modes that you can write compilers for it.  I know they had C compilers for it in 1984 because I typed in a C program for CP/M from Byte magazine and got it to run on my 6809-based TRS-80 Color Computer.  Programming languages for the 6502 were usually implemented with virtual machine techniques likehttps://en.wikipedia.org/wiki/SWEET16or the truly atrocioushttps://en.wikipedia.org/wiki/UCSD_Pascalwhich was one reason a generation of programmers hated PASCAL with a passion and declared you could pry BASIC from our cold dead hands.Myself I'd want to hollow it out and put something based onhttps://en.wikipedia.org/wiki/Zilog_eZ80because it is way faster,  has a bigger address space,  and has wider registers so you can do pointer math over that bigger address space unlike this turkeyhttps://en.wikipedia.org/wiki/WDC_65C816A lot of people enjoyed writing assembly for the 6502 back in the day though.reply"
    ],
    "link": "https://jcs.org/2019/05/03/mailstation",
    "first_paragraph": "The Cidco MailStation is a series of dedicated e-mail terminals sold\n\t\t\t\t\t\tin the 2000s as simple, standalone devices for people to use to send and receive\n\t\t\t\t\t\te-mail over dialup modem.\n\t\t\t\t\t\tWhile their POP3 e-mail functionality is of little use today, the hardware is a\n\t\t\t\t\t\tneat Z80 development platform that integrates a 320x128 LCD, full QWERTY keyboard,\n\t\t\t\t\t\tand an internal modem.After purchasing one (ok, four) on eBay some months ago, I've learned enough\n\t\t\t\t\t\tabout the platform to write my own software that allows it to be a terminal for\n\t\t\t\t\t\taccessing BBSes via its modem or as a terminal for a Unix machine connected over\n\t\t\t\t\t\tparallel cable.I've been\n\t\t\t\t\t\ttinkering\n\t\t\t\t\t\twith old computers in the past few years, but the\n\t\t\t\t\t\tBASIC-interpreter-hooked-up-to-a-TV\n\t\t\t\t\t\tor the single-board-6502 never really appealed to me.\n\t\t\t\t\t\tThis is probably because I skipped that generation of computing growing up, with\n\t\t\t\t\t\tmy first computers being full IBM-compatible PCs.The MailStat"
  },
  {
    "title": "Embedding user-defined indexes in Apache Parquet (apache.org)",
    "points": 94,
    "submitter": "jasim",
    "submit_time": "2025-07-14T16:29:02 1752510542",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=44562036",
    "comments": [
      "I think this post is a response to some new file format initiatives, based on the criticism that the Parquet file format is showing its age.One of the arguments is that there is no standardized way to extend Parquet with new kinds of metadata (like statistical summaries, HyperLogLog etc.)This post was written by the DataFusion folks, who have shown a clever way to do this without breaking backward compatibility with existing readers.They have inserted arbitrary data between footer and data pages, which other readers will ignore. But query engines like DataFusion can exploit it. They embed a new index to the .parquet file, and use that to improve query performance.In this specific instance, they add an index with all the distinct values of a column. Then they extend the DataFusion query engine to exploit that so that queries like `WHERE nation = 'Singapore'` can use that index to figure out whether the value exists in that .parquet file without having to scan the data pages (which is already optimized because there is a min-max filter to avoid scanning the entire dataset).Also in general this is a really good deep dive into columnar data storage.reply",
      "Yeah I'm happy to see this, we have been curious as part of figuring out cloud native storage extensions to GFQL (graph dataframe-native query lang), and my intuition was parquet was pluggable here... And this is the first I'm seeing a cogent writeup.Likewise, this means, afaict, it's likewise pretty straightforward to do novel indexing schemes within Iceberg as well just by reusing this.The other aspect I've been curious about is the happy path pluggable types for custom columns. This shows one way, but I'm unclear if same thing.reply",
      "What are the new file format initiatives you're referencing here?This solution seems clever overall, and finding a way to bolt on features of the latest-and-greatest new hotness without breaking backwards compatibility is a testament to the DataFusion team. Supporting legacy systems is crucial work, even if things need a ground-up rewrite periodically.reply",
      "Off the top of my head:- Vortex https://github.com/vortex-data/vortex- Lance https://github.com/lancedb/lance- Nimble https://github.com/facebookincubator/nimbleThere are also a bunch of ideas coming out of academia, but I don't know how many of them have a sustained effort behind them and not just a couple of papersreply",
      "Lance (from LanceDB folks), Nimble (from Meta folks, formerly known as Alpha); I think there are a few othershttps://github.com/lancedb/lancehttps://github.com/facebookincubator/nimblereply",
      "nice summary!reply",
      "Note that there are \"Puffin files\" associated with Iceberg which have some overlap with this functionality: https://iceberg.apache.org/puffin-spec/#file-structurereply",
      "Cool, but this is very specific to DataFusion, no?  Is there any chance this would be standardized so other Parquet readers could leverage the same technique?reply",
      "The technique can be applied by any engine, not just DataFusion. Each engine would have to know about the indexes in order to make use of them, but the fallback to parquet standard defaults means that the data is still readable by all.reply",
      "But does data fusion publish a specification of how this metadata can be read, along with a test suite for verifying implementations? Because if they don't, this cannot be reliably used by any other implreply"
    ],
    "link": "https://datafusion.apache.org/blog/2025/07/14/user-defined-parquet-indexes/",
    "first_paragraph": "Posted on: Mon 14 July 2025 by Qi Zhu, Jigao Luo, and Andrew LambIt\u2019s a common misconception that Apache Parquet files are limited to basic Min/Max/Null Count statistics and Bloom filters, and that adding more advanced indexes requires changing the specification or creating a new file format. In fact, footer metadata and offset-based addressing already provide everything needed to embed user-defined index structures within Parquet files without breaking compatibility with other Parquet readers.Motivating Example: Imagine your data has a Nation column with dozens of distinct values across thousands of Parquet files. You execute:Relying on the min/max statistics from the Parquet format will be ineffective at pruning files when Nation spans \"Argentina\" through \"Zimbabwe\". Instead of relying on a Bloom Filter, you may want to store a list of every distinct Nation value in the file near the end. At query time, your engine will read that tiny list and skip any file that does not contain 'Sin"
  },
  {
    "title": "Strategies for Fast Lexers (xnacly.me)",
    "points": 125,
    "submitter": "xnacly",
    "submit_time": "2025-07-14T14:42:54 1752504174",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=44560871",
    "comments": [
      "As an alternative to the computed gotos, you can use regular functions with the `[[musttail]]` attribute in Clang or GCC to achieve basically the same thing - the call in the tail position is replaced with a `jmp` instruction to the next function rather than to the label, and stack usage remains constant because the current frame is reutililzed for the called function. `musttail` requires that the calling function and callee have the same signature, and a prototype.You'd replace the JUMP_TARGET macro:    #define JUMP_TARGET goto *jump_table[(int32_t)l->input.p[l->pos]]\n\nWith:    #ifdef __clang__\n    #define musttail [[clang::musttail]]\n    #elif __GNUC__\n    #define musttail [[gnu::musttail]]\n    #else\n    #define musttail\n    #endif\n    #define JUMP_TARGET return musttail jump_table[(int32_t)l->input.p[l->pos]](l, a, out)\n\nThen move the jump table out to the top level and replace each `&&` with `&`.See diff (untested): https://www.diffchecker.com/V4yH3EyF/This approach has the advantage that it will work everywhere and not only on compilers that support the computed gotos - it just won't optimize it on compilers that don't support `musttail`. (Though it has been proposed to standardize it in a future version of C).It might also work better with code navigation tools that show functions, but not labels, and enables modularity as we can split rules over multiple translation units.Performance wise should basically be the same - though it's been argued that it may do better in some cases because the compiler's register allocator doesn't do a great job in large functions with computed gotos - whereas in musttail approach each function is a smaller unit and optimized separately.reply",
      "Can't wait for mandatory TCO coming to Rust. But it's not there yet. https://github.com/phi-go/rfcs/blob/guaranteed-tco/text/0000...reply",
      "Not sure I like the `become` keyword. Seems bizarre - someone encountering this word in code for the first time would have no idea what it's doing.Why don't they just use `tailcall`? That would make it's obvious what it's doing because we've been using the term for nearly half a century, and the entire literature on the subject uses the term \"tail call\".Even better would be to just automatically insert a tail call  - like every other language that has supported tail calls for decades - provided the callee has the same signature as the caller. If it's undesirable because we want a stack trace, then instead have some keyword or attribute to suppress the tail call - such as `no_tail`, `nontail` or `donttail`.Requiring tail calls to be marked will basically mean the optimization will be underutilized. Other than having a stack trace for debugging, there's basically no reason not to have the optimization on by default.reply",
      "Rust does allow tail call optimization. But that's LLVM's decision to optimize tail calls on a case-by-case basis. An explicit syntax to denote tail calls would be the difference between tail call optimization and guaranteed tall call elimination, which is important because if you're writing a tail-recursive function then it's pretty trivial to blow the stack at any moderate recursion depth unless you can guarantee the elimination.As for why it's not trivial for Rust to do this by default, consider the question of what should happen in the case of local destructors, which in an ordinary function would be called after `return myfunc()` returns, but in a tail-recursive function would need to be called beforehand. The proposals for `become` tend to handle this by making it a compiler error to have any locals with destructors in scope at the point of the tail-call, further motivating the explicit syntax.reply",
      "I'm generally pretty conservative about keywords. But it changes the semantics of the return, so it makes sense to change the word used in that position.reply",
      "> As introduced in the previous chapters, all identifers are hashed, thus we can also hash the known keywords at startup and make comparing them very fast.One trick that postgres uses [1][2] is perfect hashing [3]. Since you know in advance what your keywords are, you can design such hashing functions that for each w(i) in list of i keywords W, h(w(i)) = i. It essentially means no collisions and it's O(i) for the memory requirement.[1] https://github.com/postgres/postgres/blob/master/src/tools/P...[2] https://github.com/postgres/postgres/blob/master/src/tools/g...[3] https://en.wikipedia.org/wiki/Perfect_hash_functionreply",
      "I like to have my lexers operate on `FILE*`, rather than string-views. This has some real-world performance implications (not good ones); but, it does mean I can operate on streams. If the user has a c-string, the string can be easily wrapped by `funopen()` or `fopencookie()` to provide a `FILE*` adapter layer. (Most of my lexers include one of these, out-of-the-box.)Everything else, I stole from Bob Nystrom: I keep a local copy of the token's string in the token, aka, `char word[64]`. I try to minimize \"decision making\" during lexing. Really, at the consumption point we're only interested in an extremely small number of things: (1) does the lexeme start with a letter or a number?; (2) is it whitespace, and is that whitespace a new line?; or, (3) does it look like an operator?The only place where I've ever considered goto-threading was in keyword identification. However, if your language keeps keywords to \u2264 8 bytes, you can just bake the keywords into `uint64_t`'s and compare against those values. You can do a crapload of 64b compares/ns.The next level up (parsing) is slow enough to eat & memoize the decision making of the lexer; and, materially, it doesn't complicate the parser. (In fact: there's a lot of decision making that happens in the parser that'd have to be replicated in the lexer, otherwise.)The result, overall, is you can have a pretty general-purpose lexer that you can reuse for a any old C-ish language, and tune to your heart's content, without needing a custom rewrite, each time.reply",
      "Have you considered making your lexer operate in push mode instead?This does mean you have to worry about partial tokens ... but if you limit yourself to feeding full lines that mostly goes away.Besides, for reasonable-size workloads, \"read the whole file ahead of time\" is usually a win. The only time it's tempting not to do so is for REPLs.reply",
      "I agree. But, I also like the discipline of lexing from `FILE*`. I've ended up with cleaner separation of concerns throughout the front-end stack, because I can't dip back into the well, unless I'm thinking very clearly about that operation. For instance, I keep around coordinates of things, rather than pointers, etc.reply",
      "I'd do this in almost any other language than C :)In C, I like just passing a const char * around as input; this also gives me ability to return progress and unget chars as an added bonus.https://github.com/codr7/shi-c/blob/b1d5cb718b7eb166a0a93c77...reply"
    ],
    "link": "https://xnacly.me/posts/2025/fast-lexer-strategies/",
    "first_paragraph": "In this blog post I\u2019ll explain strategies I used to make the purple garden\nlexer really fast.purple-garden is an s-expr based\nlanguage I am currently developing for myself. Its my attempt at building a\nlanguage I like, with a battery included approach, while designing it with\nperformance in mind.This doesn\u2019t mean all approaches are feasible for your use case, architecture\nand design. I tried to bring receipts for my performance claims, so\nwatch out for these blocks at the end of chapters:A lexer (often also referred to as a tokeniser) is the easiest part of any compilation and\nlanguage pipeline. The idea is to convert a list of characters into a list of\ntokens in which each token conveys some meaning. This list of tokens can then\nbe used by the parser to generate an abstract syntax tree (AST), which the\ncompiler consumes, converting it to bytecode, which the vm executes.As an overview:For a list of characters, lets say (@std.fmt.println \"my pi is: \" 3.1415):Input to the lexer:As charac"
  }
]