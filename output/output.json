[
  {
    "title": "Cerebras Code (cerebras.ai)",
    "points": 166,
    "submitter": "d3vr",
    "submit_time": "2025-08-01T22:04:38 1754085878",
    "num_comments": 78,
    "comments_url": "https://news.ycombinator.com/item?id=44762959",
    "comments": [
      "Tried this out with Cline using my own API key (Cerebras is also available as a provider for Qwen3 Coder via via openrouter here: https://openrouter.ai/qwen/qwen3-coder) and realized that without caching, this becomes very expensive very quickly. Specifically, after each new tool call, you're sending the entire previous message history as input tokens - which are priced at $2/1M via the API just like output tokens.The quality is also not quite what Claude Code gave me, but the speed is definitely way faster. If Cerebras supported caching & reduced token pricing for using the cache I think I would run this more, but right now it's too expensive per agent run.reply",
      "This seems to be rate limited by message not token so the lack of cache may matter lessreply",
      "I'm pretty sure it's rate limited by token usage. The message count is almost certainly a rough estimate.reply",
      "If you would like to try this in a coding agent (we find the qwen3-coder model works really well in agents!), we have been experimenting with Cerebras Code in Sketch. We just pushed support, so you can run it with the latest version, 0.0.33:  brew install boldsoftware/tap/sketch\n  CEREBRAS_API_KEY=...\n  sketch --model=qwen3-coder-cerebras -skaband-addr=\n\nOur experience is it seems overloaded right now, to the point where we have better results with our usual hosted version:  sketch --model=qwenreply",
      "> running at speeds of up to 2,000 tokens per second, with a 131k-token context window, no proprietary IDE lock-in, and no weekly limits!I was excited, then I read this:> Send up to 1,000 messages per day\u2014enough for 3\u20134 hours of uninterrupted vibe coding.I don't mind paying for services I use. But it's hard to take this seriously when the first paragraph claim is contradicting the fine prints.reply",
      "To put this into perspective, github copilot Business license is 300 \"premium\" requests a MONTH.reply",
      "Pretty sure this is there to prevent this[1] from happening to them[1] https://www.viberank.app/reply",
      "That's a CO2 emissions leader board!reply",
      "It\u2019s a true statement - no weekly limits, just a daily limit. Easier to work with when you can only get locked out of your tool for 23h59mreply",
      "The CC weekly limits are in place to thwart abuse. This bit of marketing isn't particular useful as that limit primarily impacts those who are running it at all hours.OTOH, 5 hour limits are far superior to daily limits when both can be realistically hit.reply"
    ],
    "link": "https://www.cerebras.ai/blog/introducing-cerebras-code",
    "first_paragraph": "ProductsCustomersDevelopersResourcesCompanyAug 01 2025We are launching two new plans designed to make AI coding faster and more accessible: Cerebras Code Pro ($50/month) and Code Max ($200/month). Both plans give you access to Qwen3-Coder, the world\u2019s leading open-weight coding model\u2014running at speeds of up to 2,000 tokens per second, with a 131k-token context window, no proprietary IDE lock-in, and no weekly limits!Even with the best frontier models, you still end up waiting around for completions. And as coding workflows get more agentic, the latency adds up fast. You\u2019re not just waiting once. You have to wait on every LLM call across multi-step edits, tool use, retries, and planning.At 2,000 tokens per second, code generation becomes instant. And starting at $50/month, anyone can use Cerebras Code and enjoy fast code generation that keeps you in flow.Qwen3\u2011Coder is Alibaba\u2019s flagship coding agent model. The 480B parameter model delivers performance comparable to Claude Sonnet\u202f4 and "
  },
  {
    "title": "Coffeematic PC \u2013 A coffee maker computer that pumps hot coffee to the CPU (dougmacdowell.com)",
    "points": 101,
    "submitter": "dougdude3339",
    "submit_time": "2025-08-01T21:53:13 1754085193",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=44762880",
    "comments": [
      "Why not rig it the other way: pump water past the CPU, then through your coffee grounds?It probably wouldn't be great for your CPU, because the temperature required to properly brew coffee is hotter than you really want for your CPU. But maybe get the water to 80C, and a secondary heater after that.reply",
      "I'm not expert in CPU water cooling but I'd guess the CPU would have to be way over 100C in order to get the water to 80C quickly.reply",
      "You could recirculate water past the CPU via an insulated storage carafe. This would create a fun and exciting gamble wherein you might receive a freshly brewed pot of coffee OR your computer might turn itself off just before the water is hot enough to brew with, and the time it would take would be based on how hard you worked the PC.reply",
      "This, except when it comes time to actually brew, it goes to a 5.25\u201d slot to heat up, then you can determine the best delivery mechanism for your build. Shot/Kup, drip, pour over, just don\u2019t build a french press PC.And have a reservoir large enough to replenish the closed loop circuit when you press the button.reply",
      "The CD ROM drive should open so you can insert a paper cup and then the coffee dispenses into it.reply",
      "Use a heat pump to keep the CPU (and GPU as a secondary heat source) at a lower temperature then heat the coffee water with a secondary heat exchanger.  Then you can control the temperature of both cooling loops independently.reply",
      "I'm glad someone is still building what needs to be built <3reply",
      "v0.2a needs to mine crypto to pay for its own coffee beans while peculating the coffee. =3reply",
      "I assume you meant \"percolating\", but you very nearly spelled \"speculating\", which, given the crypto, seems more appropriate.reply",
      "And of course, peculation means misappropriating or embezzling funds. Again, given crypto (and certain notorious crypto exchanges), even more appropriate.reply"
    ],
    "link": "https://www.dougmacdowell.com/coffeematic-pc.html",
    "first_paragraph": "\n            Sometime during winter 2024, I found myself at a thrift store. I was staring at rows of appliances, \n            wrapped in plastic and clinging to life, trying to answer one question: which of these is the right \n            chassis for a retro gaming computer?\n            \n            Driving home, I took corners carefully, checking that the General Electric (GE) drip coffee maker I\u2019d \n            chosen was safe in the backseat. The coffee maker's given name was Coffeematic.  Circa 1980, \n            it is boxy yet athletic \u2013 unfazed by any considerations of future internet connectivity. Best, it is perfect for being hacked.\n            \n            Coffeematic is now Coffeematic PC \u2013 part gaming computer, part coffee maker. \n            A newly synthesized machine percolating processes well beyond its original configuration. \n            Coffeematic PC is part of a lineage of coffee maker computers made since 2002. \n            I'll describe that fascinating lineage he"
  },
  {
    "title": "Ethersync: Peer-to-peer collaborative editing of local text files (github.com/ethersync)",
    "points": 44,
    "submitter": "blinry",
    "submit_time": "2025-07-29T13:15:42 1753794942",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44722950",
    "comments": [
      "Having trouble finding plugins \u2026 mousepad?reply",
      "5 points and 0 comments? IMO this looks like a very well researched project, not sure why it went under the radar.reply",
      "Looks like we put it in the second-chance pool (https://news.ycombinator.com/pool, explained at https://news.ycombinator.com/item?id=26998308), so it got a random placement on HN's front page a couple days later...where it happily resides for the time being.If anyone is confused by the relativized timestamps, there are explanations here: About the timestamps, there are past explanations here: https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que....reply",
      "My bet would be that people confuse it with Etherpad https://github.com/ether/etherpad-lite which is quite old stable project so probably not that exciting.reply"
    ],
    "link": "https://github.com/ethersync/ethersync",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Editor-agnostic, real-time collaborative editing of local text files.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Multiplayer mode for your text editor!Ethersync enables real-time collaborative editing of local text files. You can use it for pair programming or note-taking, for example. It's the missing real-time complement to Git!The project is under active development right now. We use it every day, but there's still some bugs to be aware of.Ethersync works on Linux, macOS, Android, and on the Windows Subsystem for Linux.The releases on GitHub come with precompiled static binaries. Download one and put it somewhere in your shell's PATH:This repository provides a Nix flake. To put ethersync in your PATH temporarily, run:Make sure to also have it in your"
  },
  {
    "title": "Show HN: Draw a fish and watch it swim with the others (drawafish.com)",
    "points": 770,
    "submitter": "hallak",
    "submit_time": "2025-07-29T04:57:22 1753765042",
    "num_comments": 205,
    "comments_url": "https://news.ycombinator.com/item?id=44719222",
    "comments": [
      "The leaderboard is fascinating. Some people are clearly putting a lot of time into this, while the rest of us are trying to sneak phallic shapes past your CNN.1. https://drawafish.com/rank.html?userId=1753510318634_cdeh6a4...reply",
      "I am literally trying my best to draw a fish only to be told it is only 30% likely to be a fish. Cruel.reply",
      "Got a potted flower through. It's swimming nicelyhttps://drawafish.com/tank.html?capacity=55&sort=popular also don't sleep on that onereply",
      "My hot dog with a smiley face got a 64%, I'm sorry.Semi relevant Silicon Valley clip (maybe nsfw, language)https://www.youtube.com/watch?v=ACmydtFDTGsreply",
      "Well what's the difference between a lamprey and an hot dog?reply",
      "Mr Worf: \"an hot ...\". Strictly correct but try saying it out loud - its quite painful!  I too was taught to use \"a\" as the indefinite pronoun when the noun had h as the initial capital letter.  \"An\" would normally be the correct form if the noun's initial letter is a vowel (a vowel, not an vowel).Any en_GB speaker will probably do one of two things here:  \"an 'ot\" - where the h is dropped and \"an\" and \"'ot\" sound like a bit like \"annot\"\n  \"a hot\" - here the a becomes ay (rhymes with hay)\n\nI'm very impressed that the old school rules still turn up.  I do own a copy of \"Usage and abusage\" somewhere but it is and should be largely consigned to history.When you trot out a phrase like:\"Well what's the difference between a lamprey and an hot dog?\"I can't help but notice a lack of a comma post \"well\"!A lamprey is a fish and a hot dog is a sausage.  The first is a living organism and the other is a processed food.Cheers matereply",
      "That makes me feel better about my fish, I thought it was among the worst, but good to know it atleast qualified.reply",
      "Also make sure you\u2019re filling up the canvas \u2014 don\u2019t draw something too small.reply",
      "Did it face the right way?reply",
      "I was extremely happy with my 60% Wang fish. And now after looking at the leaderboard I feel bad.reply"
    ],
    "link": "https://drawafish.com",
    "first_paragraph": ""
  },
  {
    "title": "Weather Model based on ADS-B (obrhubr.org)",
    "points": 55,
    "submitter": "surprisetalk",
    "submit_time": "2025-07-30T14:14:56 1753884896",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=44734515",
    "comments": [
      "Another fun thing to do is to get mode c (barometric altitude) from aircraft transponders (either SSR  or Mode-S downlink 5 or 21 - same physical layer as ADS-B just different bitfield header) and compare it to its GNSS altitude (from ADS-B most of the time) from the same aircraft (the Mode S address used as key) and you can build a map of atmospheric pressures.reply",
      "This is really cool and not what I was expecting. Nice work!reply",
      "Could the same be done with (marine) AIS?* https://en.wikipedia.org/wiki/Automatic_identification_syste...* https://www.marinetraffic.com/en/ais/home* https://www.vesselfinder.comreply",
      "Very cool!Maybe I missed it but I didn\u2019t quite follow why you needed to buy an adsb receiver if adsb exchange is already aggregating all the datareply",
      "The receiver gives you realtime data in the immediate vicinity. The exchange gives you slightly older data from everywhere.Determining what benefit this gives the operator is left as an exercise for the reader.reply",
      "You're right, but \"slightly older\" is on the order of seconds.reply",
      "Flight plans are usually filed hours before a flight with old wind data and sometimes can't be changed in congested airspace.But pilots really care about wind shear.  Its the thing that makes people suddenly hit the overhead compartment.  It typically requires flight crews reporting it to ATC over radio.  Improving accuracy of local wind events is very valuable.reply",
      "I remember that during COVID, the weather forecast got noticeably worse. One of the explanations I read was that, because so many planes were grounded, there was far less data for the models available. I\u2018m not sure which source that was from, though.reply",
      "I don\u2019t remember reading that but I had an ADSB receiver prior to COVID and I watched in real time as the aircraft traffic nearly stopped for months using the the data recorded by my receiver and parsed by FlightAware running on my Raspberry Pi 3B+ - as the world shut down.reply",
      "Clever idea! Well donereply"
    ],
    "link": "https://obrhubr.org/adsb-weather-model",
    "first_paragraph": "I recently bought an RTL-SDR dongle and an antenna to receive ADS-B messages. These are short packets of data, broadcast by every plane in the sky, to inform others of their position, heading, speed and other flight data. The transmission of these messages is mandatory for aircraft, as it prevents mid-air accidents.They are also unencrypted, which means anyone can listen to them. All you need is an antenna and a dongle to ingest the data on your PC (pictured above), which can be bought for less than 100$. The incoming data can then be processed by software like readsb which decodes the messages.You can choose to broadcast your own data to central servers like the ADS-B Exchange, like many hobbyists do. Thanks to them, we can visualise just about every aircraft currently in the sky. They also provide access to historic data.One way these massive amounts of data can be used is to make cool visualisation, like Clickhouse did. We\u2019re going to do something a bit different.ADS-B messages are "
  },
  {
    "title": "At 17, Hannah Cairo solved a major math mystery (quantamagazine.org)",
    "points": 204,
    "submitter": "baruchel",
    "submit_time": "2025-08-01T16:35:40 1754066140",
    "num_comments": 108,
    "comments_url": "https://news.ycombinator.com/item?id=44759152",
    "comments": [
      "\u201cThere was this inescapable sameness, in a way. No matter what I did, I was in the same place doing mostly the same things,\u201d she said. \u201cI was very isolated, and nothing I could do could really change that. I\u2019d wake up on certain days and realize, I\u2019m just older.\u201d\n\n\nI finally have something in common with a math prodigy.reply",
      "Maybe hot take\u2026I can see the point of sameness in homeschooling, but compared to traditional education? I\u2019m not sure how much flexibility one would have to teach oneself calculus by 11 or the equivalent of an undergrad in math by 14!That flexibility must be found in something non-traditional!I\u2019m no prodigy at all whatsoever but school was mostly dull and filled with teenager drama! Nobody knew what Linux was, cared about music production or anything interesting! The talk was which boy/girl whateverreply",
      "Thank God she found math instead of Factorio.reply",
      "- moved between countries or first/second gen immigrant? check- home schooled? checkThis on top of her extraordinary talent and hard work.  Institutional education truly is a great leveler, at both the top and bottom.reply",
      "> moved between countries or first/second gen immigrant?\u201cCairo grew up in Nassau, the Bahamas, where her parents had moved so that her dad could take a job as a software developer\u201d\u201cTravel restrictions stranded her family at her grandparents\u2019 house in Chicago. While they were there, she joined the Math Circles of Chicago\u201dThis doesn\u2019t read like an immigrant.  It kind of reads like her dad is a fully American finance dev.reply",
      "It's wonderful that Khan Academy played a role in enriching her early education. It's proving to be a solid resource across the spectrum of math ability.reply",
      "Here's a link to the paper on the arxiv: https://arxiv.org/abs/2502.06137reply",
      "Her notes are so clear and so artfully wrought! I wonder if learning from online resources makes one naturally focus more on presentation.From the article:https://www.quantamagazine.org/wp-content/uploads/2025/08/Ha...reply",
      "Zvezdalina Stankova who comments on miss Cairo is on her own super out of the ordinary.https://math.berkeley.edu/~stankova/Not only she did grow in Bulgaria during the most turbolent times of regime change from communism to democracy, but later graduates with a PHD from Harvard, and later becomes  Director and Founder of the Berkeley Math Circle, and is also organizer of math competitions in Bay Area, and publisher of what seems to be a complete set of Math Books, carefully crafted with her peers from BG and presented herehttps://archi-math.com/Curious whether miss Cairo was a student of hers or is to be.reply",
      "Earlier discussion: https://news.ycombinator.com/item?id=44481441I wish her the best in her coming career.reply"
    ],
    "link": "https://www.quantamagazine.org/at-17-hannah-cairo-solved-a-major-math-mystery-20250801/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesAugust 1, 2025Valerie Plesch for\u00a0Quanta MagazineContributing WriterAugust 1, 2025It\u2019s not that anyone ever said sophisticated math problems can\u2019t be solved by teenagers who haven\u2019t finished high school. But the odds of such a result would have seemed long.Yet a paper posted on February 10 left the math world by turns stunned, delighted and ready to welcome a bold new talent into its midst. Its author was Hannah Cairo, just 17 at the time. She had solved a 40-year-old mystery about how functions behave, called the Mizohata-Takeuchi conjecture.\u201cWe were all shocked, absolutely. I don\u2019t remember ever seeing anything like that,\u201d said Itamar Oliveira of the University of Birmingham, who has spent"
  },
  {
    "title": "Does the Bitter Lesson Have Limits? (dbreunig.com)",
    "points": 90,
    "submitter": "dbreunig",
    "submit_time": "2025-08-01T20:21:29 1754079689",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=44762022",
    "comments": [
      "The last time I was reminded of the bitter lesson was when I read about Guidance & Control Networks, after seeing them used in an autonomous drone that beat the best human FPV pilots [0]. Basically it's using a small MLP (Multi Layer Perceptron) on the order of 200 parameters, and using the drone's state as input and controlling the motors directly with the output. We have all kinds of fancy control theory like MCP (Model Predictive Control), but it turns out that the best solution might be to train a relatively tiny NN using a mix of simulation and collected sensor data instead. It's not better because of huge computation resources, it's actually more computationally efficient than some classic alternatives, but it is more general.[0] https://www.tudelft.nl/en/2025/lr/autonomous-drone-from-tu-d...https://www.nature.com/articles/s41586-023-06419-4https://arxiv.org/abs/2305.13078https://arxiv.org/abs/2305.02705reply",
      "But I have also seen people trying to use deep networks to identify rotating machinery faults, like bearings, from raw accelerometer data collected a high frequencies like 40 kHz. Whereas the spectrum of the data from running FFT on the signal contains fault information much more obviously and clearly.Throwing a deep network on a problem without some physical insight into the problem has also its disadvantages it seems.reply",
      "Yeah, we're shouting into the wind here. I have had people tell me directly that my ideas from old school state estimation were irrelevant in the era of deep learning. They may produce (in this case) worse results, but the long game I'm assured is superior.The specific scenario was estimating the orientation of a stationary semi trailer. An objectively measurable in number and it was consistently off by 30 deg, yet I was the jerk for suggesting we move from end to end DL to trad Bar Shalom techniques.That scene isn't for me anymore.reply",
      ">It's not better because of huge computation resources, it's actually more computationally efficient than some classic alternativesIt's similar with options pricing. The most sophisticated models like multivariate stochastic volatility are computationally expensive to approximate with classical approaches (and have no closed form solution), so just training a small NN on the output of a vast number of simulations of the underlying processes ends up producing a more efficient model than traditional approaches. Same with stuff like trinomial trees.reply",
      "This is really interesting. I think force fields in molecular dynamics have underwent a similar NN revolution. You train your NN on the output of expensive calculations to replace the expensive function with a cheap one. Could you train a small language model with a big one?reply",
      "> Could you train a small language model with a big one?Yes, it's called distillation.reply",
      "Interesting. Are these models the SOTA in the options trading industry (e.g. MM) nowadays?reply",
      "I was not at all a fan of \"The Bitter Lesson versus The Garbage Can\", but this misses the same thing that it missed.The Bitter Lesson is from the perspective of how to spend your entire career. It is correct over the course of a very long time, and bakes in Moore's Law.The Bitter Lesson is true because general methods capture these assumed hardware gains that specific methods may not. It was never meant for contrasting methods at a specific moment in time. At a specific moment in time you're just describing Explore vs Exploit.reply",
      "Right, and if you spot a job that needs doing and can be done by a specialized model, waving your hands about general purpose scale-leveraging models eventually overtaking specialized models has not historically been a winning approach.Except in the last year or two, which is why people are citing it a lot :)reply",
      "Probably because this is how bubbles happen.reply"
    ],
    "link": "https://www.dbreunig.com/2025/08/01/does-the-bitter-lesson-have-limits.html",
    "first_paragraph": "\nAug 1, 2025\n    Recently, \u201cthe bitter lesson\u201d is having a moment. Coined in an essay by Rich Sutton, the bitter lesson is that, \u201cgeneral methods that leverage computation are ultimately the most effective, and by a large margin.\u201d Why is the lesson bitter? Sutton writes:The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.Sutton walks through how the fields of computer chess, computer go, speech recognition, and computer vision have all experienced the bitter lesson.Lately, people have "
  },
  {
    "title": "I couldn't submit a PR, so I got hired and fixed it myself (skeptrune.com)",
    "points": 184,
    "submitter": "skeptrune",
    "submit_time": "2025-08-01T16:59:51 1754067591",
    "num_comments": 98,
    "comments_url": "https://news.ycombinator.com/item?id=44759417",
    "comments": [
      "Reminds me when I got banned from Amazon for suspected fraud (had an old account, but deleted my email and number since it was in a lot of DB dumps). After I got hired, I reached out to the guy in charge of the anti-fraud team at Amazon, and got unbanned. Emails to support etc. did nothing before I reached out internally (unbanned by 1am the next day).reply",
      "Interesting. I still have a bricked phone from my onboarding at Google, and no internal people cared either. There's a tool I could have used to fix it, but it's accompanied by a message saying that if you use it without permission you'll be fired.reply",
      "> accompanied by a message saying that if you use it without permission you'll be firedProbably why none of the internal people cared either. They didn't want to be the person on the line in case it was determined that the usage wasn't valid.I'm curious how you bricked it beyond repair though. Most devices have a way to enter a recovery/flash mode where you can upload your own firmware from the bootloader. And if you haven't unlocked the bootloader then I don't get how you could have bricked it unless there's an Android bug... which would have probably triggered a more serious look.reply",
      "This is the level of epic I aspire to in lifereply",
      "Except they're working at Amazon now.reply",
      "Next level epic is hand your resignation letter right after you get unbanned. \"My job here is done.\"reply",
      "And then banned again the next day.reply",
      "tbh you could probably easily have enough gripes with Epic to do this too... but then you'd have to move to Wisconsin.reply",
      "At least their headquarters are coolreply",
      "seems like they could turn this into a lucrative side hustle \"super premium secret support\" embrace the technofascist feudalism!reply"
    ],
    "link": "https://www.skeptrune.com/posts/doing-the-little-things/",
    "first_paragraph": "For over a year, I was bugged by a search quirk on Mintlify that caused race conditions and wonky search results.Here\u2019s the fun irony: I was the founder of Trieve, the company that powered search for their 30,000+ documentation sites, yet their debounced search queries weren\u2019t being aborted as you typed. Check out this delightful chaos:I had brought this up in our shared Slack before when I was just a vendor to them us (weird), but it wasn\u2019t a priority and never got fixed. It was extra frustrating because the race condition on the query was apparent enough that search would sometimes feel low quality since it would return results for a query many characters before the user was done typing.Even worse, as the founder of the search company powering this experience, it felt like a poor reflection on Trieve every time someone encountered these wonky results.Now that I\u2019m on the team, I was able to finally fix it. I added an AbortController to the debounced search function, so that it aborts "
  },
  {
    "title": "Ask HN: Who is hiring? (August 2025)",
    "points": 150,
    "submitter": "whoishiring",
    "submit_time": "2025-08-01T15:00:05 1754060405",
    "num_comments": 188,
    "comments_url": "https://news.ycombinator.com/item?id=44757794",
    "comments": [
      "Swayable | https://www.swayable.com/ | SF, NY, Remote | Full-TimeSwayable measures how content changes people's opinions. We apply a variety of sophisticated machine learning classification, regression, causal AI, and GenAI-based analyses to survey-based data we collect. Customers receive high-level, actionable data about different group's responses through an ever-expanding portfolio of web-based visualizations, reports, and natural language interfaces.All positions support remote US work or SF/NY office.- Senior Engineer: AI Applications. AI Applications Engineer that blends full stack software development expertise with agentic/multi-node workflow architectures. You will be responsible for creating and building our portfolio of LLM-based classification, reporting, and analysis applications. Stack: Python (langgraph, pandas, celery, flask, MCP), JavaScript (Vue.js, Node.js), MongoDB, GraphQL, and a variety of LLM providers.- Senior Engineer: Full-stack Web. Full-stack web to build and enhance our core browser-based applications for building surveys, collecting responses, and visualizing results generated by our suite of sophisticated numerical and qualitative analyses. Stack: Vue 3 (Nuxt), Tailwind CSS, Node (Express), GraphQL, Mongoose, MongoDB, Cypress.- Senior AI/ML Engineer: Scientific Computing. Blending Python software development expertise with scientific computing, machine learning, and AI experience to advance the state of the art analytics engine that powers our core product. Stack: Python (Numpy, Pandas, scikit-learn, Celery, Flask), machine learning (linear regression, casual AI, text classification), MongoDB, and GraphQL.Postings are available at https://www.swayable.com/careers/ or free free to contact me (the hiring manager) at eng-jobs@swayable.comreply",
      "Stellar Science | Hybrid (USA) Albuquerque NM, Washington DC (Tysons VA), Dayton OH | Full time, interns/co-ops | U.S. citizenship required | https://www.stellarscience.comCompany: We're a small scientific software development company that develops custom scientific and engineering analysis applications in domains including: space situational awareness (monitoring the locations, health and status of on-orbit satellites), image simulation, high power microwave systems, modeling and simulation, laser systems modeling, AI/ML including physics-informed neural networks (PINN), human body thermoregulation, computer vision and image processing, high performance computing (HPC), computer aided design (CAD), and more. All exciting applications and no CRUD. We emphasize high quality code and lightweight processes that free software engineers to be productive.Experience: Other than interns, we currently require a Bachelors degree in physics, engineering, math, computer science, or a related field, plus preferably 3+ years of work experience or a Masters or PhD in lieu of work experience. (Roughly 30% of our staff have PhDs.)Technologies: Mostly C++23, Qt 6.9, CMake, git, OpenGL, CUDA, Boost, Jenkins. Windows and Linux, msvc/gcc/clang/clangcl. AI/ML and other projects use Python, some use Java or Javascript/Typescript/React.Apply online at https://www.stellarscience.com/careers/.reply",
      "SerpApi | https://serpapi.com | Junior to Senior Fullstack Engineer multiple positions | Customer Success Engineer | Hiring Coordinator | Python/Ruby/PHP/Js/Rust/Cotlin/C#/Crystal/Nim/Elixir Developer Advocate positions | Based in Austin, TX but remote-first structure | Full-time | ONSITE or FULLY REMOTE | $150K - 180K a year 1099 for US or local avg + 20% for outside the USSerpApi is the leading API to scrape and parse search engine results. We deeply support Google, Google Maps, Google Images, Bing, Baidu, and a lot more.Our current stack is Ruby, Rails, MongoDB, and React.JS. We are looking for more Junior and Senior FullStack Engineers.We have an awesome work environment: We are a remote first company (before Covid!). We do continuous integration, continuous deployments, code reviews, code pairings, profit sharing, and most of communication is async via GitHub.We value super strongly transparency, do open books, have a public roadmap, and contribute to the EFF.Apply at: https://serpapi.com/careersreply",
      "Yall are gonna get ddosed by having a junior positionreply",
      "Brilliant.org | Software Engineers & Designers | Remote (North America), SF, NYC | Full-time | $170k \u2014 $235k | https://brilliant.orgBrilliant is building world-class interactive learning experiences that combine challenging problems, compelling narratives, and delightful visual storytelling.We're hiring engineers and designers to help craft the next generation of interactive learning and change how the world learns.Engineers at Brilliant think about both \"building the right thing\" AND \"building the thing right\" while pursuing high standards of excellence for ourselves, our product, and our codebase.Our designers craft interaction patterns that make hard math, science, and computer science concepts feel approachable, delightful, and addictively learnable.If you're energized by the prospect of doing the best work of your career and changing how the world learns alongside the most talented peers you've ever worked with, you can learn more and apply here: https://brilliant.org/careers.reply",
      "I had a positive interview experience with you folks a few months ago when I was on the market, and walked away with a positive impression of the whole team and project.reply",
      "Promptfoo | Senior/Staff Engineers, Security Researchers, GTM & Founding Operators | REMOTE (North America) / Hybrid San Mateo CA | Full-time | https://promptfoo.devPromptfoo is the MIT-licensed open-source toolkit 125 000+ developers use to evaluate and secure LLM apps. We just closed an $18.4 M Series A led by Insight Partners with participation from a16z and are scaling a small, senior team of high-agency builders.Open roles- Senior / Staff Full-stack Product Engineer (TypeScript + Python)- Senior / Staff AI Security & Red-Team Engineer- Solutions Architect / SE (multiple)- Product Marketing Manager (cyber focus)- Enterprise Account Executive (Bay Area, multiple)- Technical Writer- Developer AdvocateWhy join- Build the definitive AI security stack already used at 30+ Fortune 500s.- Work in open source.- Competitive salary, meaningful equity, async-friendly culture of ownership.How to apply1. Skim https://github.com/promptfoo/promptfoo then run:  npx promptfoo@latest init --example getting-started\n\n2. Email careers@promptfoo.dev with subject \u201cHN \u2013 July 2025\u201d, a short intro, and a GitHub / LinkedIn link.3. I reply to every thoughtful application and send swag to anyone who tries or contributes to Promptfoo.Careers page: https://www.promptfoo.dev/careers/reply",
      "Chronograph (chronograph.pe) | DevOps Engineer | Full-Time | Remote (US) | $140-160K USD + equityChronograph was founded to bring next-generation technology to private capital markets. Through our suite of cloud-based analytics and data management solutions, we help many of the world\u2019s largest and most sophisticated venture capital, private equity, and credit funds understand their investment performance in unprecedented detail.We are looking for a candidate with a generalist background in software development, including 3-5+ years of experience on DevOps, Platform Engineering, Site Reliability Engineering (SRE), or MLOps teams. You\u2019d be joining a small cross-functional team and have the chance to make critical contributions as we scale our engineering team and business.Our ideal candidate has a passion for automating ops, troubleshooting infrastructure, and creating first-class developer experiences. On top of that, expertise with the following (or similar) tools/technologies is a strong signal of fit: Kubernetes, Prometheus, Grafana, Terraform, AWS, GitHub Actions, PostgreSQL, Node.js, Ruby on Rails, Nix, and Docker.Note that while this is a remote position, travel to our NYC HQ 3x/year for \"team week\u201d on-sites is required.If interested, apply here: https://grnh.se/1q1yybxf7usreply",
      "VersaFeed.com | SENIOR SOFTWARE ENGINEER (Python/Django) | REMOTE (USA/EU) | Full-timeAbout us: Fancy ETL pipeline which processes products from huge ecommerce companies. Data extraction and massage, delivery to destinations like Google/Meta/TikTok/etc. Profitable, 15+ yrs stable, 100% employee-owned. No VC, no pointless meetings, just serious coding.Stack: Python/Django, JavaScript, VueJS, PostgreSQL, Snowflake, Docker, Git, AWS, AI/LLM integrations (OpenAI & Gemini).Compensation: $150K\u2013$250K USD/year DOE.You: Senior dev who's seen (and fixed) enough dumpster-fire code to last a lifetime. Python/Django deeply internalized; ideally strong Vue (or React) skills. Git/Docker/REST are second nature. You\u2019re the coder other devs come to when their stuff breaks: an architect-level thinker who\u2019s rewritten \u2018clever\u2019 code into something that actually works. You play well with others and write code that\u2019s easy to live with. Bonus: AI integrations, Py2\u2192Py3 migrations, Snowflake (or Databricks) experience.Timezones: VersaFeed's \"core\" time zone is PST and we have M/W/F standups at 9AM PST. Otherwise, we are async-friendly and welcome US and EU applicants.Benefits: 401K match (USA), healthcare, equity, fully remote. Stable company with no time-wasters.Apply: email jobs+hn253 [the-at-mark-thing] versafeed [the-period-thing] comreply",
      "Sudowrite | https://sudowrite.com | \u221a remote | \u221a profitable | \u221a full-timePROFITABLE, SUSTAINABLE SMALL TEAM, MAKING SOMETHING PEOPLE WANTKind, smart, low-drama people, seeking the same to help make writing tools authors dream about.We're building a sustainable company, not chasing unrealistic growth targets set by VCs.\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014Hiring: Staff Product DesignerThis is the best job listing you will read this year: https://sudowrite.com/jobs/designer\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014reply"
    ],
    "link": "item?id=44757794",
    "first_paragraph": ""
  },
  {
    "title": "Researchers map where solar energy delivers the biggest climate payoff (rutgers.edu)",
    "points": 55,
    "submitter": "rbanffy",
    "submit_time": "2025-08-01T20:21:42 1754079702",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=44762026",
    "comments": [
      "> The central finding is that a 15% increase in solar generation across the U.S. is associated with an annual reduction of 8.54 million metric tons (MMT) of CO2, a significant step toward national climate goals.Whoa, that's really cool.You can see the paper along with figures & regional breakdowns here: https://openpaper.ai/paper/share/1d0c6956-4820-4ee2-ac1e-12c...reply",
      "US Produced about 4.8 Billion Metric Tons of CO2 in 2024 ( https://www.statista.com/statistics/183943/us-carbon-dioxide... )The savings is minuscule. But important nonetheless. It just goes on to show how much more solar is required.reply",
      "Why do people keep making this argument? Jevon's paradox means that if oil isn't burned to keep US people cool, it's burned in India for air conditioning, or in China for factories. Hell, Putin famously refused to cut output and simply burned it on site out of spite, tens of thousands of barrels per day. Oil pumping is running at capacity. Or to put it more technically: price elasticity of supply is minimal at best.In other words, the only way to significantly alter CO2 output on a global level, the only level that matters, is to affect oil production. Saudi Arabia (and middle east generally), Russia, Venezuela, US, Canada, ...Anyone else just cannot make things happen, and it cannot be done without very large economic implications. Well, not without war.reply",
      "The reason this is a stupid argument is that solar power is significantly cheaper than fossil fuel power almost everywhere.  And not in a \"calculating all of the global impacts\" way, in the very direct, greedy, \"I want the cheapest electricity possible\" way.  \"Whatabout\"s with storage and time of day, etc. aren't necessary, battery tech is cheap and solar production is so cheap you can do inefficient things with it (panels at non-ideal angles to get more power at off peak hours) and still come out ahead.I really doubt China is installing solar at insane rates to be nice to the world.reply",
      "Direct study link (with associated diagrams): https://www.science.org/doi/10.1126/sciadv.adq5660reply",
      "The study compares a percentage increase of solar power against an absolute decrease of CO2 emissions.This seems like questionable reasoning to me.  If California has 100 MW of solar power for every 10 MW in Indiana, a 10% increase in solar will show up as 10x more CO2 savings for California just because it has a larger installed base.To me the relevant question is the relative dirtiness of the nonrenewables being replaced, and the relative cost and effectiveness of solar.  IMHO the data ought to be normalized to a per-MW-installed-rating basis.I wish the study went like this (all the following numbers are completely made up, based on nothing more than the fertile imagination of an HN commentator mildly annoyed by the study's questionable numeracy):- In California, clouds / latitude / etc. mean a panel's only usable 10/24 hours on average per day- In Indiana, the geography's less ideal, so clouds / latitude / etc. make it usable 8/24 hours on an average day- In California, it would be replacing a super-clean natural gas plant installed in 2008 that has expensive high-tech emissions control devices required by the super-strict California environmental regulations and emits 0.4 tons of CO2 per MWH.- In Indiana, there was no money or political will for modern power plants or strict environmental regulations, so the solar panel would be replacing a smoke belching coal plant from the previous millenium that emits 1.2 tons of CO2 per MWH.- In California, labor for >1 MW solar installations costs $0.20 / W, costs are inflated by high CoL / taxes and business unfriendly regulations but there are lots of firms with experience who can install quickly.- In Indiana, labor for >1 MW solar installations is $0.15 / W, they pay a lot less and don't have as much red tape, which slightly outweighs the fact installers don't have much experience and bumble around being slow and making expensive mistakes.- Your per-watt cost is $0.20 / (10/24) = $0.48 in California but $0.15 / (8/24) = $0.45 in Indiana (which is also your per-MW cost in millions).- Your daily emissions reduction is 0.4 x 10 = 4.0 tons for California and 1.2 x 8 = 9.6 tons emissions reduction for Indiana.- Therefore every $1M spent in California buys 4.0 / $0.48 = 8.3 tons / day of emissions reduction and every $1M spent in Indiana buys 9.6 / .45 = 21.3 tons / day of emissions reduction.If you care about efficiently spending money to reduce emissions, in this example (using made-up numbers) Indiana is the low-hanging fruit, investments there are better by a factor of 21.3 / 8.3 ~ 2.6.But the way the study's written, if we assume solar is currently 2000 MW for California and 200 MW for Indiana, its calculations would suggest a 10% increase in California (200 MW) would save 200 x 4.0 = 800 tons and a 10% increase in Indiana would save 20 x 9.6 = 192 tons.This is very misleading.If you don't think about the units and just look at the numbers, you might be tempted to conclude the study's telling you that California's emissions reduction rating is 800 and Indiana's rating is 192, so if you care about CO2 reduction every dollar of investment is a factor of 4 as effective in California -- when in reality, with these numbers every dollar is actually a factor of 2.6 more effective in Indiana.reply",
      "There is no \"super clean natural gas plant\" you're still burning a nonrenewable hydrocarbon and letting its carbon go into the atmospherereply",
      "> The study compares a percentage increase of solar power against an absolute decrease of CO2 emissions.local CO2 emissions. This has not affected pumping of oil, and since we aren't even able to store much oil, that means it's getting burned. That makes it clear the global effect must be very close to zero. And for CO2, only global matters.reply",
      "GH project with a link to the data and the instructions how to process it https://github.com/NSAPH-Projects/green-energy-optimizationreply",
      "\"raw data\" is from EIA (a veritable rabbit hole!)>EIA publishes hourly operational data across the United States electricity grid, including demand, net generation of electricity from various sources (such as coal, natural gas, solar), CO2 emissions, import/export to other regions, and many more. The complete details of the EIA-930 data is available here: https://www.eia.gov/electricity/gridmonitor/about. Furthermore, we obtained the solar capacities of each year and each region from EIA (https://www.eia.gov/electricity/data/state/) and had stored the information in the file solar_capacity_factor.csv. (2023-07-01)reply"
    ],
    "link": "https://www.rutgers.edu/news/researchers-map-where-solar-energy-delivers-biggest-climate-payoff",
    "first_paragraph": "DateJuly 30, 2025Media ContactPatti Zielinskipatti.zielinski@rutgers.eduIncreasing solar power generation in the United States by 15% could lead to an annual reduction of 8.54 million metric tons of carbon dioxide emissions, according to researchers at Rutgers, the Harvard T.H. Chan School of Public Health and Stony Brook University. The study, published in Science Advances, found that the climate benefits of solar power differ markedly throughout U.S. regions, pinpointing where clean energy investments return the greatest climate dividends. In 2023, 60% of U.S. electricity generation relied on fossil fuels, while 3.9% came from solar, according to the U.S. Energy Information Administration. Because fossil fuel-generated electricity is a leading source of carbon dioxide, or CO2, and harmful air pollutants such as fine particulate matter, expanding solar could not only mitigate CO2 but help reduce illness, hospitalizations and premature deaths linked to air pollution exposure.From a com"
  },
  {
    "title": "Gemini 2.5 Deep Think (blog.google)",
    "points": 402,
    "submitter": "meetpateltech",
    "submit_time": "2025-08-01T11:10:38 1754046638",
    "num_comments": 202,
    "comments_url": "https://news.ycombinator.com/item?id=44755279",
    "comments": [
      "I started doing some experimentation with this new Deep Think agent, and after five prompts I reached my daily usage limit. For $250 USD/mo that\u2019s what you\u2019ll be getting folks.It\u2019s just bizarrely uncompetitive with o3-pro and Grok 4 Heavy. Anecdotally (from my experience) this was the one feature that enthusiasts in the AI community were interested in to justify the exorbitant price of Google\u2019s Ultra subscription. I find it astonishing that the same company providing free usage of their top models to everybody via AI Studio is nickel-and-diming their actual customers like that.Performance-wise. So far, I couldn\u2019t even tell. I provided it with a challenging organizational problem that my business was facing, with the relevant context, and it proposed a lucid and well-thought-out solution that was consistent with our internal discussions on the matter. But o3 came to an equally effective conclusion for a fraction of the cost, even if it was less \u201ccohesive\u201d of a report. I guess I\u2019ll have to wait until tomorrow to learn more.reply",
      "They might not have been ready/optimized for production, but still wanted to release it before Aug 2 EU AI Act, this way they have 2 years for compliance. So the strategy with aggressively rate-limit for few users make sense.reply",
      "wheee, great way to lock in incumbents even more or lock out the EU from startupsreply",
      "Welcome to the lovely world of regulation, enjoy your stay.reply",
      "Several years ago I thought a good litmus test for mastery of coding is not finding a solution using internet search nor getting well written questions about esoteric coding problems answered on StackOverflow. For a while, I would post a question and answer my own question after I solved the problem for posterity (or AI bots). I always loved getting the \"I've been working on this for 3 days and you saved my life\" comments.I've been working on a challenging problem all this week and all the AI copilot models are worthless helping me. Mastery in coding is being alone when nobody else nor AI copilots can help you and you have dig deep into generalization, synthesis, and creativity.(I thought to myself, at least it will be a little while longer before I'm replaced with AI coding agents.)reply",
      "Your post misses the fact that 99% of programming is repetitive plumbing and that the overwhelming majority of developers, even ivy league graduates, suck at coding and problem solving.Thus, AI is a great productivity tool if you know how to use it for the overwhelming majority of problems out there. And it's a boost even for those that are not even good at the craft as well.This whole narrative of \"okay but it can't replace me in this or that situation\" is honestly between an obvious touche (why would you think AI would replace rather than empower those who know their craft) and stale luddism.reply",
      "> 99% of programming is repetitive plumbingEven IF that were true (and I'd argue that it is NOT, and it's people who believe that and act that way who produce the tangled messes of spiderweb code that are utterly opaque to public searches and AI analysis -- the supposed \"1%\"), if even as low as 1% of the code I interacted with was the kind of code that required really deep thought and analysis, it could easily balloon to take up as much time as the other \"99%\".Oh, and Ned Ludd was right, by the way. Weavers WERE replaced by the powered loom. It is in the interest of capital to replace you if they are able to, not to complement you, and furthermore, the teeth of capital have gotten sharper over time, and its appetite more voracious.reply",
      "I have similar issues with support form companies that heavily push AI and self-serve models and make human support hard. I'm very accomplished and highly capable. If I feel the need to turn to support, the chances the solution is in a KB is very slim, same with AI. It'll be a very specific situation with a very specific need.reply",
      "There are a lot of internal KB's companies keep to themselves in their ticketing systems - would be interesting to estimate how much good data there is in there that could in the future be used to train more advanced (or maybe more niche or specific) AI models.reply",
      "They're remarkably useless on stuff they've seen but not had up-weighted in the training set. Even the best ones (Opus 4 running hot, Qwen and K2 will surprise you fairly often) are a net liability in some obscure thing.Probably the starkest example of this is build system stuff: it's really obvious which ones have seen a bunch of `nixpkgs`, and even the best ones seem to really struggle with Bazel and sometimes CMake!The absolute prestige high-end ones running flat out burning 100+ dollars a day and it's a lift on pre-SEO Google/SO I think... but it's not like a blowout vs. a working search index. Back when all the source, all the docs, and all the troubleshooting for any topic on the whole Internet were all above the fold on Google? It was kinda like this: type a question in the magic box and working-ish code pops out. Same at a glory-days FAANG with the internal mega-grep.I think there's a whole cohort or two who think that \"type in the magic box and code comes out\" is new. It's not new, we just didn't have it for 5-10 years.reply"
    ],
    "link": "https://blog.google/products/gemini/gemini-2-5-deep-think/",
    "first_paragraph": "Aug 01, 2025\n          We're rolling out Deep Think in the Gemini app for Google AI Ultra subscribers, and we're giving select mathematicians access to the full version of the Gemini 2.5 Deep Think model entered into the IMO competition.\n        Today, we\u2019re making Deep Think available in the Gemini app to Google AI Ultra subscribers \u2014 the latest in a lineup of extremely capable AI tools and features made exclusively available to them.This new release incorporates feedback from early trusted testers and research breakthroughs. It\u2019s a significant improvement over what was first announced at I/O, as measured in terms of key benchmark improvements and trusted tester feedback. It is a variation of the model that recently achieved the gold-medal standard at this year\u2019s International Mathematical Olympiad (IMO). While that model takes hours to reason about complex math problems, today\u2019s release is faster and more usable day-to-day, while still reaching Bronze-level performance on the 2025 IM"
  },
  {
    "title": "DeepSeek won the best paper award at ACL 2025 (arxiv.org)",
    "points": 57,
    "submitter": "CalmStorm",
    "submit_time": "2025-08-01T19:48:06 1754077686",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44761548",
    "comments": [
      "Title: Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse AttentionThe awards page for ACL seems to disagree with this editorialized title: https://2025.aclweb.org/program/awards/reply",
      "The ACL webpage has not been updated yet. Here are the announcement slides: https://cspaper.org/topic/116/record-breaking-acl-2025-crown...reply",
      "I'd say award for best title is a tie between: \"Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems\"; \"Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?\"; and \"Steering off Course: Reliability Challenges in Steering Language Models.\"reply",
      "> Despite being sparse, NSA surpasses Full Attention baseline on average across general benchmarks, long-context tasks, and reasoning evaluation.Isn't it very notable that the latency improvement didn't have a performance loss? I'm not super familiar with all the technical aspects, but that seems like it should be one of the main focuses of the paper.reply",
      "Well deservedreply",
      "For the first time, it introduced native sparse attention into the full training process, achieving up to 11\u00d7 inference speedup while maintaining model performance.reply"
    ],
    "link": "https://arxiv.org/abs/2502.11089",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Anthropic revokes OpenAI's access to Claude (wired.com)",
    "points": 94,
    "submitter": "minimaxir",
    "submit_time": "2025-08-01T21:50:28 1754085028",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=44762856",
    "comments": [
      "The article does not say anything substantial, but just some opposite viewpoints.1/ Openai's technical staff were using Claude Code (API and not the max plans).2/ Anthropic's spokesperson says API access for benchmarking and evals will be available to Openai.3/ Openai said it's using the APIs for benchmarking.I guess model benchmarking is fine, but tool benchmarking is not. Either openai were trying to see their product works better than Claude code (each with their own proprietary models) on certain benchmarks and that is something Anthropic revoked. How they caught it is far more remarkable. It's one thing to use sonnet 4 to solve a problem on Livebench, its slightly different to do it via the harness where Anthropic never published any results themselves. Not saying this is a right stance, but this seems to be the stance.reply",
      "Feels like something a Jepsen or such should be doing instead of competitors trying to clock each other directly. I can see why they would feel uncomfortable about this situation.reply",
      "\"OpenAI was plugging Claude into its own internal tools using special developer access (APIs)\"Unless it's actually some internal Claude API which OpenAI were using with an OpenAI benchmarking tool, this sounds like a hyped-up way for Wired to phrase it.Almost like: `Woah man, OpenAI HACKED Claude's own AI mainframe until Sonnet slammed down the firewall man!` ;D\nSeriously though, why phrase API use of Claude as \"special developer access\"?I suppose that it's reasonable to disagree on what is reasonable for safety benchmarking, e.g: where you draw a line and say, \"hey, that's stealing\" vs \"they were able to find safety weak spots in their model\". I wonder what the best labs are like at efficiently hunting for weak areas!Funnily enough I think Anthropic have banned a lot of people from their API, myself included - and all I did was see if it could read a letter I got, and they never responded to my query to sort it out! But what does it matter if people can just use OpenRouter?reply",
      "> Seriously though, why phrase API use of Claude as \"special developer access\"?Isn't that precisely what an API is? Normal users do not use the API. Other programs written by developers use it to access Claude from their app. That's like asking why is an SDK phrased as a special kit for developers to build software that works with something they wish to integrate into their appreply",
      "If I'm an OpenAI employee, and I use Claude Code via the API, I'm not doing some hacker-fu, I'm just using a tool a company released for the purpose they released it.I understand that they were technically \"using it to train models\", which, given OpenAI's stance, I don't have much sympathy for, but it's not some \"special developer hackery\" that this is making it sound like.reply",
      "Because it's not \"special developer access\". It's just \"normal developer access\". The phrasing gives an impression they accessed something other users cannot.reply",
      "Normal users use the API constantly, they just don\u2019t realize it.Isn\u2019t half the schtick of LLMs making software development available for the layman?reply",
      "> According to Anthropic\u2019s commercial terms of service, customers are barred from using the service to \u201cbuild a competing product or service, including to train competing AI models\u201dThat's... quite a license term. I'm a big fan of tools that come with no restrictions on their use in their licenses. I think I'll stick with them.reply",
      "These anti-competitive clauses are becoming standard across all major AI providers - Google, Microsoft, and Meta have similar terms. The industry is converging on a licensing model that essentially creates walled gardens for model development.reply",
      "Well, Open AI had been whining about DeepSeek back in the day, so it is fair in a way.reply"
    ],
    "link": "https://www.wired.com/story/anthropic-revokes-openais-access-to-claude/",
    "first_paragraph": "All products featured on WIRED are independently selected by our editors. However, we may receive compensation from retailers and/or from purchases of products through these links.Anthropic revoked OpenAI\u2019s API access to its models on Tuesday, multiple sources familiar with the matter tell WIRED. OpenAI was informed that its access was cut off due to violating the terms of service.\u201cClaude Code has become the go-to choice for coders everywhere and so it was no surprise to learn OpenAI's own technical staff were also using our coding tools ahead of the launch of GPT-5,\u201d Anthropic spokesperson Christopher Nulty said in a statement to WIRED. \u201cUnfortunately, this is a direct violation of our terms of service.\u201dAccording to Anthropic\u2019s commercial terms of service, customers are barred from using the service to \u201cbuild a competing product or service, including to train competing AI models\u201d or \u201creverse engineer or duplicate\u201d the services. This change in OpenAI\u2019s access to Claude comes as the Cha"
  },
  {
    "title": "Deep Agents (langchain.com)",
    "points": 103,
    "submitter": "saikatsg",
    "submit_time": "2025-08-01T19:28:45 1754076525",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=44761299",
    "comments": [
      "Author here!Main takeaways (which I'd love feedback on) are:There are series of agents recently (claude code, manus, deep research) which execute tasks over longer time horizons particular wellAt the core of it, it's just an LLM running in a loop calling tools... but when you try to do this naively (or at least, when I try to do it) the LLM struggles with doing long/complex tasksSo how do these other agents accomplish it?These agents all do similar things, namely:1. They use a planning tool2. They use sub agents3. They use a file system like thing to offload context4. They have a detailed system prompt (prompting isn't dead!)I don't think any of these things individually is novel... but I also think that they are not super common place to do when building agents. And the combination of them is (I think) an interesting insight!Would love any feedback :)reply",
      "As I think through this, I agree with others mentioning that \"deep agents\" still sounds a lot like agents+tools. I guess the takeaway for me is:1. You need a good LLM for base knowledge.2. You need a good system prompt to guide/focus the LLM (create an agent).3. If you need some functionality that doesn't make any decisions, create a tool.4. If the agent + tools flows get too wily, break it down into smaller domains by spawning sub agents with focused prompts and (less?) tools.reply",
      "This matches my expectations.Now that its increasingly clear that writing MCP servers isn't a winning strategy, people need a new way to jump on the band wagon as easily as possible.Writing your own agent like geminin and claude code is the new hotness right now.- low barrier to entry (tick)- does something reasonably useful (tick)- doesnt require any deep ai knowledge or skill (tick)- easy to hype (tick)Its like \u201ccursor but for X\u201d but easier to ship.Were going to see a tonne of coding agents built this way, but my intuition is, and what Ive seen so far, is theyre not actually introducing anything novel.Maybe having a quick start like this is good, because it drops the value of an unambitious direct claude code clone to zero.I like it.reply",
      "ah, deep agents = agents with planning + agents as tools => so regular agents.i hate how LangChain has always tried to make things that are simple seem very complicated, and all the unnecessary new terminology and concepts they've pushed,  but whatever sells LangSmith.reply",
      "I'm also in the process of creating a general purpose agent cli+library in rust: https://github.com/fdietze/alorsStill work in progress, but I'm already using it to code itself. Feedback welcome.reply",
      "At least from what I noticed - Junie from Jetbrains was the first to use a very high quality to do list, and it quickly became my favoriteI haven't used it since it became paid, but back then Junie was slow and thoughtful, while Cursor was constantly re-writing files that worked fine, and Claude was somewhere in the middlereply",
      "Cursor added a UI for todo list and encourages it's agent to use it (its great ux, but you can't really see a file of it)kiro from amazon does both tasks (in tasks.md) and specs.Too many tools soon, choose what works for youreply",
      "offloading context to a shared file system sounds good but at what point does it start getting messy when multiple subagents start working in parallelreply",
      "Do subagents run in parallel?reply",
      "sub agents adding isolating context is the real deal rest is just langgraph react agentreply"
    ],
    "link": "https://blog.langchain.com/deep-agents/",
    "first_paragraph": "Using an LLM to call tools in a loop is the simplest form of an agent. This architecture, however, can yield agents that are \u201cshallow\u201d and fail to plan and act over longer, more complex tasks. Applications like \u201cDeep Research\u201d, \u201cManus\u201d, and \u201cClaude Code\u201d have gotten around this limitation by implementing a combination of four things: a planning tool, sub agents, access to a file system, and a detailed prompt.Acknowledgements: this exploration was primarily inspired by Claude Code and reports of people using it for more than just coding. What about Claude Code made it general purpose, and could we abstract out and generalize those characteristics?The dominant agent architecture to emerge is also the simplest: running in a loop, calling tools.Doing this naively, however, leads to agents that are a bit shallow. \u201cShallow\u201d here refers to the agents inability to plan over longer time horizons and do more complex tasks.Research and coding have emerged as two areas where agents have been creat"
  },
  {
    "title": "Self-Signed JWTs (selfref.com)",
    "points": 79,
    "submitter": "danscan",
    "submit_time": "2025-08-01T18:27:59 1754072879",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=44760561",
    "comments": [
      "I _love_ JWTs for API authentication - one of the nicest APIs I ever consumed was essentially JSON RPC over JWTs. Unfortunately they represent a huge usability hit over API Keys for the average joe. Involving cryptography to sign a JWT per request makes an API significantly harder to consume with tools like Postman or CURL. You can no longer have nice click-to-copy snippets in your public docs. You either have an SDK ready to go in your customer's language or ecosystem of choice, or you're asking them to write a bunch of scary security-adjacent code just to get to their first successful request. No, I don't have a JWT library recommendation for Erlang, sorry.Not that an API couldn't support both API Keys and JWT based authentication, but one is a very established and well understood pattern and one is not. Lowest common denominator API designs are hard to shake.reply",
      "Interesting, so instead of OpenAI giving me an API key, I give them a public key, which they register. Sounds like what we already do with GitHub. I like it.reply",
      "Yes.and it\u2019s easy to do keypair generation in the browser using subtle crypto. That API doesn\u2019t provide jwk generation, but seems like it would be relatively easy to do even without the jose module. And the browser cab \u201cdownload\u201d (really just save) the keypair using the Blob API. Keys need not leave the browser.An api developer portal could just offer \n- generate a new keypair?\n- upload your existing public key?\u2026As a choice. Either way the public key gets registered for your account.The end. Easy.reply",
      "Which, unless I'm missing something, undercuts the entire article? The private key, in the generated keypair, is the thing that you can then never commit to your VCS.When you \"register\" the public key with whatever the relying party is, you're also likely going to bind it to some form of identity, so you can't leak this private key to others, either. (And I'm curious, of course, how the relying party comes to trust the public key. That call would seem to require its own form of auth, though we can punt that same as it would be punted for an API key you might download.)reply",
      "In theory, I as the service provider know when my key database has been compromised. In theory. In practice, I will never know if a customer has been compromised, however up to a point a compromised user box can forward tokens to an attacker. So pending on whether you ever rotat the private keys, it\u2019s a matter of ho long an attacker can retreat to a server they own to continue the attack.In a way this reminds me a bit of SRP, which was an attempt to handle login without the server ever having your password. Which makes me think this is something to be integrated with password managers.reply",
      "Sorry, are you expecting some way to authenticate without any secrets?Could you describe how that would work? If two people have the same\ninfo, how on earth do you tell which is which?The post is talking about simplifying things by eliminating all the back and forth. It\u2019s not pretending to invent a secret-less auth system.reply",
      "This is actually how GCP has always done service account authentication. A GCP service account key is an asymmetric keypair and Google stores the public key. AWS is somewhat similar, but they use an symmetric HMAC so they store the same secret key you use.reply",
      "It's interesting to imagine taking the pubkey as identity concept to its full extents in situations like this, for example if you could create a cloud account, spin up resources, and authorize payment for them all programmatically without having to enter payment details on a form (because your keypair can authorize payment with the whatever payment method you use)reply",
      "Even better if they would take a private CA cert.reply",
      "This is similar to ssh key auth. (Pubkey, privkey)reply"
    ],
    "link": "https://www.selfref.com/self-signed-jwts",
    "first_paragraph": "Get a load of this (totally normalized) BS.Visit our website. Create an account. Verify your email. Create a project. Add your credit card. Go to settings. Create an API key. Add it to your password manager. Drop it in your .env file. Download our SDK. Import it. Pass your env var in. Never share your API key. Make sure you never commit it to source control.On the client, we have a React SDK. Make sure you use your publishable key for that. For the server, download our admin SDK. Use your secret key. Never mix the two up.\u201dIt\u2019s truly wild to me what some of y\u2019all will tolerate.Let me show you something\u2026 Did you know generating a JWK is stupidly easy?That\u2019s it. Your JWK keypair is now effectively your own self-issued API key.No need to visit a website, make an account, verify your email, create a project, go to settings, create an API key, or copy it and use it. You just generated your own.Let\u2019s see how we can get rid of secret versus publishable keys and separate client and admin SDKs.W"
  },
  {
    "title": "Twentyseven 1.0 (poisson.chat)",
    "points": 23,
    "submitter": "082349872349872",
    "submit_time": "2025-08-01T22:10:07 1754086207",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44763016",
    "comments": [
      "Hah. Neat. I love projects like this just for fun.For my old (2010-era) Bitcoin casino, I wrote a slot machine based on a Rubik's cube. When you would \"spin\" the slot, the cube would reset to a perfect position and then scramble itself randomly 4-6 times. You had 60 seconds (with max 3 moves) to solve as many lines as possible. Payout was based on how many triplets you had.I never wrote a solver for it. But the goal was for it to be skill-based. Determining the payout odds involved a LOT of monte carlo solving. I wanted the expected value for a perfect player to be 100%.Very few people ever actually played it. And those who did mostly played the \"dumb\" version where the payouts were higher per line, but you didn't get the 3 manipulations after the spin. That version was calibrated to about 92% EV, if I remember right.Diving into the math of it was one of the most entertaining things I've ever done as a programmer. A universal poker hand evaluator (from 3 card to 5 to 7 Holdem and Omaha) in 200 lines of PHP, was the second.reply",
      "Incase the author of the original article ends up reading this, is there any significance to the skipping of the 9th index after each face? (i.e. first face is 00-08, next one starts at 10 and goes to 18, then 20 to 28, etc)A naive guess on my part is that doing it this way keeps the number in each specific spot of the 3x3 grid the same, X0 is the top left and X8 is the bottom right.reply"
    ],
    "link": "https://blog.poisson.chat/posts/2025-08-01-twentyseven.html",
    "first_paragraph": "Twentyseven\r\nis a Rubik\u2019s cube solver and one of my earliest projects in Haskell.\r\nThe first commit dates from January 2014, and version 0.0.0 was uploaded on Hackage in March 2016.I first heard of Haskell in a course on lambda calculus in 2013.\r\nA programming language with lazy evaluation sounded\r\nlike a crazy idea, so I gave it a try.\r\nSince then, I have kept writing in Haskell as my favorite language.\r\nFor me it is the ideal blend of programming and math.\r\nAnd a Rubik\u2019s cube solver is a great excuse for doing group theory.Twentyseven 1.0.0 is more of a commemorative release for myself,\r\nwith the goal of making it compile with the current version of GHC (9.12).\r\nThere was surprisingly little breakage:Aside from that, the code is basically just as it was 9 years ago,\r\nincluding design decisions that I would find questionable today.\r\nFor example, I use unsafePerformIO to read precomputed tables\r\ninto top-level constants, but the location of the files to read from\r\ncan be configured by "
  },
  {
    "title": "Show HN: TraceRoot \u2013 Open-source agentic debugging for distributed services (github.com/traceroot-ai)",
    "points": 24,
    "submitter": "xinweihe",
    "submit_time": "2025-08-01T16:58:51 1754067531",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44759406",
    "comments": [
      "I like the idea of this and the use case, but don't love the tight coupling to openai. I'd love to see a framework for allowing BYOM.reply",
      "Yes, there is a roadmap to support more models. For now there is a in progress PR to support Anthropic models https://github.com/traceroot-ai/traceroot/pull/21 (contributed by some active open source contributors) Feel free to let us know which (open source) model or framework (VLLM etc.) you want to use :)reply",
      "Why not use something like litellm?reply",
      "That's also one option, we will consider add it later :)reply"
    ],
    "link": "https://github.com/traceroot-ai/traceroot",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Find the Root Cause in Your Code's Trace\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\n\n\n\n\n\n\nTraceRoot is an open-source debugging platform that helps engineers fix production issues 10x faster by combining structured traces, logs, and source code context with AI-powered analysis.Contributing |\nTraceRoot.AI |\nCommunity |\nSDK |\nDocumentationJoin us (Discord) in pushing the boundaries of debugging with AI agents.Please \ud83c\udf1f Star TraceRoot on GitHub and be instantly notified of new releases.The framework enables multi-agent systems to continuously evolve by interacting with environments.The framework enables real-time tracing and logging to your applications.The framework enables utilizing structured loggings and tracing data to improve the performance of "
  },
  {
    "title": "What's Not to Like? (theamericanscholar.org)",
    "points": 18,
    "submitter": "wyndham",
    "submit_time": "2025-07-30T17:00:42 1753894842",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=44736668",
    "comments": [
      "One thinks of the late Tom Lehrer:  Your lips were like wine,\n  If you'll pardon the simile;\n  The music was fine\n  If a bit Rudolph Friml-y.\n\n(The Wienerschnitzel Waltz)reply",
      "Since this is about language and similes, what about \"You can't compare apples and oranges\"? People say that frequently, but why in particular is that so?I think you can compare any one thing to any other one thing. You can discuss what are their common features and what features they have that are not shared.So it seems to me \"Can't compare apples and oranges\" is often used just  as a polemic device, trying to attack your opponents by claiming what they are saying cannot be said.reply",
      "I think it's more you shouldn't judge apples based on the criteria of how good it is at being an orange, and vice-versa.Kind of like how you don't judge a fish on how well it climbs trees.reply",
      "Who doesn't love them tree climbing fishies https://en.wikipedia.org/wiki/Mudskipperreply",
      "It seems to me that \"can't compare apples and oranges\" is trying to say that you're using apple criteria to try to judge oranges.  It's not that you can't compare apples and oranges, but you have to use fruit criteria to do so, not apple criteria or orange criteria.So, to stop using similes:  You can compare CPUs.  You can compare memory chips.  You can also compare memory chips and CPUs on, say, power consumption.  But you can't compare memory chips to CPUs in terms of MIPS.  If you try, then it's appropriate to accuse you of comparing apples to oranges.reply",
      "Good point. If things exist in different \"ontological categories\" trying to evaluate which of them is \"better\" makes little sense.But apples and oranges are both good food, so we can compare how much calories you get forjm them, or vitamins etc.reply",
      "The Czechs say that you can't compare the sky (or the heavens, depending on how you want to translate it) and bagpipes.reply",
      "Moreover if you chuck an apple and an orange in a mass spectrometer you will find that they are more or less exactly the same. I believe someone won an igNobel prize for that observation.reply",
      "It's always been like \"you cannot compare values of different units\" to me. Maybe we should start saying \"you cannot compare kilograms to metres\".reply",
      "A kilogram is more than enough gasoline to move my car a meter.reply"
    ],
    "link": "https://theamericanscholar.org/whats-not-to-like/",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: Societies.io (YC W25) \u2013 AI simulations of your target audience",
    "points": 74,
    "submitter": "p-sharpe",
    "submit_time": "2025-08-01T12:13:12 1754050392",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=44755654",
    "comments": [
      "First off, congrats on the funding and the progress so far!I\u2019ve seen a a couple of start ups pitching similar ideas lately - platforms that use AI personas or agents to simulate focus groups, either for testing products or collecting user insights. I can see the appeal in scaling audience feedback, reducing costs, reaching demographics that are traditionally hard to access.That said, this is one of the areas of AI that gives me the most concern. I work at a company building AI tools for creative professionals, so I'm regularly exposed to the ethical and sustainability concerns in this space. But with AI personas specifically, there is something a little more troubling to me.One recent pitch really stuck with me, in this case, the startup was proposing to use AI personas for focus groups on products and casually mentioned local government consultation. That's where I think this starts to veer into troubling territory. The idea of a local council using synthetic personas instead of talking directly to residents about policy decisions is alarming. It may be faster, cheaper, or even easier to implement but it fundamentally misunderstands what real feedback looks like.LLMs don't live in communities. They don't vote, experience public services, or have lived context. No matter how well calibrated or \"representative\" the personas are claimed to be, they are ultimately a reflection of training data and assumptions - not the messy, multimodal, contradictory, emotional reality of human beings. And yet, decisions based on these synthetic signals could end up shaping products, experiences, or even policies that affect real people.We're entering an era where human behaviour is being abstracted and compressed into models, and then treated as if it's a reliable proxy for actual human insight. That's a level of abstraction I'm deeply uncomfortable with and it's not a signal I think I would ever trust, regardless of how well it's marketed.Would be curious to know what your approach is to convince others that may also be skeptical or not want to see this kind of tech being abused for the reasons listed above?reply",
      "Thank you! We 100% agree. My research back in Cambridge was on misinformation, so we take the danger of misuse very seriously even as a tiny team of 3 people right now. As a social science researcher, one big challenge we faced was just how difficult it was to run experiments - it's quite unethical (and impossible) to have 100k people under policy A and 100k under policy B, so as a result, we as a society struggle to find the \"golden path\" with big issues like misinformation, climate change, or even everyday economics.That's what motivated me to start researching in the area of creating \"Artificial Societies\" - first as an academic project, now as a product everyone can use, because I believe the best way to build a new technology is to try to make it useful for as many people as possible, rather than reserving it for governments and enterprises only. That's why unlike other builders in this space, we've made it a rule to never touch defence use cases; that's why we've gone against much business wisdom to produce a consumer product that anyone can use, rather than going after bigger budgets.We totally agree that synthetic audiences should never replace listening to real people - we ourselves actually insist on doing manual user interviews so that we can feel our users pain ourselves. We hope what we build doesn't replace traditional methods, but expands what market research can do - that's why we try to simulate how people behave in communities and influence one another, so that we capture the ripple effects that a traditional survey ignores because it treats humans like isolated line items, rather than the communities we really are.Hopefully, one day, just like a new plane is first tested in a wind tunnel before risking the life of a test pilot, a new policy will also first be tested in an artificial society, before risking unintended consequences in real participants. We are still in the early days though, so for now, we are just working hard to make a product people would love to use :)reply",
      "But \"artificial societies\" are only possible with AGI, not with LLMs. These are not reasoning engines. They do not think or have values or care or worry.reply",
      "Someone must have a wild-ass theorem about whether or not consciousness is representable as  some distribution over possible realities. But yeah, I agree this feels like taking a huge step towards fewer and fewer people having agency in their own (real) lives.I'm certain Big [insert industry] will gobble this kind of thing up.reply",
      "Exactly my concerns as well. If we're indeed heading toward \u201cask AI first, humans later\u201d model there's potential for a slippery slope\u2014one that could be exploited depending on which regime happens to be in power. If politicians or special-interest groups can manipulate or curate AI-generated \u201copinions,\u201d they could present those biased outputs as if they were genuine reflections of their constituents\u2019 views. Over time, the line between authentic public sentiment and engineered AI propaganda could blur, undermining informed democratic debate.reply",
      "See https://en.wikipedia.org/wiki/Franchise_(short_story)reply",
      "I read the accuracy report and I'm yet to find on what basis is your accuracy score being built on. Is it the number of personas that re-post, like, comment, see, all of the above?I think you guys might be onto something but I'm still skeptic as to whether you are the most accurate (on whatever metric). It's not surprising that you beat a survey of experts, or straight out of the box commercial LLMs.I'm more interested in seeing how your model performs against purpose specific models that are currently industry standard. Unless you're making the claim that you're the first service to predict content engagement?reply",
      "Nice work, clean demo. Who is your target buyer?This seems like it could be useful for product discovery (\u201cwhat are these people complaining about?\u201d), content marketing (\u201chow will my twitter followers react to this blog post?\u201d), and other\u2026 reactionary\u2026 activities. But what about GTM and lead-gen? Can you ask it \u201cwho has job title of CISO, within two degrees of connection to me, working at a company with at least 500 employees that is SOC2 certified?\u201dI think you need to focus on a target buyer and make sure you nail their use case, or you risk wasting time on a really cool product that kinda/sorta does everything.What\u2019s your differentiator? Are you in the business of data gathering and curation? Or do you enhance some existing targeting data with \u201ctalk to my audience?\u201d These are two distinct product development paths\u2026 either you invest in sophisticated data scraping, or you focus on \u201cbring your own audience.\u201d Most companies already have this sort of data on their customers and prospects \u2013 how can you meet them where they are?The other problem is garbage in, garbage out. This product is only as useful as the data you can gather (or that your customer brings to you). A list of emails and names isn\u2019t much on its own. You need the data generated by those people. Maybe you need to partner with data brokers to enrich audience data with social media profiles. Or maybe you leave it up to your customer \u2013 let them upload all their support tickets (ZenDesk) and sales calls (Gong) to your software so that they can \u201ctalk to their customers.\u201d (Hint: maybe you should partner with Gong, and similar companies who already have this data, to provide this feature to their customers. White-labeling this product might be your fastest path to market.)But more existentially\u2026 is \u201copinions\u201d the most important aspect of your customer that you want to simulate? And if so\u2026 why do you need a _network_ of customers for this? It seems like two disconnected ideas. An \u201caudience\u201d might be a group of people that you only know to be associated because of their shared subscription to your product. Or they all follow someone on Twitter. Or they\u2019ve all written an HN comment with \u201ctrivial\u201d in its text. Does the _network_ aspect actually matter, at all?And if the network aspect is important\u2026 why? Is it because you want to discover a new audience? In that case, are you focusing on the right value by simulating the current audience? Or should you be focused more on features for expanding/enriching/discovering \u201csimilar\u201d profiles?I think you\u2019ve got the basis of something really cool here, but you need to figure out your identity and core competency, or you risk doing a bunch of marginally useful stuff kinda well.Did you see the recent HN launch of Sumble? I see some overlap and similarities between your products, and I\u2019d suggest reaching out to them in case you can work together\u2026edit: Just saw you went to Cambridge\u2026 I live here, if you\u2019re ever around and want to grab coffee. I\u2019m \u201cMiles Richardson\u201d on LinkedIn (and uh\u2026 in life). Feel free to message me\u2026 I spent five years on a startup that never hit product/market fit, so I\u2019m always happy to point out the hazards\u2026reply",
      "This is very cool. I tested it with a specific linkedin post and it was pretty much spot-on (the reaction estimate, that is). Can't wait to try the optimized versions in the future.reply",
      "Do you ensure you have enough personas in the desired target area to get enough survey responses?  Are there demographics you are not able to simulate at this time?reply"
    ],
    "link": "item?id=44755654",
    "first_paragraph": ""
  },
  {
    "title": "Ask HN: Who wants to be hired? (August 2025)",
    "points": 67,
    "submitter": "whoishiring",
    "submit_time": "2025-08-01T15:00:05 1754060405",
    "num_comments": 167,
    "comments_url": "https://news.ycombinator.com/item?id=44757792",
    "comments": [
      "Location: New OrleansRemote: yesWilling to relocate: Noemail: egypt@urnash.comDoes your company still practice stack ranking? Do you have a great team with nobody you're willing to lose in the next cull? I'm a queer artist who's barely scraping by. I will be happy to be your sacrificial goat for the small price of a year of your fancy-ass tech salary. I will get next to nothing done, at an exceedingly slow pace.In the unlikely event that anyone here is actually looking for a real human artist, my site is http://egypt.urnash.com. I used to be an animator but I burnt way the heck out on that twenty years ago. Mostly I draw comics and furry porn.reply",
      "Location: Northeastern United StatesRemote: MaybeRelocate: Yes!Technology is constantly evolving. Most recently familiar with the PowerShell/C#.NET ecosystem, but not exactly looking to reprise that experience. Worked primarily with Interpreted languages ranging from Perl, PHP since version 3.1, Brainfuck, Python, Ruby, Lua, various flavors of Shell, and many more. Not scared of Compiled Languages or Assembly.Email:  Eugene@Kashpureff.orgEmployment History: Upon Request. Most recently at Microsoft - departed for Family Reasons.I am seeking a Position which is Technically Interesting. I would like to be part of a Team working towards a common goal that improves Society, rather than a collection of Individuals connected only by their Salaries at a megacorporation. I am not searching for any specific Job Title - you may be looking for a Software Engineer, Business Analyst, Technical Manager, Security Researcher, Systems Architect, or maybe just a part-time Consultant. In my career since 1995 I have chased bizarre memory-alignment performance regressions in C code for a Physics library, built distributed database replication systems with leader-election consensus, chased timing issues within Multiplayer game protocols, implemented Financial audit controls to identify untrustworthy employee behaviour, built Monitoring &  Active DevOps response systems for \u201cFive-ish Nines\u201d Uptimes of customer Environments, designed and installed redundant Low-Voltage and High-Voltage Electrical systems on Ships (DP2 standards) and in Data Centers, performed physical security penetration testing for Restricted Sites, and participated in a takeover of the Global Domain Name System\u2019s root servers.If you have any Questions, please send me an Email!reply",
      "Location: Canberra / Sydney, Australia or Remote\n    Willing to Relocate: No\n    Resume: https://kernelcat.au/resume.pdf\n    Technologies: C, C++, Go, Rust, Python, Linux (Kernel) / UNIX, AWS, Cryptography, Networking\n    Availability: 20 hours per week\n    Contact: hn@kernelcat.au\n    Website: https://kernelcat.au/\n\nHi,I have over 20 years in the industry starting out as a Linux SysAdmin / Network Engineer and now doing more Systems / Low level Programming, R&D, and occasional DevOps.Looking for opportunities involving low level / embedded systems / backend software development. Happy to also do automation / SysAdmin / DevOps as well. Although not my forte, I like to do robust automated testing / QA for software to ensure they meet (potentially undocumented) requirements.reply",
      "USA REMOTE | NYC HYBRID  Languages: C/C++, Python, JavaScript, Kotlin, VHDL, SystemVerilog\n  Hardware: PowerPC, ESP32, STM32, iCE40, ECP5\n  ML: TensorFlow Lite Micro, PyTorch, ONNX, OpenCV\n  IoT: BLE, WiFi, MQTT, LoRa\n\n  Resume: https://docs.google.com/document/d/18mjB1tIH5s-ZmiET_smUxbMo3FaiC637aW_us8P0U5I/edit?usp=drivesdk\n  Email: dm@datameta.info\n\nHi, I'm an embedded systems engineer/architect bridging the full compute spectrum of ultra-low power IoT, edge systems, and HPC.My latest projects have been in full-stack edge ML R&D, memory controller firmware dev for POWER servers, and chip bringup/testing for Z mainframes.I'm passionate about modular synthesis and tinkering with all sorts of analog circuits and DSP. Currently upskilling in analog PCB design and refining my abilities in FPGA development. Also WIP on a 3D-printed robot arm to practice control systems and actuation.reply",
      "Location: Cuernavaca, MexicoRemote: Yes.Willing to relocate: probably not, but never say neverTechnologies: JS/TS, Python, PHP, Go, C, Shell, SQL; Django, React, Laravel, Emacs; Linux, git, Prometheus, Loki, Grafana, DockerR\u00e9sum\u00e9/CV: Available on requestEmail: slow.tiger6655@fastmail.comI'm a generalist with a background in full stack development, release engineering, and systems administration. I can do pointer arithmetic but I can also set up a DNS server or \u2014 in a pinch \u2014 configure Webpack from scratch.US and Mexican passport holder; willing and able to travel.  Based in central Mexico, I have good timezone overlap from Buenos Aires to Seattle, and I keep early hours to sync with teams in Europe as well.A native English speaker with C1-ish Spanish, I often act as a liaison between international teams and our Mexican office.At my current job I've thrived when assigned to work on large, legacy projects \u2014 which I've ended up leading more than once.I like documenting (yes, really) and mentoring and putting out fires.reply",
      "Location: Indonesia\nRemote: Yes\nWilling to relocate: Yes (Asian region)\nTechnologies: \n- Language: C, C++, Assembly (ISA: RV64I/RV32I) GAS, FASM, zig, python, PHP, SQL, JVM language (Java, kotlin), erlang (still learning), typst\n- framework: PyTorch/LibTorch, CodeIgniter, Arduino\n- Project Management tools: gradle, CMake, Make, zig build\n- debugging tools: GDB, LLDB\n- profiling tools: valgrind\nresume: -\nemail: triilmanafattah01@outlook.comProject that I have build:\nhttps://github.com/triilman25/tcp-socket-in-riscv-assembly (using GAS/GNU ASSEMBLER RISC-V)\nhttps://github.com/triilman25/evaluation-machine-for-classif... (using LibTorch and Raylib for UI)\nhttps://codeberg.org/Fattah25/agriculture-geographic-informa... (stack CodeIgniter, MariaDB, BootStrap, and HTMX)I am a freshgraduate with 6 month internship experience as a server maintenaceI am interested in robotics and 3D design (familiar with tools like autodesk inventor, onshape, sketchUp, and freecad)reply",
      "Location: Bangkok, Thailand (currently)Remote: YesWilling to relocate: YesTechnologies: Javascript, TypeScript, Node.js, Next.js, React, Python, Docker, Kubernetes, Terraform, AWS, GCP, SQL/Postgres, MongoDB, Redis.R\u00e9sum\u00e9/CV: Available on request via emailEmail: sj2564 [at] columbia [dot] eduI\u2019m a generalist engineer with past experience including full-stack engineering at a YC legal-tech startup and full-stack + cloud infra at an NYC quant fund. I also have entrepreneurship experience that gives me an understanding of the end-to-end product development process at early stage startups.My current project is a study mode for AI assistants with spaced repetition integration:\nhttps://app.polymax.ai/study-modeI\u2019m skilled at taking initiative on projects and synthesizing requirements from multiple stakeholders into meaningful technical solutions. I\u2019m passionate about functional programming, building reliable and scalable distributed systems, and optimizing developer experience. I also speak 4 languages (English, Sinhala, Mandarin Chinese, and Thai).reply",
      "Location: Edmonton, Alberta, CanadaRemote: YesWilling to relocate: YesTechnologies: Java with Spring Framework, Python with Django, React, Angular with TypeScript, PostgreSQL, PHP, WordPress, Golang, C# with .NET Maui, Azure, Docker, CI/CD with GitHub ActionsR\u00e9sum\u00e9/CV: R\u00e9sum\u00e9 can be sent when needed.Blog: https://ifesunmola.com/Email: contact@ifesunmola.comI am a recent graduate with a B.Sc. in Computer Science and Mathematics with approximately 2 years of experience from internships and contract jobs. While my degree provided a strong theoretical foundation, I am a hands-on developer who learns by building and teaching myself technologies by diving into documentation.My in-progress (demo) project is a full-stack marketplace application built with Java/Spring, TypeScript/Angular, and PostgreSQL. I also took on the challenge of containerizing it with Docker and setting up a complete CI/CD pipeline on Azure with GitHub Actions.My *passion for fundamentals also led me to build a compiler for my programming language that generates JVM bytecode (link in website).I enjoy exploring diverse computer science topics out of curiosity, and I am looking for an opportunity where I can contribute to meaningful projects while growing alongside a talented team.*It was more of an obsession that I just needed to get out of my system.reply",
      "Location: London (UK)Remote: Yes (Remote/Hybrid depending on location)Willing to relocate: NoTechnologies: Typescript, Javascript, BashR\u00e9sum\u00e9/CV: https://punkbit.com/docs/cv-punkbit-helder-oliveira.20250728...I'm a Product Engineer and a creative based in London. I\u2019ve built full-stack applications across web, mobile, blockchain and embedded platforms. My client-side work includes React, Electron, Roku\u2019s Scenegraph, and native iOS development with Swift and SwiftUI, always with a strong focus on UX and design-first thinking. On the service-side, I\u2019ve worked with traditional service hosting, containers, and serverless, including (but not limited to) AWS, GCP, Cloudflare, Workers, CloudFormation, SAM CLI, nodejs, bunjs, MySQL, Postgres, NoSQL, grpc, Redis, Docker, nginx, and a few legacy tools best left unnamed (yes, including CodeIgniter and ftp).I\u2019ve also developed developer tools like CLIs and SDKs, primarily JavaScript land, and have written code in systems languages such as Rust and Zig.In the AI space, I\u2019ve integrated models via the OpenAI SDK, leveraged prompts, LLMs, and explored LangGraph.I care about clean code, great UX, developer experience, documentation (yes), rapid iteration and automating workflows with CI/CD (GitHub Actions, Bash scripts, etc).Want to know more? https://punkbit.comreply",
      "Location: EURemote: Yes, EU timezones preferredWilling to relocate: Depends on the location (but with a strong bias for EU-Schengen/US locations)Technologies: Java, Python (and variants thereof like Groovy, Clojure, Pypy), Node/TS | AWS/Lambda Serverless, GCE/Kubernetes | Redis, MySQL, PostgreSQL, DynamoDBResume: https://bit.ly/3B3o65M (It links to my CV repo at Github, pinky promise. You can also visit github.com/<hnusername>.)I'm not actively looking (hence why my resume link is obfuscated like that) but I'm at least interested in getting a feel for the market right now. That said, I'm willing to consider a position with a great fit for my skill set and career goals.Here's my pitch: I have experience in a multitude of industries and positions. From improving legacy infra and processes in an established telco company to scaling a fast-moving startup from 200K to 2M users. In my free time, I love writing Code That Is Poetry but day-to-day I am not an idealist engineer who doesn't compromise. Well-engineered code is clean and correct but correct above all else.Oh, also, I'm great at writing documentation. I consider myself introverted but apparently my communication skills are above average for Software Engineers. I also pride myself on my humility and modesty.I'm currently a backend engineer developing features and improving infra for an online game with millions of daily active users. I'd love to explore other technical positions in the games industry short of joining a AAA studio because (a) I don't want to crunch and (b) my skill set does not lay that way; other tech-creative industries would also appeal to me! Another particular interest is in B2C businesses where the 'C' is software developers. I'd love to chat and network about opportunities; if you think you have a product that could benefit from my skill set, drop me a line!reply"
    ],
    "link": "item?id=44757792",
    "first_paragraph": ""
  }
]