[
  {
    "title": "Size of Life (neal.fun)",
    "points": 1366,
    "submitter": "eatonphil",
    "submit_time": "2025-12-10T16:02:57 1765382577",
    "num_comments": 174,
    "comments_url": "https://news.ycombinator.com/item?id=46219346",
    "comments": [
      "The dynamic soundscape is delightful, as it subtly adds instruments and musical texture as you progress. And going back down the scale regresses it to simple again. Smoothly done.It reminded me of Operation Neptune (1991): each level starts with just one channel, probably percussion, and as you progress through the rooms it adds and removes more channels or sometimes switches to a different section of music. It is unfortunately all sharp cuts, no attempts at smoothing or timing instrument entry and exit. A couple of samples: https://www.youtube.com/watch?v=S0LNaatyoQk is an hour of gameplay revelling in \u201cthe dynamic and sometimes beautiful music of Operation Neptune\u201d using a Roland MT-32 MIDI synthesiser; and https://www.youtube.com/watch?v=wPxEdQ4wx9s&list=PL3FC048B13... is the PCM files used on some platforms (if you want to compare that track with the MT-32, it starts at 28 minutes).reply",
      "I love how the music swells and becomes more intricate as life expands and grows more complicated.reply",
      "Man I played Operation Neptune a lot when I was a kid. I wonder if it was the first game to do this style of adaptive music layering. It predates the iMUSE system used in LucasArts games like X-Wing and TIE Fighter.For anyone curious, you can actually play it here: https://archive.org/details/msdos_Super_Solvers_Operation_Ne...reply",
      "The arcade classic Space Invaders had a primitive soundscape in that every time the remaining invaders advance, it plays a short bass note. As fewer and fewer invaders remain, it takes less time for them to advance, and the note repeats faster and faster, it adds a remarkable amount of increasing tension as each level progresses.So not exactly the same, but perhaps prototypical. I think Asteroids did as well.reply",
      "Interesting Space Invaders Trivia:The game speeding up as invaders are eliminated was an unintended consequence of the hardware running full speed to draw all 55 invaders. As invaders are eliminated the draw calls finish faster and the game speeds up. There is no code in the game to throttle the speed. The 2 Mhz 8080 is always drawing full speed. It's delightfully serendipitous this happens to ramp up the difficulty as you near the end of each level in such a compellingly perfect way. (https://www.tomshardware.com/video-games/retro-gaming/space-...)I've watched some interviews with the game's programmer Tomohiro Nishikado and, although translated (so subject to garbling), he seems to confirm this was a 'happy accident'. He indicates he set the max number of invaders based on what the hardware could draw but there was no intent to have the speed ramp up. Of course, he noticed that it did this during play testing but decided to keep it that way. Arguably, it's one of the most compelling aspects of the game. Modern emulators have to add code game-specific code to limit the speed or the game plays too fast. Leaving no CPU cycles unused is the sign of an elegant design.reply",
      "The music was breathtaking here - I'd absolutely pay for a version of it. Really solidified the experiencereply",
      "From the author on twitter[1] \"The background music is a cello performance by Iratxe Ibaibarriaga and composed by Aleix Ramon\"[1] https://x.com/nealagarwal/status/1998788695449808920reply",
      "This is something you do when scoring a game too, wonder if the author ever worked on game programming.reply",
      "Anyone find an actual link for the finished track? Credits are mentioned on his site and twitter but I didn't find it anywhere when searching for the artist names.reply",
      "I absolutely loved that looping music track, please authors make it available.reply"
    ],
    "link": "https://neal.fun/size-of-life/",
    "first_paragraph": ""
  },
  {
    "title": "Australia begins enforcing world-first teen social media ban (reuters.com)",
    "points": 555,
    "submitter": "chirau",
    "submit_time": "2025-12-09T18:12:29 1765303949",
    "num_comments": 871,
    "comments_url": "https://news.ycombinator.com/item?id=46208348",
    "comments": [
      "A lot of the criticism is based on the concept that it won't be technically watertight. But the key is that it doesn't have to be watertight to work. Social media is all about network effects. Once most kids are on there, everyone has to be on there. If you knock the percentage down far enough, you break the network effect to the point where those who don't want to don't feel pressured to. If that is all it does, it's a benefit.My concerns about this are that it will lead to(a) normalising people uploading identification documents and hence lead to people becoming victims of scams. This won't be just kids - scammers will be challenging all kinds of people including vulnerable elderly people saying \"this is why we need your id\". People are going to lose their entire life savings because of this law.(b) a small fraction of kids branching off into fringe networks that are off the radar and will take them to very dark places very quickly.Because it's politically unattractive, I don't think enough attention has been given to the harms that will flow from these laws.reply",
      "Well, yes but the other problem is this is putting authoritarians in charge of more stuff. I had a comment comparing this to allowing people to eat too much food and that is literally where the logical outcome of this sort of thinking goes - it happens in practice, that isn't some sort of theoretical risk. The more the government decides what people can and can't want to do the worse the potential gets when they make mistakes. And this is further normalising the government making decisions about speech where they have every incentive and tendency to shut down people who tell inconvenient and important truths.The risks are not worth the rewards of half-heatedly trying to stop kids communicating with other kids. They're still going to bully each other and what have you. They're still going to develop unrealistic expectations. They're probably even still going to use social media in practice.reply",
      "These are government regulations regarding kids. Nothing new here, we\u2019ve been regulating what you can market to kids for decades. I\u2019m not buying a slippery slope argument.As a parent myself, it definitely helps when you can collectively avoid having your kids on these platforms. I can\u2019t express how much easier it is to restrict it and not seem like a kook when authorities are also on board.reply",
      "The government isn't helping you, they just pushed every child in Australia to un-moderated and decentralised social networks. Complete free for alls.reply",
      "This idea that regulation fails to destroy industries is farcical. Most examples of \u201cfailed regulation\u201d like American prohibition were runaway successes as public policy. Whether it is good or desirable is a different question.The idea that someone is going to make an engaging experience on a \u201cdecentralized\u201d network is honestly a bit silly to me. The market potential of this business is low. Decentralized networks with much larger incentives have failed to capture critical mass.There will be side effects, but social media has been so ridiculously corrosive to the welfare of teenagers that I can\u2019t imagine a ban would be worse.",
      "Authoritarians use social networks to undermine democratic principles so not exposing kids to that takes power away from them. Or did I misunderstand something?reply",
      "Authoritarians also use state influenced media to undermine democratic principles.reply",
      "Social media is the worst state propaganda machine ever created. Destroying it would be a huge hit to authoritarians.reply",
      "My take for a while has been that authoritarian ideas (both hard right and hard left) dominate on social media because of the short form short attention span format. Authoritarianism tends to run on simple slogans, grievances, and identity politics. That stuff is very well suited to 140 characters, memes, and short videos.Liberal ideas require more explaining and historical context, and they don\u2019t play well when everyone has been triggered and trolled into limbic system mode by rage bait.Liberal politics speaks to the neocortex. Authoritarianism speaks to the brain stem.reply",
      "Liberals can also be authoritarian. See reddit, where ideas that don't conform are typically downvoted out. Here too.reply"
    ],
    "link": "https://www.reuters.com/legal/litigation/australia-social-media-ban-takes-effect-world-first-2025-12-09/",
    "first_paragraph": ""
  },
  {
    "title": "Getting a Gemini API key is an exercise in frustration (ankursethi.com)",
    "points": 214,
    "submitter": "speckx",
    "submit_time": "2025-12-10T20:29:12 1765398552",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=46223311",
    "comments": [
      "The same billing experience applies to the Google programmable search api.  Easy to get a key, but a Byzantine maze to pay for more than the free version.reply",
      "The odd thing about all of this (well, I guess it's not odd, just ironic), is that when Google AdWords started, one of the notable things about it was that anyone could start serving or buying ads. You just needed a credit-card. I think that bought Google a lot of credibility (along with the ads being text-only) as they entered an already disreputable space: ordinary users and small businesses felt they were getting the same treatment as more faceless, distant big businesses.I have a friend that says Google's decline came when they bought DoubleClick in 2008 and suffered a reverse-takeover: their customers shifted from being Internet users and became other, matchingly-sized corporations.reply",
      "I have had way too many arguments over the years with product and sales people at my job on the importance of instant self-signup. I want to be able to just pay and go, without having to talk to people or wait for things.I know part of it is that sales wants to be able to price discriminate and wants to be able to use their sales skills on a customer, but I am never going to sign up for anything that makes me talk to someone before I can buy.reply",
      "The number one rule of business that should just be passively reiterated to everyone working in any type of transactional field:1. Never make it hard for people to give you money.reply",
      "Parking apps don\u2019t seem to care much for that. They know you\u2019ll jump through their shoddy UIs and data collection because they have a local monopoly. Often with physical payment kiosks removed and replaced with \u201cdownload our shitty app!\u201d notices.reply",
      "It depends on the environment.If a platform is designed in a way that users can sign up and go, it can work well.If an application is complicated or it\u2019s a tool that the whole business runs on, often times the company will discover their customers have more success with training and a point of contact/account manager to help with onboarding.reply",
      "You are also a developer though, and developers are notorious for wanting self serve.Someone who works in finance or conpliances might want a demo, or views those things as signals the product is for serious use cases.reply",
      "Sure, and they should have that option. But in my experience business-folks ask techies to evaluate services all the time, and ideally we can just start out in the low-/no-touch tier to feel things out. If that tier isn't available, us techs might just try a different service.reply",
      "> I know part of it is that sales wants to be able to price discriminate and wants to be able to use their sales skills on a customerYou say that as if it isn\u2019t the entire reason why these interactions should be avoided at all costs. Dynamic pricing should be a crime.reply",
      "> You say that as if it isn\u2019t the entire reason why these interactions should be avoided at all costs. Dynamic pricing should be a crime.Does segmentation also count as dynamic pricing?--    The IT guy at Podunk Lutheran College has no money: Gratis.\n    The IT guy at a medium-sized real estate agency has some money: $500.\n    The IT guy at a Fortune 100 company has tons of money: $50,000.\n\n\n\nhttps://blog.codinghorror.com/oh-you-wanted-awesome-edition/reply"
    ],
    "link": "https://ankursethi.com/blog/gemini-api-key-frustration/",
    "first_paragraph": "Reader, writer, computer gremlin. Afflicted with cats.Last week, I started working on a new side-project. It\u2019s a standard React app partly made up of run-of-the-mill CRUD views\u2014a perfect fit for LLM-assisted programming. I reasoned that if I could get an LLM to quickly write the boring code for me, I\u2019d have more time to focus on the interesting problems I wanted to solve.I\u2019ve pretty much settled on Claude Code as my coding assistant of choice, but I\u2019d been hearing great things about Google\u2019s Gemini 3 Pro. Despite my aversion to Google products, I decided to try it out on my new codebase.I already had Gemini CLI installed, but that only gave me access to Gemini 2.5 with rate limits. I wanted to try out Gemini 3 Pro, and I wanted to avoid being rate limited. I had some spare cash to burn on this experiment, so I went looking for ways to pay for a Gemini Pro plan, if such a thing existed.Thus began my grand adventure in trying to give Google my money.The name \u201cGemini\u201d is so overloaded tha"
  },
  {
    "title": "Auto-grading decade-old Hacker News discussions with hindsight (karpathy.bearblog.dev)",
    "points": 288,
    "submitter": "__rito__",
    "submit_time": "2025-12-10T17:23:53 1765387433",
    "num_comments": 145,
    "comments_url": "https://news.ycombinator.com/item?id=46220540",
    "comments": [
      "I just wonder how accurate the \u201cthen what happened\u201d sections are. I find they present facts and trends in a way that I have no way of checking. Example is the \u201cGuesstimate\u201d announcement:https://karpathy.ai/hncapsule/2015-12-31/index.html#article-...There\u2019s a lot of narrative in there I have a hard time believing is real a not hallucinations. Like can anyone familiar verify this?> The app at getguesstimate.com survived and remained open source (client-side), but it did not become a large commercial SaaS. It found a niche user base, especially in the Effective Altruism / forecasting / decision-analysis communities.reply",
      "One thing this really highlights to me is how often the \"boring\" takes end up being the most accurate. The provocative, high-energy threads are usually the ones that age the worst.If an LLM were acting as a kind of historian revisiting today\u2019s debates with future context, I\u2019d bet it would see the same pattern again and again: the sober, incremental claims quietly hold up, while the hyperconfident ones collapse.Something like \"Lithium-ion battery pack prices fall to $108/kWh\" is classic cost-curve progress. Boring, steady, and historically extremely reliable over long horizons. Probably one of the most likely headlines today to age correctly, even if it gets little attention.On the flip side, stuff like \"New benchmark shows top LLMs struggle in real mental health care\" feels like high-risk framing. Benchmarks rotate constantly, and \u201cstruggle\u201d headlines almost always age badly as models jump whole generations.I bet theres many \"boring but right\" takes we overlook today and I wondr if there's a practical way to surface them before hindsight doesreply",
      "The one about LLMs and mental health is not a prediction but a current news report, the way you phrased it.Also, the boring consistent progress case for AI plays out in the end of humans as viable economic agents requiring a complete reordering of our economic and political systems in the near future.  So the \u201cboring but right\u201d prediction today is completely terrifying.reply",
      "\u201cBoring\u201d predictions usually state that things will continue to work the way they do right now. Which is trivially correct, except in cases where it catastrophically isn\u2019t.So the correctness of boring predictions is unsurprising, but also quite useless, because predicting the future is precisely about predicting those events which don\u2019t follow that pattern.reply",
      "\"Boring but right\" generally means that this prediction is already priced in to our current understanding of the world though. Anyone can reliably predict \"the sun will rise tomorrow\", but I'm not giving them high marks for that.reply",
      "I'm giving them higher marks than the people who say it won't.LLMs have seen huge improvements over the last 3 years. Are you going to make the bet that they will continue to make similarly huge improvements, taking them well past human ability, or do you think they'll plateau?The former is the boring, linear prediction.reply",
      ">The former is the boring, linear prediction.right, because if there is one thing that history shows us again and again is that things that have a period of huge improvements never plateau but instead continue improving to infinity.Improvement to infinity, that is the sober and wise bet!reply",
      "The prediction that a new technology that is being heavily researched plateaus after just 5 years of development is certainly a daring one. I can\u2019t think of an example from history where that happened.reply",
      "LaunchHN: Announcing Twoday, our new YC backed startup coming out of stealth mode.We\u2019re launching a breakthrough platform that leverages frontier scale artificial intelligence to model, predict, and dynamically orchestrate solar luminance cycles, unlocking the world\u2019s first synthetic second sunrise by Q2 2026. By combining physics informed multimodal models with real time atmospheric optimisation, we\u2019re redefining what\u2019s possible in climate scale AI and opening a new era of programmable daylight.reply",
      "LLMs aren't getting better that fast.  I think a linear prediction says they'd need quite a while to maybe get \"well past human ability\", and if you incorporate the increases in training difficulty the timescale stretches wide.reply"
    ],
    "link": "https://karpathy.bearblog.dev/auto-grade-hn/",
    "first_paragraph": "Home Blog\n\n\n    10 Dec, 2025\n\n\nTLDR: https://karpathy.ai/hncapsule/Yesterday I stumbled on this HN thread Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now, where Gemini 3 was hallucinating the frontpage of 10 years from now. One of the comments struck me a bit more though - Bjartr linked to the HN frontpage from exactly 10 years ago, i.e. December 2015. I was reading through the discussions of 10 years ago and mentally grading them for prescience when I realized that an LLM might actually be a lot better at this task. I copy pasted one of the article+comment threads manually into ChatGPT 5.1 Thinking and it gave me a beautiful analysis of what people thought + what actually happened in retrospect, even better and significantly more detailed than what I was doing manually. I realized that this task is actually a really good fit for LLMs and I was looking for excuses to vibe code something with the newly released Opus 4.5, so I got to work. I'm going to get all the "
  },
  {
    "title": "Super Mario 64 for the PS1 (github.com/malucard)",
    "points": 162,
    "submitter": "LaserDiscMan",
    "submit_time": "2025-12-10T18:58:55 1765393135",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=46221925",
    "comments": [
      "If you like this port, you may also enjoy this ground-up effort to clone SM64 on the GBA https://youtu.be/nS5rj80L-pkreply",
      "Given that this is HN, I'm contractually obligated to mention that the GBA port is written in Rust: https://www.digitec.ch/en/page/the-impossible-port-super-mar...reply",
      "Interesting, I'm wondering if the GBA could handle a light version of a Minecraft style game, but the N64 looks like it could be great at it too. I need to get me a SummerCart64 one of these days and experiment with my old N64.reply",
      "Probably. There's Tomb Raider for the GBA via OpenLara: https://www.youtube.com/watch?v=_GVSLcqGP7greply",
      "this guy builds a very similar engine https://www.youtube.com/@3DSage/videosreply",
      "While this is cool, it is really hard to look at for me.Still bravo! I know getting it working and complete is the real goal and it is commendable.reply",
      "> it is really hard to look at for me.What were you expecting?reply",
      "Nothing. I have zero expectations. Giving an honest take on what I saw is all.reply",
      "Affine texture mapping is kinda jarring to look at, especially in this GBA port since there is no fixup with huge ground polygons drifting around.One of the listed features in the PS1 port in the OP article is tesselation to reduce the issues of the PS1 HW affine texture mapper, on the GBA you have some base cost of doing manual software texture mapping but also oppurtunities to do some minor perspective correction to lessen the worst effects (such as doing perspective correction during the clipping process).reply",
      "The GBA version does actually leverage dynamic polygon splitting in direct reference to how PS1 games used this approach https://www.youtube.com/watch?v=1Oo2CZWbHXw&t=271sI think the resolution makes it particularly rough though.reply"
    ],
    "link": "https://github.com/malucard/sm64-psx",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A very WIP port of https://www.github.com/n64decomp/sm64 for the PlayStation 1\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.This repo does not include all assets necessary for compiling the game.\nAn original copy of the game is required to extract the assets.Pull requests are welcome. For major changes, please open an issue first to\ndiscuss what you would like to change.\n        A very WIP port of https://www.github.com/n64decomp/sm64 for the PlayStation 1\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Rubio stages font coup: Times New Roman ousts Calibri (reuters.com)",
    "points": 147,
    "submitter": "italophil",
    "submit_time": "2025-12-10T00:08:34 1765325314",
    "num_comments": 259,
    "comments_url": "https://news.ycombinator.com/item?id=46212438",
    "comments": [
      "When I read the headline i thought \u201cwell obviously they don\u2019t mean Marco Rubio, there must be some famous publicist or something\u201d. Cannot believe it actually was Marco Rubio, lolreply",
      "[flagged]",
      "Forgive my ignorance but this seems to be one of the most neutral things Hitler did. He just didn't like the font so he ordered it to be changed. Equivalent to your boss ordering tabs be used instead of spaces. After the war was lost the arguments just continued. https://en.wikipedia.org/wiki/Antiqua%E2%80%93Fraktur_disput...reply",
      "I tend to agree with you, many people are passionate about typefaces, and dictators are no exception. [Passion about typeface] seems to be a low-signal detector for dictators. I'm passionate about lasagna, and I'll bet Mussolini was too -- but that probably doesn't mean I'm a fascist.reply",
      "It didn't happen in isolation though. There were a few changes that used aesthetics as a culture influence and what being properly German should mean. Another one which was more explicit was music https://en.wikipedia.org/wiki/Music_in_Nazi_Germany It was literally anti the idea of diversity and inclusion. Much like this change.And just like with the font, that shaped preferences for years.reply",
      "That's still using their other culture choices to manufacture a problem with producing consistency in typeface. It's a stretch. Any good (don't take this out of context, please) leader will settle these kinds of trivial internal disputes and move onto important problems.reply",
      "Yeah it was so the occupied peoples could read the edicts better. Sp perhaps not so neutral, after all.reply",
      "\u201cI want a new font so it\u2019s easier to read\u201d isn\u2019t neutral?reply",
      "Not when you are the aggressor in WW2?I guess if Russia invaded Western Europe and Putin decided to switch from Cyrillic to Latin script so the subjugated peoples would more easily read and learn Russian, that would be neutral too?reply",
      "That isn\u2019t a genuine argument.Font face != different language + different alphabet.Font, still a bad argument but technically correct. Font face, nah.reply"
    ],
    "link": "https://www.reuters.com/world/us/rubio-stages-font-coup-times-new-roman-ousts-calibri-2025-12-09/",
    "first_paragraph": ""
  },
  {
    "title": "When would you ever want bubblesort? (2023) (buttondown.com/hillelwayne)",
    "points": 52,
    "submitter": "atan2",
    "submit_time": "2025-12-10T21:45:11 1765403111",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=46224311",
    "comments": [
      "The article, and many of the responses, are hinting at the fact that bubblesort is an example of an anytime algorithm. This is a wide class of algorithms which provide a correct answer after some amount of time, but provide an increasingly good answer in increasing amounts of time short of the completion time. This is a super valuable property for real time systems (and many of the comments about games and animations discuss that). The paper that introduced me to the category is \"Anytime Dynamic A*\" [0], and I think it's both a good paper and a good algorithm to know.[0] https://cdn.aaai.org/ICAPS/2005/ICAPS05-027.pdfreply",
      "I used bubblesort on purpose in a game project. Specifically, to sort sprites in an NES game back to front, lazily, spending as few CPU cycles as possible. Bubblesort on the very small list (a dozen objects max), and early exit after the first swap. It eventually completes, and that was just fine. It's tiny, incredibly simple, and somewhat resilient to the list changing from frame to frame as objects spawn and despawn. Each partial sort makes some progress no matter what.A few other algorithms would have fit the bill just as well, but bubblesort is perfectly adequate, so that's what will likely ship. More complex algorithms end up losing out due to greater initial overhead or larger ROM size.reply",
      "Why use it over insertion sort which is faster and easier to implement?reply",
      "A time traveler.reply",
      "Traveling through time at a rate of 1sec per second.reply",
      "I've used bubblesort when simulating LEO satellite constellations, calculating which satellite is closest to a location.  I used one single backwards pass of bubblesort, so O(n) every k timesteps to bring the closest to the head of the array, then every timestep just do one backwards bubblesort pass over the first few in the array.  Given satellites move smoothly, if you initialize right (a few full passes at the start to get the closest few at the front) and get the constants right so a satellite outside the front few in the array can't have moved far enough to become closest without being promoted to the front few by a periodic full pass, then you always maintain the closest at the front of the array very cheaply.  And this has the advantage of also being very simple to code.reply",
      "Yeah, the article beat me to the gamedev example. Bubble sort being able to always \"soft sort\" on every iteration makes it the easiest to suspend and resume when you have a lot of other work to do, and when sorting is low priority.Also, general wisdom to be  mindful of data sizes and cache coherency. O(NLogN) vs. O(N^2) doesn't mean much when you're only sorting a few dozen items. Meanwhile, O(N) space can have drastic performance hitches when reallocating memory.reply",
      "The appeal of bubble sort for me is that is it the only one I understand well enough to implement myself without having to think much about it.reply",
      "Insertion sort and radix sort are also quite easy to understand, perhaps even more so.reply",
      "I felt this comment in my soul. I\u2019ll never understand it: I\u2019ve written thousands of lines of code (as a hobbyist) to solve all sorts of problems I\u2019ve run into and yet always seem to struggle to wrap my mind around the core algorithms any real developer should be able to handle easily. This is why I\u2019ve never pursued programming as a career.reply"
    ],
    "link": "https://buttondown.com/hillelwayne/archive/when-would-you-ever-want-bubblesort/",
    "first_paragraph": "There are very few universal rules in software engineering, but there are are a lot of near-universal principles. Things like \"prefer composition to inheritance\" is near-universal. I love finding the rare situations where these principles don't hold, like where you do want inheritance over composition. A similar near-universal principle is \"don't use bubblesort\". Some would even say it's a universal rule, with Donald Knuth writing \"bubble sort seems to have nothing to recommend it, except a catchy name and the fact that it leads to some interesting theoretical problems\".1 But Knuth's been wrong before, so let's see if this universal rule is only near-universal.Theoretically, bubblesort is faster than quick or mergesort for small arrays. This makes it useful as part of a larger sorting strategy: most of the fast-in-principle sorting algorithms work by recursively sorting subpartitions of an array, ie if you apply quicksort to 2^20 random integers, at some point you're sorting 2^17 8-int"
  },
  {
    "title": "Qwen3-Omni-Flash-2025-12-01\uff1aa next-generation native multimodal large model (qwen.ai)",
    "points": 196,
    "submitter": "pretext",
    "submit_time": "2025-12-10T16:13:38 1765383218",
    "num_comments": 80,
    "comments_url": "https://news.ycombinator.com/item?id=46219538",
    "comments": [
      "This is a 30B parameter MoE with 3B active parameters and is the successor to their previous 7B omni model. [1]You can expect this model to have similar performance to the non-omni version. [2]There aren't many open-weights omni models so I consider this a big deal. I would use this model to replace the keyboard and monitor in an application while doing the heavy lifting with other tech behind the scenes. There is also a reasoning version, which might be a bit amusing in an interactive voice chat if it pronounces the thinking tokens while working through to a final answer.1. https://huggingface.co/Qwen/Qwen2.5-Omni-7B2. https://artificialanalysis.ai/models/qwen3-30b-a3b-instructreply",
      "This is a stack of models:- 650M Audio Encoder- 540M Vision Encoder- 30B-A3B LLM- 3B-A0.3B Audio LLM- 80M Transformer/200M ConvNet audio token to waveformThis is a closed source weight update to their Qwen3-Omni model. They had a previous open weight release Qwen/Qwen3-Omni-30B-A3B-Instruct and a closed version Qwen3-Omni-Flash.You basically can't use this model right now since none of the open source inference framework have the model fully implemented. It works on transformers but it's extremely slow.reply",
      "Looks like it's not open source:\nhttps://www.alibabacloud.com/help/en/model-studio/qwen-omni#...reply",
      "No... that website is not helpful. If you take it at face value, it is claiming that the previous Qwen3-Omni-Flash wasn't open either, but that seems wrong? It is very common for these blog posts to get published before the model weights are uploaded.reply",
      "The previous -Flash weight is closed source. They do have weights for the original model that is slightly behind in performance https://huggingface.co/Qwen/Qwen3-Omni-30B-A3B-Instructreply",
      "Based on things I had read over the past several months, Qwen3-Flash seemed to just be a weird marketing term for the Qwen3-Omni-30B-A3B series, not a different model. If they are not the same, then that is interesting/confusing.reply",
      "It is an in-house closed weight model for their own chat platform, mentioned in Section 5 of the original paper: https://arxiv.org/pdf/2509.17765I've seen it in their online materials too but can't seem to find it now.reply",
      "I can't find the weights for this new version anywhere. I checked modelscope and huggingface. It looks like they may have extended the context window to 200K+ tokens but I can't find the actual weights.reply",
      "They link to: https://huggingface.co/collections/Qwen/qwen3-omni-68d100a86... from the blog post but it does seem like this redirects to their main space on HF so maybe they didn't yet make the model public?reply",
      "I dont think the Flash model discussed in the article is 30BTheir benchmark table shows it beating Qwen3-235B-A22BDoes \"Flash\" in the name of a Qwen model indicate a model-as-a-service and not open weights?reply"
    ],
    "link": "https://qwen.ai/blog?id=qwen3-omni-flash-20251201",
    "first_paragraph": ""
  },
  {
    "title": "Common Lisp, ASDF, and Quicklisp: packaging explained (cdegroot.com)",
    "points": 35,
    "submitter": "todsacerdoti",
    "submit_time": "2025-12-10T11:10:58 1765365058",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=46216446",
    "comments": [
      "Quicklisp is great, it's the defacto standard, but compared to OCICL it kinda feels ancient. There's also CLPM, but last time I checked it was broken by a combination of dead links and missing functions.reply",
      "Last time I checked quicklisp also didn\u2019t support https and doesn\u2019t do any signature checking.reply",
      "What's missing from any of this, which has really confused me in the past, is any notion of dependency versioning.  We get predefined dependencies as a distribution in quicklisp - which is great as far as it goes - but how do people manage without being able to say \"this system depends on a version of that system greater than X\"?reply",
      "TL;DR: If I find a library I'm using would need dependency versioning, I consider that library broken and find (or write) an alternative.You can always just add a version check and error out if it's too outdated.  The thing there isn't an easy way to do is say \"this needs a version of that system lower than X\" but it would be unusual for a system to intentionally break backwards compatibility (or for an unintentional break to not be fixed relatively quickly after being discovered); usually if there is the semver equivalent of a \"major version\" change in lisp, the system-name itself gets changed.reply",
      "I started learning Common Lisp, but ASDF and Quicklisp threw me off. I couldn't tell if you were supposed to choose one or the other or they were used together. This might revive my interest in Common Lisp if I get around to reading it. But in the meantime I drifted off to Racket, which is relatively well documented and has extensive libraries and really unique features.reply",
      "For anybody who's still confused, the tl;dr is ASDF is the actual package loading mechanism, Quicklisp doubles as an ASDF wrapper and a package manager.reply",
      "I messed around with common lisp for a while a few months ago, and I remember the packaging/dependency situation was by far the most difficult and confusing part. So thanks for writing this article, bookmarked it for the next time I write some CL :)reply"
    ],
    "link": "https://cdegroot.com/programming/commonlisp/2025/11/26/cl-ql-asdf.html",
    "first_paragraph": "Nov 26, 2025If there is one thing that confuses newcomers to Common Lisp, it is the interplay of built-in\nCL functionality, add-ons like Quicklisp and ASDF, and what all the words mean.Common Lisp is old, and its inspiration is even older. It was developed when there was\nzero consensus on how file systems worked, operating systems were more incompatible than you\ncan probably imagine, and that age shows. It pinned down terminology way before\nother languages got to the same point, and, as it happens so often, the late arrivals\ndecided that they needed different words and these words stuck.So let\u2019s do a bit of a deep dive and see how all the bits and pieces work and\nwhy they are there. All examples are using SBCL and might be SBCL-specific. Check your\nLisp\u2019s manual if you use something else. Also, I\u2019m (still) linking to the old LispWorks-provided\nHyperSpec as I\u2019m not sure that the newer versions are fully done yet.Common Lisp comes with just the bare essentials to work with files. It has "
  },
  {
    "title": "Show HN: Automated license plate reader coverage in the USA (alpranalysis.com)",
    "points": 109,
    "submitter": "sodality2",
    "submit_time": "2025-12-10T17:42:30 1765388550",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=46220794",
    "comments": [
      "I've thought about this a lot as I see more and more reckless driving in the areas I live in. Surveillance is generally a net negative, but it's also bad when you see people speeding around schools, rolling through stop signs, and running red lights. We seem to have a worst of all situations where traffic is getting increasingly difficult to enforce, driving is getting more dangerous year by year, and we're terrified of government overreach if we add any automation at all to enforcement.I don't know the solution, but I do know that in the US we've lost 10-15 years of progress when it comes to traffic fatalities.reply",
      "> Surveillance is generally a net negative, but it's also bad when you see people speeding around schools, rolling through stop signs, and running red lights.The fact that these cameras are already pervasive and the problem of bad drivers hasn't been solved anywhere doesn't give me a lot of hope that these cameras are the solution to that particular problem.It seems like police can do a lot to increase enforcement without the need of these devices. We have evidence that they've been doing less traffic enforcement so maybe start there. Increasing our standards for driving tests (some of which were eliminated entirely over the first few years of the pandemic) would probably help. Automatically shutting off/disabling or limiting the use of cell phones (all of which come with sensors that can detect when you are going at speeds you'd expect while in cars) might help. Bringing physical buttons and dials back to cars instead of burying common functions in touchscreen menus might help.There's a whole lot of places to look for solutions to safer roads before we have to resort to tracking everyone's movements at all times.reply",
      "> Automatically shutting off/disabling or limiting the use of cell phones (all of which come with sensors that can detect when you are going at speeds you'd expect while in cars) might help.I can\u2019t think of a way to implement this that wouldn\u2019t ban passengers from using their phone while riding in a vehicle. Which could be even a bus or limousine.reply",
      "I don't disagree, but I can totally imagine a society where this inability is perfectly acceptable because it severely reduces the #1 killer of people from 5-55yo. I don't think we live in that society, if Apple and Google flipped a switch tomorrow to do that people would freak out, but I could imagine a rational, fictional society that had different shared values.reply",
      "Not entirely. \nThe phones can defect if there are other phones nearby, so a single phone in a car on a highway going 75mph could be assumed to be a driver, but that is still just an assumption.reply",
      "A lot of people would be fine with that. Drivers are impaired while on the phone, even hands-free. Not to mention texting while driving!I kind of picture the cellular telcos doing this. Maybe buses and trains come with wifi hotspots allowed to connect. Otherwise auto passengers could use their devices offline, maybe read an ebook or something. Not the end of the world.reply",
      "Lots of cars now come with a WiFi hot spot as part of their offerings. There's no way to prevent the driver from also connecting to it and circumventing whatever ill conceived notion this isreply",
      "Even connected to wifi a cell phone canstill use the wireless network. Even airplane more won't actually stop your phone from connecting anymore. GPS data can also be transmitted in the background over wifi back to apple/google and/or the device manufacturer.If they really wanted to push this they could do it directly in the baseband chipset and bypass the OS entirely when deciding to lock down the device to some kind of \"travel mode\" with limited functionality (such as no texting or no browser)Not that I'm advocating for that sort of thing, but it's good to keep in mind that we don't really own the cellular devices we pay for and that even in the rare case we have root we can't stop them from doing what they want to our devices as long as they control the closed hardware.reply",
      "We have very few alternatives to driving in the US so we have very lax driver training and testing.Across the US we have roads and infrastructure that encourage speed right next to decaying pedestrian infrastructure. It's very difficult to get state DOTs to roll back or do traffic calming. They often prohibit the use of bollards or barriers near these roadways.In a lot, not all, physical changes to the environment could drastically reduce traffic fatalities without surveillance.reply",
      "We cracked down on driving under the influence with changes from DWI to DUI. In the 10-15 years you mention, the prevalence of distracted driving from mobile devices has gotten out of hand. There's no field sobriety test that can prove one was distracted by a device. That makes this much more difficult to crack down on.reply"
    ],
    "link": "https://alpranalysis.com",
    "first_paragraph": ""
  },
  {
    "title": "Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise (arxiv.org)",
    "points": 93,
    "submitter": "kelseyfrog",
    "submit_time": "2025-12-10T18:37:27 1765391847",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=46221594",
    "comments": [
      "I worked on something very similar for my master's degree.The problem I could never solve was the speed, and from reading the paper it doesn't seem like they managed to solve that either.In the end, for my work, and I expect for this work, it is only usable for pre generated terrains and in that case you are up against very mature ecosystems with a lot of tooling to manipulate and control terrain generation.It'll be interesting to see of the authors follow up this paper with research into even stronger ability to condition and control terrain outputs.reply",
      "I came here to say this. My masters was on procedural generation. Perlin, fBm, etc. The things these noise functions have that an LLM doesn\u2019t is speed. 1-D perlin is just a dozen or so multiplications with a couple random coefficients. The GPU can do 4-D Perlin all day long every frame taking up a 4096x4096x32 texture volume.While I do like the erosion effects and all, having a few height texture brushes that have those features that you can multiply on the GPU is trivial. I still welcome these new approaches but like you said, it\u2019s best for pre generation.reply",
      "My masters was also on procedural generation. Now I wonder how many of us are out there.At any rate, given that this paper divides the terrain in regions and apparently seeds each region deterministically, it looks like one could implement a look-ahead that spawns the generation on async compute in Vulkan and lets it cook as the camera flies about.reply",
      "Hi everyone, I wrote this paper. Cool to see it has been posted here already.I want to clarify some points on things other people have mentioned:- This architecture is not as fast as Perlin noise. IMO it is unlikely we will see any significant improvement on Perlin noise without a significant increase in compute, at least for most applications. Nonetheless, this system is not too slow for real-time use. In the Minecraft integration, for instance, the bottleneck in generation speed is by far Minecraft's own generation logic (on one RTX 3090 Ti).- I agree that this is not \"production-ready\" for most tasks. The main issue is that (1) terrain is generated at realistic scales, which are too big for most applications, and (2) the only control the user has is the initial elevation map, which is very coarse. Thankfully, I expect both of these issues to be fixed pretty quickly. (1) is more specific to terrain generation, but I have a number of ideas on how to fix it. (2) is mostly an issue simply because I did not have the time to engineer a system with this many features (and as-is, the system is quite dense). I believe a lot of existing work on diffusion conditioning could be adapted here.- The post title misses one key part of the paper title: \"in Infinite, Real-Time Terrain Generation.\" I don't expect this to replace perlin noise in other applications. And for bounded generation, manual workflows are still superior.- The top level input is perlin noise because it is genuinely the best tool for generating terrain at continental scale. If I had more time on my hands, I would like to use some sort of plate tectonics simulator to generate that layout, but for something simple, reasonably realistic, and infinite, perlin noise is pretty much unbeatable. Even learned methods perform on-par with perlin noise at this scale because the data is so simple.reply",
      "> in Infinite, Real-Time Terrain GenerationMy sincerest apologies. The submission disallowed the title in its entirety. It's generally unclear if the guidance for submitters favors omission or rewording. I take full responsibility for omitting those qualifiers.reply",
      "No worries! It's worded fine as-is given the restrictions. Just wanted to clear up any misunderstandings.reply",
      "The irony of this paper is that the part that isn't geographic (towns, roads, fields, etc) which have non-random ordered structure are the parts that are most suitable for this approach.reply",
      "Could be! I think maps are definitely the most interesting direction for future research to take.reply",
      "Convincing AND useful procedural terrain is usually hard-simulated along some manually placed guides, which is typically faster and more versatile than a diffusion model. I don't see any model being used in practice for this, at least not until it has good controlnets trained specifically for this task. However something like this can be useful for texture generation, especially with geometry/camera position/lighting as additional inputs.reply",
      "This is really awesome, actually! It looks great, very diverse, and clearly is scalable to extremely large maps. Props for testing the generation out on Minecraft - where terrain generation really matters.reply"
    ],
    "link": "https://arxiv.org/abs/2512.08309",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n"
  },
  {
    "title": "How Google Maps allocates survival across London's restaurants (laurenleek.substack.com)",
    "points": 118,
    "submitter": "justincormack",
    "submit_time": "2025-12-09T10:20:02 1765275602",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=46203343",
    "comments": [
      "It's always annoyed me that zooming in on a building will not reliably show the business that operates there. I understand that at low zoom levels you may need to filter what is displayed based on the high density, but when I zoom in I want to see everything that is there. Sometimes I am forced to go to street view to read the sign, then type the company name into the search box to force the business marker to show up and get clickable.I've found Apple Maps is a little better in this regard. They show a higher density of business markers at any given zoom level.reply",
      "Click on the building, it populates \u201cbusinesses at this address\u201d - at least, when I\u2019ve tried.reply",
      "Google's Maps search ranking doesn't seem sophisticated to me. In fact it seems unbelievably naive. Ranking is Google's core business and yet they seem to forget how to do it when a map is involved.When I want to find something that's actually good, I use this site: https://top-rated.online. At first glance it looks like an unremarkable SEO spam site, but it's actually a great way to get properly ranked Google Maps reviews. It uses proper Bayesian ranking, so it won't show you a 5 star place with two reviews over a 4.9 star place with 2,000 reviews, as Google often will. And it has good sorting and filtering options so you can, for example, filter or sort by number of reviews.reply",
      "I've said for decades that Google is terrible at search in every area except Google Search. Youtube search? Terrible! Chrome history search? Abysmal! Gmail search? Atrocious! Google Maps Search? At some point, standing in a middle of a mall searching for \"coffee\" returned only 3 SERPs despite me standing in front of a coffeeshop that I could not get to show up.reply",
      "SERP = Search Engine Results Page. I\u2019m pretty sure what you mean is simply \u201c3 results\u201d, and not \u201c3 search engine result pages\u201dreply",
      "I find YouTube search to be serviceable. At least it has decent filtering and sorting options. Gmail search is just OK, but I haven't found anything much better. Chrome history search, though, is completely worthless. Especially since it got merged into that myactivity thing that is utter garbage, completely non-functional for any purpose. There's so much potential in searching a complete history of everything you've ever personally seen online, and it would make Chrome more sticky. Incredible fumble by Google here.reply",
      "Youtube search does a baffling thing where it shows you 5 SERPs, then a bunch of unrelated things it thinks you like, then another 5 SERPs. It used to only show you the top 5 SERPs before switching to \"suggested videos\" for the rest of the scroll. Truly a terrible product when that was the design.reply",
      "I never understood why the \"collaborative filtering\" approach never took off with most review options. Google Maps shows you what the average person thinks is a good restaurant, meaning the rich get richer faster and tiny statistical noise converts to durable competitive advantage.Instead, I'd love for Google to understand me well enough to show me which restaurants I would disproportionately love compared to other people based on its understanding of my taste profiles. That way, the love can be shared amongst a much wider base of restaurants and each distinctive restaurant could find its 10,000 true fans.On top of that, it actually gives me an incentive to rate things. Right now, you only rate from some vague sense of public service instead of \"this can actively improve your experience with our product\".It's not just Google Maps, Netflix used to operate on the model of deep personalization that they've slowly de-emphasized over the years. I'm still waiting for Letterboxd to introduce a feature to give me personalized film recs based on the over 1000 ratings I've given it over the years as a paying customer but they seem in no hurry to do so. Amazon used to take your purchase history into account when ordering search results but I think that's also been significantly de-emphasized.About the only arena this is widespread is streaming music services like Spotify.reply",
      "related to your letterboxd suggestion, https://couchmoney.tv is quite good! it uses trakt instead of letterboxd but it's given me quite a few good suggestions. their FAQ describes a similar approach to what you've been talking about, it tries to find movies and tv you like disproportionately like.reply",
      "> This disproportionately rewards chains and already-central venues. Chains benefit from cross-location brand recognition. High-footfall areas generate reviews faster....I think this is very likely false if you mean compared to the status quo ante. Before Maps, a well-loved but hard-to-find venue just wouldn't ever be seen by most people, and the absence of reviews made branding more important because it was all you had to go on. I'd be very doubtful if the proportion of independent cafes and restaurants decreases when Google Maps enters an area. (Couldn't find any causal research designs though....)The more general point that the algorithm is not neutral (and probably never could be) must be right.(I asked ChatGPT but it ended up with: \"We have almost no clean exogenous variation in Maps rankings or feature rollouts at fine geographic scales that would let you estimate impacts on entry, survival, or market structure in a neat DiD/IV way.\")reply"
    ],
    "link": "https://laurenleek.substack.com/p/how-google-maps-quietly-allocates",
    "first_paragraph": ""
  },
  {
    "title": "Scientists create ultra fast memory using light (isi.edu)",
    "points": 64,
    "submitter": "giuliomagnifico",
    "submit_time": "2025-12-04T18:11:21 1764871881",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=46150797",
    "comments": [
      "People have done these sort of \"optical computing\" based demonstrations for decades, despite David Miller showing that fundamentally digital computing with optical photons will be immensely power hungry (I say digital here, because there are some applications where analog computing can make sense, but it almost never relies memory for bits).Specifically this paper is based on simulations, and I've only skimmed the paper, but the power efficiency numbers sound great because they say 40 GHz read/write speeds, but these consume comparatively large powers even if not reading or writing (the lasers have to be running constantly). I also think they did not include the contributions of the modulation and the required drivers (typically you need quite large voltages)? Somebody already pointed out that the size of these is massive, and that's again fundamental.As someone working in the broad field, I really wish people would stop these type of publications. While these numbers might sound impressive at a first glance, they really are completely unrealistic. There are lots of legitimate applications of optics and photonics, we don't need to resort to this sort of stuff.reply",
      "> showing that fundamentally digital computing with optical photons will be immensely power hungry> they really are completely unrealisticUnrealistic only because they're power hungry? That sounds like a temporary problem, kind of like when we come up with a bunch of ML approaches we couldn't actually do in the 80s/90s because of the hardware resources required, but today work fine.Maybe even if the solution aren't useful today, they could be useful in the future? Or maybe with these results, there are more people being inspired to create solutions specifically about the power usage?\"we don't need to resort to this sort of stuff\" makes it sound like this is all so beneath you and not deserving of attention, but why are you then paying attention to it?reply",
      "Free version of the research paper:https://arxiv.org/abs/2503.19544v1The memory cell is huge in comparison with semiconductor memories, but it is very fast, with a 40 GHz read/write speed.There are important applications for a very high speed small memory, e.g. for digital signal processing in radars and other such devices, but this will never replace a general-purpose computer memory, where much higher bit densities are needed.reply",
      "MRAM and MRAM-CIM is like 10 years ahead of this and going to make a huge impact on efficiency and performance in the next few years, right? Or so I thought I heard.Memristors are also probably coming after MRAM-CIM and before photonic computing.reply",
      "Cool. Memory bandwidth is a major bottleneck for many important applications today, including AI. Maybe this kind of memory \"at the speed of light\" can help alleviate the bottleneck?For a second, I thought the headline was copied & pasted from the hallucinated 10-years-from-now HN frontpage that recently made the HN front page:https://news.ycombinator.com/item?id=46205632reply",
      "This just in, OpenAI has already committed to buying the entire world\u2019s supply once it becomes available.reply",
      "Wow 300mm chips. They must be huge!(I am sure they meant nm, but nobody is checking the AI output)reply",
      "It almost certainly refers to 300 mm wafers, which are the largest size used right now. They offer significantly better economics than the older 200 mm wafers or lab experiments done in even smaller (i.e. 100 mm) wafers.The text in the article supports this:> This is a commercial 300mm monolithic silicon photonics platform, meaning the technology is ready to scale today, rather than being limited to laboratory experiments.reply",
      "From the paper> footprint of 330 \u00d7 290 \u00b5m2 using the GlobalFoundries 45SPCLOThat\u2019s a 45nm process but the units for the chip size probably should have been 330um? However I\u2019m not well versed enough in the details to parse it out.https://arxiv.org/abs/2503.19544reply",
      "I'm very familiar with this process as I use it regularly.The area is massive.  330um \u00d7 290um are the X and Y dimensions. The area is roughly 0.1 mm2. You can see the comparison on table 1. This is roughly 50000 times larger than an SRAM of 45nm process.This is the problem with photonic circuits. They are massive compared to electronics.reply"
    ],
    "link": "https://www.isi.edu/news/81186/scientists-create-ultra-fast-memory-using-light/",
    "first_paragraph": ""
  },
  {
    "title": "Is it a bubble? (oaktreecapital.com)",
    "points": 140,
    "submitter": "saigrandhi",
    "submit_time": "2025-12-10T17:30:43 1765387843",
    "num_comments": 193,
    "comments_url": "https://news.ycombinator.com/item?id=46220640",
    "comments": [
      "> In many advanced software teams, developers no longer write the code; they type in what they want, and AI systems generate the code for them.What a wild and speculative claim. Is there any source for this information?reply",
      "At $WORK, we have a bot that integrates with Slack that sets up minor PRs. Adjusting tf, updating endpoints, adding simple handlers. It does pretty well.Also in a case of just prose to code, Claude wrote up a concurrent data migration utility in Go. When I reviewed it, it wasn't managing goroutines or waitgroups well, and the whole thing was a buggy mess and could not be gracefully killed. I would have written it faster by hand, no doubt. I think I know more now and the calculus may be shifting on my AI usage. However, the following day, my colleague needed a nearly identical temporary tool. A 45 minute session with Claude of \"copy this thing but do this other stuff\" easily saved them 6-8 hours of work. And again, that was just talking with Claude.I am doing a hybrid approach really. I write much of my scaffolding, I write example code, I modify quick things the ai made to be more like I want, I set up guard rails and some tests then have the ai go to town. Results are mixed but trending up still.FWIW, our CEO has declared us to be AI-first, so we are to leverage AI in everything we do which I think is misguided. But you can bet they will be reviewing AI usage metrics and lower wont be better at $WORK.reply",
      "You should periodically ask Claude to review random parts of code to pump your metrics.reply",
      "> it wasn't managing goroutines or waitgroups well, and the whole thing was a buggy mess and could not be gracefully killedFirst pass on a greenfield project is often like that, for humans too I suppose. Once the MVP is up, refactor with Opus ultrathink to look for areas of weakness and improvement usually tightens things up.Then as you pointed out, once you have solid scaffolding, examples, etc, things keep improving. I feel like Claude has a pretty strong bias for following existing patterns in the project.reply",
      "I think your experience matches well with mine.  There are certain workloads and use cases where these tools really do well and legitimately save time; these tend to be more concise tasks and well defined with good context from which to draw from.  The wrong tasking and the results can be pretty bad and a time sink.I think the difficulty is exercising the judgement to know where that productive boundary sits.  That's more difficult than it sounds because we're not use to adjudicating machine reasoning which can appear human-like\n...  So we tend to treat it like a human which is, of course, an error.reply",
      "The line right after this is much worse:> Coding performed by AI is at a world-class level, something that wasn\u2019t so just a year ago.Wow, finance people certainly don't understand programming.reply",
      "World class? Then what am I? I frequently work with Copilot and Claude Sonnet, and it can be useful, but trusting it to write code for anything moderately complicated is a bad idea. I am impressed by its ability to generate and analyse code, but its code almost never works the first time, unless it's trivial boilerplate stuff, and its analysis is wrong half the time.It's very useful if you have the knowledge and experience to tell when it's wrong. That is the absolutely vital skill to work with these systems. In the right circumstances, they can work miracles in a very short time. But if they're wrong, they can easily waste hours or more following the wrong track.It's fast, it's very well-read, and it's sometimes correct. That's my analysis of it.reply",
      ">  I frequently work with Copilot and Claude Sonnet, and it can be useful, but trusting it to write code for anything moderately complicated is a bad ideaThis sentence and the rest of the post reads like an horoscope advice. Like \"It can be good if you use it well, it may be bad if you don't\". It's pretty much the same as saying a coin may land on head or on tail.reply",
      "Is this why AI is telling us our every idea is brilliant and great? Because their code doesn't stand up to what we can do?reply",
      "Whichever PM sold glazing as a core feature should be ejected into space.reply"
    ],
    "link": "https://www.oaktreecapital.com/insights/memo/is-it-a-bubble",
    "first_paragraph": ""
  },
  {
    "title": "OpenRouter Broadcast (openrouter.ai)",
    "points": 8,
    "submitter": "Topfi",
    "submit_time": "2025-12-06T11:28:56 1765020536",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://openrouter.ai/docs/guides/features/broadcast/overview",
    "first_paragraph": ""
  },
  {
    "title": "Gundam is just the same as Jane Austen but happens to include giant mech suits (eli.li)",
    "points": 147,
    "submitter": "surprisetalk",
    "submit_time": "2025-12-02T16:55:36 1764694536",
    "num_comments": 106,
    "comments_url": "https://news.ycombinator.com/item?id=46123310",
    "comments": [
      "\"It is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a robot suit to ride around and fight things with.\"I was visiting Jane Austen's House Museum last year and it always gives me pleasure to see how wildly popular her work remains. There always seem to be tourists there visiting from all over the world. That is really heartening.She was very innovative. Maybe even underrated as a craftsperson at the sentence level. My favourite trick that I believe she invented is slipping from prose into a soft Iambic pentameter, essentially unnoticed. Lots of people have copied that from her.And class-pressure narratives will never not be relevant to people's lives. She's a very very humane storyteller in that respect.I am slightly biased - she's my great aunt (x 6). Used to find that embarrassing but now I feel quite proud.reply",
      "I'm not well read, and don't think I'd be able to finish any of the classics. As such I have no clue what \"slipping from prose into a soft Iambic pentameter\" means. I came here for the robots.reply",
      "You know how in Disney movies they shift smoothly from talking to singing? It\u2019s just like that, only instead of the bass beat to the character\u2019s song starting to play, her \u2018prose\u2019 (think \u2018non-poetry words\u2019, aka what most people consider books to be full of) shifts smoothly into Shakespeare-like syllable emphasis patterns. Listen for the percussion notes starting about ten seconds into https://youtu.be/79DijItQXMM and imagine that instead of him bursting into musical song, he burst into chanting a limerick:There once was a demi-god, Maui / Amazing and awesome: I\u2019m Maui // Who stole you your fire / and made your days lighter // Yes, thank you, you\u2019re welcome! Love: MauiIt\u2019s a bit odd of an analogy, but limericks and \u201cIambic pentameter\u201d are specific instances of an underlying language architectural thing, so it should be just enough to convey the basics of that \u201cprose to Iambic\u201d sentence. And: if you\u2019ve ever watched \u201cMuch Ado About Nothing\u201d from the mid-90s, that\u2019s 100% Iambic.(If you\u2019re an English major, yes, I know, this is all wrong; it\u2019s just a one-off popsicle-sticks context-unique mindset-conveyance analogy-bridge, not step-by-step directions to lit/ling coordinates in your field.)reply",
      "This is a great example, and not odd as an analogy at all. It surfaces something subtle.Language architecture is really interesting, I think, for programmers who have bought into the LLM hype in any meaningful way. It's an important field to have a sense of.Tokenizers, for example, generally have multi-syllabic tokens as their base-level, indivisible unit.You rarely see this mentioned when LLM capability against non-coding tasks is discussed, despite it being deeply important for prose construction.Not to mention, putting language models aside, that the vast majority of code is written in language with a logical grammar. The disciplines are highly linked.reply",
      "Not with that attitude you won\u2019t! But dip your toe in, _Pride and prejudice_ is pretty light and breezy while having some depth to it.reply",
      "> to see how wildly popular her work remainsThere's an annual Jane Austen festival there too - it really brings people from all over the world. Very fun event even if you're just +1 to someone who's into it.reply",
      "I upvoted for the perfect first line for this HN post.  That you're related, makes sense.reply",
      "Go ahead, be proud!  Be Austen-tatious!reply",
      "Do you have an example of her writing moving into iambic pentameter in prose, please?I googled for examples from her books but \u2014 search results are terrible.reply",
      "Of course! This is my favourite example, from Sense and Sensibility, because it announces itself with \"burst\", and that's the novel where she deploys it most:\"Elinor could sit it no longer. She almost ran out of the room, and as soon as the door was closed, burst into tears of joy, which at first she thought would never cease.\"She 'tends towards Iambic' in literary criticism terminology. So it's not a strict Iambic, more like a 'soft Iambic' which is a term I can't remember if it's actually used in lit crit, or if I made it up.You need to drop the \"at\" syllable, in that example (which you would do in vocal rhythms of English, then and now), for it to be a true Iambic.There's lots of good writing on the King James Bible \"tending towards\" Iambic, which should be more Google-able, and her father was a preacher, so that's a likely influence there, I would speculate.Some others I like that I remember:\"You pierce my soul. I am half agony, half hope.\" - Persuasion (I think?).\"Till this moment I never knew myself.\" - Sense and Sensibility again? I can't remember off the dome. That's a gorgeous strict Iambic.There are much longer examples - whole paragraphs that close chapters of Sense and Sensibility specifically. I'll try and find the version I have notations on when I'm next around my books. She regularly slips into it to close moments of emotional crescendo - \"Cursus\" being the Latin term for an analogous technique, when it was more frequently used in a more stylised manner.reply"
    ],
    "link": "https://eli.li/gundam-is-just-the-same-as-jane-austen-but-happens-to-include-giant-mech-suits",
    "first_paragraph": ""
  },
  {
    "title": "Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux (heise.de)",
    "points": 512,
    "submitter": "OsrsNeedsf2P",
    "submit_time": "2025-12-10T17:20:06 1765387206",
    "num_comments": 294,
    "comments_url": "https://news.ycombinator.com/item?id=46220488",
    "comments": [
      "Summarizing this thread:- I paid for a device with a properly licensed hdmi port.  It runs linux.  So patent exhaustion applies, at least in the US.  I can say ignore the patents to make my property work.- I have no relationship to the HDMI people.  (Never entered into a contract with them.)- The links to the spec are here. (Trade secrets/nda no longer apply.  This is the problem with using trade secrets to protect your stuff.)- If I point a coding assistant (assume open weights/source) at this thread, and a copy of linux main, it can probably just fix the damn driver.- I could probably publish my patch with a big fat \u201conly for use with licensed hdmi hardware, not for resale\u201d disclaimer on it.At that point, what law would I have broken?reply",
      "The problem is that software distributors might break laws if the said drivers lands on unlicensed hdmi hardware, so they should be liable to check if the hardware is properly licensed, which might generate headaches.Or maybe lawyers cannot anticipate everything that happens in court, so it just feels better to do things properly and not try to circumvent laws, especially when you're valve. It's better to not take risks.reply",
      "Would it be feasible for a driver patch to be shared via e.g. an anonymous torrent, with a checksum (to certify authenticity) held somewhere more reliable, like GitHub?reply",
      "Maybe nothing, but can you afford to prove that in court?reply",
      "If you take the effort to anonymise your contributions, can they afford to try to find you?reply",
      "Standard link to download: https://dokumen.pub/download/hdmi-specification-21-high-defi...Alternative: https://annas-archive.org/md5/4dd395c749519a36cb755e6ebbe488...Alternative (incomplete, only couple first page):  https://device.report/m/91235972e8cbf6d6ce84f7cf84ca0ac12623...Other HDMI stuff: https://pdfhost.io/v/YidEvBDkS_EP92A7E_EP91A7E_DS_V04Older available here: https://glenwing.github.io/docs/reply",
      "AIUI the spec being leaked ironically makes things worse, because for an unofficial implementation to be legally kosher it would have to be clean-room reverse engineered anyway, and since the official spec is out there the integrity of such an effort would be called into doubt. You'd somehow have to prove you didn't look at it, ever, or at least be trusted enough for people to take your word for it.(I'm not a lawyer, please correct me if I'm wrong)reply",
      "Reading a standards spec to understand what the device you paid for does?Straight to jail!Pirating the entire internet to train your AI?That's fair use.reply",
      "Can we just train an AI with the spec and then vibe code an implementation?reply",
      "I hope someone can do this in such a manner as to engineer the collision of the legal titans. Either way, we win on some ground.IP vs AI, round two, Fight!!!reply"
    ],
    "link": "https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html",
    "first_paragraph": "\n        Technically, the Steam Machine supports HDMI 2.1. However, Valve and AMD are not allowed to offer an open-source driver for it.\n      \n      (Image:\u00a0Valve)\n    The HDMI Forum, responsible for the HDMI specification, continues to stonewall open source. Valve's Steam Machine theoretically supports HDMI 2.1, but the mini-PC is software-limited to HDMI 2.0. As a result, more than 60 frames per second at 4K resolution are only possible with limitations.In a statement to Ars Technica, a Valve spokesperson confirmed that HDMI 2.1 support is \"still a work-in-progress on the software side.\" \"We\u2019ve been working on trying to unblock things there.\"The Steam Machine uses an AMD Ryzen APU with a Radeon graphics unit. Valve strictly adheres to open-source drivers, but the HDMI Forum is unwilling to disclose the 2.1 specification. According to Valve, they have validated the HDMI 2.1 hardware under Windows to ensure basic functionality.\n        Videos by heise\n      The restriction imposed by "
  },
  {
    "title": "The future of Terraform CDK (github.com/hashicorp)",
    "points": 84,
    "submitter": "mfornasa",
    "submit_time": "2025-12-10T19:14:03 1765394043",
    "num_comments": 86,
    "comments_url": "https://news.ycombinator.com/item?id=46222165",
    "comments": [
      "It's odd to always say \"Hashicorp, an IBM company\". Looks like they want to assign blame.I did try Pulumi a while back, but the compatibility with Terraform modules was not great, so I've switched to CDKTF, which can handle unmodified modules. Dunno if I'll switch back to Pulumi or just use OpenTofu directly.reply",
      "> It's odd to always say \"Hashicorp, an IBM company\". Looks like they want to assign blame.All their branding does this now, including the HashiCorp logo on their website [0]. There's gotta be a name for this specific branding pattern, but I don't know it.[0] https://www.hashicorp.com/en/blog/products/terraformreply",
      "Metastatized brandingreply",
      "I was recently working for a company which got acquired by IBM and we had to do it too. It\u2019s an IBM thing. I bet most people at HashiCorp hate it, at least that was the case for us.reply",
      "Makes IBM look really bad. Do they also force people to bow when the CEO of IBM enters the room, and address them as sir or your highness?reply",
      "They used to have their employees sign songs praising the company...Granted, that was in the 1930s or something, but still.reply",
      "I have absolutely nothing good to say about Pulumi. Stay far, far away.reply",
      "My experience with Pulumi is you can write bad pulumi code and good pulumi code and just like everything else, it's easy to end up in a codebase where one poor soul was tasked with writing it all and they didn't do the best job with it.reply",
      "Why? I\u2019ve had nothing but good experiences, but I don\u2019t run it and the team that does is extremely competentreply",
      "Strange, I have a lot of good things to say about both it and Terraform.Probably some specifics might be more useful there...reply"
    ],
    "link": "https://github.com/hashicorp/terraform-cdk",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Define infrastructure resources using programming constructs and provision them using HashiCorp Terraform\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Terraform CDK (CDKTF) will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date. Unfortunately, Terraform CDK did not find product-market fit at scale. HashiCorp, an IBM Company, has chosen to focus its investments on Terraform core and its broader ecosystem.As of December 10, 2025, Terraform CDK will be archived on GitHub, and the documentation will reflect its deprecated status. The archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements (including compatibility upd"
  },
  {
    "title": "Launch HN: InspectMind (YC W24) \u2013 AI agent for reviewing construction drawings",
    "points": 40,
    "submitter": "aakashprasad91",
    "submit_time": "2025-12-10T16:05:03 1765382703",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=46219386",
    "comments": [
      "This is fun to see. Some of my family are Division 10 contractors: their GCs love them because they spot design coordination and code issues early and keep the project from getting derailed. Bringing that to the entire project is a serious lifesaver.reply",
      "Totally! Division 10 and specialty trades are often the first to see coordination issues show up in the field. We\u2019re trying to bring that same early-warning benefit across the entire drawing set so errors never make it to construction. Would love to run a real project from your family\u2019s world if they\u2019re open to it!reply",
      "What kind of system to you have for parsing symbology?Do you check anything like cross discipline coordination (e.g. online searching specification data for parts on drawings like mechanical units and detecting mismatch with electrical spec), or it wholly within 1 trades code at a time?edit: there's info that answers this on the website. It seems limited to the common ones (e.g. elec vs arch), which makes sense.reply",
      "Symbol variation is a huge challenge across firms.Our approach mixes OCR, vector geometry, and learned embeddings so the model can recognize a symbol plus its surrounding annotations (e.g., \u201c6-15R,\u201d \u201cDIM,\u201d \u201cGFCI\u201d).When symbols differ by drafter, the system leans heavily on the textual/graph context so it still resolves meaning accurately. We\u2019re actively expanding our electrical symbol library and would love sample sets from your workflow.reply",
      "We parse symbols using a mix of vector geometry, OCR, and learned detection for common architectural/MEP symbols. Cross-discipline checks are a big focus as we already flag mismatches between architectural, structural, and MEP sheets, and we\u2019re expanding into deeper electrical/mechanical spec alignment next. Would love to hear which symbols matter most in your workflow so we can improve coverage.reply",
      "I do electrical so parsing lighting is often a big issue. (Subcontractor)One big issue Ive had is drafters use the same symbol for different things per person.  One person's GFCi is another's switched receptacle.  People use the specialty putlet symbol sometimes very precisely and others not.  Often accompanied by an annotation (e.g. 6-15R).Dimmers being ambiguous is huge; avoiding dimming type mismatches is basically 80% the lutron value add.reply",
      "We're in a similar space doing machine assisted lighting take offs for contractors in AU/NZ, with bespoke models trained for identifying & measuring luminaires on construction plans.Compliance is a space we've branched into recently. Would be super interested in seeing how you guys are currently approaching symbol detection.reply",
      "Happy to swap notes. If you send a representative lighting plan set, we can run it and share how the detector clusters, resolves, and cross-references symbols across sheets. Always excited to compare approaches with teams solving adjacent problems.reply",
      "Maybe this is saying the quiet part out loud: how do you deal with bogus specs that designers end up not caring about since they're copy pasted? Is it just mission accomplished when you point out a potential difficulty?reply",
      "We see that a lot \u2014 specs that are clearly boilerplate or outdated relative to the drawings. Our goal isn\u2019t to force a change, but to surface where the specs and drawings diverge so the designer can quickly decide what\u2019s intentional vs what\u2019s baggage. \u201cFlag + context for fast human judgment\u201d is the philosophy.reply"
    ],
    "link": "item?id=46219386",
    "first_paragraph": ""
  },
  {
    "title": "Sharding to Contain the Blast Radius of Data Breaches (mimirsec.com)",
    "points": 9,
    "submitter": "jboutwell",
    "submit_time": "2025-12-08T16:31:39 1765211499",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.mimirsec.com/2025/12/05/sharding-to-contain-the-blast-radius-of-data-breaches/",
    "first_paragraph": "Modern SaaS platforms sit on top of massive, multi-tenant data stores. When those stores are breached, the damage is rarely limited to a single record; it is often \u201cwholesale\u201d compromise of large slices of the user base. For a CISO or CTO, this is the critical risk: not that a record can be stolen, but that everything a given system knows becomes available in one incident.Cloud providers and SaaS security guidance have converged on a simple principle: design for tenant isolation and blast radius reduction. You assume compromise is possible and work to ensure that any single failure affects as few tenants and as little data as possible, instead of the entire corpus.\u00a0AWS DocumentationDatabase and infrastructure sharding emerged first as a scalability technique, but security literature increasingly frames sharding as a way to structurally prevent widespread data compromise, especially in multi-tenant SaaS.\u00a0Amazon Web Services, Inc.+1This article explains how sharding can be used as a deli"
  }
]