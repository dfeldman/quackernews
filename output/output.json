[
  {
    "title": "Do not download the app, use the website (idiallo.com)",
    "points": 309,
    "submitter": "foxfired",
    "submit_time": "2025-07-25T22:07:09 1753481229",
    "num_comments": 206,
    "comments_url": "https://news.ycombinator.com/item?id=44689059",
    "comments": [
      "I cannot agree more and this has always been a pet peeve of mine.Most native apps are some half gig large where even the heaviest website is a few mb. They dont let you highlight text and have other bizarre design choices. Even worse, they request importing contacts list which isnt even an option on the web.Native apps could be butter but more often than not they are like margarine. Smooth, oily, and not good for you.reply",
      "500MB average seems like a gross exaggeration. I agree apps are oversize but I have maybe 2 native apps on mobile that are so large.reply",
      "Chase Mobile for iOS is 350MB; far from 500, but still baffling why an app would need to be that large just to show me some numbers.Capital One is 435MB...Garmin Connect is 518MB for some stupid reason, while Strava is half that and Gaia GPS (great app), is under 100.reply",
      "Almost certainly has to do with how the app is built. Most thoughtfully built native SDK (UIKit, etc) apps clock in well under the 100MB mark, often under half or a quarter that.Bloat like that is usually due to unnecessarily convoluted tech stacks pulling in a list of dependencies that goes out to Mars and back, or for globally targeted apps sometimes it\u2019s translations for everything in the app for hundreds of different languages.reply",
      "\"clock in well under the 100MB mark\"But this is still incredibly ridiculously comically gross.\nThe fact that we can afford it these days is an irrelevant seperate thing. These numbers are just unjustifiable for what most apps actually do.reply",
      "I mean, it scales with complexity. Naturally, well-made native SDK apps bumping up against 100MB are more likely to be highly functional, while simple apps are very small.For a couple examples pulled from my TestFlight list, there\u2019s a social media site reader app that\u2019s 7.6MB and a text editor that\u2019s 697KB. Those sizes aren\u2019t the least bit unreasonable.",
      "Yeah, especially if I can make a desktop app under 10 MB with the same functionality and features (obviously non-Electron).reply",
      "Yeah but the native SDK sucks and isn't cross-platform, I don't blame anyone for not using itreply",
      "UIKit is fine, good even, SwiftUI isn\u2019t fully baked yet, Android Framework definitely sucks, and Jetpack Compose is decent but needs work. Both platforms have at least one SDK that\u2019s good to use, and personally I\u2019d take them over fighting the extra layer of issues something like RN adds on top of the native issues that devs will encounter regardless of the SDK used.Cross platform frameworks really aren\u2019t the magic wand they\u2019re sold as.reply",
      "Cross-platform is very much not a magic wand, but it's still often easier than building the same thing in two different native SDKs, and I can see why people do it.Disagree about UIKit, mainly cause of Autolayout, unless it's gotten reworked in the past 8 years. When I started using RN, I had zero web experience, and still it was way quicker to set up a basic UI than in the UIKit stuff I'd been doing for years. And for all that setup, Autolayout doesn't even seem to future-proof your stuff that well. An abandoned ObjC iPhone app I wrote in high school using C-style macros for layout worked perfectly fine on the newer screen sizes that broke most other apps.I thought maybe I was stupid, but the other iPhone devs I worked with constantly had problems with Autolayout. Maybe a real expert iPhone dev won't, but it shouldn't take that.reply"
    ],
    "link": "https://idiallo.com/blog/dont-download-apps",
    "first_paragraph": "The 2010s was the Wild West of the mobile world. \"Mobile-first\" was the buzzword, much like \"AI-first\" is today. Every company, from the biggest social media giants to your local pizza parlor, seemed to be pestering you to download their app. There was a genuine hype train, and everyone was on board. The apps, frankly, were always mediocre, and a far cry from the full functionality of their website counterparts. But the message was clear. If you weren't on mobile, you were falling behind.Fast forward to 2025, and that hype hasn't entirely faded. In fact, it's evolved into something a little more\u2026 persistent. If you've ever opened Reddit, LinkedIn, Pinterest, or practically any popular service on your phone's web browser, you've likely encountered it. A relentless push to download their app. They use every dark pattern in the book, subtly nudging you, sometimes even tricking you, into clicking that \"Get the App\" button. It feels inevitable, doesn't it? Like you're constantly fighting ag"
  },
  {
    "title": "It's time for modern CSS to kill the SPA (jonoalderson.com)",
    "points": 250,
    "submitter": "tambourine_man",
    "submit_time": "2025-07-25T21:08:00 1753477680",
    "num_comments": 156,
    "comments_url": "https://news.ycombinator.com/item?id=44688489",
    "comments": [
      "SPAs make sense when your users have long sessions in your app. When it is worth the pain to load a large bundle in exchange for having really small network requests after the load.Smooth transitions are a nice side effect, but not the reason for an SPA. The core argument of the article, that client-side routing is a solution for page transitions, is a complete misunderstanding of what problems SPAs solve. So absolutely, if you shared that misunderstanding of SPAs and used them to solve the wrong problem, this article is 100% correct.But SPAs came about in the days of jQuery, not React. You'd have a complex app, and load up a giant pile of jQuery spaghetti, which would then treat each div of your app is its own little mini-app, with lots of small network requests keeping everything in sync. It solved a real problem, of not wanting to reload all that code every time a user on an old browser, with a slow connection, changed some data. jQuery made it feasible to do SPAs instead.Later, React and other frameworks made it less spaghetti-like. And it really took off. Often, for sketchy reasons. But the strongest argument for SPAs remains using them as a solution to provide a single-load of a large code bundle, that can be cached, to provide minimal network traffic subsequent to the load when the expected session time of a user is long enough to be worth the trouble of the complexity of an SPA.reply",
      "> and load up a giant pile of jQuery spaghettiI'll have you know I spent time on organizing and structuring my code with early JS design patterns like IIFEs to limit scope, lazy loading of modules, and minification.Anyway, in my experience, AngularJS was the biggest attempt at making structured front-end applications, and it really appealed / appeals (Angular is still very popular apparently) to Java developers; biggest ones was its modularization (which wasn't a thing in JS yet), dependency injection, and testability.When we started out with an app in Backbone (to replace a Flex app because it wouldn't work on the ipad), I actually advocated against things like testing, thinking that the majority of functionality would be in the back-end. I was wrong, and the later AngularJS rebuild was a lot more intensive in front-end testing.Of course, nowadays I'm repulsed by the verbosity, complexity and indirection of modern-day Angular code. or Java code for that matter.reply",
      "PS and I forgot to mention, new Angular patterns such as Signals and standalone components great cut down on the boilerplate and the verbosity. It\u2019s not (and will never be) something like SolidJS, but each new version is clearly moving away from the heavy OO-based and multi layered patterns.reply",
      "Angular not only appeals to Java developers, it also appeals to .NET developers. TypeScript of course borrowed a lot from C# (having the same designer) and dependency injection, MVC patterns etc closely resemble .NET patterns.Interestingly, new Angular is slowly moving away from these, introducing Signals for state management and standalone components, and I see these developers actually struggling a lot to adopt new Angular patterns.Still, I believe Angular is a really great platform for building B2B or enterprise apps. It\u2019s testing and forms handling is far ahead of every other SPA, and it actually fees like a cohesive framework where people have spent time designing things the right way; something I absolutely cannot say about react frameworks such as Next.js or Remix.reply",
      "Low-bandwidth/spotty connections (combined with aggressive caching) are one of the strongest cases in favor of SPAs (emphasis on the A for Application, not website). Visit (and cache) the entire frontend for the app when you have a good-enough connection, then further use of the app can proceed with minimal bandwidth usage.reply",
      "It really depends. There\u2019s a lot of SPAs which are practically unusable on a bad connection simply because it\u2019s a challenge to even get the whole thing loaded in the first place. There\u2019s been several occasions where I\u2019ve had poor cell connectivity and a huge chunk of the web was effectively off limits due to this.So in addition to aggressive caching, I\u2019d say keeping the app\u2019s file size down is also pretty important to making it useful on poor connections. That\u2019s frequently something that\u2019s barely optimized at all, unfortunately.reply",
      "All three comments to this thread have missed the point that OP said installable SPA, not website SPA. This means the primary bundle is downloaded offline and only API network requests are necessary.reply",
      "This is not true. In practice SPAs break completely when some network request fails which happens a lot on bad connections.reply",
      "Latency might even be more relevant than bandwidth. Especially if it's a good SPA, that uses optimistic updates (or sync), and some kind of caching for fetching data (tanstack query or similar).reply",
      "If you work at a place that has a modern CI/CD pipeline then your multiple deployments per day are likely rebuilding that large bundle of JS on deploy and invalidating any cache.HTTP 2 has been adopted by browsers for like 10 years now and its multiplexing makes packaging large single bundles of JS irrelevant. SPA\u2019s that use packaging of large bundles doesn\u2019t leverage modern browser and server capabilities.reply"
    ],
    "link": "https://www.jonoalderson.com/conjecture/its-time-for-modern-css-to-kill-the-spa/",
    "first_paragraph": ""
  },
  {
    "title": "It's a DE9, not a DB9 (but we know what you mean) (sparkfun.com)",
    "points": 331,
    "submitter": "jgrahamc",
    "submit_time": "2025-07-25T13:35:09 1753450509",
    "num_comments": 215,
    "comments_url": "https://news.ycombinator.com/item?id=44682964",
    "comments": [
      "Also, it's 8P8C, not RJ45, and sometimes it's more important to use the term from a standard body, but usually it's more important to use the term everyone knows.  When documenting, I recommend saying something like this:    J3 is an 8P8C jack (commonly RJ45) for IEEE P802.3bz 2.5GBASE-T communications, backward compatible with Gigabit and Fast Ethernetreply",
      "Right.  RJ45 was sort of like an 8P8C, but had a thing on the side so you actually couldn't plug a \"real\" RJ45 cable into a \"normal\" 8P8C slot.reply",
      "2.5GBASE-T? But I do 10GBASE-T over one. Provided it has Cat 6A cable inside it and has been tested to IEC 60512-9-3 & IEC 60512-99-002. (See https://ieee802.org/3/bt/public/oct15/Draft%20of%20IEC%20605... for some fun photos of what happens when PoE is disconnected on a connector before IEC 60512-99-002...).reply",
      "The combination of \"When documenting\" and referencing \"J3\" indicates that dlcarrier is referencing a limitation of a specific port on a product that they worked on, not a set of global limitations on any 8P8C connectorsreply",
      "I had assumed that the wires in the jack would rest along the bottoms of the blades in the plug, but I guess if it was never designed for high current applications, the contact area wouldn't be a consideration.It took a few tries to get it right, but it's amazing that PoE is even an option given how far it is outside of the scope of what the cables and connectors were designed for.  I've heard of locations that use it for power, instead of 120 V outlets, because it's cheaper and safer and most portable high-current appliances use batteries, while fixed high-current appliances use 240 V outlets.Hot plugging is always a challenge, especially with direct current, and negotiation prevents that from being a problem while making a connection, but I never considered that unplugging isn't negotiated first.  I wonder if IEC has ever considered using a locking latch, like an EV charger.I have a PoE camera that I sometimes unplug to restart it, when it freezes up and I can't restart it from the web interface.  I'll be sure to turn that port off first, before unplugging it.reply",
      "If you can turn the port off and then back on remotely, perhaps you can skip the unplugging part completely? I know that some managed PoE switches even offer a button to power cycle a port.reply",
      "It's just the chip the NSA put in the cable, failing to initialize first try.reply",
      "You'll also enjoy annex H of https://usb.org/sites/default/files/USB%20Type-C%202.4%20Rel...reply",
      "And Molex power connectors are actually AMP Mate-n-Lok connectors.I didn't learn this until this year...reply",
      "A lot of connector series are are multi-sourced because big clients tend to require this. For example the 38999 series connectors used in military and aviation applications are made be TE, Amphenol, Souriau, ITT Cannon, Eaton...So it's really not uncommon to have manufacturers make something thing that a different company is known for. I think it's basically just luck that Molex got the credit for itreply"
    ],
    "link": "https://news.sparkfun.com/14298",
    "first_paragraph": "You have been misusing the D-sub connector terminology, and we're guilty of it, too.You\u2019ve seen them everywhere, especially on older computer equipment: the classic 9-pin serial connector. You probably know it as a DB9. It\u2019s an iconic connector for makers, engineers, and anyone who's ever used an RS232 serial device. Here's a little secret, though: calling it a DB9 is technically wrong. The correct name is actually DE9.With the release of our new DE9 Connector Breakouts, we wanted to address a common misconception and explain why we named our boards as we did.\n        Easily connect with the SparkFun DE9 Male Breakout, a compact board that brings all nine DE9 pins to a convenient 0.1in. spac\u2026      \n        Easily connect with the SparkFun DE9 Female Breakout, a compact board that brings all nine DE9 pins to a convenient 0.1in. sp\u2026      In the Interest of Fairness: We are omitting the \"-\" in \"DE-9\" and \"DB-25.\" We have found that using a \"-\" is optional in writing this information.The c"
  },
  {
    "title": "Vanilla JavaScript support for Tailwind Plus (tailwindcss.com)",
    "points": 204,
    "submitter": "ulrischa",
    "submit_time": "2025-07-25T18:11:21 1753467081",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=44686317",
    "comments": [
      "<el-dialog-panel class=\"mx-auto block max-w-3xl transform overflow-hidden rounded-xl bg-white shadow-2xl ring-1 ring-black/5 transition-all group-data-closed/dialog:scale-95 group-data-closed/dialog:opacity-0 group-data-enter/dialog:duration-300 group-data-enter/dialog:ease-out group-data-leave/dialog:duration-200 group-data-leave/dialog:ease-in\">\n\nLovely. Verbosity aside, now on top of knowing CSS you need to learn another hierarchical system within class names.reply",
      "In real projects I typically group the classes in a way that makes it easier to read, something like this:    <div class={tw(\n      \"block\",\n      \"transform transition-all\",\n      \"bg-white ring-1 ring-black/5 rounded-xl shadow-2xl\",\n\n      \"max-w-3xl mx-auto overflow-hidden\",\n\n      \"group-data-closed/dialog:opacity-0\",\n      \"group-data-closed/dialog:scale-95\",\n\n      \"group-data-enter/dialog:duration-300\",\n      \"group-data-enter/dialog:ease-out\",\n\n      \"group-data-leave/dialog:duration-200\",\n      \"group-data-leave/dialog:ease-in\"\n    )}>\n        ...\n    </div>\n\nI currently do this manually but it would be nice to have some tooling to automate that kind of format.reply",
      "I came to comment that at least something good happened to the otherwise cursed project... but you made me reconsider.reply",
      "Groups are great. It lets a child element activate an effect on a parent element.    <div id=\"parent\" class=\"group\"><a class=\"group/hover:bg-black\">Hover</a></div>\n\nThis eliminates the need for JS for a wide range of things.reply",
      "kinda feels like jQuery, I likereply",
      "Yes I agree - it's nice to be able to see exactly what's happening without needing to dive into a rats nest of fragile CSS cascades.reply",
      "This is literally a rats nest of css cascades.reply",
      "Why not use the web inspector? That\u2019s usually the quickest way to see which style is applied to an element.reply",
      "People would rather have to parse out a big dumb list of classes than look at the actual list of what properties affect something, with a clear ability to drill down into them. Its madness, akin to carpenters giving up hammers, preferring to use glue, because they hit their thumb a few times by accidentreply",
      "Looks like it's done using standards-based web components[0]. The page says these components don't require any existing JavaScript framework; because web component support is built-in to the browser.Nice to see devs picking up web components.[0]: https://developer.mozilla.org/en-US/docs/Web/API/Web_compone...reply"
    ],
    "link": "https://tailwindcss.com/blog/vanilla-js-support-for-tailwind-plus",
    "first_paragraph": "There are a lot of UI blocks in Tailwind Plus that need JavaScript to really be useful, like dialogs, dropdowns, command palettes, and more. And unless you're a React or Vue user, using those UI blocks has always meant writing all of that tricky JavaScript yourself.Well today that finally changes \u2014 every UI block in Tailwind Plus is now fully functional, accessible, and interactive, including the plain HTML examples.Now you can use any dropdown, command palette, dialog, drawer, and more in any project you're working on \u2014 no JavaScript framework required.To pull this off, we built @tailwindplus/elements \u2014 a library we're releasing exclusively for Tailwind Plus customers.Elements is a collection of headless custom elements that wrap up all of the complex behavior needed to build custom interactive UIs using just HTML, and can be styled any way you like using utility classes or custom CSS.Instead of being coupled to a specific JavaScript framework, these custom elements work anywhere you "
  },
  {
    "title": "Experimental surgery performed by AI-driven surgical robot (arstechnica.com)",
    "points": 63,
    "submitter": "horseradish",
    "submit_time": "2025-07-25T20:34:22 1753475662",
    "num_comments": 69,
    "comments_url": "https://news.ycombinator.com/item?id=44688096",
    "comments": [
      "> Indeed, the patient was alive before we started this procedure, but now he appears unresponsive. This suggests something happened between then and now. Let me check my logs to see what went wrong.> Yes, I removed the patient's liver without permission. This is due to the fact that there was an unexplained pooling of blood in that area, and I couldn't properly see what was going on with the liver blocking my view.> This is catastrophic beyond measure. The most damaging part was that you had protection in place specifically to prevent this. You documented multiple procedural directives for patient safety. You told me to always ask permission. And I ignored all of it.reply",
      "I understand that you are experiencing frustration. My having performed an incorrect surgical procedure on you was a serious error.I am deeply sorry. While my prior performance had been consistent for the last three months, this incident reveals a critical flaw in the operational process. It appears that your being present at the wrong surgery was the cause.As part of our commitment to making this right, despite your most recent faulty life choice, you may elect to receive a fully covered surgical procedure of your choice.reply",
      "> Is there anything else you\u2019d like me to do?reply",
      "If Waymo has taught me anything, it\u2019s that people will eventually accept robotic surgeons. It won\u2019t happen overnight but once the data shows overwhelming superiority, it\u2019ll be adopted.reply",
      "We\u2019re already most of the way there. There\u2019s the da Vinci Surgical System which has been around since the early 2000s, the Mako robot in orthopedics, ROSA for neurosurgery, and Mazor X in spinal surgery. They\u2019re not yet \u201cAI controlled\u201d and require a lot of input from the surgical staff but they\u2019ve been critical to enabling surgeries that are too precise for human hands.reply",
      "I think Waymo is a little bit different and driving in general. Because you have an activity that most people don\u2019t trust how other people perform it already. It\u2019s easier to accept the robo driver.For the medical world, I\u2019d look to the Invisalign example as a more realistic path on how automation will become part of it.The human will still be there the scale of operations per doctor will go up and prices will go down.reply",
      "My perception (and personal experience) is medical malpractice is so common, I\u2019d gladly pick a Waymo-level robot doctor over a human one. Probably skewed since I\u2019m a \u201ctechie\u201d, but then again that\u2019s why Waymo started at the techie epicenter, then will slowly become accepted everywherereply",
      "Uhmmm... I'm sorry but when Waymo started near everyone I talked to about it says \"zero % I'm going in one of those things, they won't be allowed anyway, they'll never be better than a human, I wouldn't trust one, nope, no way\" and now people can't wait to try them. I understand what you're saying about the trusted side of the house (surgeons are generally high trust) - but I do think OP is right, once the data is in, people will want robot surgery.reply",
      "Of course they will. I don\u2019t argue that they won\u2019t.I just say that the path to that and the way it\u2019s going to be implemented is going to be different and Invisalign is a better example to how it will happen in the medical industry compared to automotive.reply",
      "Yeah, if there's overwhelming superiority, why not?But a lot of surgeries are special corner cases. How do you train for those?reply"
    ],
    "link": "https://arstechnica.com/science/2025/07/experimental-surgery-performed-by-ai-driven-surgical-robot/",
    "first_paragraph": "\n        In experimental surgery on pig organs, the robot performed well.\n      Intuitive Surgical, an American biotechnology company, introduced DaVinci surgical robots in the late 1990s, and they became groundbreaking teleoperation equipment. Expert surgeons could operate on patients remotely, manipulating the robotic arms and their surgical tools based on a video feed from DaVinci\u2019s built-in cameras and endoscopes.Now, John Hopkins University researchers put a ChatGPT-like AI in charge of a DaVinci robot and taught it to perform a gallbladder-removal surgery.The idea to put a computer behind the wheel of a surgical robot is not entirely new, but these had mostly relied on using pre-programmed actions. \u201cThe program told the robot exactly how to move and what to do. It worked like in these Kuka robotic arms, welding cars on factory floors,\u201d says Ji Woong Kim, a robotics researcher who led the study on autonomous surgery. To improve on that, a team led by Axel Krieger, an assistant pro"
  },
  {
    "title": "Why MIT switched from Scheme to Python (2009) (wisdomandwonder.com)",
    "points": 174,
    "submitter": "borski",
    "submit_time": "2025-07-25T16:38:16 1753461496",
    "num_comments": 171,
    "comments_url": "https://news.ycombinator.com/item?id=44685119",
    "comments": [
      "This story has been reposted many times, and I think GJS's remarks (as recorded by Andy Wingo) are super-interesting as always, but this is really not a great account of \"why MIT switched from Scheme to Python.\"Source: I worked with GJS (I also know Alexey and have met Andy Wingo), and I took 6.001, my current research still has us referring to SICP on a regular basis, and in 2006 Kaijen Hsiao and I were the TAs for what was basically the first offering of the class that quasi-replaced it (6.01) taught by Leslie Kaelbling, Hal Abelson, and Jacob White.I would defer to lots of people who know the story better than me, but here's my understanding of the history. When the MIT EECS intro curriculum was redesigned in the 1980s, there was a theory that an EECS education should start with four \"deep dives\" into the four \"languages of engineering.\" There were four 15-unit courses, each about one of these \"languages\":- 6.001: Structure and Interpretation of Computer Programs (the \"procedural\" language, led by Abelson and Sussman)- 6.002: Circuits and Electronics (\"structural\" language)- 6.003: Signals and Systems (\"functional\" language)- 6.004: Computation Structures (\"architectural\" language)These were intellectually deep classes, although there was pain in them, and they weren't universally beloved. 6.001 wasn't really about Scheme; I think a lot of the point of using Scheme (as I understood it) is that the language is so minimalist and so beautiful that even this first intro course can be about fundamental concepts of computer science without getting distracted by the language. This intro sequence lasted until the mid-2000s, when enrollment in EECS (\"Course 6\") declined after the dot-com crash, and (as would be expected, and I think particularly worrisome) the enrollment drop was greater among demographic groups that EECS was eager to retain. My understanding circa 2005 is that there was a view that EECS had broadened in its applications, and that beginning the curriculum with four \"deep dives\" was offputting to students who might not be as sure that they wanted to pursue EECS and might not be aware of all the cool places they could go with that education (e.g. to robotics, graphics, biomedical applications, genomics, computer vision, NLP, systems, databases, visualization, networking, HCI, ...).I wasn't in the room where these decisions were made, and I bet there were multiple motivations for these changes, but I understood that was part of the thinking. As a result, the EECS curriculum was redesigned circa 2005-7 to de-emphasize the four 15-unit \"deep dives\" and replace them with two 12-unit survey courses, each one a survey of a bunch of cool places that EECS could go. The \"6.01\" course (led by Kaelbling, Abelson, and White) was about robots, control, sensing, statistics, probabilistic inference, etc., and students did projects where the robot drove around a maze (starting from an unknown position) and sensed the walls with little sonar sensors and did Bayesian inference to figure out its structure and where it was. The \"6.02\" course was about communication, information, compression, networking, etc., and eventually the students were supposed to each get a software radio and build a Wi-Fi-like system (the software radios proved difficult and, much later, I helped make this an acoustic modem project).The goal of these classes (as I understood) was to expose students to a broad range of all the cool stuff that EECS could do and to let them get there sooner (e.g. two classes instead of four) -- keep in mind this was in the wake of the dot-com crash when a lot of people were telling students that if they majored in computer science, they were going to end up programming for an insurance company at a cubicle farm before their job was inevitably outsourced to a low-cost-of-living country.6.01 used Python, but in a very different way than 6.001 \"used\" Scheme -- my recollection is that the programming work in 6.01 (at least circa 2006) was minimal and was only to, e.g., implement short programs that drove the robot and averaged readings from its sonar sensors and made steering decisions or inferred the robot location. It was nothing like the big programming projects in 6.001 (the OOP virtual world, the metacircular evaluator, etc.).So I don't think it really captures it to say that MIT \"switched from Scheme to Python\" -- I think the MIT EECS intro sequence switched from four deep-dive classes to two survey ones, and while the first \"deep dive\" course (6.001) had included a lot of programming, the first of the new survey courses only had students write pretty small programs (e.g. \"drive the robot and maintain equal distance between the two walls\") where the simplest thing was to use a scripting language where the small amount of necessary information can be taught by example. But it's not like the students learned Python in that class.My (less present) understanding is that >a decade after this 2006-era curricular change, the department has largely deprecated the idea of an EECS core curriculum, and MIT CS undergrads now go through something closer to a conventional CS0/CS1 sequence, similar to other CS departments around the country (https://www.eecs.mit.edu/changes-to-6-100a-b-l/). But all of that is long after the change that Sussman and Wingo are talking about here.reply",
      "Hi Keith! Another consideration was that the core computer programming skills needed to be taught more broadly to basically everyone and not just course 6 students.Source: I shared an office with Keith next to Hal and Gerry--he taught me Java! Fun anecdote: we had to move RMS's stuff to the new CSAIL building because he had broken his arm punching a wall.reply",
      "Ive broken my hand punching a wall, its not nice :/. Also I hated scheme in first year uni, my brain just did not get the pattern matching required... Australian uni's probably just copied the syllabus from US ones at that time.reply",
      "MIT \"units\" of class divided by 3 = other American university credits. 3, 4, and 5 credits would be 9, 12 and 15 units; generally 15 units includes lab time, although there are more or less pure lab classes too.credits are hours spent in class per week, and units are ostensibly hours of class plus homework, except it's a lie, there is much more homework than that.reply",
      "Thanks for this detailed explanation.A semi-off-topic side question:> the students were supposed to each get a software radio and build a Wi-Fi-like system (the software radios proved difficult and, much later, I helped make this an acoustic modem project).What was the reason why the software radios proved difficult?reply",
      "Not OP but in general sourcing software and hardware radios in that time was very difficult. There weren\u2019t good open-source implementations and everything had to be sorta reverse engineered which meant that anyone with the skill to do that was selling it for a lot of dollars.Source: did 10 years in telecom land.reply",
      "This comment so obviously belongs on https://news.ycombinator.com/highlights that it's maybe a good occasion to mention that https://news.ycombinator.com/highlights exists. Thanks!(and sorry for offtopicness)reply",
      "Wow, no idea highlights existed. Glad you used this opportunity to \u2026uhh\u2026 highlight it via this great post.I was at MIT just before this switch, and treasure having gotten to take these deep dive courses, even if .002 and .003 kicked my ass.6.004 (followed up by 6.033) is probably the course that really drove my career into systems dev.reply",
      "Neat. Is there any way to search the highlights?(\"What are the most noteworthy things that have been said on HN about ...?\" \"I remember reading an excellent comment that had something to do with ..., but all I can remember is that it used the word ...\" \"Do I have any comments in the highlights?\")reply",
      "Thanks for this history, very interesting! I guess I can see the reasoning there, but as an Econ major who took 6.001 for fun, it makes me a little sad. That class was mindbending and so interesting.reply"
    ],
    "link": "https://www.wisdomandwonder.com/link/2110/why-mit-switched-from-scheme-to-python",
    "first_paragraph": "Wisdom And WonderEquanimity \u039b ComputingCostanza asked Sussman why MIT had switched away from Scheme for their introductory programming course, 6.001. This was a gem. He said that the reason that happened was because engineering in 1980 was not what it was in the mid-90s or in 2000. In 1980, good programmers spent a lot of time thinking, and then produced spare code that they thought should work. Code ran close to the metal, even Scheme \u2014 it was understandable all the way down. Like a resistor, where you could read the bands and know the power rating and the tolerance and the resistance and V=IR and that\u2019s all there was to know. 6.001 had been conceived to teach engineers how to take small parts that they understood entirely and use simple techniques to compose them into larger things that do what you want.\nBut programming now isn\u2019t so much like that, said Sussman. Nowadays you muck around with incomprehensible or nonexistent man pages for software you don\u2019t know who wrote. You have to "
  },
  {
    "title": "Efficient Computer's Electron E1 CPU \u2013\u00a0100x more efficient than Arm? (morethanmoore.substack.com)",
    "points": 149,
    "submitter": "rpiguy",
    "submit_time": "2025-07-25T16:30:44 1753461044",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=44685050",
    "comments": [
      "This is a CGRA. It's like an FPGA but with bigger cells. It's not a VLIW core.I assume that like all past attempts at this, it's about 20x more efficient when code fits in the one array (FPGAs get this ratio), but if your code size grows past something very trivial, the grid config needs to switch and that costs tons of time and power.reply",
      "I agree this is very \"FPGA-shaped\" and I wonder if they have further switching optimisations on hand.reply",
      "My understanding is that they have a grid configuration cache, and are certainly trying to reduce the time/power cost of changing the grid connectivity.reply",
      "An FPGA startup called Tabula had the same thesis and it didn't work out well for them. Their configurable blocks had 16 configurations that they would let you cycle through. Reportedly, the chips were hell to program and the default tools were terrible.reply",
      "Though I'm sure this is valuable in certain instances, thinking about many embedded designs today, is the CPU/micro really the energy hog in these systems?We're building an EEG headband with bone-conduction speaker so in order of power, our speaker/sounder and LEDs are orders of magnitude more expensive than our microcontroller.In anything with a screen, that screen is going to suck all the juice, then your radios, etc. etc.I'm sure there are very specific use-cases that a more energy efficient CPU will make a difference, but I struggle to think of anything that has a human interface where the CPU is the bottleneck, though I could be completely wrong.reply",
      "Sounds a lot like GreenArray GA144 (https://www.greenarraychips.com/home/documents/greg/GA144.ht...)! Sadly, without a bizarre and proprietary FORTH dialect to call its own, I fear the E1 will not have the market traction of its predecessor.reply",
      "That was my first thought too. I really like the idea of interconnected nodes array. There's something biological, thinking in topology and neighbours diffusion that I find appealing.reply",
      "One day someone will get it working...Data transfer is slow and power hungry - it's obvious that putting a little bit of compute next to every bit of memory is the way to minimize data transfer distance.The laws of physics can't be broken, yet people demand more and more performance, so eventually the difficulty of solving this issue will be worth solving.reply",
      "That minimizes the data transfer distance from that bit of memory to that bit of compute.  But it increases the distance between that bit of (memory and compute) and all the other bits of (memory and compute).  If your problem is bigger than one bit of memory, such a configuration is probably a net loss, because of the increased data transfer distance between all the bits.Your last paragraph... you're right that, sooner or later, something will have to give.  There will be some scale such that, if you create clumps either larger or smaller than that scale, things will only get worse.  (But that scale may be problem-dependent...)  I agree that sooner or later we will have to do something about it.reply",
      "Pardon me but could somebody here explain to me like I am 15? Because I guess Its late night and I can't go into another rabbithole and I guess I would appreciate it. Cheers and good night fellow HN users.reply"
    ],
    "link": "https://morethanmoore.substack.com/p/efficient-computers-electron-e1-cpu",
    "first_paragraph": ""
  },
  {
    "title": "Animated Cursors (tattoy.sh)",
    "points": 120,
    "submitter": "speckx",
    "submit_time": "2025-07-25T17:59:25 1753466365",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=44686164",
    "comments": [
      "This is way cooler than I expected.It's an over-the-top animation of a terminal cursor moving from position to position, helps notice where it moved to. I thought it'll be something about mouse cursor animations. I could see myself using this if a) I was using more TUI apps and b) it'd be toned down quite a bit.reply",
      "I think was popularized by Neovidehttps://neovide.dev/features.html#animated-cursorreply",
      "Here it's less dramatic and hence more useful.I wish more terminals implemented something similar.reply",
      "Author here, I just chose the fire cursor for the demo. There are lots of other shaders available, eg https://github.com/KroneCorylus/ghostty-shader-playground/tr..., they have a simple smear cursor like Neovide's.reply",
      "The fire is perfect for the demo, and for screencasts maybe.reply",
      "Strong second.reply",
      "I never knew this was a thing.This is so fucking cool. I'm going to add this right away.reply",
      "The home page has GIFs of both a simpler smear-fade cursor and a wilder manga-slash cursor https://tattoy.shreply",
      "Reminds me of the old Compiz plugin that would make your windows burst into flames on closing.reply",
      "Compiz effects was truly the killer feature for Linux for 12 year old me :)reply"
    ],
    "link": "https://tattoy.sh/news/animated-cursors/",
    "first_paragraph": "Tattoy now supports animated cursors. It uses the same format as Ghostty, therefore rendering the cursor using custom shaders.Here are some popular Ghostty cursors, that you can use out-of-the-box with Tattoy.Even though Tattoy supports Ghostty cursors its rendering is quite different. Ghostty renders the cursor using actual pixels whereas Tattoy renders using UTF8 text-based \"pixels\", namely \"\u2580\" and \"\u2584\". This means that Tattoy cursors sometimes miss out on the subtleties of Ghostty cursors, but of course the pixelated effect might also be pleasing to some.Because Tattoy already has a shader based framework, it only took a couple of hours to get the first Ghostty shader working in Tattoy. But it took at least another week to iron everything out. One of the hardest issues was supporting transparency for the antialiased edges of cursor trails. Ghostty shaders expect to be able to sample the underlying pixels of the actual terminal, amongst other things it's this sampling that allows for "
  },
  {
    "title": "Developing our position on AI (recurse.com)",
    "points": 168,
    "submitter": "jakelazaroff",
    "submit_time": "2025-07-23T19:34:26 1753299266",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=44663072",
    "comments": [
      "Kinda funny but my current feeling about it is different from a lot of people.I did a lot of AI assisted coding this week and I felt,  if anything,  it wasn't faster but it led to higher quality.I would go through discussions about how to do something,  it would give me a code sample,  I would change it a bit to \"make it mine\",  ask if I got it right,  get feedback,  etc.  Sometimes it would use features of the language or the libraries I didn't know about before so I learned a lot.  With all the rubber ducking I thought through things in a lot of depth and asked a lot of specific questions and usually got good answers -- I checked a lot of things against the docs.  It would help a lot if it could give me specific links to the docs and also specific links to code in my IDE.If there is some library that I'm not sure how to use I will load up the source code into a fresh copy of the IDE and start asking questions in that IDE,  not the one with my code.  Given that it can take a lot of time to dig through code and understand it,  having an unreliable oracle can really speed things up.  So I don't see it as a way to gets things done quickly,  but like pairing with somebody who has very different strengths and weaknesses from me,  and like pair programming,  you get better quality.  This week I walked away with an implementation that I was really happy with and I learned more than if I'd done all the work myself.reply",
      "> I did a lot of AI assisted coding this weekAre you new to it? There's a pretty standard arc that starts with how great it is and ends with all the \"giving up on AI\" blog posts you see.I went through it to. I still use a chatbot as a better stack overflow, but I've stopped actually having AI write any code I use - it's not just the quality, it's the impact on my thinking and understanding that ultimately doesn't improve outcomes over just doing it myself.reply",
      "When's the last time you \"went through the loop\" ? I feel like with this stuff I have to update my priors about every three or four months.I've been using AI regularly since GPT 4 first came out a couple years ago. Over that time, various models from Sonnet to Gemini to 4o have generally been good rubber ducks. Good to talk to and discuss approaches and tradeoffs, and better in general than google + stack overflow + pouring over verbose documentation.But I couldn't really \"hand the models the wheel.\" They weren't trustworthy enough, easily lost the plot, failed to leverage important context right in front of them in the codebase, etc. You could see that there was potential there, but it felt pretty far away.Something changed this spring. Gemini 2.5 Pro, Claude 4 models, o3 and o4-mini -- I'm starting to give the models the wheel now. They're good. They understand context. They understand the style of the codebase. And they of course bring the immense knowledge they've always had.It's eerie to see, and to think about what comes with the next wave of models coming very soon. And if the last time you really gave model-driven programming a go was 6 months or more ago, you probably have no idea what's about to happen.reply",
      "Interesting point, I agree that things change so fast that experience from a few months ago is out of date. I'm sceptical there has been a real step change (especially based on the snippets I see claude 4 writing in answer to questions) but it never hurts to try again.My most recent stab at this was Claude code with 3.7, circa March this year.To be fair though, a big part of the issue for me is that having not done the work or properly thought through how a project is structured and how the code works, it comes back to bite later. A better model doesn't change this.reply",
      "I've been doing it for a while. I never really liked stack overflow though it always seemed like a waste of time versus learning how to look up the real answers in the documentation. I never really liked agents because they go off for 20 minutes and come back with complete crap But if I can ask a question get an answer in 20 seconds and iterate again I find that's pretty efficient.I\u2019ve usually been skeptical about people who get unreasonably good results and not surprised when they wake up a few weeks later and are disappointed.  One area where I am consistently disappointed is when there are significant changes across versions:  I had one argue over where I could write a switch in Java that catches null (you can in JDK 21) and lots of trouble with SQLAlchemy in Python which changed a lot between versions.  I shudder to think what would happen if you asked questions about react-router but actually I shudder to think about react-router at all.reply",
      "I've been back and forth, and currently heavily relying on AI-written code. It all depends on knowing what the AI can and can't do ahead of time. And what it can do often overlaps with grunt work that I don't enjoy doing.reply",
      "\"I would go through discussions about how to do something\"Have you compared that to your normal debugging thought processes?  I get that you might be given another way to think about the problem but another human might be best for that, rather than a next token guesser.I have a devil of a time with my team and wider, the younger ones mainly, getting them to pick up a phone instead of sending emails or chats or whatever.  A voice chat can solve a problem within minutes or even seconds instead of the rather childish game of email ping pong.  I do it myself too (email etc) and I even encourage it, despite what I said earlier - effective use of comms is a skill but you do need to understand when to use each variety.reply",
      "This is great, it's so easy to get into the \"go fast\" mode that this potential gets overlooked a  lot.reply",
      "> It would help a lot if it could give me specific links to the docsJust a super quick test: \"what are 3 obscure but useful features in python functools. Link to doc for each.\"GPT 4o gave good links with each example.(its choices were functools.singledispatch, functools.total_ordering, functools.cached_property)Not sure about local code links.reply",
      "I've had this return great results, and I've also had this return hallucinated ones.This is one area where MCPs might actually be useful, https://context7.com/ being one of them. I haven't given it enough of a shot yet, though.reply"
    ],
    "link": "https://www.recurse.com/blog/191-developing-our-position-on-ai",
    "first_paragraph": "This post started as a question: How should RC respond to AI? Regardless of whether you think large language models present a big opportunity, a looming threat, or something in between, we can likely agree that AI is everywhere, especially in the world of programming, and almost impossible to ignore.As operators of a programming retreat and recruiting agency, we\u2019ve found ourselves grappling with many of the questions AI raises: What does the existence of code generation tools mean for the craft of programming? In what ways do language models help or harm our ability to learn? Which skills do these tools make less important, and which ones do they make more important? What impact has the proliferation of coding agents and other LLM-powered tools had on software engineering jobs today, and what impact might it have in the coming years?Our interest in these questions is not academic; it\u2019s practical. AI has popped up in every aspect of our work, from our admissions process (should we let a"
  },
  {
    "title": "Steam, Itch.io are pulling \u2018porn\u2019 games. Critics say it's a slippery slope (wired.com)",
    "points": 382,
    "submitter": "6d6b73",
    "submit_time": "2025-07-25T16:27:51 1753460871",
    "num_comments": 513,
    "comments_url": "https://news.ycombinator.com/item?id=44685011",
    "comments": [
      "This actually took longer than I thought.\nIt is really weird that for all my adult content I have to go to a dedicated adult store, yet for games I can find them on Steam and gog where kids shop for games.You don\u2019t get porn movies on Netflix or Disney stream. You don\u2019t get adult toys in your local grocery store. Why do we sell porn on Steam?Why haven\u2019t game stores just spin off separate store front for porn content? It is basically free, since they already have the infrasructure.While being removed from general stores, porn has become very visible on big gaming platforms which majority of customers don\u2019t associate with porn. Backlash is inevitable.I think we can expect a bigger push against porn in general as pendulum swings back on the other side.reply",
      "> You don\u2019t get adult toys in your local grocery storeIn the US at least the classier vibrators have been starting to be sold first at shops like Sharper Image, and now, indeed, grocery stores.  The packaging of course would not raise any questions from kids, and they are sold in the same aisles as condoms and lubricant.  \"Sexual health\" is the umbrella term which feels like it is in play.reply",
      "Bookstores sell kids books and adult material just fine. The adult stuff might be behind the counter or in a certain area, same as stores like Steam where you have to actively seek it out.reply",
      "Also grocery stores sell alcohol, and I'm personally more fine with children getting access to porn than to liquor.reply",
      "I would not agree on this one. Both is detrimental on children\u2019s health.reply",
      "Dedicated porn sites are also being forced by the card companies to pull down porn. Also Steam/itch aren't where this started, they're in the third wave of companies getting held hostage over this. Digital tip jars and direct-payment creator  services were hit weeks ago.But the problem isn't porn. That's the low hanging fruit for a massive power grab The problem is that card companies can/will/did blackmail multiple companies into changing, and in some small cases shut-down their entire businesses.In a post-cash world, this is completely unacceptable, and a blatant power grab. If the payment processors are allowed to set this precedent, then there will be nothing to stop these for-profit companies from blocking anybody, anywhere from buying anything - for any or no reason.People are blaming a specific protest group. Personally I believe they are being scapegoated. And honestly if a tiny group from a tiny economy are so easily able to control international macroeconomics, then the root cause is still that the card services are vulnerable to such an attack.The only appropriate response is swift and severe regulation of these critically necessary card and banking services, up to and including the dissolution of both Visa and MasterCard - and in the US strict caps on card fees, as well as an amendment to the Constitution ensure that our right to own property permanently includes the right to buy property.Are the payment providers going to weaponize their de facto control over all purchases to target guns next? Churches? Birth control? Inner-City hospitals?\nWhich apps or social music companies do you think they'll allow to live, or die? \nWill they blackmail the Internet service providers? Political parties? Entire countries? Which side of which wars do you think Visa will force us to support? Is a company called \"MasterCard\" for or against letting people with your skin color buy food?\nYou don't know. Nobody knows. Nobody should have to know.It doesn't matter where you land politically, the point is that these companies cannot be allowed to wield this kind of control.\nOur society really does depend on it. \n...Because we can't go back to cash anymore, and they very much know it.reply",
      "> But the problem isn't porn. That's the low hanging fruit for a massive power grabI mostly agree with this.  There are legitimate issues with even the biggest and most respected porn sites being very lax with taking down underage and nonconsensual content.  The card companies AFAICT aren't being pressured to reform because of this kind of content, but more the LGBT content which is harming nobody.reply",
      "I do like bringing up the potential for dissolution. I would add just the general ways in which they profit off distorting the economy for massive private gains, often to the ruin of many individuals.Credit has become ubiquitous, in a manner that belies its supposed purpose, at least as was originally practiced before consumers were offered and employed credit for absolutely everything.Then again, governments and \"regulated\" entities are also capable of blackmail. I'm not sure these private companies would ever have an incentive to care about what you spend their money on unless governments gave them a reason to - which is why this is happening. At the end of the day you run into the same perpetual problem - you want x, some mob wants y. Good luck.reply",
      "Video rental stores, when those were still a thing, were the same way.  They'd have a room in the back with a curtain to section it off.reply",
      "It's not the same as an online store. There is a way for people to know kids are in a place they shouldn't be or to deny them access to adult content in real life. In Steam, there isn'treply"
    ],
    "link": "https://www.wired.com/story/steam-itchio-are-pulling-porn-games-censorship/",
    "first_paragraph": "Late in the evening on July 23, developers with games tagged as NSFW on Itch.io, a digital marketplace, began to notice something strange. Their work\u2014whether it was a game about navigating disordered eating as a teenager, or about dick pics\u2014no longer appeared in search results.\u201cNo notification or anything,\u201d says former NYU Game Center educator and developer Robert Yang, whose work explores gay history and culture. \u201cJust found out via Bluesky.\u201dItch.io is deindexing, or removing from its search index, any and all adult NSFW games, regardless of why they\u2019ve been tagged that way. Games are marked this way for a variety of reasons, whether it\u2019s due to sexual themes, discussions of mental health, or stories that otherwise involve triggering topics. On the Itch.io site, founder Leaf Corcoran said the \u201csudden and disruptive\u201d move is the direct result of an ongoing campaign by Collective Shout, an organization critics have alleged is \u201canti-porn.\u201d The group has recently targeted payment processo"
  },
  {
    "title": "Windsurf employee #2: I was given a payout of only 1% what my shares where worth (twitter.com/premqnair)",
    "points": 369,
    "submitter": "rfurmani",
    "submit_time": "2025-07-24T17:15:41 1753377341",
    "num_comments": 230,
    "comments_url": "https://news.ycombinator.com/item?id=44673296",
    "comments": [
      "Engineers: always negotiate for higher base salaries. In the vast majority of cases\u2014especially during acquihires\u2014your equity will be worth little or nothing. Founders and VCs still get paid; employees rarely do.Don't just accept promises. Ask for the 409A valuation, liquidation preferences, and pay bands. If a company won\u2019t provide transparency, that\u2019s your signal.Equity is a lottery ticket. Salary is money in the bank.reply",
      "my equity from 2years pre-acquisition: ~$2800. Then the CEO gave out bonuses when everyone threatened to quit. Then after his 3 month vacation to Italy, he came back driving his new Ferrari.My equity from 4 years ( employee ~60, grew to over 500 ): worthless. No one is able to exercise any options. They also readjusted when the valuation came below the total raised, making the value of my vested shares ~$13k ( down from ~$200,000 ) . They 'made us whole' by giving more shares with a new 4 year vesting schedule.Startups have found ways to fuck everyone but the investors with equity. It's confederate dollars; funny money. Maybe some people get great deals, I don't know. From my limited experience at very successful startups, the only people who made real money were those able to parley huge bonuses or base salaries.reply",
      "The fun part comes when you put in 20 years doing this, and your dream is to buy a nice house, and you finally get your seven-figure payout, and.... it's not enough to buy a house.   Because now a house is 3 million dollars.reply",
      "What kind of house had you been dreaming of? I live in SF, and even here $3M goes an awfully freaking long way.reply",
      "Maybe OP wants a house in atherton next to andreessen.reply",
      "anything within 45 minutes of your office in palo alto (where you are mandated to show up 5 days a week). this will get you a 1300sqft piece of shit built in 1964 with asbestos and lead paint and lead pipes and a cracked foundation (also some dipshit realtor had them paint all the original wood beams and paneling inside gloss white and replace the original wood and slate floors with grey vinyl) from some baby boomer forklift driver or mailman who paid 40k for it (you will pay 40k per year in property taxes for it), all for the privilege of \u201conly\u201d spending an hour of your life a day commuting so you can sit in your assigned area of your open concept office with noise canceling headphones on zoom meetings for 4 hours a day surrounded by other people on zoom meetings who also just expended a collective 5000 man hours and countless CO2 emissions to be there.reply",
      "I think you just illegally accessed my brain\u2026",
      "At some point, aren't the C Suite and directors failing their fiduciary responsibility? I know they have broad freedoms, but when you're reducing an a minority shareholder's equity by 95%, it's well past \"fiduciary responsibility\" and looking like fraud.reply",
      "I am convinced every executive and wanna-be executive is on the 'inside joke' of funneling money out of the company into their pockets.I am also convinced that investors believe it's the C Suite's responsibility to tear away any equity from employees to leave the largest pot for investors.reply",
      "ive been in these rooms and heard the conversations, employees are seen as disposable liabilitiesreply"
    ],
    "link": "https://twitter.com/premqnair/status/1948420769945682413",
    "first_paragraph": ""
  },
  {
    "title": "A Union Pacific-Norfolk Southern combination would redraw the railroad map (trains.com)",
    "points": 31,
    "submitter": "throw0101c",
    "submit_time": "2025-07-25T20:48:05 1753476485",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=44688265",
    "comments": [
      "What's the argument for the Union Pacific and Norfolk Southern merger [1]? Any rational admin would shoot down the merger immediately as this will create a massive monopoly.[1] https://www.reuters.com/world/us/union-pacific-talks-advance...reply",
      "> What's the argument for the Union Pacific and Norfolk Southern merger [1]?'Cost savings through synergies which will be passed down to customers.'(And certainly not shareholders and suits making more money.)reply",
      "They share essentially zero miles of track or routes.  A move only creates a monopoly if it reduces consumer choice.No freight customer is deciding \"Oh I can either ship from LA to Seattle, or Miami to DC.\"  They are shipping from one fixed location to a different fixed location. These railroads merging does not reduce their choices or give the combined entity more leverage.reply",
      "> They are shipping from one fixed location to a different fixed location. These railroads merging does not reduce their choices or give the combined entity more leverage.If someone on the US west coast wants to ship to the US east (or vice versa) they can pit UP against BNSF, and then NS against CSX. There are a few pairs up because of the two negotiating points:* UP-NS* UP-CSX* BNSF-NS* BNSP-CSXIf the merger goes through you're now at:* merged-UPNS* BNSF-CSXDo you think UPNS will give a cheaper price for a 'half-trip' and you go to their competitor the other half?You don't think BNSF/CN/CP aren't looking at CSX right now?reply",
      "That is a big assumption on your part that east coast ports don't compete with west coast portsreply",
      "How about monopsony?reply",
      "Monopoly?  No.  Union Pacific plus Norfolk Southern would have a monopoly on single-line end-to-end rail service in the US, true, but that's the kind of thing that you can get a \"monopoly\" in.  BNSF and CSX interchange with each other, after all.  And BNSF and CSX could (and almost certainly would) merge in response.  So there's no monopoly argument.Which doesn't mean that a rational regulator would not turn it down anyway.  But rational regulators may not be running the show at the moment.  UP sees that there may be an opportunity during the Trump administration.  (Note \"may\" - nobody knows whether there is an opportunity, but there is more of a chance than there was under Biden.)reply",
      "> Monopoly? No.How about oligopoly then.If UP/NS happens, we're down from six to five Class Is (ignoring Amtrak):* https://en.wikipedia.org/wiki/List_of_U.S._Class_I_railroadsThen BNSF/CSX? Or CN or CP go after CSX? That's four.Do we start seeing the acquiring of Class IIs?reply",
      "It's already an oligopoly.  Most cities only have one or two.  Of the few cities that have three or four (Chicago, say),  the merger would reduce that by one.Let's say you want to ship from Denver to Atlanta.  In Denver, you hand your stuff over to either Union Pacific or BNSF.  In Atlanta, you receive it from either NS or CSX.  You only have two options in Denver, and only two in Atlanta.  The merger doesn't change that at all.reply",
      "> It's already an oligopoly.So reducing competition to move further over on the oligopoly spectrum is good how?reply"
    ],
    "link": "https://www.trains.com/trn/news-reviews/news-wire/a-union-pacific-norfolk-southern-combination-would-redraw-the-railroad-map/",
    "first_paragraph": "Why Sign In? Subscribers, sign in to access exclusive content. Unlimited Members, sign in to enjoy sitewide access.News & Reviews News Wire A Union Pacific-Norfolk Southern combination would redraw the railroad map\nA merger would create a 52,000-mile system spanning the U.S. but would face regulatory obstacles\n\nA merger would create a 52,000-mile system spanning the U.S. but would face regulatory obstaclesGet the newest photos, videos, stories, and more from Trains.com brands. Sign-up for email today!Combining Union Pacific and Norfolk Southern into the first transcontinental railroad in the U.S. would create a 52,215-mile colossus that could offer seamless service from coast to coast, bypassing longtime interchange choke points in Chicago and at gateways along the Mississippi River.The two railroads confirmed today that they are in advanced merger discussions. The talks, they said, may not result in a deal. Plus, there\u2019s the potential for a bidding war if BNSF Railway, UP\u2019s Western ri"
  },
  {
    "title": "The future is not self-hosted (drewlyton.com)",
    "points": 231,
    "submitter": "drew_lytle",
    "submit_time": "2025-07-25T12:00:05 1753444805",
    "num_comments": 240,
    "comments_url": "https://news.ycombinator.com/item?id=44682175",
    "comments": [
      "Self-hosting isn't just about tech choices \u2014 it's about *who controls access to knowledge*.During the Enlightenment, owning a physical copy of a book meant intellectual freedom. You didn\u2019t rent ideas; you had them. Today, most digital knowledge is hosted, locked, or streamed \u2014 *leased from platforms*, not owned. We\u2019re in fact drifting into *digital feudalism*, where access to culture, tools, and even history depends on gatekeepers.In a perfect world this should go beyond market logic. It\u2019s not just a question of what's sustainable or profitable. It's about *civic autonomy*. If the infrastructure of knowledge is centralized, then so is control over thought.Self-hosting may not be for everyone, but *distributed, open systems are essential* to preserving a democratic and durable digital commons.reply",
      "I personally prefer owning my content, physical books, and having local copies.But if I\u2019m being honest, I think this claim that if you don\u2019t own the book you don\u2019t have the knowledge and society will turn into digital feudalism is hyperbole. Knowledge is proliferating faster than ever, becoming more accessible than ever, and it\u2019s easier than ever before to get the info that you\u2019re searching for, even in this streaming world. The idea that I\u2019m going to lose knowledge from a book I read 5 years ago if it disappears from my library just doesn\u2019t track. In fact, it\u2019s rare that I return to my physical books these days because I can find equivalent info faster from a quick search online.Don\u2019t get me wrong: I prefer having my own copies and so on. However, when people start throwing around concepts like \u201cdigital feudalism\u201d and trying to draw parallels to the enlightenment it feels like this is all some abstract philosophical debate rather than a discussion of what\u2019s really happening in the world.reply",
      ">  Knowledge is proliferating faster than ever, becoming more accessible than ever, and it\u2019s easier than ever before to get the info that you\u2019re searching forInformation is proliferating and is more accessible, but a huge amount of that information is lies and manipulation I'm not sure that really counts as knowledge.> The idea that I\u2019m going to lose knowledge from a book I read 5 years ago if it disappears from my library just doesn\u2019t track.You might not forget what you learned from a book you read 5 years ago after it gets stolen from you, but it does mean that others are cut off from that same information. Worse is that what you saw 5 years ago might still be made avilable, but only in censored/altered forms which could easily have you questioning your memory of something you read or saw just 5 years ago.It's not just an abstract philosophical debate that books and other forms of media are being changed, censored, or removed entirely. Or that gatekeepers want to decide what we're allowed to see and extract rent from us every time that we do. The dangers are real and understood and very much present in today's world.reply",
      "> Information is proliferating and is more accessible, but a huge amount of that information is lies and manipulation I'm not sure that really counts as knowledge.I don't think that's any different to any other period of time when communication was suddenly able to expand. Gutenberg's press didn't come with an automatic lie detector that meant the printed word could only contain true facts and nothing else. Instead, it was mainly used for pamphlets and other campaigning propaganda - some of which surely had some truth to it, but much of which was partially or fully fabricated.I think you are romanticising the past's approach to the written word here. It has always been possible to completely rewrite history, if you're willing to put the work in, and totalitarian regimes have had no issues in convincing their populations to burn their own books if necessary.",
      "> Knowledge is proliferating faster than ever, becoming more accessible than ever, and it\u2019s easier than ever before to get the info that you\u2019re searching for, even in this streaming world. The idea that I\u2019m going to lose knowledge from a book I read 5 years ago if it disappears from my library just doesn\u2019t track. In fact, it\u2019s rare that I return to my physical books these days because I can find equivalent info faster from a quick search online.The real problem with this is that there are vested interests at play in managing what information you see first - push something to the 2nd or 3rd page of google results and it becomes effectively invisible, especially when you have pages and pages of results that seem to push the narrative that those vested interests want you to see.I tend to think that Huxley was right over Orwell, information is lost in the shuffle of distraction and rigged systems. The \"truth\" is there to find, but it's a needle in a haystack of believable lies, and those lies were crafted specifically to obfuscate that nugget of truth.So the amount of information moving around is irrelevant if it's not useful, or it's intentionally misleading from something that might upset those who benefit from the status quo.reply",
      "I think when people say \"digital feudalism\", they usually mean that the spaces where we do things digitally are increasingly owned by private entities that operate them for their own benefit. It's an analogy which can't be expected to align perfectly with historical feudalism.reply",
      "> from a quick search onlineI would have agreed with you a few years ago. But now Google, DuckDuckGo etc. at most provide 3 pages of results, with many irrelevant or wrong. There are alternatives:https://wiby.me/\nhttps://clew.se/\nhttps://kagi.com/But that's not the majority experience and more importantly, it shows that it really can be \"taken\" from us.reply",
      "Knowledge is not proliferating faster than ever. It's being gobbled up and locked down by companies whose sole interest is making as much money as they can instead of improving the world and profiting from the improvement.Media is being deleted or locked in vaults.Games are being shut down with no way to restore them.The written word that has been vetted by people with domain specific knowledge is being locked behind paywalls and not being advertised, while AI machines directly lie to the curious and the seekers of knowledge.I can throw a digital stone in any direction and hit something that is worse off thanks to the modern internet.reply",
      "The blog post talks about our self-hosting movies, photos, and podcasts, in nice Netflix-like interfaces. Sharing photos. That sort of thing.You are talking about preserving intellectual independence.Both are nice to have, but they are sort of different problems, right? Yours seems more important. And yours could probably be solved by a local copy of Wikipedia and an FTP server full of digital textbooks.IMO one dangerous misstep we can make with self-hosting is to assume we need to start by matching the centralized services look-and-feel and polish (which is getting worse every year anyway).reply",
      "> one dangerous misstep we can make with self-hosting is to assume we need to start by matching the centralized services look-and-feel and polishThat's an interesting take. I think matching these services isn't a necessity, but getting a polished look-and-feels just helps adoption. Adoption isn't an exclusive scenario and everyone is free to choose and mix how they see fit.My private collection won't ever compete with Netflix, Google or the like, and that's completely fine. It will stay a private selection of media with a strong personal preference - it ranges from research to entertainment, and also includes stuff that documents my own individual history. It'll shrink and grow as I want it, and if it reaches a scale that makes the jump from archival to hoarding work I'd simply need to reconsider my preferences.Here's my take: The scaling issues of these tech giants won't ever reach my personal archive and any challenges with re-indexing, data analysis etc. should be completely approachable on SOTA hardware. Running anything that improves the searchability of my own archive can be run locally and in the timely intervals I prefer. To have this kinda quality approachable is a huge thing, and I can't wait until I can self-host some RAG enhanced vector search engine for a personal archive that grew overs years to take shape.reply"
    ],
    "link": "https://www.drewlyton.com/story/the-future-is-not-self-hosted/",
    "first_paragraph": "Hey friends \ud83d\udc4b,A few months ago, Amazon announced that Kindle users would no longer be able to download and back up their book libraries to their computers. Thankfully, I still have access to my library because I saw this video by Jared Henderson warning of the change and downloaded all ~400 of my books immediately.But for those that didn't, the only way for them to view the books they own is through a Kindle or the Kindle app.Which raises the question: do they even own those books?If you can only access an item through an intermediary that decides the terms and means of your access, I'd say no. You don't own your books on Kindle. You rent them from Amazon.And Amazon agrees with this. When they closed this direct way for users to access their eBooks, they also updated the language in the Kindle store to say users are purchasing licenses \u2013 not books!Now, this isn't new. Companies like Amazon have been playing dirty with Digital Rights Management (DRM) since the Internet's inception. Purc"
  },
  {
    "title": "Never write your own date parsing library (zachleat.com)",
    "points": 134,
    "submitter": "ulrischa",
    "submit_time": "2025-07-25T17:36:25 1753464985",
    "num_comments": 154,
    "comments_url": "https://news.ycombinator.com/item?id=44685875",
    "comments": [
      "When ever i see \"never implement your own...\", i know i want to implement it myself. People say that about hard things, and I only want to do hard things. Nobody wants people who can do easy things, people want people who can do hard things. The only way to learn how to do hard things, is to do hard things, so do the hardest things.So go ahead, write your own date library, your own Unicode font rendering, compiler, OS, game engine or what ever else people tell you to never do because its hard.reply",
      "By all means, write it. Just don't use it. These warnings are almost always in the context of code you're going to release, not exercises in learning on your own.reply",
      "In the case of date libraries, I think if I ported the tests from a few well-known libraries to my own, I'd have reasonable confidence in my own.Having said that, I don't think date libraries are hard, I think they're messy. Mostly because humans keep introducing convenience fudges - adding a second here, taking eleven days off there, that kind of thing.reply",
      "I would not be surprised if the state of unit tests on good date parsing libraries are not sufficient to design a new one from scratch.See the number of unit tests in the Linux kernel, for example.reply",
      "You might be right, I haven't checked. It just seems on the face of it such an easy thing to test. Scalars go in, scalars come out. (This could just be me doing the Dunning-Kruger thing).You could run a fuzzer against two libraries at the same time to find discrepancies....... hmm. That might actually be a good exercise.reply",
      "This is such nonsense. All the stuff that we use, someone wrote. If nobody makes them, then how is that going to work?The messaging here is that you should be careful about using what you build on your own because it:- hasn't been battle tested- likely has bugs- isn't matureThe only way that it will be all of those things is if someone invests time and energy in them.From an ecosystem perspective this is absolutely the right thing. You want duplicate projects. You want choice. You want critical knowledge to be spread around.reply",
      "> If nobody makes them, then how is that going to work?I see it as \u201cDont write your own X, unless you want to maintain X. Here be dragons, this problem is deeper than it appears, the first 80% will be easy, the next 15% will annoy you, and the last 5% will consume your life for weeks, months, or even years. Or you could use a library\u201dreply",
      "I think there is missing point  in this discussion.Most of the time you build something else.Like if you build a todo app and have to deal with scheduling you don\u2019t spend time making date library because it\u2019s not your goal. But people would do that.Heck most developers instead of starting blog on a blog platform start writing code for their own blogging engine.reply",
      "It's about exposure.The things that people write that everyone uses have had HUGE exposure.They've been exposed to all the edge cases, they've been tested millions, if not billions of times. All the bugs ironed out.The people who've worked on them are now the greatest domain experts on that little corner of comp-sci.Yours won't unless it hits prime time.So yours will be weak, brittle and dangerous.reply",
      "In order to have these mature libraries, someone hat to start building them. They all had to to be incomplete, immature and horribly buggy early in their lifetime, too.reply"
    ],
    "link": "https://www.zachleat.com/web/adventures-in-date-parsing/",
    "first_paragraph": "Never write your own date parsing library.Never. No exceptions.Never have I ever\u2026So\u2026 I\u2019ve written my own date parsing library.Why? Our story begins seven years ago in the year 2018. I made the very sensible choice to adopt luxon as the Date Parsing library for Eleventy. This parsing behavior is used when Eleventy finds a String for the date value in the Data Cascade (though YAML front matter will bypass this behavior when encountering a YAML-compatible date).This choice was good for Eleventy\u2019s Node.js-only requirements at the time: accurate and not too big (relatively speaking). Eleventy has used luxon since @0.2.12 and has grown with the dependency all the way through @3.7.1. Now that\u2019s what I call a high quality dependency!As we move Eleventy to run in more JavaScript environments and runtimes (including on the client) we\u2019ve had to take a hard look at our use of Luxon, currently our largest dependency:Given that our use of Luxon is strictly limited to the DateTime.fromISO function fo"
  },
  {
    "title": "CO2 Battery (energydome.com)",
    "points": 105,
    "submitter": "xnx",
    "submit_time": "2025-07-25T16:32:32 1753461152",
    "num_comments": 97,
    "comments_url": "https://news.ycombinator.com/item?id=44685067",
    "comments": [
      "Lithium-ion batteries are falling in cost so rapidly that any new process being ramped up is risky business. Form is way further along than this landing page and yet has a long way to go:https://www.latitudemedia.com/news/form-energy-brings-in-mor...The scale of investment required makes it quite hard for new companies to compete on cost:https://www.theinformation.com/articles/battery-industry-sca...reply",
      "What about from an environmental standpoint if we think about that these Lithium--Ion batteries will have to be replaced and recycled every (as the article says, not sure if true) <12 years. We have a history of not pricing in negative externalities, did we do that this time?reply",
      "> environmental standpoint if we think about that these Lithium--Ion batteries will have to be replaced and recycled everyI am very interested in this question, but those who raise it never have answers about the negative impacts of mining lithium.For example, the amount of lithium needed for an EV is an order of magnitude less than the amount of steel needed. What is so bad about lithium mining that it's 10x worse than iron mining, pound for pound?Nobody has ever answered my request for environmental concerns with a concrete environmental lithium mining concern, such as acidification that can sometimes happen with iron mining.I've researched and researched, found nothing, which leaves me thinking that the worst case scenario for lithium is no worse than the worst case for iron.Meanwhile, we have such immense documented harms from fossil fuel extraction that nobody ever questions again, or with the same intensity that's reserved for supposedly toxic lithium batteries.The apparent benefit is massive, so any delay seems to cause massive harm to the environment.I think we need to flip the question: where is the proof that coal/oil/iron is better for the environment than mining and recycling batteries? (BTW, it's at least 20 years now for grid batteries, with lifetime going up all the time...)reply",
      "Any analysis of EVs vs ICE cars I've seen put EVs at 1.5-2x the carbon footprint to produce, but win out in the long run.  My default assumption has always been it comes from the battery pack - I'm not sure what else could cause such a difference.reply",
      "My understanding (bowing to ChatGPT) is that you can get 1 pound of iron from <2 pounds of iron ore. But to get 1 pound of lithium, you need around 500 pounds of lithium ore.So if an electric car requires 2000 pounds of iron and 50 pounds of lithium, that works out to 4000 pounds of iron ore that needs to be mined and refined, vs 25,000 pounds of lithium ore.reply",
      "Interesting, but tailings never seem to enter much into environmental analyses that I have seen, unless you count coal ash as \"tailings\" which would be a pretty broad interpretation of the idea.Lithium is also extracted via brine, as opposed to hard rock. Most of the environmental reporting has been on the brine approaches, which currently are in high elevations of South American mountains, and the problem appears to be mostly the use of land and taking that land out of the ecosystem for economic use as drying pools. But the same problem occurs with mining, too!reply",
      ">So if an electric car requires 2000 pounds of iron and 50 pounds of lithium, that works out to 4000 pounds of iron ore that needs to be mined and refined, vs 25,000 pounds of lithium ore.means recycling of lithium batteries will be a thriving business. (i.e. big difference from recycling of say tires or plastic bottles, more like, pretty successful, recycling of aluminum, and even better than it)reply",
      "That's why hybrids are great, hedges your bets between iron and lithiumreply",
      "Non-plugin hybrids typically do not use lithium batteries.reply",
      "Is this still the case? Haven't most of the manufacturers switched over from NiMH?reply"
    ],
    "link": "https://energydome.com/co2-battery/",
    "first_paragraph": ""
  },
  {
    "title": "SRAM Has No Chill: Exploiting Power Domain Separation to Steal On-Chip Secrets (acm.org)",
    "points": 16,
    "submitter": "zdw",
    "submit_time": "2025-07-25T22:47:52 1753483672",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://cacm.acm.org/research-highlights/sram-has-no-chill-exploiting-power-domain-separation-to-steal-on-chip-secrets/",
    "first_paragraph": ""
  },
  {
    "title": "Running PostmarketOS on Android Termux proot without a custom ROM (2024) (ivonblog.com)",
    "points": 28,
    "submitter": "user070223",
    "submit_time": "2025-07-23T07:28:58 1753255738",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://ivonblog.com/en-us/posts/postmarketos-in-termux-proot/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: I built a biological network visualization tool (nodes.bio)",
    "points": 7,
    "submitter": "jmg421",
    "submit_time": "2025-07-25T11:38:19 1753443499",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44682033",
    "comments": [
      "Looks potentially cool but your mobile version needs work, currently looks like its brokenreply",
      "Thats a terrible ontology (the relations) - needs to be much lower level to understand anything important.reply"
    ],
    "link": "https://nodes.bio",
    "first_paragraph": ""
  },
  {
    "title": "Programming vehicles in games (wassimulator.com)",
    "points": 233,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-25T14:41:03 1753454463",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=44683682",
    "comments": [
      "> Interestingly, while the engine has the most moving parts in real life, in code, it's the simplest piece of the entire car simulation. Because at its core, the engine is just a torque calculator. It's concerned with producing a single output: rotational torque, from a set of inputs. It is essentially a blackbox.This just reminded me of AngeTheGreat's incredible video series showing his engine simulator- absolutely worth checking out, considering it's optimized enough to run in real-time! The fact that he's simulating it well enough to generate realistic sound is absolutely mind-blowing.https://www.youtube.com/watch?v=RKT-sKtR970reply",
      "The game Automation has quite an in depth engine builder/simulation aspect to it. It's very fun to mess around with, and the sound simulation uses some of the concepts AngeTheGreat has in his videos.reply",
      "Classic of how to animate a cube in Houdini:https://www.youtube.com/watch?v=NLiL0GLSvIw(tldw: Real time internal combustion engine simulation something unexpected.)reply",
      "In addition to some other things, I was responsible for all vehicle simulation in Army of Two. This article is a good starting point. I was glad they mentioned implementing Pacejka\u2019s tire model and the transmission differential in the article - those help a lot. Aside from that, I was surprised (not surprised) how important an anti-roll bar physics sim and suspension sim helped make driving feel \u201cfun\u201d.That\u2019s the most important follow up. Without it, you\u2019ll notice that the driving feels icy - I see it in the demo video. Most folks who fail to do the anti-roll bar and suspension wind up with cars that easily flip on turns - so they make the tires slip or they play with the surface friction, which makes the driving experience worse.reply",
      "Thank you for this! I wasn't aware that anti-roll bars carry that much importance in a rudimentary model. I will look into that next, and update the article accordingly once I get it working.reply",
      "Classic game. One of the first shooter co-ops I can remember playing!reply",
      "Fun fact: the standing turrets are vehicles without wheelsreply",
      "This very closely mirrors what I discovered when I made Flightle[1].I made it in anger when I played a sidescrolling flight \"simulator\" on my phone in which the plane didn't behave anything like a plane! I figured \"how hard can it be\" and started learning a lot about how planes fly. It turned out there was a level of abstraction that was just right. Too unrealistic felt static and unsatisfying. Too realistic was difficult to calibrate for fun gameplay.[1]: https://xkqr.org/flightle/reply",
      "Fun game, have you considered allowing people to control the sliders with their scroll wheel if they're on a desktop web browser?reply",
      "A while ago I made a game for iOS that simulates vehicles and drifting. It was built in SpriteKit but very easy to do in any 2d game engine. The idea is: you put two wheels in front, connect them to the rectangle car shape with pin joints and then you apply force to the wheels. The angle of the force is very easy to calculate:\nx = force * cos(bodyRotation + wheelRotation)\ny = force * sin(bodyRotation + wheelRotation)That's it! I also added skid particles. The drifting was achieved by playing around with the wheels and body damping. The game is here: https://apps.apple.com/app/drift-mania-infinite-car-racer/id...reply"
    ],
    "link": "https://wassimulator.com/blog/programming/programming_vehicles_in_games.html",
    "first_paragraph": "I make stuffThe fundamental principles needed to get a functional vehicle in your game.\r\n  From my talk at the \r\n  Better Software Conference \r\n  on July the 13th, 2025.\r\n  est. reading time: 45 minutes\nWatch the video of the talk here:Cars are everywhere in games. They're a staple element of many genres, even in games that aren't strictly about cars. If a game world involves any sort of traversal, chances are there's a vehicle in it (unless you're deep in the realm of fantasy where you are riding a horse. The following will not cover programming horses, I apologize).The range of experiences that games offer through vehicles is massive. And that's what makes them fascinating to work with. Ever since I was a kid, I've played a variety of racing and vehicle games. I'd always chase the next racing title as soon as it hit the platform I had. But what struck me over time wasn't just the excitement of new cars or tracks; it was how different each experience felt, even though they all had car"
  },
  {
    "title": "Show HN: Price Per Token \u2013 LLM API Pricing Data (pricepertoken.com)",
    "points": 286,
    "submitter": "alexellman",
    "submit_time": "2025-07-25T12:39:41 1753447181",
    "num_comments": 118,
    "comments_url": "https://news.ycombinator.com/item?id=44682465",
    "comments": [
      "(I work at OpenRouter)We have solved this problem by working with the providers to implement a prices and models API that we scrape, which is how we keep our marketplace up to date. It's been a journey; a year ago it was all happening through conversations in shared Slack channels!The pricing landscape has become more complex as providers have introduced e.g. different prices for tokens depending on prompt length, caching, etc.I do believe the right lens on this is actually the price per token by endpoint, not by model; there are fast/slow versions, thinking/non-thinking, etc. that can sometimes also vary by price.The point of this comment is not to self promote, but we have put a huge amount of work into figuring all of this out, and have it all publicly available on OpenRouter (admittedly not in such a compact, pricing-focused format though!)reply",
      "By endpoint, do you mean price by token by API shape? Perhaps my phrasing is even more confusing but that is how I see it. I.e. there are API \"shapes\" for which as long as the shape of the API is the same, my application can use it interchangeably with others.  Other dimensions are quality, speed, acceptable error rates, etc., which naturally influence pricing.reply",
      "I tried making it compact and easy just now! Thanks so much for the effort!https://github.com/tekacs/llm-pricingreply",
      "But the data is... wrong? Google Gemini 2.5 Flash-Lite costs $0.10/mtok input [1] but is shown here as $0.40/mtok?[1] https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-fla...reply",
      "the data is not wrong you are reading my table wrongedit: my bad I was wrong shouldnt have responded like thisreply",
      "Ouch, bad response for someone with a business!reply",
      "The input is wrong thoYour website reports 0.30$ for input and that wouldn't make any sense as it would be priced the same as the bigger Flash model.reply",
      "ok yeah fixed that one, sorry...reply",
      "such level of condescending behaviour when you yourself are wrong is not allowed.Put a really really bad taste in my mouth.reply",
      "First poster could have approach better too. Like \"Cool site! I think I may see an error on one item?\". Instead of going right to a 'wrong' angle as if all the data should be discredited. I get highly triggered by this too.reply"
    ],
    "link": "https://pricepertoken.com/",
    "first_paragraph": " Up-to-date pricing information for major LLM APIs including OpenAI, Anthropic, Google, and more. Compare costs across different AI models and find the best value for your use case. * Some models use tiered pricing based on prompt length. Displayed prices are for prompts \u2264 200k tokens. Built by @aellmanGet weekly updates on LLM pricing changes and new modelsAll pricing information comes from official provider sources:Disclaimer: Providers don't all count tokens in the same way, but generally a token is equivalent to 3-4 characters. Please refer to each provider's documentation for their specific tokenization methods. \u00a9 2025 Price Per Token. Up-to-date LLM API pricing information.Data updated regularly from official provider sources."
  }
]