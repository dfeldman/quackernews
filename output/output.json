[
  {
    "title": "macOS 15.2 breaks the ability to copy the OS to another drive (shirtpocket.com)",
    "points": 26,
    "submitter": "zdw",
    "submit_time": "2024-12-14T01:04:24 1734138264",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.shirtpocket.com/blog/index.php/shadedgrey/youre_a_mean_one/",
    "first_paragraph": "macOS 15.2 was released a few days ago, with a surprise. A terrible, awful surprise.Apple broke the replicator. Towards the end of replicating the Data volume, seemingly when it's about to copy either Preboot or Recovery, it fails with a Resource Busy error.In the past, Resource Busy could be worked around by ensuring the system was kept awake. But this new bug means, on most systems, there's no fix. It just fails.Since Apple took away the ability for 3rd parties (eg, us) to copy the OS, and took on the responsibility themselves, it's been up to them to ensure this functionality continues to work. And in that, they've failed in macOS 15.2.Because this is their code, and we're forced to rely on it to copy the OS, OS copying will not work until they fix it.To put it bluntly, this sucks. It's bad enough we have to work around other bugs in this code, but when it breaks completely, we're stuck pointing fingers and offering workarounds that don't involve the replicator.What this means is th"
  },
  {
    "title": "Luon programming language combines concepts from Oberon and Lua (github.com/rochus-keller)",
    "points": 47,
    "submitter": "thunderbong",
    "submit_time": "2024-12-13T23:37:45 1734133065",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42413343",
    "comments": [
      "This is an impressive achievement, given there\u2019s a whole language plus IDE.  Kudos to the author.  I couldn\u2019t see any indication of what the author plans to use it for - I hope he can share more below?I\u2019m intrigued by the LeanQt library as well that the IDE uses (https://github.com/rochus-keller/LeanQt) too.\n \nreply",
      "Luon looks mostly like Oberon and not so much like Lua, it's not obvious which of the Lua features it incorporated.  It didn't seem to have coroutines, for example.But I am glad that it went with Oberon's 0-based array indices, as opposed to Lua's 1-based table indices.https://github.com/rochus-keller/Luon/blob/master/specificat...\n \nreply",
      "I have a really hard time understanding why people like 0 based indexes. \nThey are a relic of C style arrays that are based on and interchangeable with pointers which use offsets that are naturally 0 based.\nUse in later languages gives us endless off-by-1 issues and rise to \"for 0 to count/len/num - 1\" or even better range syntax that is start inclusive BUT end exclusive.\nIt is a horrible cludge just to support 1970s language perfomace optimization.\nArrays should start and end at whatever start index is required, not at offset 0 of pointer to fist element of array.\n \nreply",
      "Hang on. Off by one issues are the argument frequently given in favour of zero-based indices, not the other way around. For example, let's iterate through items placing them in 3 different groups;JS:    for (let i = 0; i < items.length; i++) {\n        groups[i % 3].push(items[i]);\n    }\n\nLua:    for i = 1, #items do\n        table.insert(groups[((i - 1) % 3) + 1], items[i])\n    end\n\nDon't get me wrong. I like Lua, I've made my own IDE for it, https://plugins.jetbrains.com/plugin/14698-luanalysis, but this is definitely not an argument in favour of 1-based indices.\n \nreply",
      "Some countries consider the 1st floor to be the ground floor, others consider the 1st floor to be the floor above the ground floor, which the formerly mentioned countries consider the 2nd floor\u2026 I think 0/1-based indexing is more subjective than simply being a \u201crelic of C\u201d or a \u201chorrible kludge\u201d :P\n \nreply",
      "Slam!  Now this guy really knows how to hate on a zero based index!\n \nreply",
      "> locals can no longer be used before declarationThere's a lot I like about Lua but it so happens that a few days ago I spent longer than I'd like to admit debugging a trivial typo for Advent of Code day 5 that would have been caught by this.Wondering if Luon will also prohibit or at least warn about storing nil in a table.\n \nreply",
      "It's nice when a project can find such a simple pronouncable name that is also meaningful.\n \nreply"
    ],
    "link": "https://github.com/rochus-keller/Luon/blob/master/Readme.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          Luon is a high-level programming language with a syntax similar to Oberon+, Oberon-07 and Oberon-2, integrating concepts from Lua, and targeting the LuaJIT VM. Luon can be regarded as a statically typed version of Lua. The name is thus a combination of \"Lua\" and \"Oberon\".Luon procedures can be declared \"external\" and be implemented in Lua. This allows the re-use of libraries written in Lua, and also C libraries via\nthe LuaJIT foreign function interface.The language specification can be found in the specification subdirectory.\nSee also the code examples below.The project is the result of the author's experience with the Smalltalk-80 and SOM VM implementation, and the prospect to build a LuaJIT based Interlisp VM.In contrast to Oberon+, Luon doesn't have pointers, but instead all structured datatypes have reference semantics and are dynamicall"
  },
  {
    "title": "My PhD advisor rewrote himself in bash (might.net)",
    "points": 13,
    "submitter": "signa11",
    "submit_time": "2024-12-14T00:53:30 1734137610",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://matt.might.net/articles/shell-scripts-for-passive-voice-weasel-words-duplicates/",
    "first_paragraph": " The hardest part of advising Ph.D. students is teaching\nthem how to write.Fortunately, I've seen patterns emerge over the past couple years.\nSo, I've decided to replace myself with a shell script.\n In particular, I've created shell scripts for catching three problems:\n\nabuse of the passive voice,\nweasel words, and\nlexical illusions.\n\n And, I've integrated these into the build system of our LaTeX documents.   The point of these scripts is not to ban all use of constructs\nlike the passive voice.\n\n(When it comes to writing, there are exceptions to every \"rule.\")\n\nThe point of these scripts is to make sure that my students and I make a\nconscious choice to use these constructs.\n When these scripts highlight a sentence, my students should ask\nthemselves, \"Is there a better way to say what I said--a way to make\nthe text read with more clarity and precision?\"  Often enough, the\nanswer is \"yes.\"   The meta-point of this article is that writers should learn their\nindividual weaknesses.\n\nAnd, wh"
  },
  {
    "title": "Sharing new research, models, and datasets from Meta FAIR (meta.com)",
    "points": 137,
    "submitter": "ilaksh",
    "submit_time": "2024-12-13T21:07:08 1734124028",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=42412360",
    "comments": [
      "There\u2019s honestly so much interesting stuff here, esp. the llm-related things - large concept models (operating on and predicting concepts, not tokens), dynamic byte latent transformers (byte-level alternative to standard tokenization), sparse memory layers (successfully scaling key-value memory layers without an increase in computational requirements).Here they are presented as separate things, each of which apparently improves quality / efficiency. I wonder what the quality / efficiency increase is of all those methods put together? Maybe that\u2019s what Llama 4 will be?This looks like a lot of innovation is happening at Meta in those areas, really cool!\n \nreply",
      "This is so cool! Playing around with the first demo is a lot of fun. First one to get the model to moonwalk wins. My best attempt was probably something like `(body_speed_forward < -0.3) * (head_height > 1.0) * (stay_still > 0.2) * (body_speed_vertical < 0.1) * (stay_upright > 0.9)`https://i.imgur.com/O5hGMo5.gifThen the \"Meta Explore Theory of Mind\" is even more interesting. There was a thread about a month ago in which some of us were discussing some of the concepts here like \"beliefs\" and updating a model of the world accordingly. https://news.ycombinator.com/item?id=42035985\n \nreply",
      "Every time I have to clean text I wonder why I haven\u2019t just trained a byte level denoising autoencoder to handle it for me.\n \nreply",
      "I really hope Dynamic Byte Latent Transformers work out. Death to tokenizers!Interesting that it's a a hierarchical structure but only two levels of hierarchy. Stacking more levels seems like an obvious direction for further research.\n \nreply",
      "Can someone explain how watermarking AI videos voluntarily helps make AI safer?\n \nreply",
      "It lets those providing AI video generation services watermark all of their videos. So it isn't intended to by voluntary. You would be left with those services that don't comply with whatever the current Big Tech rules are, like people who used Grok/X.ai to generate images in support of Trump despite Grok/X.ai being inferior. https://arstechnica.com/information-technology/2024/08/musks...\n \nreply",
      "This is like learning 10 different new architectures lol\n \nreply",
      "Crazy stuff. Everyone\u2019s covering how exciting all these are (especially LCM and the non-tokenizing-tokenizer), but I have to ask in case anyone\u2019s been paying attention: why are they using the term \u201cadvanced machine intelligence\u201d?My initial thought is that they want to please/distract the doomers, but I\u2019m prolly just self-centered!\n \nreply",
      "It originates in Yann LeCunn\u2019s paper from 2022 [1], the term AMI being district from AGI. However, the A has changed over the past few years from autonomous to advanced and even augmented, depending on context[1] https://openreview.net/pdf?id=BZ5a1r-kVsf\n \nreply",
      "I would guess it\u2019s in response to the recent market studies showing that the general public views anything labeled \u201cAI\u201d as a likely scam and untrustworthy.\n \nreply"
    ],
    "link": "https://ai.meta.com/blog/meta-fair-updates-agents-robustness-safety-architecture/?_fb_noscript=1",
    "first_paragraph": "TakeawaysAs we continue to work towards our goal of achieving advanced machine intelligence, we want to share our progress with the research community so they can build upon our work. Today, we\u2019re excited to release some of the latest research, code, models, and datasets from Meta Fundamental AI Research (FAIR). The artifacts we\u2019re sharing today focus on building more capable agents, robustness and safety, and architecture innovations that enable models to learn new information more effectively and scale beyond current limits.In this release, we\u2019re sharing a demo and code for Meta Video Seal, an open source model work video watermarking that builds on the popular Meta Audio Seal work we shared last year. We\u2019re also sharing a variety of other artifacts, including a foundation model for controlling the behavior of virtual embodied agents, a method for scaling memory layers that will enable more factual information, and code to help models become more socially intelligent. There\u2019s plenty "
  },
  {
    "title": "Exotic new superconductors delight and confound (quantamagazine.org)",
    "points": 140,
    "submitter": "ernesto95",
    "submit_time": "2024-12-09T15:47:42 1733759262",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=42367290",
    "comments": [
      "Wow. Go over to [1] and read the papers. This is good stuff. When someone finds new physics, interesting things result.Tungsten disulfide/boron nitride superconductors? That's a new direction.This article describes a new research result as a new research result, not as \"trillion dollar industry by 2027\". That helps credibility.[1] https://physics.mit.edu/faculty/long-ju/\n \nreply",
      "As someone who knows nothing about this, how is something like \"Tungsten disulfide/boron nitride\" selected? Is it based on some models? Or, is it more of a random walk?\n \nreply",
      "They're two materials that 2D materials people commonly stock. BN is thought to be a pretty innocuous insulator. Might as well be the lettuce of the sandwich. However, it's now showing that it has effects on the nearby layers, so people are playing with it in heterobilayer devices.A large part of the field of 2D materials is just trying stuff.\n \nreply",
      "They are choosing from a subset of materials that can form stable 2D crystals in order to test effects of relative twist angles on their energy bands.\n \nreply",
      ">This article describes a new research result as a new research result, not as \"trillion dollar industry by 2027\".I don't like that language either, but it may be wise to understand that different audiences are reading this, and it may be effective for the author to reach the others in this way. And besides, in general it's easier for a rationalist to ignore such language than it is for an industrialist to add it.\n \nreply",
      "Bollocks. \"Hype language\" has a very strong correlation with people who don't know what they're talking about. (Probably because most people who use it do not, in fact, know what they're talking about, even if some might.) So other experts in the field will look down on you if you speak like a British university press release.\n \nreply",
      "I agree with you. I just think it is wasted effort to complain about the quality of press releases. I am consigned to their poor quality, and my solution is to read primary sources.\n \nreply",
      "otoh, \"a graphene device produced a mythical form of superconductivity\":)\n \nreply",
      "The great thing about watching advances in superconductors is that any day we could discover the first true practical room temp superconductor and that one day changes the world immensely. I personally think we are likely to find one in the next 5-10 years, but that estimate is based on nothing but hope and optimism on my part.\n \nreply",
      "For the most valuable applications it is also \"good enough\" to find a superconductor that can be cooled with cheap liquid nitrogen and retain the magnetic field tolerance, current-carrying capacity, and thermal stability of a superconductor cooled with expensive liquid helium.Some so-called \"high temperature\" superconductors begin superconducting at liquid-nitrogen temperature or higher. However in real life applications like MRI and particle accelerators it turned out that they still need to be cooled with much colder liquid helium to get the desired magnetic field tolerance, current-carrying capacity etc. Finding a high-quality liquid-nitrogen-grade superconductor with these desired properties would be a revolution in itself.\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/exotic-new-superconductors-delight-and-confound-20241206/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesDecember 6, 2024The new superconductors are all two-dimensional materials, honeycomb sheets of atoms that can be stacked and twisted to produce kaleidoscopic patterns and a vast range of behaviors.Mark Belan/Quanta MagazineStaff WriterDecember 6, 2024This year, superconductivity \u2014 the flow of electric current with zero resistance \u2014 was discovered in three distinct materials. Two instances stretch the textbook understanding of the phenomenon. The third shreds it completely. \u201cIt\u2019s an extremely unusual form of superconductivity that a lot of people would have said is not possible,\u201d said Ashvin Vishwanath, a physicist at Harvard University who was not involved in the discoveries.Ever since 1911"
  },
  {
    "title": "The Pentium FDIV bug, reverse-engineered (oldbytes.space)",
    "points": 116,
    "submitter": "croes",
    "submit_time": "2024-12-11T18:33:06 1733941986",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=42391079",
    "comments": [
      "An anecdote regarding this bug that always cracks me up. My college roommate showed up with a shiny new pentium machine that year, and kept bragging about how awesome it was. We used some math software called Maple that was pretty intensive for PCs at the time, and he thought he was cool because he could do his homework on his PC instead of on one of the unix machines in the lab.Except that he kept getting wrong answers on his homework.And then he realized that when he did it on one of the unix machines, he got correct answers.And then a few months later he realized why ....\n \nreply",
      "The mention of Maple brings back vivid memories of freshmen year of college when the math department decided to use the software as part of instruction and no one understood how to use it. There was a near revolt by the students.\n \nreply",
      "The story was posted a couple days ago and ken left a couple comments there:\nhttps://news.ycombinator.com/item?id=42388455I look forward to the promised proper write up that should be out soon.\n \nreply",
      "Oh to remember mid-90s humorHow many Intel engineers does it take to change a light bulb? 0.99999999\n \nreply",
      "Why didn\u2019t Intel call the Pentium the 586? Because they added 486+100 on the first one they made and got 585.999999987.\n \nreply",
      "This dude pulled out a microscope and said \"there's your problem.\" Super impressive work. Really great micro-read.\n \nreply",
      "To be fair, he knew what the problem was (errors in the lookup table) beforehand.\n \nreply",
      "This is probably one of the reasons Intel went to a microcode architecture after.I wonder how many yet to be discover silicone bugs are out there on modern chips?\n \nreply",
      "Older Intel CPUs were already using microcode. Intel went after NEC with a copyright case over 8086 microcode, and after AMD with a copyright case over 287/386/486 microcode:- https://thechipletter.substack.com/p/intel-vs-nec-the-case-o...- https://www.upi.com/Archives/1994/03/10/Jury-backs-AMD-in-di...I would totally believe the FDIV bug is why Intel went to a patchable microcode architecture however. See \u201cIntel P6 Microcode Can Be Patched  \u2014 Intel Discloses Details of Download Mechanism for Fixing CPU Bugs (1997)\u201d https://news.ycombinator.com/item?id=35934367\n \nreply",
      "Look at how long the public errata lists are, and use that as a lower bound.Related article: https://news.ycombinator.com/item?id=16058920\n \nreply"
    ],
    "link": "https://oldbytes.space/@kenshirriff/113606898880486330",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: @smoores/epub, a JavaScript library for working with EPUB publications (npmjs.com)",
    "points": 84,
    "submitter": "smoores",
    "submit_time": "2024-12-13T19:52:26 1734119546",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=42411727",
    "comments": [
      "I feel stupid. I read \u201cautomatically syncing ebooks and audiobooks\u201d and thought StoryTeller was a file synchronization service (like SyncThing) that for some reason only supported certain file types.Maybe \u201csyncing ebooks with audiobooks\u201d would be clearer? Also entirely possible this is just a me problem, not a general one.Really cool project!\n \nreply",
      "Extracting a library from a real world project is one of my favorite parts of software.I'm sure the march of LLMs will continue eating into this pie, and that's a good thing (most of it is a distraction from the real work), but I love polishing a library on my laptop in a cafe. It's like working on a painting or something.\n \nreply",
      "It was, actually, very enjoyable! When we pulled React ProseMirror[1] out of the NYT text editor, it was a pretty laborious process that we had to careful plan and execute for months, and we still ended up with an internal fork for a while.By contrast, this was mostly just moving a file around and then writing documentation and cleaning up the public API. I rather enjoy thinking about and modeling library APIs in general, so I actually had a lot of fun with it![1]: https://www.npmjs.com/package/@nytimes/react-prosemirror\n \nreply",
      "Cool! I totally could have used this earlier this year... can't remember what for...Interesting choice to publish from the storyteller \"monorepo.\" Is that because it evolved in situ, and you've no impetus to incur the overhead of extraction?\n \nreply",
      "Hahaha, well if it comes to you, the library will still be there for you :)Right, this was actually just a file within the Storyteller web package to start. It was fairly well defined, and so pretty easy to pull out into another package in the monorepo, but Storyteller is the primary consumer at the moment, and I want to be able to develop them in sync. Plus, it provides a great test bed for development of the library!edit: I forgot to mention that the eventual goal is to (hopefully!) publish this package as @storyteller/epub, along with any other packages that end up split out of Storyteller. That will probably include at least a @storyteller/synchronize and a @storyteller/cli.Unfortunately, someone seems to have snagged the @storyteller org on NPM several years ago and left it to languish without really using it, so I'm waiting to see whether GitHub will consider this squatting and transfer the org to me.I've also tried reaching out to the developer that owns the org, but they don't seem to have been active on GitHub or NPM for the past 5 years or so, and my only real strategy for reaching out to them was to open an issue on one of their other GitHub projects!\n \nreply",
      "Storyteller seems pretty cool in general. Can it be used to host books for other people?\n \nreply",
      "Thanks! Absolutely. You can invite users to your Storyteller server and give them whatever permissions are appropriate (e.g. you can choose whether they can only download books, or can also manage uploading and syncing books and/or managing users). It has SMTP support for emailing invites, or it can just generate invite links for you to share yourself.More info here: https://smoores.gitlab.io/storyteller/docs/administering#inv...\n \nreply",
      "Oh my! This looks very neat, and I\u2019ve been working on something similar to Storyteller (i think): https://github.com/project-kiosk/kioskI don\u2019t get around working on it right now, but maybe there\u2019s something useful there for you.\n \nreply",
      "Something I've been wondering: why do ebooks take so long to render? My kindle seems good at it, but opening an ebook in calibre/fbreader/etc can take minutes or even fail in some readers depending on the ebook.\n \nreply",
      "I would guess there are multiple potential pitfalls here. Firstly, not all ebook formats are created equal -- Storyteller only operates on EPUB files, because EPUB is an open source format and it supports Media Overlays (read-aloud) natively. I can only really speak to that format, but there are others (MOBI, PDF, etc).An EPUB is just a ZIP archive of XML and XHTML files (plus other assets, like images). Partly, I suspect, because of the dearth of actively maintained open source projects in the space, and partly because of the nature of tech in the book publishing industry, EPUB generation software used by authors and publishers often messes up this spec, which means that EPUB readers sometimes need to have fairly complex fallback logic for trying to figure out how to render a book. Also, because EPUBs are ZIP archives, some readers may either unzip the entire book into memory or \"explode\" it into an unzipped directory on disk, both of which may result in some slowness, especially if the book has lots of large resources. The newest Brandon Sanderson novel, for example, is ~300MB _zipped_.Additionally, and perhaps more importantly, EPUBs (and I believe MOBIs as well) represent content as XHTML and CSS, which means that readers very often need to use a browser or webview to actually render the book. Precisely how they deliver this content into the webview can have a huge impact on performance; most browser don't love to be told to format entire novels worth of content into text columns, for example.\n \nreply"
    ],
    "link": "https://www.npmjs.com/package/@smoores/epub",
    "first_paragraph": "A Node.js library for inspecting, modifying, and creating EPUB 3 publications.npm:yarn:Throughout this library's documentation, there will be many references to\nthe EPUB 3 specification. The lower level APIs\nexposed by this library require some knowledge of this specification. Here we\nwill cover the very basics necessary to work with the library, but we recommend\nthat users read through the linked specification to gain a deeper understanding\nof the format.An EPUB file is a ZIP archive with a partially specified directory and file\nstructure. Most of the metadata and content is specified as XML documents, with\nadditional resources referenced from those XML documents.The most important of these documents is the\npackage document.The package document is an XML document that consists of a set of elements\nthat each encapsulate information about a particular aspect of an EPUB\npublication. These elements serve to centralize metadata, detail the\nindividual resources, and provide the reading orde"
  },
  {
    "title": "Pompeii experts back Pliny's account of Mount Vesuvius eruption date (theguardian.com)",
    "points": 25,
    "submitter": "bookofjoe",
    "submit_time": "2024-12-12T21:06:34 1734037594",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42403324",
    "comments": [
      "The article doesn't explain the charcoal inscription discrepancy?\n \nreply",
      "https://www.forbes.com/sites/kristinakillgrove/2018/10/16/ne... says:> it is not known whether the Oct 17 graffito referred to that day, or a day in the past or the futureThe last option would explain it, potentially.\n \nreply",
      "Fun fact: we know the Vesuvius eruption, whatever the date, was on a Wednesday. How? Because we found a bread called Panis Quadratus that was only baked on Wednesdays [1].Pompeii (and Herculaneum) are endlessly fascinating and about a third of Pompeii remains underground and hasn't been examinted yet.[1]: https://www.visitnaples.eu/en/neapolitanity/flavours-of-napl...\n \nreply",
      "What if it was from the day prior?\n \nreply",
      "The bread was found in the oven of one of the bakeries[1]. It wouldn't be in the oven if the bread was from the day before.[1] https://www.bbc.com/travel/article/20230406-arculata-the-bre...\n \nreply",
      "then it'd be stale\n \nreply"
    ],
    "link": "https://www.theguardian.com/world/2024/dec/12/pompeii-experts-back-plinys-account-of-mount-vesuvius-eruption-date",
    "first_paragraph": "Study suggests Pliny\u2019s 24 August AD79 more likely than autumn dates suggested in 18th centuryThe date on which Mount Vesuvius erupted, wiping out the lives of thousands in ancient Pompeii and other nearby towns, has long divided scholars.But a study by Pompeii experts suggests that the Roman author Pliny the Younger probably had it right all along: the volcano erupted on 24 August AD79 and not later in the year as has been suggested.Pliny wrote about the eruption in two letters after having witnessed it from the home of his uncle, Pliny the Elder, in Miseno. His account of when Vesuvius unleashed its fury started to be disputed in the late 18th century, with 24 October AD79 becoming the mostly widely hypothesised date. A charcoal inscription, dated 17 October, excavated in Pompeii\u2019s archaeological park in 2018, added credence to this theory.Another written account of the eruption was provided by the Greek-Roman historian and senator, Cassius Dio, who referred to it occurring in the aut"
  },
  {
    "title": "Making my first robot as a software engineer (github.com/robertleoj)",
    "points": 198,
    "submitter": "robertleoj",
    "submit_time": "2024-12-10T22:31:32 1733869892",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=42382357",
    "comments": [
      "Super cool. And it reminds me why to do these projects: you learn so much in pursuing the project end-goal: motor selection, 3D printing, model slicing, ESP32 programming, etc.I expect to see a second robot soon with significant changes based on the lessons learned.(I too just picked up a Bambu A1 printer after deciding to dive a little more into 3D printing. I can confirm it is amazing compared to the Ender-3 I had only dabbled with a bit before.)\n \nreply",
      "I've been a software engineer for 40+ years now. I still remember the one time I wrote firmware for a cable-driven robot hand. It's such a rush to type a command on a keyboard, and something on the bench next to you goes \"wrrrrp!\".\n \nreply",
      "This. I remember in the 90's working on a software to control a plastic molding machine that made plastic cups, and hit enter and feel the power of a pneumatic system pushing up  the platform where i was standing.\n \nreply",
      "Awesome writeup! As someone who is roughly in this same stage of hardware learning, this had me laughing.> I went into \"screw with it until it works\" mode. I took it apart, re-applied the magnet, swapped wires around, did all kinds of stuff. After a while of this, the error finally went away! No idea why though.\n \nreply",
      "This gave me a chuckle too - such a familiar experience\n \nreply",
      "For a more refined machine, there is the XScara[0], a DIY SCARA 3D Printer that can be used for more than 3d print. I made one and change the 3d print head with a laser system, and also had a pen that can be used as a plotter.[0] https://github.com/madl3x/x-scara\n \nreply",
      "The SO100 arm[1] and LeRobot[2] community are great too if you're getting into robotics from the software side of things.Demonstration of the arm: https://x.com/ChrisMGreer/status/1867278261631561996[1]https://github.com/TheRobotStudio/SO-ARM100[2]https://github.com/huggingface/lerobot\n \nreply",
      "Cool project! Since the arm seems to be a 2 DoF arm in a 2D application, you don't really need numerical optimization but can get the analytical solution to the inverse kinematics problem. Otherwise using previous joint states as initial guess for the optimization is good so that you don't get weird \"swings\" in the arm (rarely happen in 2D)\n \nreply",
      "To put it simply: there's only one solution for each 2d position, if you force the mid joint to always be on one side (and that preferred side can be allowed to switch, to minimize accelerations of the lower arm).\n \nreply",
      "Very nice project, haven\u2019t seen many xy plotters built like that.Instead of inventing your own, you could have used Gcode as the protocol language.\n \nreply"
    ],
    "link": "https://github.com/Robertleoj/pen_plotter_robot/blob/main/story.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          I recently made this a vision-controlled pen plotter:People seemed to like it and were asking about it, so I thought I'd write about it here!I recently started working as a computer vision software engineer at a robotics company.This is my first time working in the robotics industry, and I've been thoroughly enjoying it.\nI've found it to be insanely satisfying to write code that translates into real-world, physical machines completing tasks intelligently.Of course, this is facilitated by physical machines - hardware. Motors, electronics, springs, power converters, 3D printed creative designs, and all kinds of stuff I have never worked with before. Absolutely fascinating.So, I decided I'd take a stab at this hardware stuff in my free time.The project I decided to go with was building a robotic pen plotter.Ok, so I want to make a pen plotter. "
  },
  {
    "title": "Show HN: Imposter Attack \u2013 Among Us-themed infrared game made with ESP32 (langworth.com)",
    "points": 146,
    "submitter": "statico",
    "submit_time": "2024-12-13T17:00:19 1734109219",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=42410229",
    "comments": [
      "> I was told that I had the second biggest crowd, second only to a Pok\u00e9mon bean bag game (which did look pretty cool). Some adults were curious, but most importantly, a handful of questions from kids who wanted to know how I built it. It was especially rewarding to show one off one of the extra targets I brought. One kid even recognized the ESP32 chips and said, \u201cOh, these are the ones you can make drones out of!\u201dThat paragraph really stood out to me. Apparently, where OP lives, people casually make stuff even cooler than a laser shooting game for a one-off school event, and elementary-school-age kids recognize specific types of microcontrollers.\n \nreply",
      "1 out of 115 kids recognizing a microcontroller doesn't seem that surprising considering many kids play with little electronics kits these days.\n \nreply",
      "Part of me wants to say, \"Well, that's Silicon Valley for you,\" but I'm confident there are many other places you could say something similar about.Compared to what my neighbors are working on and with self-driving cars roaming around, infrared shooting games seem pretty mild :)\n \nreply",
      "Super impressive project, especially for what seems to be your first embedded project. I haven't played with microPython/uOTA so this was an interesting read.Since you mentioned the water meter Flume, I wanted to shamelessly plug my open source water meter that I'm currently developing. It also uses the ESP32 so I thought you might be interested.Main page. https://y-drip.com/Docs: https://y-drip.com/docs/site/v0.4/\n \nreply",
      "Liked the reference to uOTA - OTA updater for MicroPythonhttps://github.com/mkomon/uota\n \nreply",
      "Great timing. I've been wanting to learn how to do projects like this, but been so unsure what types of microcontroller I should get and what else could be needed. Similar in the software world where we all have our preferred tech stacks, I was so uncertain of what stack to use for these projects that it definitely causes a hurdle.His mention of the ESP32 and how>While working on the game I used my newfound ESP32 skills to do some other projects, such as automating the remote-controlled blinds in our bedroom as well as a motion sensor that would send Pushover notifications to my phone.is absolutely what I'm wanting to be able to do. Learn the tech needed for one controller that can be used on tons of different places. That, plus that talk with MicroPython (and other parts) gives some confidence about learning this hardware stack.\n \nreply",
      "I'd say you're on the right track, then! It's kind of like software \u2014 figure out how the components talk to each other and figure out where to hook in. Instead of APIs, you've got multimeters and oscilloscopes.In the case of the blind automation, the remote uses some kind of proprietary wireless signal. Instead of figuring that out, I soldered some leads into the remote's momentary button terminals, which I connected to transistors on a breadboard. The ESP32 simply pretends to press a button and complete a connection on the remote.Also check out ESPHome (https://esphome.io), a firmware for ESP32 that lets you more easily integrate with home automation systems.\n \nreply",
      "This took a few evenings to make :)Full source code is on GitHub: https://github.com/statico/imposter-attack-2024\n \nreply",
      "This is awesome! I may try to get this working locally with my 6 year old son!\n \nreply",
      "Shoot me a message if you need any help!\n \nreply"
    ],
    "link": "https://blog.langworth.com/imposter-attack",
    "first_paragraph": "  13 December 2024   \u00b7 17 min read   \u00b7 Effort: 4+ months \u00b7 Fun: Maximum  At Legoland California this past summer I rode a Lego-styled ancient Egyptian adventure ride where you travel through a tomb and shoot as many snakes and mummies and things as you can with a laser gun. Two things occurred to me while riding: the fact that Legoland thought it a good idea to equip kids with lasers, and the thought that I could make a shooting gallery game like this that people would like.Making games is fun. Games are the reason lots of people get into programming, including me. Some people even make a profession out of them. Even though this was months before Halloween, the game that appeared in my mind was a fun, shoot-em-up carnival-style game, and maybe I could inspire a few kids with software and hardware along the way.But this wasn\u2019t just a \u201cthis will be fun\u201d idea. I\u2019ve noticed a pattern about myself and it\u2019s been the basis of many of my projects or even companies. I see bits of technology and"
  },
  {
    "title": "Web Origami, for making websites where you can understand how they\u2019re made (weborigami.org)",
    "points": 161,
    "submitter": "ayoreis",
    "submit_time": "2024-12-13T14:43:05 1734100985",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=42408819",
    "comments": [
      "My interest in this is piqued. I\u2019m really happy to see people doing things to simplify personal standalone website authorship making it expressive and flexible without a bulky content management system or jumping through hoops for some front-end toolchain. I know when I\u2019m developing things I\u2019m often as or more concerned with satisfying multiple use cases or functionality extensibility, but having a nice focused tool polished for one use case is nice. When I was deep in web dev and had my machine set up with a selection of go-to docker setups for different dev needs and the knowledge of how that all needed to be orchestrated was fresh in my mind, deploying most of the SSGs or whatever seemed trivial. Now in the odd event that I have a personal project or whatever that indicates more than just a few static handmade pages, the first thing I do after looking up what todays web world consider to be the \u201cobvious\u201d best tools and practices is see how many people are asking about counterintuitive config issues or other getting-started type problems. As cool as whatever application might look, I know I\u2019ve got about two good hours in me of recall, research and troubleshooting before I just say \u201cfuck it. Guess I didn\u2019t want to do that project anyway.\u201d The point of those tools is to save time and energy \u2014 you don\u2019t have to get very far outside \u201cthe loop\u201d for it to take more effort than it\u2019s worth to get back in for a lot of them. Simple tools for simple tasks are great when you know you\u2019ll never ever need built-in hooks to wrangle graphql queries and automatically invalidate CDN caches and generate 10 sizes of images optimized for every conceivable device or whatever.\n \nreply",
      "Whats wrong with just using HTML, Js and CSS for personal projects?\n \nreply",
      "I do that. Duplicating the header, menu, and footer manually on every page is a pain in the ass. Not to mention the lack of minification.\n \nreply",
      "Not sure I follow, do you not use templates and scripts to generate the static pages?I was a web developer 25 years ago and for the majority of projects we only made static sites, all templated and minified. My skills are somewhat \"of that time\".Recently I was asked to build a site to demonstrate some new software. It consisted of over 10k pages that once built would rarely, if ever be updated.I just scripted and templated the generation of every single page hosted it in S3. This may sound ridiculous in this day and age but it takes a few minutes to rebuild and update the entire site.Guess my point is I don't really find duplicating things to be a pain in the ass\n \nreply",
      "I don\u2019t think it sounds ridiculous, it sounds like you picked the right tool for the job. Don\u2019t bring dynamic solutions to static problems\u2026\n \nreply",
      "I think this issue better addressed in HTML spec. Basic functionality to include html snippets files in other HTML files should be standard. What am I missing?\n \nreply",
      "Why do you care if your personal site is minified?\n \nreply",
      "Because some people care about low-bandwith users. Or about not being wasteful as a principle.\n \nreply",
      "Doesn't compression make any minification gains negligible?\n \nreply",
      "So... it's a static site generator? I've looked through the site, but I'm having trouble putting it in context. Sounds like it takes data and turns it into a static website. Is that right?\n \nreply"
    ],
    "link": "https://weborigami.org",
    "first_paragraph": "A language for making websites where you can understand how they're madeOrigami is a new programming language that complements HTML and CSS for making small- to medium-scale websites.Everybody has something to say, and the web is a great place to say it, but creating interesting sites can be hard or expensive. Standard HTML and CSS let you define individual pages, but it\u2019s hard to efficiently create a bunch of pages and organize them into a coherent site.Corporate site hosting services offer nice drag-and-drop editors but impose creative limitations and high monthly costs. You could build something from scratch \u2014 if you master a full programming language like JavaScript and a pile of industrial development tools. The web needs better ways to create sizable, expressive sites at low cost and without entanglements.Origami is designed for you: someone who wants to make a site for yourself or a small organization, who can HTML and CSS, who\u2019s not a professional developer \u2014 or is, but wants t"
  },
  {
    "title": "Schr\u00f6dinger's IPv6 Cat (ripe.net)",
    "points": 31,
    "submitter": "minusf",
    "submit_time": "2024-12-11T13:30:07 1733923807",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=42387475",
    "comments": [
      "Shown in the article, but not linked:Google's IPv6 adoption statistics: <https://www.google.com/intl/en/ipv6/statistics.html>Facebook's IPv6 adoption statistics: <https://www.facebook.com/ipv6/?tab=ipv6_total_adoption>\n \nreply",
      "I work for a major open source network software company, we support IPv6 natively and in the past 2 years I've been asked about IPv6 by my customers exactly...zero times.\n \nreply",
      "My company would only ask for IPv6 if a software doesn't support IPv6 though.\n \nreply",
      "My hunch is that AWS charging for v4 addresses will start applying pressure across a broad cross-section of businesses as they start asking why don\u2019t they just use the free thing\n \nreply",
      "Having IPv4 just for your public facing servers is a small expense, and within the private network you can still use private IPv4. The biggest pressure is to allow your servers to call out into the internet without an IPv4 address or a NAT. That's pressure on APIs, SaaS services consumed by backend servers, update servers, etc.Maybe that's enough to remove the friction around IPv6 and make it \"just work\" to the point that everyone just keeps it on. Or maybe it doesn't and we get a divide where everything consumed by machines moves to IPv6 while content consumed by humans keeps preferring IPv4.\n \nreply",
      "Half of AWS services aren't even available from an IPv6 endpoint, it's a clusterfuck. I'm all for carrot and stick but they are making  a giant mess of it.Source: https://docs.aws.amazon.com/vpc/latest/userguide/aws-ipv6-su... , see 'IPv6 only support' column.\n \nreply",
      "> ... see 'IPv6 only support' column.Is that relevant? There's nothing wrong with having RFC1918 addresses and globally-routable IPv6 addresses assigned to your VPC.Have the RFC1918 addresses accessing IPv4-only AWS resources and the globally-routable IPv6 addresses serving the world. Easy.After all, the major cloud providers don't charge for RFC1918 addresses... they just charge for globally-routable IPv4 addresses.\n \nreply",
      "> There's nothing wrong with having RFC1918 addresses and globally-routable IPv6 addresses assigned to your VPC.It's a pretty backwards way to build your network. You pay all the costs and gain none of the benefits.\n \nreply",
      "I'm afraid I don't follow.The way to express the design in a pure-IPv6 world would be that you use ULA addresses to reach the AWS services that you use and globally-routable addresses to reach the outside world.Given that the cost that we're avoiding paying with the mechanism I described in my previous post is the ongoing cost for globally-routable IPv4 addresses, I'm not sure what cost you're talking about paying.And given that the benefits are not having to pay for globally-routable IPs, I'm not sure what benefits you're talking about that we don't get?Are you perhaps one of those \"Hosts must be IPv6-only, no dual-stack allowed!\" people? If so, I regard that as a silly stance today, and expect it will remain a silly stance for the next several decades (maybe even the next century, who knows?).\n \nreply",
      "Yeah. For example, ECR (Elastic Container Registry) is _not_ available on IPv6. Anything \"serverless\" such as ElastiCache or RDS is also not available.So it means that you can't have a fully-IPv6 stack for any modern application on AWS.\n \nreply"
    ],
    "link": "https://labs.ripe.net/author/hisham_ibrahim/schrodingers-ipv6-cat/",
    "first_paragraph": "Want to contribute? Learn how\n            Based in Dubai, UAE\n          \n        Hisham Ibrahim is the Chief Community Officer at the RIPE NCC. He leads the RIPE NCC's engagement efforts to foster a dynamic, inclusive RIPE community. He is responsible for engagement with RIPE NCC members, the RIPE community, Internet governance and training services. Hisham is active on several committees in various \u2026 More\n13 min readIPv6, a protocol developed in the late 1990s to address the anticipated Internet address exhaustion crisis, exists in a paradoxical state. For some, while its adoption might have taken longer than expected, it represents a success story - steadily expanding in deployment and enabling more users and devices to connect to the Internet. For others, it appears stalled and increasingly irrelevant, overshadowed by the enduring dominance of IPv4-based solutions, especially as the predicted exhaustion crisis never fully materialised. Much like Schr\u00f6dinger\u2019s famous cat, its status "
  },
  {
    "title": "Ask HN: What should I do with meet.hn?",
    "points": 144,
    "submitter": "sirobg",
    "submit_time": "2024-12-13T17:38:30 1734111510",
    "num_comments": 98,
    "comments_url": "https://news.ycombinator.com/item?id=42410582",
    "comments": [
      "I run a club for a certain car.The thing is, people generally don't want to be responsible for organizing meetups. Many will happily attend but not host.My guess is you need to find community leaders who can handle and own the responsibilities involved with hosting meets in their areas.At the end of the day I don't think a website is going to help convince people to take on that kind of role. It's more of a personality thing.With my club, we use Facebook events and generally just screenshot the details and further disperse them that way to discord, slack, instagram, etc. But none of that is enough alone for someone to host. Even when it's as simple as picking a meet location and time and sending out invites.\n \nreply",
      "Thanks for the perspective!I think I have a communication problem with meet.hn.People seem to assume it has been created to setup these kinds of large meetups.In fact, I created it for small or even 1-1 meetups in the first place.\nMeeting a single person or a small group of people seems much more interesting, easy and valuable to me.Of course I'm not assuming everyone thinks the same way, but don't you think there is an audience for that in the HN community?\n \nreply",
      "I'd consider the demographics of people who regularly visit HN. Not to put a slight on anyone but I think a good chunk of people on here probably don't enjoy in-person meetups.Again, IME it's not the size of the meetup but the responsibility.Even in my example, the average attendance is maybe 10-20 people. Sometimes as low as five people.And some areas only have 5 or fewer regularly.\n \nreply",
      "What might work better is an HN forum with regional or city subforums (structured based on HN member density). First get HNers living close to each other to communicate, then they will meet up by themselves.Of course, there\u2019s the moderation issue.\n \nreply",
      "Hmm if I wanted to meet up with one person from HN, I would just contact them using the details in their profile. If there were no contact details, I wouldn't meet with them. I don't quite see the value for 1:1 meetups I guess.\n \nreply",
      "How would you know this person is located in your area or in the area you might visit some time?I guess you would have to dig, right?Well, with meet.hn:1. You don't have to dig2. People are more willing to meet on average than a random person on the internet3. You can also check other locations and other people super fast\n \nreply",
      "For in person with unknown people I think large gatherings can break down the fear wall as people can assess before commiting.For most hn users offering something virtual would be more more inline with expectations and removes those local barriers.\n \nreply",
      "also, many will signup to attend and bail last minute\n \nreply",
      "Very true. About Meetup.com specifically (a couple of years ago at least), attending rate was something like 15-20% of the people who RSVP'd.\n \nreply",
      "I get about ~40-50% attendance rate from meetup, but we've been going for years so the regulars are pretty consistent.\n \nreply"
    ],
    "link": "item?id=42410582",
    "first_paragraph": ""
  },
  {
    "title": "Noninvasive imaging method can penetrate deeper into living tissue (news.mit.edu)",
    "points": 147,
    "submitter": "rbanffy",
    "submit_time": "2024-12-13T13:34:34 1734096874",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42408271",
    "comments": [
      "Mary Lou Jepsen of openwater.cc [2] has managed to image neurons and other large cell structures deep inside living bodies by phase wave interferometry and descattering signals through human tissues, even through skull and bone[1] using CMOS imageing chips, lasers, ultrasonics and holographics. A thousand times cheaper fMRI. She aims to get to realtime million pixels moving picture resolutions of around a micron. Eventually she will be able to read and write neurons or vibrate and someday maybe burn cell tissues to destruction.There are later presentations at the website where the technique is better described and visualized, but [1] is a good quick place to start and judge if you want to study their brainscanner in more depth. There are patents and a few scientific publications [3] that I'm aware of, but mostly many up to date talks with demonstrations by startup founder Mary Lou [4]. And recently she is open sourcing[5] parts of the hardware and software on github [6] so we can start building our own lab setups and improve the imageing software.[1] https://www.youtube.com/watch?v=awADEuv5vWY[2] https://www.openwater.health/[3] https://scholar.google.com/citations?hl=en&user=5Ni7umEAAAAJ...[4] https://www.youtube.com/watch?v=U_cHAH4T8Co[5] https://www.youtube.com/watch?v=hNFQtpNHufk[6] https://github.com/OpenwaterHealth\n \nreply",
      "I remember she did a talk at the Long Now Foundation a while back. My take away - which could be completely wrong - was that they saw the potential to read and write memories.\n \nreply",
      "From the OpenwaterHealth/opw_neuromod_sw README: https://github.com/OpenwaterHealth/opw_neuromod_sw :> open-LIFU uses an array to precisely steer the ultrasound focus to the target location, while its wearable small size allows transmission through the forehead into a precise spot location in the brain even while the patient is moving.Does it use one beam of the array to waveguide another beam? For imaging or for treatment?From \"A simple technique to overcome self-focusing, filamentation, supercontinuum generation, aberrations, depth dependence and waveguide interface roughness using fs laser processing\" (2017) https://www.nature.com/articles/s41598-017-00589-8 https://scholar.google.com/scholar?start=10&hl=en&as_sdt=5,4... :> We show that all these effects can be significantly reduced if not eliminated using two coherent, ultrafast laser-beams through a single lens - which we call the Dual-Beam technique. Simulations and experimental measurements at the focus are used to understand how the Dual-Beam technique can mitigate these problems. The high peak laser intensity is only formed at the aberration-free tightly localised focal spot, simultaneously, suppressing unwanted nonlinear side effects for any intensity or processing depth. Therefore, we believe this simple and innovative technique makes the fs laser capable of much more at even higher intensities than previously possible, allowing applications in multi-photon processing, bio-medical imaging, laser surgery of cells, tissue and in ophthalmology, along with laser writing of waveguides.\n \nreply",
      "Interesting, but probably not cheap:> This is achieved by having more than 0.5 megawatts peak powerand> The input peak power up to 1.60 MW (350-nJ pulse energy)https://www.science.org/doi/10.1126/sciadv.adp2438I wonder how much it affects/fries the tissue. HHG also has issues with attenuation.The paper abstract also says previous state of the art was 300um not 200um like in the press release.\n \nreply",
      "The question is, how long is that power needed.Edit: \"Ultrashort pulses\" so likely not much. Because indeed, you cannot burn the human. So the energy consumption likely won't be a problem. Except that it might make the machine expensive to build.\n \nreply",
      "In fact, GP quotes \"350 nJ\" which is a tiny fraction of a watt-second.\n \nreply",
      "Bulk ordered, that is probably a ~$50k laser. Not nothing, but on the scale of medical device costs, not terrible.\n \nreply",
      "300 to 700 micrometers? So almost nothing to still almost nothing.Could anyone tell a difference in the before and after images, other than one was grey and the other was blue? Structurally, they looked identical to me.Edit: internet tells me human cells are around 25um, so I guess you can tens of cells deep\n \nreply",
      "I think this is just one \"slice\" of a full scan. The one in blue has a lot more detail, and less noise.\n \nreply",
      "The blue one is pretty significantly less noisy, and the animation showing the two 3D reconstructions is much clearer. The noise reduction probably has a lot to do with that.\n \nreply"
    ],
    "link": "https://news.mit.edu/2024/noninvasive-imaging-method-can-penetrate-deeper-living-tissue-1211",
    "first_paragraph": "Suggestions or feedback?\n    Images for download on the MIT News office website are made available to non-commercial entities, press and the general public under a \n    Creative Commons Attribution Non-Commercial No Derivatives license.\n    You may not alter the images provided, other than to crop them to size. A credit line must be used when reproducing images; if one is not provided \n    below, credit the images to \"MIT.\" \n  \n\n\n\n\n\n\n\n\n\n\n\n\nPrevious image\nNext image\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetabolic imaging is a noninvasive method that enables clinicians and scientists to study living cells using laser light, which can help them assess disease progression and treatment responses.But light scatters when it shines into biological tissue, limiting how deep it can penetrate and hampering the resolution of captured images.Now, MIT researchers have developed a new technique that more than doubles the usual depth limit of metabolic imaging. Their method also boosts imaging speeds, yielding richer and mor"
  },
  {
    "title": "An Italian town that built its own sun (2021) (vice.com)",
    "points": 87,
    "submitter": "Amorymeltzer",
    "submit_time": "2024-12-08T20:21:14 1733689274",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=42360074",
    "comments": [
      "> The mirror was designed by Bozani with the help of engineer Gianni Ferrari, and cost about \u20ac100,000...First reaction: why would a mirror cost this much?> Eight metres wide and five tall, it reflects the sunlight for six hours a day, following the sun\u2019s path in the sky thanks to a software programme that makes it rotate.Also saw elsewhere that the reflectors are made of steel. So a giant, software-controlled, motorized structure, reflecting just the right amount of sunlight to a precise location, sitting out there in the elements...Totally worth it, and what a cool project!Relevant: https://en.wikipedia.org/wiki/Heliostat (\"Aziz, Light!\")\n \nreply",
      "The hardware may cost very modestly. But consider the salary of the people who designed it, built it, transported it, and installed it. These must be several pros, working on that full-time, at a salary near the competitive level (even if they agree to take a hit out of being charitable). Much of that salary would go to the taxes.\n \nreply",
      "Interesting. It's hydraulically controlled -https://youtu.be/kWiilCH1AO0?si=PxE3UuB9DE9sB0Hq&t=124Norway's Rjukan seems to have implemented it betterhttps://www.youtube.com/watch?v=1PbAsci1D0k\n \nreply",
      "\"It's a Ferrari!\"\"It's a steel box!\"\n \nreply",
      "This reference was such a classic for years after the release of the Fifth Element!\n \nreply",
      "my thought was the opposite: \"only EUR 100k for a giant sun tracking device mounted above a village? Maybe Montgomery Burns' idea of doing the same thing in reverse wasn't so ludicrous after all...\"\n \nreply",
      "I lived in Inuvik, NWT (Canada) for a decade in my youth. It's above the Arctic Circle and has 30 days without sunlight, bracketed by months of near darkness.  Each year a new crop of noobs would move in and there would be a little exodus when the folks who just couldn't hack the dark would finally realize what they had signed up for.  Summer was grand compensation though, three or four months of the sun being up whenever you might be tempted to be.  An odd thing was, in the summer, being up at 3 am and seeing things uncannily lit from an unfamiliar side!  Quite a fascinating place to experience, all in all, and well worth the couple thousands of kilometers of driving to get there too.\n \nreply",
      "Soon available as a service https://www.reflectorbital.com/\n \nreply",
      "Assuming this works (which might be a big if, even with recently greatly expanded launch capabilities), it raises the question of who gets to decide whether a given piece of land should be illuminated at night or not.Hopefully not just the highest bidder, without any veto right of the (other) people that are there too?\n \nreply",
      "Dave from the EEVBlog did a take on this.\nhttps://www.youtube.com/watch?v=lkjyeI0ykGM\n \nreply"
    ],
    "link": "https://www.vice.com/en/article/viganella-italy-fake-manmade-sun/",
    "first_paragraph": "Newsletters\n\tBy Giacomo RaffaelliThis article originally appeared on VICE Italy.A town where the sun doesn\u2019t rise for three months a year. This image probably conjures up desolate landscapes in Scandinavia, Russia or Alaska in the depths of winter, when the lights have to be on all day and people resort to light therapy to tackle their falling serotonin levels.\u00a0But at a much lower latitude, at the border between Switzerland and Italy, the town of Viganella experiences similar conditions. Clinging to the side of a steep valley and surrounded by mountains that block the sun\u2019s rays, Viganella is deprived of sunlight every year from November until February.According to historical archives, the area has been settled as far back as the 13th century, meaning generations of locals have spent more than 800 winters in the dark. Every year, the community sees its last sunset on the 11th of November and waits for the rays to reappear on the 2nd of February. On that day, residents wear traditional "
  },
  {
    "title": "McKinsey and Company to pay $650M for role in opioid crisis (npr.org)",
    "points": 51,
    "submitter": "pseudolus",
    "submit_time": "2024-12-13T22:57:04 1734130624",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42413086",
    "comments": [
      "https://en.wikipedia.org/wiki/Value_of_lifeThey could figure out how to divvy up their 65 life sentences.Why do they get to pay their way out of this?> According to Kavanaugh, former McKinsey senior partner Martin Elling [2] \"personally deleted various Purdue related electronic materials from his McKinsey laptop with the intent to obstruct future investigations.\"Corporate laptops are backed up, with backups offsite. I find it hard to believe that the only copy was on his laptop.From the tweet [2], which has a screenshot of an email presumably sent by Martin Elling, he looks to be directing everyone to start deleting criminal evidence.> McKinsey's payment, which includes $2 million paid to the Virginia Medicaid Fraud Control Unit, settles federal civil and criminal charges against the firm and includes a \"deferred prosecution\" agreement. Under the civil settlement, McKinsey is not admitting liability. A copy of the deferred prosecution agreement was not publicly available at the time of publication.Given the opioid deaths in 2022 alone, McKinsey should be dissolved and the responsible parties serving jail time.Can someone explain how this [3] is presented as a win, when  only money has changed hands. They paid a fee for aiding in the deaths of hundreds of thousands of people.Does this ruling now shield them from any criminal repercussions at the state level?[1] https://www.cdc.gov/overdose-prevention/about/understanding-...[2] https://x.com/CoruscaKhaya/status/1676330070472814593[3] https://www.justice.gov/opa/pr/justice-department-announces-...\n \nreply",
      "They 100% should be put in jail, if fines are the only deterrant then they just become cost-of-business and dont deter anything at all.\n \nreply",
      "In a few decades there'll be similar payouts to people given puberty blockers and sex change surgeries as minors.\"Gender affirming care\" is the new opioid crisis.Nothing has changed.\n \nreply",
      "McKinsey is responsible for a lot of crimes, seemingly. Ultimately they just don't seem like a trustworthy company and I think they've avoided accountability by maintaining political connections (and donations). Another example of their untrustworthy practices - I recall accusations from a few years ago where they assured the US government that they were not doing work for the CCP, but then it turned out that they were (https://www.nbcnews.com/politics/national-security/mckinsey-...). And then earlier this year at a US Senate hearing, it turned out McKinsey has once again been doing dirty work for the CCP by advising a large number of state owned corporations, who are involved in activities like building China's militarized artificial islands: https://youtu.be/tQ5kWfotE8Y\n \nreply",
      "i'm assuming the supreme court will void this one too?\n \nreply",
      "Jail time for role in opioid crisis: 0.You can understand how the common person might think that an adjustment is due.\n \nreply",
      "what kind of adjustment and who are adjusters?\n \nreply",
      "You and I destroying evidence when accused of a crime? Tampering, a felony in most states.Send emails to your team and clients that even explicitly says \"We need to eliminate documents and emails about this as the US Attorney has already begun investigating us?\"Oh well, no big deal, just have the company pay a fine.Adjust that, for just one thing.\n \nreply",
      "Left hand. COVID proved that we could establish safety & efficacy of a medical treatment in about 12 months, to the point where as I recall a lot of the manufacturers have a legal exemption from any liability for damage done by vaccines.Right hand. There are these opioids have been around for decades and somehow they reached this huge level of damage. Largely the same cultures of people involved.I still think the authoritarian policies used during COVID were a mistake. The level of compartmentalisation needed to look past scandals like this one and still force people to trust big pharma unconditionally is pretty extreme. People should be allowed to make their own mistakes based on their own flawed judgement, rather than the flawed judgement of the likes of McKinsey & Perdue. It is bad enough when everything is voluntary.\n \nreply",
      "Opioids were known to be harmful. Purdue attacked the gatekeepers and policy makers not the science.  It was mostly a story of what happens when a well funded con artist enters an environment built on trust.Suddenly pain management was viewed as very important by the medical establishment, while mostly paying lip service to all the long term consequences of said actions.  After all you can\u2019t actually know how much someone is actually suffering\u2026\n \nreply"
    ],
    "link": "https://www.npr.org/2024/12/13/nx-s1-5155962/mckinsey-purdue-opioid-prosecution-doj",
    "first_paragraph": "\n\n      Brian Mann\n    \n\n                McKinsey and Company has agreed to pay $650 million to settle federal civil and criminal probes into alleged wrongdoing linked to \"turbocharging\" opioid sales on behalf of Purdue Pharma.\n                \n                    \n                    Fabrice Coffrini/AFP via Getty Images\n                    \n                \nhide caption\nThe global consulting firm McKinsey and Company Friday agreed to pay $650 million to settle a federal probe into its role in helping \"turbocharge\" sales of the highly addictive opioid painkiller OxyContin for Purdue Pharma, the U.S. Justice Department announced on Friday.Federal officials said the influential consulting company - which often advises governments and powerful corporations around the globe - committed crimes while trying to aggressively boost opioid sales.\"It was a strategy, it was executed and it worked,\" said U.S. attorney Christopher Kavanaugh during a press conference on Friday. \"McKinsey's strategy "
  },
  {
    "title": "Elon Musk wanted an OpenAI for-profit (openai.com)",
    "points": 357,
    "submitter": "arvindh-manian",
    "submit_time": "2024-12-13T19:36:41 1734118601",
    "num_comments": 380,
    "comments_url": "https://news.ycombinator.com/item?id=42411608",
    "comments": [
      "I guess it's not news but it is pretty wild to see the level of millenarianism espoused by all of these guys.The board of OpenAI is supposedly going to \"determine the fate of the world\", robotics to be \"completely solved\" by 2020, the goal of OpenAI is to \"avoid an AGI dictatorship\".Is nobody in these very rich guys' spheres pushing back on their thought process? So far we are multiple years in with much investment and little return, and no obvious large-scale product-market fit, much less a superintelligence.As a bonus, they lay out the OpenAI business model:> Our fundraising conversations show that:>   * Ilya and I are able to convince reputable people that AGI can really happen in the next \u226410 years>   * There\u2019s appetite for donations from those people>   * There\u2019s very large appetite for investments from those people\n \nreply",
      "> Is nobody in these very rich guys' spheres pushing back on their thought process?Yes, frequently and loudly.When Altman was collecting the award at Cambridge the other year, protesters dropped in on the after-award public talk/Q&A session, and he actively empathised with the protestors.> So far we are multiple years in with much investment and little return, and no obvious large-scale product-market fit, much less a superintelligence.I just got back from an Indian restaurant in the middle of Berlin, and the table next to me I overheard a daughter talking to her mother about ChatGPT and KI (K\u00fcnstliche Intelligenz, the German for AI).The product market fit is fantastic. This isn't the first time I've heard random strangers discussing it in public.What's not obvious is how to monetise it. Old meme parroted around was \"has no moat\", which IMO is like saying Microsoft has no moat for spreadsheets: sure, anyone can make the core tech, and sure we don't know who is Microsoft vs StarOffice vs ClarisWorks vs Google Docs, but there's more than zero moat. From what I've seen, if OpenAI didn't develop new products, they'd be making enough to be profitable, but it's a Red Queen race to remain worth paying for.As for \"much less a superintelligence\": even the current models meet every definition of \"very smart\" I had while growing up, despite their errors. As an adult, I'd still call them book-smart if not abstractly smart. Students or recent graduates, but not wise enough to know their limits and be cautious.For current standards of what intelligence means, we'd better hope we don't get ASI in the next decade or two, because if and when that happens then \"humans need not apply\" \u2014 and by extension, foundational assumptions of economics may just stop holding true.\n \nreply",
      "> When Altman was collecting the award at Cambridge the other year, protesters dropped in on the after-award public talk/Q&A session, and he actively empathised with the protestors.He always does that to give himself cover, but he has clearly shown that his words mean very little in this regard. He always dodges criticism. He used to talk about the importance of him being accountable to the OpenAI board and them being able to fire him if necessary when people were questioning the dangers of having one person have this much control over something as big as bleeding edge AI. He also used to mention how he had no direct financial interests in the company since he had no equity.Then the board did fire him. What happened next? He came back, the board is gone, he now openly has complete control over OpenAI, and they have given him a potentially huge equity package. I really don't think Sam Altman is particularly trustworthy. He will say whatever he needs to say to get what he wants.\n \nreply",
      "Wasn't he fired for questionable reasons? I thought everyone wanted him back, and that's why he was able to return. It was, as I remember, just the board that wanted him out.I imagine if he was doing something truly nefarious, opinions might have been different, but I have no idea what kind of cult of personality he has at that company, so I might be wrong here.\n \nreply",
      "> I thought everyone wanted him back, and that's why he was able to return.Everyone working at OpenAI wanted him back. Which only includes people who have a significant motivation to see OpenAI succeed financially.Also, there are rumours he can be vindictive. For all I know, that might be a smear campaign. But if that were the case, and half the people at OpenAI wanted him back, the other half would have a motivation to follow so as not to get whatever punishment from Sam.\n \nreply",
      "It sounds to me people working in AI these days have a lot more options than being fraid of a particularly vindictive man.\n \nreply",
      ">  I thought everyone wanted him back,Ilyia Sutskever who was the chief Scientist of the company and honestly irreplacable in terms of AI knowledge left after Altman returned.\n \nreply",
      "Only 1 of the 6 board members are still at OAI.\n \nreply",
      "At the time, was it possible for people working at OpenAI to, er, \"cash out\"?\n \nreply",
      "Define everyone. I was delighted when they fired him. I don't believe he has humanity's best interest at heart.\n \nreply"
    ],
    "link": "https://openai.com/index/elon-musk-wanted-an-openai-for-profit/",
    "first_paragraph": ""
  },
  {
    "title": "Donald Bitzer has died (computerhistory.org)",
    "points": 148,
    "submitter": "sohkamyung",
    "submit_time": "2024-12-13T05:32:42 1734067962",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=42406158",
    "comments": [
      "This makes me sad, more than other recently seen obituaries, but I can't picture an image of him without his smile that could stretch his whole face up and back.  I'll always remember him as his mirthful and investigative mind.I think my first interaction with him best describes the influence he had on me as an educator, adviser and scientist.  I hadn't met him yet, I was in his office because I noticed a few of my fellow Comp. Sci. undergrads there, just chatting as we do.  I didn't even know whose office it was, at that point, now that I think about it.In he walks with one of those wall-mounted soap dispensers that I recognized from the gym locker rooms.  He sits down and starts fishing out screws from it, all while jumping right into our conversation without missing a beat.  At my first chance, I ask him what he's doing, I was a little confused but my curiosity was clearly something he had an appetite for.  He starts describing his investigation of which screws to replace.  You see, the things kept falling down because something in the soap was causing the coating or material of the screws to disintegrate.  I think I inquired about why he had to do it, or maybe the question was written on my face, because I also remember he was not obligated to, just that kind of person to see an open question as an opportunity for experiment.Twenty-plus years later, and many many experiments of my own, I still remember this interaction.  Here he was describing a very practical approach (rather than hit the books on the components in the soap and what *-oxide coatings were added or developing on the screws, just throw the experiment together -- its answer will be as good or better).  He was affable and delighted to share knowledge, and he didn't exude any of the pretentiousness that you might expect from someone whose walls were covered (literally, to the ceiling) with framed copies of his patents and awards.  He was still actively going to the gym even at his clearly advanced age (even 20 years ago, I think he was already emeritus, and he played racquetball at least weekly).  I learned what a convolution was just from looking at what he'd done.  All this and he managed to inspire without personifying it.RIP Dr. Donald Bitzer\n \nreply",
      "He is the main character in The Friendly Orange Glow [1], an amazing history of the PLATO system that has many valuable lessons on how to foster technological innovation and create thriving online communities.[1] http://friendlyorangeglow.com/\n \nreply",
      "PLATO is notable for being the origin of the of the computer role playing game. The history of early CRPGs is murky, because PLATO was intended for educational use and games programmers had to work in secret to avoid the administrators deleting their work, but it's possible that the first ever CRPG was the Reginald Rutherford's 1975 game \"The Dungeon\" (a.k.a. \"pedit5\" after its inconspicuous lesson name). The Dungeon was probably earlier than the lost game \"m199h\" that was previously thought to be first. These early CRPGs are all influenced by Dungeons and Dragons, which was first published in 1974.The Dungeon is still playable today. The CRPG Addict blog has details:http://crpgaddict.blogspot.com/2019/01/revisiting-dungeon-19...And more information about lost games:http://crpgaddict.blogspot.com/2021/06/brief-everything-we-k...\n \nreply",
      "And not only the beginnings of the CRPG. The 1977 PLATO game Oubliette definitely was the model for the 1981 Apple II/C64 (and later NES) gane Wizardry and the later games like The Bard's Tale and Might & Magic.\n \nreply",
      "Donald Bitzer was the first Computer Science professor I had in college. He taught a discrete mathematics course (boolean logic).Though he was on the older side when I took his course, he still brought laughter and enthusiasm to his classes, and set the tone for the rest of my college career. He will be missed!\n \nreply",
      "Same. It was my first CS class after transferring to NCSU in 2000.  I was pretty lost at times but he was super kind and patient whenever I went to office hours.  He was an older professor at that time and it was always cool to see was still teaching well beyond when I graduated.\n \nreply",
      "Ditto, I took his discrete math course at NCSU in 1998. It was mainly taught by Tiffany Barnes day to day (who was also nice and a great explainer), but Bitzer was often present and always smiling and jovial.I really regret having spent so little time interacting with my professors though. I was one of those kids that spent the least amount of time in class possible, almost never going to office hours, aiming to get the course work out of the way asap so I could \"have a life\". So much wisdom and life/industry experience was concentrated on that campus and at my fingertips, but I totally took it for granted. Seeing his obit amplifies this feeling; I wish I had cared enough at the time to meet and know the guy.\n \nreply",
      "Yeah, there were some other older professors at NC State who had clearly aged out of knowing the state of the art, but Bitzer was an enthusastic teacher who cared about engaging students, and still knew his stuff.\n \nreply",
      "IBM did a roadshow around 79-82 time frame in the UK and showed off plasma displays. They were very cool. Orange glow, very fast response they were built into the walls of an IBM mobile trailer hauled around the country drumming up business in the university towns. I didn't see one again until a very early Toshiba luggable in the early 90s.PLATO seemed to me to kind of not lead anywhere solid. The field of computer aided instruction went on of course, NATO funded summer schools across Europe looking at it for decades. Maybe if you're in the field it has strong roots and a context. I worked alongside people in the space in that time and it felt like it wasn't living up to the promise.That said, lots of things stem from it. All across the surface of things we do today. Mice, workstations, immersive experience, scripted interactions. I'm not sure I buy \"email was born in PLATO\"\n \nreply",
      "I think it was a bit too far ahead of its time. By the mid-1980s when I encountered it, it felt dated; the communications increasingly felt slow. Attempts at commercializing it, and on running it on newer hardware didn't really go very far.There were implementations of TUTOR for MS-DOS as well, with TenCORE being one that I saw. Early in my programming career, I came across it when we were rewriting a financial planner that was originally written in it into C. I was flabbergasted when my Lotus 1-2-3 importer was twenty times faster then the original. On reflection, I realized that TenCORE so completely imitated its CDC Cyber heritage that it used Cyber floating-point format for its math, and had to emulate every math operation.\n \nreply"
    ],
    "link": "https://computerhistory.org/blog/in-memoriam-donald-bitzer-1934-2024/",
    "first_paragraph": "With sadness, we say goodbye to computer pioneer and 2022 CHM Fellow Donald L. Bitzer.Don Bitzer. Credit: National Inventors Hall of FameBitzer was born January 1, 1934, and was an American electrical engineer and computer scientist. He was co-inventor of the flat-panel plasma display and the \"father of PLATO,\u201d the world\u2019s earliest time-shared, computer-based education system and home to one of the world\u2019s most pioneering online communities.Bitzer studied electrical engineering at the University of Illinois at Urbana-Champaign (UIUC), obtaining a PhD in 1960. Following graduation, he joined the UIUC faculty, where he learned of efforts to bring lessons to students over a closed-circuit television network. While a committee of engineers, psychologists, and educators were unable to agree on a single solution at the time, Bitzer wrote up a proposal within a week, got it approved, and immediately started developing his PLATO system for the university\u2019s groundbreaking ILLIAC I computer\u2014the "
  },
  {
    "title": "MarkItDown: Python tool for converting files and office documents to Markdown (github.com/microsoft)",
    "points": 203,
    "submitter": "Handy-Man",
    "submit_time": "2024-12-13T18:02:03 1734112923",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=42410803",
    "comments": [
      "If you have uv installed you can run this against a file without first installing anything like this:    uvx markitdown path-to-file.pdf\n\n(This will cache the necessary packages the first time you run it, then reuse those cached packages on future invocations.)I've tried it against HTML and PDFs so far and it seems pretty decent.\n \nreply",
      "Is uvx just part of uv? I keep a few python packages around via pipx (itself via homebrew) but am a big fan of uv for python projects\u2026 Do I just need to install uv globally (via brew?) to do this? Is there a mechanism to also have the installed utils available in my PATH (so I can invoke them without a uvx prefix)?\n \nreply",
      "You can install to your path with 'uv tool install'.uvx is just an alias for 'uv tool run'.\n \nreply",
      "Thank you! I should explore the uv docs properly.\n \nreply",
      "Wow that is magic! I just installed uv because of your comment.\n \nreply",
      "I worked on an in-house version of this feature for my employer (turning files into LLM-friendly text). After reading the source code, I can say this is a pretty reasonable implementation of this type of thing. But I would avoid using it for images, since the LLM providers let you just pass images directly, and I would also avoid using it for spreadsheets, since LLMs are very bad at interpreting Markdown tables.There are a lot of random startups and open source projects who try to make this space sound fancy, but I really hope the end state is a simple project like this, easy to understand and easy to deploy.I do wish it had a knob to turn for \"how much processing do you want me to do.\" For PDF specifically, you either have to get a crappy version of the plain text using heuristics in a way that is very sensitive to how the PDF is exported, or you have to go full OCR, and it's annoying when a project locks you into one or the other. I'm also not sure I'd want to use the speech-to-text features here since they might have very different performance characteristics than the text-to-text stuff.\n \nreply",
      "The reason there's a lot of startups in the OCR space (us being one of them) is the classic 80/20 rule. Any solution that's 80% accurate just doesn't work for most applications.Converting a clean .docx into markdown is 10 lines of python. But what about the same document with a screenshot of an excel file? Or complex table layouts? The .NORM files that people actually use. Definitely agree with having a toggle between rules-based/ocr. But if you're looking at company wide docs, you won't always know which to pick.Example with one of our test files:Input: https://omni-demo-data.s3.us-east-1.amazonaws.com/zerox/Omni...MarkItDown: https://omni-demo-data.s3.us-east-1.amazonaws.com/zerox/mark...Ours: https://omni-demo-data.s3.us-east-1.amazonaws.com/zerox/omni...The response from MarkItDown seems pretty barebones. I expected it to convert the clean pdf table element into a markdown table, but it just pulls the plaintext, which drops the header/column relationship.\n \nreply",
      "> Any solution that's 80% accurate just doesn't work for most applications.And yet people use LLMs, for which \"80% accuracy\" is still mostly an aspiration. :-)I think it's reasonably likely most people companies end up using open source libraries, at least partly because it lets them avoid adding another GDPR sub-processor. Unstructured.io, one of your competitors, goes as far as having an AWS Marketplace setup so customers can use their own infrastruture but still pay them.LLMs might get better at consuming badly-formatted data, so the data only needs to meet that minimum bar, vs the admittedly very nice output you showed.\n \nreply",
      "> LLMs might get better at consuming badly-formatted dataOh agreed. There's definitely a meeting in the middle between better ingestion and smarter models. LLMs are already a great fuzzing layer for that type of interpretation. And even with a perfect WYSIWYG text extraction, you're still limited by how coherent the original document was in the first place.\n \nreply",
      "LLM providers also let you send PDFs  directly, too.OTOH, sometimes you are the LLM provider, and you may not be using a multimodal LLM. (Or, even though feeding an LLM is a common use. You may be using the markdown for another purpose.)\n \nreply"
    ],
    "link": "https://github.com/microsoft/markitdown",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Python tool for converting files and office documents to Markdown.\n      The MarkItDown library is a utility tool for converting various files to Markdown (e.g., for indexing, text analysis, etc.)It presently supports:The API is simple:This project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.When you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.This project has adopted the"
  },
  {
    "title": "SCCS roach motel (tuhs.org)",
    "points": 36,
    "submitter": "rdpintqogeogsaa",
    "submit_time": "2024-12-13T20:07:30 1734120450",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=42411868",
    "comments": [
      "> It should be obvious that I love SCCS, it's a dramatically\nbetter file format than a patch based one, you can get any version of\nthe file in constant time, authorship can be preserved across versions,\nit's pretty brilliant and I consider myself blessed to be posting this\nin response to SCCS's creator.I have seen Larry make similar claims about the weave format vs. patch-based format many times, and he has also put git firmly in the \"patch-based\" camp, but I believe the only real effect to git not using a weave is increased time-complexity of \"blame\" operations.1. Git has constant time access any version of a file as well; the --depth option to the pack algorithm places a constant (but configurable) upper bound on the number of deltas that will need to be applied whenever fetching a blob.  Intuitively, it would seem to me that for files with extremely large numbers of changes, this could be faster than extracting the weave, potentially at reduced space efficiency.2. Merges are separate from the commits that effect the change; the lm/clem example in TFA would work as expected on git.  Merge commits will only show up in the annotation if there were conflicts.\n \nreply",
      "I got into unix after CVS had pretty much displaced SCCS and RCS, but the older per-file version control systems persisted long enough that I had a few close encounters with them.When I took over Cambridge University\u2019s DNS, its code and configuration was still in SCCS, because that was what shipped with SunOS in 1991ish. I converted the SCCS archive via RCS and CVS to git \u2013 https://dotat.at/@/2014-11-27-uplift-from-sccs-to-git.html \u2013 which was a fairly entertaining exercise. (Sadly the links in that blog post are mostly broken.) I even used those conversion scripts more than once! https://dotat.at/@/2016-07-19-uplift-from-sccs-to-git-again.... (That repository ended up with at least three distinct root commits, one for the main DNS history, one for the Ansible setup that started with DHCP and later grew to handle DNS too, and later the separate vanity domain DNS setup.)\n \nreply",
      "I once had one of my users come to me: \"I accidentally typed \"ci filename\" rather than \"vi filename\", it asked me some questions and I answered them, and now my file is gone.\"  I told her: \"Don't worry, I know exactly what happened and how to fix it!\"  She was one of that day's Lucky 10,000.\n \nreply",
      "I, when a young lad, did the same thing.  Many of us did.\n \nreply",
      "For those that don't know, Larry was the author of BitKeeper and when he changed the license for it, it prompted Linus to write Git.  Guessing if he had never done that, we'd all be using BitKeeper now and Git wouldn't exist.\n \nreply",
      "It was also the impetus for the lesser known SCMs Mercurial and Fossil.\n \nreply",
      "And Marc Rochkind (the OP) wrote SCCS, as well as one of the more seminal Unix programming books and a ton of other notable achievements.Looking through the rest of the archive, nice to see that Larry has gone into retirement but makes time away from fishing to continue to tell us how fucking smart he is and how stupid everyone else is.  Never change, Larry.\n \nreply",
      "We still use SCCS at the investment firm I work at, to track configuration file change history.The source code itself was moved to Subversion (via RCS and CVS) long ago, and later to Git, but the configuration files continue to be tracked using SCCS.There is an open source implementation of SCCS called GNU CSSC: https://www.gnu.org/software/cssc/\n \nreply",
      "The SCCS \"weave\" data structure is indeed poorly-understood; and what almost nobody knows is that it's equivalent to a text CRDT!https://braid.org/meeting-60/sccs-is-a-time-collapse\n \nreply",
      "Server is hanging up on me for some reason. Posting an archive link in case anyone else has this problem.https://web.archive.org/web/20241213205017/https://www.tuhs....\n \nreply"
    ],
    "link": "https://www.tuhs.org/pipermail/tuhs/2024-December/031188.html",
    "first_paragraph": "\nPrevious message (by thread): [TUHS] SCCS roach motel\n\nNext message (by thread): [TUHS] SCCS roach motel\n\n Messages sorted by:\n[ date ]\n[ thread ]\n[ subject ]\n[ author ]\n\n\n\n\nOn Fri, Dec 13, 2024 at 09:52:28AM -0700, Marc Rochkind wrote:\n> IEEE Transactions on Software Engineering has asked me to write a\n> retrospective on the influence of SCCS over the last 50 years, as my SCCS\n> paper was published in 1975. They consider it one of the most influential\n> papers from TSE's first decade.\n> \n> There's a funny quote from Ken Thompson that circulates from time-to-time:\n> \n> \"SCCS, the source motel! Programs check in and never check out!\"\n> \n> But nobody seems to know what it means exactly. As part of my research, I\n> asked Ken what the quote meant, sunce I wanted to include it. He explained\n> that it refers to SCCS storing binary data in its repository file,\n> preventing UNIX text tools from operating on the file.\n> \n> Of course, this is only one of SCCS's many weaknesses. If you have anyt"
  }
]