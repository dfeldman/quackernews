[
  {
    "title": "Do AI Companies Work? (benn.substack.com)",
    "points": 35,
    "submitter": "herbertl",
    "submit_time": "2024-09-29T23:44:57.000000Z",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=41691943",
    "comments": [
      "This article, and all the articles like it, are missing most of the puzzle.Models don\u2019t just compete on capability. Over the last year we\u2019ve seen models and vendors differentiate along a number of lines in addition to capability:- Safety- UX- Multi-modality- Reliability- EmbeddabilityAnd much more. Customers care about capability, but that\u2019s like saying car owners care about horsepower \u2014 it\u2019s a part of the choice but not the only piece.\n \nreply",
      "To me, the vast majority of \"consumers\" as in B2C only care about price, specifically free.  Pro and enterprise customers may be more focused on the capabilities you listed, but the B2C crowd is vastly in the free tier only space when it comes to GenAI.\n \nreply",
      "You may be forgetting that ChatGPT has 10M paying customers. Not to mention everyone that pays for Claude Pro, Perplexity Pro, and so on.\n \nreply",
      "The math on this doesn't work.",
      "> OpenAI has 10M paying customersAccording to who?\n \nreply",
      "https://www.theinformation.com/articles/openai-coo-says-chat...",
      "Not OP but what is your guess? Bloomberg says 1M customers in the business plan [1].[1] https://www.bloomberg.com/news/articles/2024-09-05/openai-hi...",
      "This is like when VCs were funding all kinds of ride share, bike share, food delivery, cannabis delivery, and burning money so everyone gets subsidized stuff while the market figures out wtf is going on.I love it. More goodies for us\n \nreply",
      "No, it means creating a bunch of unprofitable businesses that make it really hard for folks trying to build a sustainable business without VC money.\n \nreply",
      "Yep, you will probably lose. The VCs aren't out there to advance the technology. They are there to lay down bets on who's going to be the winner. \"Winner\" has little to do with quality, and rides much more on being the one that just happens to resonate with people.The ones without money will usually lose because they get less opportunity to get in front of eyeballs. Occasionally they manage it anyway, because despite the myth that the VCs love to tell, they aren't really great at finding and promulgating the best tech.\n \nreply"
    ],
    "link": "https://benn.substack.com/p/do-ai-companies-work",
    "first_paragraph": ""
  },
  {
    "title": "Being Raised by the Internet (jimmyhmiller.github.io)",
    "points": 515,
    "submitter": "DamonHD",
    "submit_time": "2024-09-25T12:39:45.000000Z",
    "num_comments": 160,
    "comments_url": "https://news.ycombinator.com/item?id=41646749",
    "comments": [
      "> I am certain they never intended to inspire a 12 year-old kid to find a better life.i can't speak for everyone, but as one of the people writing tutorials and faqs and helping people learn to do things with free software during the period miller is talking about, that is absolutely what i intended to do.  and, from the number of people i knew who were excited to work on olpc, conectar igualdad, and huayra linux, i think it was actually a pretty common motivationas a kid on bbses, fidonet, and the internet, i benefited to an unimaginable degree from other people's generosity in sharing their learning and their inventions (which is what software is).  how could i not want to do the same?underwritten by the nsf, the internet was a gift economy, like burning man: people giving away things of value to all comers because if you don't do that maybe it's because you can't.  the good parts of it still are\n \nreply",
      "\"the internet was a gift economy, like burning man: people giving away things of value to all comers because if you don't do that maybe it's because you can't. the good parts of it still are\"But it feels like more and more are taken over by money from advertisement. It is allways a relieve to me, find a site in the old spirit.\n \nreply",
      "I'm old and fortunate enough to have gotten on the Internet in 1993, when it was smaller, more communal, and less commercial. As much as we old-timers lament the direction things have gone, there are still corners of the Internet where people still help each other, where people seek to share their knowledge freely, and help other humans, even strangers, without regard to artificial reputational or commercial gain. You just have to seek them out.\n \nreply",
      "i only lament some things; others have gotten better.  there's enormously more free software and better information, and disks are big enough for kiwix to be a thing.  consider: wikipedia, openstreetmap, library genesis, sci-hub, the internet archive, bitcoin, stack exchange, tor, debian, termux, f-droid, and lineageos.  heck, even firefox is noticeably better than lynx was when i joined the internet!and, as i alluded to in my comment, it's not clear that people were ever purely altruistic; artificial reputational gain was always a consideration\n \nreply",
      "> It is allways a relieve to me, find a site in the old spirit.Here is the corresponding search engine for that: https://wiby.me\n \nreply",
      "Also: https://search.marginalia.nu\n \nreply",
      "Kagi has a small web thing too. But very few of those places are a community\n \nreply",
      "kagi is explicitly not a community; it's a service you pay for.  it's organized around a them/us distinction, and the users are the (atomized) outgroup, individually paying the ingroup for the service provided by that ingroupthere is nothing wrong with that; it's a perfectly good way of organizing things.  but it's important not to confuse it with the relationship between, for example, linux users, any of whom is free at any moment to improve the kernel for everyone\n \nreply",
      "I think you misinterpreted what I was saying. Kagi is indeed a paid service and not a community. I was saying it has a way to find small web type sites, but lamenting the fact that part of what made those sites so useful in the past was a tiny community, is gone, and probably not coming back.\n \nreply",
      "Nobody suggested Kagi is a community.\n \nreply"
    ],
    "link": "https://jimmyhmiller.github.io/raised",
    "first_paragraph": "I grew up relatively poor. I was fortunate enough to have a roof over my head, clean water, electricity, a computer, internet, and cable tv. But food was often harder to come by. This may seem like a contradiction, but when your mom has left to marry her uncle and your dad has schizophrenia, you aren\u2019t really in charge of how the money is spent.Starting at the age of 12, I was given $20 a week for my food. (If it was a good week. Otherwise it might $10 or even $0). During the school year that meant I just had to make that stretch for dinner and the weekends \u2014 I had free school lunch. But in the summer, that made things quite a bit harder. One week, I had only a few jars of sprinkles left in the top of our pantry.When I did have money for food, I had to buy it. Luckily there were a few restaurants and a large grocery store about a half-mile walk away. I still remember the first time I made that trip alone. It was snowing, I didn't have a heavy coat and my brother didn't want to go with "
  },
  {
    "title": "96% of climate policy since 1998 failed (ox.ac.uk)",
    "points": 25,
    "submitter": "debo_",
    "submit_time": "2024-09-29T22:59:33.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.alumni.ox.ac.uk/article/96-of-climate-policy-since-1998-failed",
    "first_paragraph": "A landmark international study shows 1,437 fails and 63 successes, and whyPublished: 23 August 2024\u00a0Share this articleAn international research team has unveiled the first comprehensive global evaluation of 1,500 climate policy measures from 41 countries across six continents, between 1998 and 2022.Published in the prestigious journal Science, this unprecedented study provides a detailed impact analysis of the wide range of climate policy measures implemented over the last two decades.The findings reveal a sobering reality, that the vast majority of policy measures failed. Only in 63 cases of climate policies, or approximately 4% of the total analysed, was there a meaningful emission reduction of 19%. The key characteristic of these successful cases is the inclusion of tax and price incentives in well-designed policy mixes.The new analysis is sophisticated and expansive in ways that previous analysis was not. Led the Potsdam Institute for Climate Impact Research (PIK), the Mercator Res"
  },
  {
    "title": "Ask HN: What are you working on (September 2024)?",
    "points": 126,
    "submitter": "david927",
    "submit_time": "2024-09-29T20:16:40.000000Z",
    "num_comments": 342,
    "comments_url": "https://news.ycombinator.com/item?id=41690087",
    "comments": [
      "API tool to automate all the stuff Postman makes painful: https://callosum.dev\nSpec generation from request logs, automatic schema generation and validation, test generation (eventually), totally offline, no accounts or cloud sync necessary!Been taking longer than I hoped but should be released soon (next few days)\n \nreply",
      "I'm working on my scifi novel. I had started writing it when LLMs started taking off - I had been doing AI for two decades and I was well-placed to be in a good position to profit with the rise of LLMs, but I ended up gaining nothing much and I was depressed about it - so I started writing instead. Been picking at it for about a year before befriending an editor who encouraged me to keep writing. He's helped me developmentally edit it to a point I am now ready to work on my second draft.It's a hard scifi novel with mild existential horror tones that is borne mostly of maths jokes. At one point the main character tries to escape the matrix (reality). But the matrix is defective, so the best way out was to orthogonalize the subspace and reduce the matrix to its eigenbasis instead. Most of the scenes are based on similar maths jokes.Tentative name is Diagonalization of the Meta (I had previously called it The Metaverse).\n \nreply",
      "I learned how to weld (MIG) and built a giant mushroom to house a mannequin I dubbed \"the mushroom man\" over about 100 hours in the last 4 weeks. I covered the outside with thick foam panels cut to size, cementing them in place with copious amounts of spray foam. I shaved the outside to a nice shape with a sawzall and the inside I covered in chicken-fenced, then attached a painters tarp to that (so it could be painted on).To fit on a trailer (the mushroom's cap is 11.5ft wide) the cap comes off the stem and the edges of the cap are two half-moons which have fixed mounting points where threaded rod sticks through some welded washers, and a nut is put on in place. I was too last minute to install the 200 WS2811 pixels and have them run some cool patterns, before the music festival I brought it to came time, but even just a lantern on top (another painters tarp covered the cap's metal-frame, and everything was spray painted) looked great.Super fun project. Expensive, but I learned a lot, got to be creative, and I'm happy to try out new things and make the best of my before-children time. Also, it was such a joy seeing people croud around the mushroom (and site beside the mushroom man inside) at night during the festival.\n \nreply",
      "Where/how did you learn welding? Have been considering doing a community college welding course (as they have all the equipment, instruction, etc.).\n \nreply",
      "MIG is really just a glue gun for metal. For things where structural integrity isn\u2019t critical you MIG stuff together by watching a couple YouTube videos and then going at it.\n \nreply",
      "That's incredible - do you have any photos of this anywhere?I learned to weld awhile back, but haven't pulled the trigger on purchasing all the stuff I need.\n \nreply",
      "https://bauble.studio/ is a programmatic 3D art playground that I've been working on for a while now, and I'm pretty excited about it! It's based around signed distance functions, which are a way to represent 3D shapes as, well, functions, and you can do a lot of like weird mathematical distortions and operations that give you cool new shapes. Like average two shapes together, or take the modulo of space to infinitely repeat something... it's a really fun and powerful way to make certain kinds of shapes.SDFs are very cool in general, and widely used in the generative art communities, but kinda hard to wrangle when you're writing shader code directly. They really are functions, but GLSL doesn't support first-class functions, so if you want to compose shapes you have to manually plumb a bunch of arguments around. So Bauble is essentially a high-level GLSL compiler that lets you model SDFs as first-class values, and as a result you can make a pretty cool 3D shape in just a few lines of code. And then 3D print them!I need to do some actual work to promote and publicize it once I'm done with the documentation and implement a few more primitives, but it's very close!The docs have lots of examples of the sorts of things you can do with SDFs: https://bauble.studio/help/And for examples of some \"art\" that I've made with it recently:https://x.com/ianthehenry/status/1839061056301445451\nhttps://x.com/ianthehenry/status/1839649510597013592\nhttps://x.com/ianthehenry/status/1827461714524434883\n \nreply",
      "I really want to look at your art but it\u2019s on twitter so I can\u2019t!\n \nreply",
      "oh yeah good point. i probably shouldn't link to that anymore. it's all on mastodon too! https://mastodon.social/@ianthehenry\n \nreply",
      "I'm working on https://nuenki.app/, a language learning tool. It teaches you a language while you procrastinate by inserting translations of appropriate-difficulty sentences into webpages as you browse HN etc.Currently trying to reduce costs by switching from using DeepL (high quality, low latency, high cost) everywhere to a hybrid that also uses Claude (high quality, high latency, low cost) for text that is far from the user. Also experimenting with Gemma 2 9B via Groq to go in between them, but it's bad at following instructions and I don't quite trust the quality numbers I'm seeing for it (they're benchmarked with gpt-4o as a judge).I'm also trying to work out marketing. I'm not good at it, and I dislike it, but I need to get good at it. Currently considering Reddit ads for awareness, some content marketing going over the technical details (there's some fun language processing and performance optimisations), and... I feel that's not enough, but I'm not sure what to add to that.I'm running on very little budget (I just left school and I'd rather not go into my limited savings over this), so I can't afford to just throw money at ads.\n \nreply"
    ],
    "link": "item?id=41690087",
    "first_paragraph": ""
  },
  {
    "title": "Gavin Newsom vetoes SB 1047 (wsj.com)",
    "points": 250,
    "submitter": "atlasunshrugged",
    "submit_time": "2024-09-29T20:43:32.000000Z",
    "num_comments": 180,
    "comments_url": "https://news.ycombinator.com/item?id=41690302",
    "comments": [
      "https://www.wsj.com/tech/ai/californias-gavin-newsom-vetoes-...",
      "Excellent move by Newsom. We have a very active legislature, but it's been extremely bandwagon-y in recent years. I support much of Wiener's agenda, particularly his housing policy, but this bill was way off the mark.It was basically a torpedo against open models. Market leaders like OpenAI and Anthropic weren't really worried about it, or about open models in general. Its supporters were the also-rans like Musk [1] trying to empty out the bottom of the pack, as well as those who are against any AI they cannot control, such as antagonists of the West and wary copyright holders.[1] https://techcrunch.com/2024/08/26/elon-musk-unexpectedly-off...\n \nreply",
      "> Excellent move by Newsom. [...] It was basically a torpedo against open models.He vetoed it in part because the threshold it applies to at all are well-beyond any current models, and he wants something that will impose greater restrictions on more and much smaller/lower-training-compute models that this would have left alone entirely.> Market leaders like OpenAI and Anthropic weren't really worried about it, or about open models in general.OpenAI (along with Google and Meta) led the institutional opposition to the bill, Anthropic was a major advocate for it.\n \nreply",
      "> He vetoed it in part because the threshold it applies to at all are well-beyond any current models, and he wants something that will impose greater restrictions on more and much smaller/lower-training-compute models that this would have left alone entirely.Well, we'll see what passes again and when. By then there'll be more kittens out of the bag too.> Anthropic was a major advocate for it.I don't know about being a major advocate, the last I read was \"cautious support\" [1]. Perhaps Anthropic sees Llama as a bigger competitor of theirs than I do, but it could also just be PR.[1] https://thejournal.com/articles/2024/08/26/anthropic-offers-...\n \nreply",
      "why would Google, Microsoft and OpenAI oppose a torpedo against open models? Aren't they positioned to benefit the most?\n \nreply",
      "Some laws are just bad. When the API-mediated/closed-weights companies agree with the open-weight/operator-aligned community that a law is bad, it\u2019s probably got to be pretty awful. That said, though my mind might be playing tricks on me, I seem to recall the big labs being in favor at one time.There are a number of related threads linked, but I\u2019ll personally highlight Jeremy Howard\u2019s open letter as IMHO the best-argued case against SB 1047.https://www.answer.ai/posts/2024-04-29-sb1047.html\n \nreply",
      "> The definition of \u201ccovered model\u201d within the bill is extremely broad, potentially encompassing a wide range of open-source models that pose minimal risk.Who are these wide range of >$100mm open source models he's thinking of? And who are the impacted small businesses that would be scared to train them (at a cost of >$100mm) without paying for legal counsel?\n \nreply",
      "The bill included language that required the creators of models to have various \"safety\" features that would severely restrict their development.  It required audits and other regulatory hurdles to build the models at all.\n \nreply",
      "If you spent $100MM+ on training.\n \nreply",
      "Advanced technology will drop the cost of training.The flop targets in that bill would be like saying \u201c640KB of memory is all we will ever need\u201d and outlawing anything more.Imagine what other countries would have done to us if we allowed a monopoly like that on memory in 1980.\n \nreply"
    ],
    "link": "https://www.wsj.com/tech/ai/californias-gavin-newsom-vetoes-controversial-ai-safety-bill-d526f621",
    "first_paragraph": ""
  },
  {
    "title": "A Taxonomy of Tech Debt (2018) (riotgames.com)",
    "points": 112,
    "submitter": "jakey_bakey",
    "submit_time": "2024-09-29T18:28:26.000000Z",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=41689332",
    "comments": [
      "Contagion is exactly why interfaces are one of the most important pieces of design and should be given significant thought. A beautiful interface with a suboptimal implementation can be easily cleaned up when time is allotted. The reverse is rarely true.\n \nreply",
      "I gotta say, it's pretty amazing to me that this was written by an engineering manager. None of the EMs I've worked with would be capable of discussing our codebase at this level of technical detail. Even the ones that used to be engineers.Although to be fair, we don't have any EMs who were promoted from within. We have a bad habit of hiring managers from outside, as nobody internally really wants to stop doing engineering (myself included).\n \nreply",
      "Discussed at the time:A Taxonomy of Technical Debt - https://news.ycombinator.com/item?id=16810092 - April 2018 (113 comments)also this bit:A Taxonomy of Tech Debt (2018) - https://news.ycombinator.com/item?id=39782923 - March 2024 (1 comment)\n \nreply",
      "Great article, from a technical perspective! I would say it\u2019s more a \u201cnomenclature\u201d than a \u201ctaxonomy\u201d because it\u2019s neither exhaustive nor discrete (by design), but I might be mistaken there. I loved the physical examples for each especially, really thought provoking.As always, I have a philosophical nit to pick: the \u201cthree axes\u201d introduced at the top are just \u201cReturn\u201d and \u201cInvestment\u201d from good ol\u2019 RoI, with a subcategory added for a particular type of forward-looking/conditional Return. I\u2019m guessing this decision has worked in practice and I don\u2019t expect video game development practices to be absolutely scientifically sound, but some extra philosophical certainty never hurts!\n \nreply",
      "Great article. The \"contagion\" factor is a useful concept that I hadn't seen before. Needs a [2018] tag.\n \nreply",
      "One important aspect is when you knowingly take on tech debt in return of some short-term benefit. Then this benefit becomes an other axis to weigh against.\n \nreply",
      "My experience at big corporate is that (edit: unmanageable) tech debt is caused by undisciplined and unorganized scrum team.When you have a proper backlog of tickets, including tech debt tickets, the team will eventually fix the tech debt when there are not enough feature tickets to exhaust capacity.\n \nreply",
      "Agile is perfectly optimised for creating tech debt. Corporate software is almost always impossible to change once released  so it\u2019s obvious that frequent iterative deliverables that you can only code around or on top of propagate technical debt\n \nreply",
      "> the team will eventually fix the tech debt when there are not enough feature tickets to exhaust capacityI have yet to visit this misterious universe you describe.\n \nreply",
      "> I have yet to visit this misterious universe you describe.The trick is to have 1 backlog. Tech debt and features live on the same list and it is up to the PM to prioritize. Engineering\u2019s job is to argue cost.Good PMs will prioritize relevant tech debt or pull it in with feature work in the same area. They understand the tradeoff of go slow to go fast. They also understand when tech debt will never become relevant (because the feature is getting nixed, or hasn\u2019t shown desired impact yet, or because the cost of interest is waaaay lower than the cost of paying it off in many cases).This only works when engineers have the discipline to look stinky awful code in the eye and say \u201cnot today\u201d and stay within agreed timeboxes. You blow this estimate once or twice, get the PM in hot water with leadership, and you\u2019ve lost the trust.\n \nreply"
    ],
    "link": "https://technology.riotgames.com/news/taxonomy-tech-debt",
    "first_paragraph": ""
  },
  {
    "title": "A Bendy RISC-V Processor (ieee.org)",
    "points": 188,
    "submitter": "rbanffy",
    "submit_time": "2024-09-29T14:42:07.000000Z",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=41687739",
    "comments": [
      "Nearly any uses for flexible electronics would also be satisfied by sufficiently small electronics such that lack of flexibility doesn't matter.Eg. rather than having every pixel in your flexible screen be flexible, you make each pixel rigid and have the joints between pixels flexible.In this case, this design is based on SERV, which uses ~2100 gate equivalents, which in a recent tech node would be 40 um^2.    That means you could fit a 10x10 grid of these in a single pixel on an iphone screen.I really can't think of a use case where a region 1/100th of an iphone screen pixel being rigid would be a problem.\n \nreply",
      "Some questions you might consider which would help you to think of some use cases;1) How would wiring to you processor work?2) How many flexible compute applications are currently using just really small processors?3) Given that Pragmatic has raised a lot of money, what was it in their use case that the investors thought would make a better product?4) Besides flexibility, are there other requirements in this product space?5) Given that you've just imagined a product with a flexible screen but solid pixels, does this exist on the market? Are there flexible screens on the market? How do those screens choose to implement flex versus the idea you have proposed? What factors might make their choices better (or worse) than the idea you proposed?I'm not being critical here, I think you start with an excellent starter question which is \"Would the requirements be satisfied by sufficiently small electronics such that [the] lack of flexibility [in the electronics] doesn't matter?\"The trick then is to see if you can see how other people who invested time and money in answering either that, or a closely adjacent, question answered it. When you do that you'll get to see what they thought the overall requirements were vs the technology they picked, and perhaps it might inform if the Pragmatic solution would be a better fit or the 'tiny electronics' solution would be a better fit.I'll be the first to admit that I'm 'weird' in that I really do enjoy going down these sort of engineering optimization rabbit holes to develop a better understanding of what problems various proposed solutions are trying to solve.\n \nreply",
      "> 1) How would wiring to you processor work?My (relatively limited) experience is that this is what really makes wearable projects obnoxious.Even if you have a chip with a tiny footprint, you either put it on a breakout board that isn't tiny or you spend twenty hours soldering nearly microscopic bits of magnet wire to it. It's the same for the piles of passive components and peripherals that every project requires, the voltage regulators and smoothing capacitors and power transistors and stuff: You either attach everything to a big PCB or you're faced with a spaghetti nightmare of point-to-point wiring that makes \"normal\" dead-bug circuitry, the kind you might find embedded in a block of resin for aesthetic points, look like a walk in the park.Flexible processors don't necessarily solve that problem, but they definitely demonstrate that flexible circuits in general are advancing in useful ways, better signal quality and longer runs and better process yield. The bigger these things get the better they are for replacing that mess of integration spaghetti that I always see DIY wearable projects suffering from.(I think that industrial wearables typically solve this by concentrating everything complicated down to a rigid brain-box, c.f. smart-watches or those heated jackets that have a socket for a power tool battery in the pocket.)\n \nreply",
      "> or you spend twenty hours soldering nearly microscopic bits of magnet wire to it.A real chip would only need two or three contacts to vastly outperform thing demonstrated here. These would probably not be soldered, they would ideally be bonded directly to the chip.Imagine a near-microscopic 4-ball BGA on a bit of flexible PCB, except the PCB material can flex in multiple axes simultaneously.\n \nreply",
      "You can look at die attach[1] which basically solders to pads on the circuit board (no magnet wires required :-)).[1] \"Die Attach Comes to PCBs\" --- https://www.eeweb.com/die-attach-comes-to-pcbs/\n \nreply",
      "That article describes traditional chip on board construction that has been in use for decades. Buried at the end it mentions wire bonding as the final step. i.e. pads are up. Flip chip mounting requires careful attention to thermal expansion coefficients. You're not going to do that on any run of the mill cheap board or flex materials.\n \nreply",
      "> The trick then is to see if you can see how other people who invested time and money in answering either that, orOT, but I've been wondering how one might teach this young. Perhaps LLM-generated business case studies? Other thoughts? Part of the context is generative storytelling might permit intensively overlaying implicit curriculum on to existing learning objectives (eg, it's a chemistry problem, but chosen to also scaffold biology and illustrate supply chains).\n \nreply",
      "> 1) How would wiring to you processor work?Sure, there's a modulus gap to be interfaced, but flexible circuits have been worked on forever.The whole point is of this tech is that the transistors themselves are flexible.But since the transistors they end up with are orders of magnitude worse than what the microprocessor age started with, to me this just shows that this tech is not anywhere close to practical application.\n \nreply",
      "Yes, the entire chip (wiring and transistors) is flexible. Which is something I find kind of amazing. Back in 2008 there was a company in the UK called 'Plastic Logic'[1] that was going to make an e-reader that could be rolled up. Back when organic LEDs were just starting to be possible and this stuff was living on a glass substrate, doing \"all\" of the circuits in long change hydrocarbons was a pretty revolutionary idea.My original point was that dismissing the technology out of hand because you imagine you could solve the same problem with tiny ICs is probably premature. Dismissing any technology coming to market because you think it doesn't solve any problem is usually a bad idea because it takes non-zero effort and resources to bring anything to market. As a result, if you imagine what something is irrelevant because there are other proven solutions, then take that as a signal to say \"Hmmm, what am I missing here?\"> But since the transistors they end up with are orders of \n> magnitude worse than what the microprocessor age started \n> with, to me this just shows that this tech is not anywhere \n> close to practical application.This doesn't really track though does it? The \"first\" microprocessor, the 4004 ran at 750kHz max. Most of the challenge here appears to be heat dissipation as plastic melts at a much lower temperature than silicon, but the chemistry is still interesting.I completely agree that this isn't going to displace servers in the data center any time soon, but I can imagine applications for an all (or nearly all) plastic computer on a flexible plastic substrate.[1] Their IP (not the reader though) lives on at https://www.e-pi.com/\n \nreply",
      "> The \"first\" microprocessor, the 4004 ran at 750kHz max.The 4004 wasn't useful to power a general-purpose computer as we think of one today, it was made for a 4 function calculator and it's hard to find many examples of it being used in other systems online. It took another 10 years of Moore's Law for the ingredients to come together and microprocessor-powered desktop computers to achieve critical mass.Look at Table 2 in the (awful, IMO) Nature article. This thing is 10x slower than even a 4004.> Dismissing any technology coming to market because you think it doesn't solve any problem is usually a bad idea because it takes non-zero effort and resources to bring anything to market. As a result, if you imagine what something is irrelevant because there are other proven solutions, then take that as a signal to say \"Hmmm, what am I missing here?\"100%!But is there reason to think Moore's Law is happening here?Or did these researchers just print some minimum viable transistors on kapton?\n \nreply"
    ],
    "link": "https://spectrum.ieee.org/flexible-risc-v",
    "first_paragraph": "The new 6-mW open-source plastic chip can run machine learning tasks and operate while bent around a pencilCharles Q. Choi is a Contributing Editor for IEEE Spectrum.A new RISC-V chip loses only about 4 percent of its performance when bent like this.For the first time, scientists have created a flexible programmable chip that is not made of silicon. The new ultralow-power 32-bit microprocessor from U.K.-based Pragmatic Semiconductor and its colleagues can operate while bent, and can run machine learning workloads. The microchip\u2019s open-source RISC-V architecture suggests it might cost less than a dollar, putting it in a position to power wearable healthcare electronics,  smart package labels, and other inexpensive items, its inventors add.For example, \u201cwe can develop an ECG patch that has flexible electrodes attached to the chest and a flexible microprocessor connected to flexible electrodes to classify arrhythmia conditions by processing the ECG data from a patient,\u201d says Emre Ozer, se"
  },
  {
    "title": "Map with public fruit trees (mundraub.org)",
    "points": 158,
    "submitter": "dschuessler",
    "submit_time": "2024-09-29T16:29:36.000000Z",
    "num_comments": 59,
    "comments_url": "https://news.ycombinator.com/item?id=41688469",
    "comments": [
      "There seems to be quite the split of opinion on public fruit trees.I encountered something like this when I planted a row of red currents at the front of our property.  My mother-in-law said \"You can't plant those there, people will take the fruit\" whereas my thinking was \"If I plant these here, people can take the fruit\"\n \nreply",
      "One of my favorite parts of visiting family in Puerto Rico is the ability to stop almost anywhere and pick up a free, fresh mango/passion fruit/papaya/etc.. It\u2019s a beautiful thing to experience nature providing at such scale\n \nreply",
      "A fun coincidence - I saw this link right after jumping off the plane from a trip to Hiiumaa and Saaremaa in Estonia. Public apple trees are everywhere. Additionally, people leave some of their apples in boxes for everyone to take for free - some are in front of houses and shop, others on public bus stops etc. Such a lovely tradition.\n \nreply",
      "There aren't a lot of public fruit trees in US cities because the falling ripe fruit can create a sanitization issue.\n \nreply",
      "That's more of an inefficient allocation issue. Mostly people driving past ripe fruit trees to buy fruit imported across oceans at the grocery store.\n \nreply",
      "There's a spot in St. Paul, MN that I drive by sometimes that has had treefall apples all over the sidewalk for the last few weeks. I'm surprised they're left on the tree for that long, since it's in a pretty busy area.\n \nreply",
      "Unattended apple trees can create rotting apples on the ground, certainly. Those are admittedly not pretty, but in Central Russia (and, presumably, in Estonia, which is not that far off climate- and fauna-wise) they\u2019re just one more layer of soil by spring. Do hotter temperatures or different wildlife make them a bigger problem in the US somehow?\n \nreply",
      "It is more likely to be seen as messy, just aesthetics. Another big reason for chopping down fruit trees in urban areas is they mess up cars that are parked under them.\n \nreply",
      "Probably a situation with stuck up neighbors most of the time. If you\u2019ve heard of the homeowners association problem in the USA, this could be the cause. Having rotting fruit is fine for the soil and everything, but the stick up the butt neighbors or HOA probably would complain or ban the practice. US Americans are pretty separated from nature in their big suburbs.\n \nreply",
      "hornets"
    ],
    "link": "https://mundraub.org/map",
    "first_paragraph": ""
  },
  {
    "title": "Prep: Golang Comptime (github.com/pijng)",
    "points": 46,
    "submitter": "Seb-C",
    "submit_time": "2024-09-27T17:23:40.000000Z",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=41673242",
    "comments": [
      "The cool thing that zig comptime does is that it interacts with the type system. This seems geared around computations, more than e.g. defining structs.\n \nreply",
      "TIL `go build -toolexec`.  That... seems like it'd enable a lot of interesting shenanigans...I'm somewhat surprised by how little I see online about it.\n \nreply",
      "I wonder what Go would look like if it had generics removed but something like comptime added.\n \nreply",
      "I always felt like if and when Go chose to implement Generics it would be like what Zig did today.\n \nreply"
    ],
    "link": "https://github.com/pijng/prep",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Golang comptime. Pure blasphemy\n      prep is a small Go tool that enables compile-time function evaluation. By using prep.Comptime, you can evaluate functions at build time, replacing them with their computed results. Just like comptime from Zig. Except it's not.To use prep in your build process, install it as a binary executable:To use the prep library in your Go project, add it via Go modules:To mark a function for compile-time evaluation, wrap it with prep.Comptime:After wrapping your functions with prep.Comptime, you need to use prep during the build process. This is done by using the -toolexec flag:This command will evaluate all functions wrapped with prep.Comptime and replace them with their computed results during the build.Important:Note the speed and absence of calculating fibonacci for %d message.Basic Literals OnlyCurren"
  },
  {
    "title": "Some Go web dev notes (jvns.ca)",
    "points": 267,
    "submitter": "tosh",
    "submit_time": "2024-09-29T14:36:23.000000Z",
    "num_comments": 82,
    "comments_url": "https://news.ycombinator.com/item?id=41687707",
    "comments": [
      "> In general everything about it feels like it makes projects easy to work on for 5 days, abandon for 2 years, and then get back into writing code without a lot of problems.To me this is one of the most underrated qualities of go code.Go is a language that I started learning years ago, but did't change dramatically. So my knowledge is still useful, even almost ten years later.\n \nreply",
      "I've picked up some Go projects after no development for years, including some I didn't write myself as a contractor. It's typically been a fairly painless experience. Typically dependencies go from \"1.3.1\" to \"1.7.5\" or something, and generally it's a \"read changelogs, nothing interesting, updating just works\"-type experience.On the frontend side it's typically been much more difficult. There are tons of dependencies, everything depends on everything else, there are typically many new major releases, and things can break in pretty non-obvious ways.It's not so much the language itself, it's the ecosystem as a whole. There is nothing in JavaScript-the-language or npm-the-package-manager that says the npm experience needs to be so dreadful. Yet here we are.\n \nreply",
      "I agree but those first 5 days are going to be a mixed bag as you pick through libraries for logging, database drivers, migrations, as well as project organization, dependency injection patterns for testing, organize your testing structure, and more.If you have a template to derive from or sufficient Go experience you'll be fine, but selecting from a grab bag of small libraries early on in a project can be a distraction that slows down feature development significantly.I love Go but for rapid project development, like working on a personal project with limited time, or at a startup with ambitious goals, Go certainly has its tradeoffs.\n \nreply",
      "> I agree but those first 5 days are going to be a mixed bag as you pick through libraries for logging, database drivers, migrations, as well as project organization, dependency injection patterns for testing, organize your testing structure, and more.So the same as every other language that lacks these in the standard lib?\n \nreply",
      "I think 80% of this is people coming to Go from other languages (everybody comes to Go from some other language) and trying to bring what they think was best about that language to Go. To an extent unusual in languages I've worked in, it's idiomatic in Go to get by with what's in the standard library. If you're new to Go, that's what you should do: use standard logging, just use net/http and its router, use standard Go tests (without an assertion library), &c.I'm not saying you need to stay there, but if your project environment feels like Rails or Flask or whatever in your first month or two, you may have done something wrong.\n \nreply",
      "Go these days has had a good few stdlib improvements that reduce your reliance on third party libraries even further.The http router now handles path parameters and methods, so you might just pull in a library to run a middleware stack.There is structured logging in the stdlib, which works with the existing log package for an easy transition.The thing I\u2019ve struggled with is structuring a project nicely, what with the way modules work, especially for services that aren\u2019t exactly \u2018micro\u2019, and especially when the module and workspace system is still pretty unintuitive.\n \nreply",
      "I completely agree with the comment, except for the Flask example. Django would be a better example.Both Flask and Golang's http package have simplicity and minimalism as their philosophy. Of course, most mature projects will eventually diverge from that. But both can start out as a single file with just a few lines of code.\n \nreply",
      "I really think the library search is more of something you inherit from other languages, though database drivers are something you need to go looking for.  The standard library has an adequate HTTP router (though I prefer grpc-gateway as it autogenerates docs, types, etc.) and logger (slog, but honestly plain log is fine).For your database driver, just use pgx.  For migrations, tern is fine.  For the tiniest bit of sugar around scanning database results into structs, use sqlx instead of database/sql.I wouldn't recommend using a testing framework in Go: https://go.dev/wiki/TestComments#assert-librariesHere's how I do dependency injection:   func main() {\n       foo := &Foo{\n           Parameter: goesHere,\n       }\n       bar := &Bar{\n           SomethingItNeeds: canJustBeTypedIn,\n       }\n       app := &App{\n           Foo: foo,\n           Bar: bar,\n       }\n       app.ListenAndServe()\n   }\n\nIf you need more complexity, you can add more complexity.  I like \"zap\" over \"slog\" for logging.  I am interested in some of the DI frameworks (dig), but it's never been a clear win to me over a little bit of hand-rolled complexity like the above.A lot of people want some sort of mocking framework.  I just do this:   - func foo(x SomethingConcrete) {\n   -     x.Whatever()\n   - }\n   + interface Whateverer { Whatever() }\n   + func foo(x Whateverer) {\n   +     x.Whatever()\n   + } \n\nThen in the tests:   type testWhateverer {\n      n int\n   }\n   var _ Whateverer = (*testWhateverer)(nil)\n   func (w *testWhateverer) Whatever() { w.n++ }\n   func TestFoo(t *testing.T) {\n       x := &testWhateverer{}\n       foo(x)\n       if got, want := x.n, 1; got != want {\n           t.Errorf(\"expected Whatever to have been called: invocation count:\\n  got: %v\\n want: %v\", got, want)\n       }\n   }\n\nIt's easy.  I typed it in an HN comment in like 30 seconds.  Whether or not a test that counts how many times you called Whatever is up to you, but if you need it, you need it, and it's easy to do.\n \nreply",
      "About 50% of the time learning a new language I find that the consensus framework/library choice is not quite to my taste. It isn\u2019t that it\u2019s bad, it just often feels like one thing went viral and then ends up boxed in by their success such that people double down/put up with it rather than evolve it further.Point being you\u2019re probably going to spend those first five days evaluating the options. The \u201ccommunity\u201d doesn\u2019t know your taste or your needs. You have no idea what their goals are, or what the average skill level is. All of those things can make a big difference in selecting tech to build atop of.\n \nreply",
      "I stumbled on this Go starter project that has enough batteries included to get you started I think. You might find it usefulhttps://github.com/mikestefanello/pagoda\n \nreply"
    ],
    "link": "https://jvns.ca/blog/2024/09/27/some-go-web-dev-notes/",
    "first_paragraph": "\n\nI spent a lot of time in the past couple of weeks working on a website in Go\nthat may or may not ever see the light of day, but I learned a couple of things\nalong the way I wanted to write down. Here they are:I\u2019ve never felt motivated to learn any of the Go routing libraries\n(gorilla/mux, chi, etc), so I\u2019ve been doing all my routing by hand, like this.But apparently as of Go 1.22, Go\nnow has better support for routing in the standard library, so that code can be\nrewritten something like this:Though it would also need a login middleware, so maybe something more like\nthis, with a requireLogin middleware.One annoying gotcha I ran into was: if I make a route for /records/, then a\nrequest for /records will be redirected to /records/.I ran into an issue with this where sending a POST request to /records\nredirected to a GET request for /records/, which broke the POST request\nbecause it removed the request body. Thankfully Xe Iaso wrote a blog post about the exact same issue which made it\nea"
  },
  {
    "title": "FDA approves a novel drug for schizophrenia (washingtonpost.com)",
    "points": 111,
    "submitter": "tintinnabula",
    "submit_time": "2024-09-29T18:02:47.000000Z",
    "num_comments": 94,
    "comments_url": "https://news.ycombinator.com/item?id=41689138",
    "comments": [
      "https://archive.is/BYzWs",
      "I lost a good friend to this.  Hope it helps other people.The meds helped him but he didn't like the side effects so he stopped taking them.  Went in and out of homelessness.  In the end he thought he had superpowers and could fly.  He could fly, but he could not land.  It eventually took him.\n \nreply",
      "It's this https://en.wikipedia.org/wiki/Xanomeline/trospium_chloride\n \nreply",
      "> M4 and M1 receptor stimulation indirectly rebalances dopaminergic and glutamatergic circuits involved in the symptoms associated with neurological and neuropsychiatric diseases such as schizophrenia and Alzheimer's disease.Whoa. Wonder if that's being evaluated?\n \nreply",
      "Co-administration of an agonist and an antagonist for the same pharmacophore seems like an interesting approach.\n \nreply",
      "Looks like the antagonist is only outside the brain, so it works to counteract the side-effects, pretty cool.I wanted sort of the opposite of this for opioids - work in the body, not the brain. There's been a few attempts but non that passed trials.\n \nreply",
      "> I wanted sort of the opposite of this for opioids - work in the body, not the brainThat's already how some anti-diarrheals work like loperamide. And some anticonstipation drugs like oral naloxone and methylnaltrexone that work as peripheral or locally-acting antagonists\n \nreply",
      "Yes but loperamide doesn't alleviate pain, which maybe just that opioids only alleviate pain if they do reach the brain, but I did see trials for non-bbb crossing ones that were for pain so not sure what's going on there.\n \nreply",
      "It's possible that the analgesic and euphoric effects of opioids are one and the same. In other words, it's centrally dampening the experience of pain, both physical and mental. One is experienced as analgesia and the other as pleasure, but both may share the same mechanism, making one impossible without the other.\n \nreply",
      "Would the opposite (work in the brain but not the body) also be a healthier alternative for people addicted to getting high on opiates?\n \nreply"
    ],
    "link": "https://www.washingtonpost.com/business/2024/09/26/fda-antipsychotic-mental-illness-alzheimers/",
    "first_paragraph": "Cobenfy showed in clinical trials that it was effective without causing common side effects that lead patients to stop taking their medication.The U.S. Food and Drug Administration late Thursday approved a new kind of drug to treat schizophrenia, a breakthrough after 70 years of incremental innovation that appears to avoid side effects that cause many patients to stop taking their medication.The new drug, Bristol Myers Squibb\u2019s Cobenfy, targets a different area of the brain than traditional antipsychotic drugs to relieve symptoms like delusions without causing patients to gain weight, fall asleep and experience involuntary muscle jerking.The drug was not without its own side effects. Participants in clinical trials reported higher levels of nausea, vomiting and constipation than in a placebo group. Even so, the arrival of Cobenfy offers a new tool for treating schizophrenia \u2014 a disease with profound societal consequences, including homelessness and encounters with police \u2014 beyond a cla"
  },
  {
    "title": "Pagoda: Rapid, easy full-stack web development starter kit in Go (github.com/mikestefanello)",
    "points": 77,
    "submitter": "tosh",
    "submit_time": "2024-09-29T18:19:49.000000Z",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=41689254",
    "comments": [
      "As an Ent user, I\u2019m surprised to see that as the default ORM. It is graph oriented for better and for worse. No composite  primary keys for \u2018nodes\u2019 and minimal use of joins (no use?) in the underlying generated SQL. The DX is great, but GORM is a better default IMO.Nonetheless, great to see a new serious Go meta framework.\n \nreply",
      "Ent heavily uses joins and does support multi field indices, you should read up on the docs. You can show the queries it\u2019s running using a debug client.It\u2019s not a Graph DB under the hood and uses any normal relational db quite normally beneath the DX\n \nreply",
      "Has anyone tried both Pagoda and GoBuffalo and can compare?GoBuffalo recently archived their github project and basically become unmaintained, which is extremely sad for such a mature framework used in production by many.\n \nreply",
      "I found Pagoda required me to juggle too many things that were only loosely coupled together.GoBuffalo was great but as soon as I started using, it got archived :\u2019)Now I default to beego. It isn\u2019t as batteries included as a rails or django app, but there\u2019s enough there that I don\u2019t have to write as much boilerplate as with only the stdlib.\n \nreply",
      "Is this common in Go?Just this week I was examining moving my early stage stack to Golang, but I repeatedly came across highly recommended packages that were dead. Gorilla had apparently died but come back in some capacity, Echo seems to be actively dying as PRs aren't being addressed, Buffalo was an option I looked at and is now archivedDoes the \"just use the stdlib\" mentality mean everyone is just rolling the glue layers on their own 1000x over?\n \nreply",
      "Can\u2019t speak for buffalo but there are many libraries that have not been updated in a while and there\u2019s a reason for that - they are complete.There is no reason to update them, this isn\u2019t nodejs that depends on one billion packages to do one thing where one of those changing basically affects any downstream users.The std library is awesome, backwards compatible, and lots of libraries just add onto it. The interfaces are compatible and you can just keep your code simple.I used to code a lot in Go. These days I\u2019m back in node because it\u2019s just easier for me to move faster. I\u2019m also not doing anything with concurrency, so haven\u2019t had a real need for GoI think for core critical services I would use Go again just I haven\u2019t needed to yet with my new project.\n \nreply",
      "I can appreciate feature complete software but ignoring PRs and literally archiving the Github project means it's dead, not complete.\n \nreply",
      "Looks impressive, and the docs are thorough. Nice work!\n \nreply"
    ],
    "link": "https://github.com/mikestefanello/pagoda",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Rapid, easy full-stack web development starter kit in Go\n      \n\n\n\n\n\nPagoda is not a framework but rather a base starter-kit for rapid, easy full-stack web development in Go, aiming to provide much of the functionality you would expect from a complete web framework as well as establishing patterns, procedures and structure for your web application.Built on a solid foundation of well-established frameworks and modules, Pagoda aims to be a starting point for any web application with the benefit over a mega-framework in that you have full control over all of the code, the ability to easily swap any frameworks or modules in or out, no strict patterns or interfaces to follow, and no fear of lock-in.While separate JavaScript frontends have surged in popularity, many prefer the reliability, simplicity and speed of a full-stack approach wit"
  },
  {
    "title": "On With Theo / T3.gg (ma.tt)",
    "points": 46,
    "submitter": "tosh",
    "submit_time": "2024-09-29T21:15:24.000000Z",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41690667",
    "comments": [
      "There's a fun moment in this interview where Matt says that WP Engine was warned that access to wordpress.org would be cut off. Theo, the podcast host, asks when they were warned and Matt says they were sent a term sheet a week before the cut-off.Theo then reads out the specific terms that Matt says contain the warning, and there is in fact no warning about service disruption.\n \nreply",
      "I enjoyed the part where he explains that he has to operate WordPress.org personally because the IRS wouldn\u2019t allow a non-profit to operate a website with commercial value. He then talks about the structure of the WordPress Foundation, explaining that it has a for-profit subsidiary to run the WordCamps which generates around $5 million per year in revenue from commercial partners. Matt, you just shared a workaround that would work for WordPress.org that you\u2019re already using for operating the WordCamps! He speaks with a calm and polite tone but has a complete lack of sincerity. Anyone with an ounce of integrity would at least pause to consider their contradictions.\n \nreply",
      "PR pro tip: if you're being portrayed negatively in various media and want to correct/respond to/counteract that portrayal, you need people to be able to hear your side of the story.  And of the people that have heard about the Wordpress drama, statistically speaking approximately zero of them will sit through a 2 hour interview video, so consider summarizing your points in some other form (and \"changed my mind on a few things\" is not a summary)\n \nreply",
      "This is just a long way of saying \"tl;dr\", isn't it?\n \nreply",
      "The whole interview feels so fake. Matt consistently avoided answering direct questions, such as whether he had to defend the WordPress trademark in the past 20 years and if so, how. Additionally, he frequently changed the subject, particularly when questioned about why WP Engine was chosen as a sponsor despite his negative characterization of them - calling them \u201ccancer\u201d.It\u2019s difficult to take the interview seriously. Very disappointing and a waste of time in my opinion.\n \nreply",
      "The tone is very calm, Mullenweg is vocally very soft spoken and I think it made sense for Theo to follow this. However he does confront him on some things. Especially here: https://youtu.be/OUJgahHjAKU?si=VnIqx8LPHcEXnTl-&t=2366\n \nreply",
      "Doesn't he have a whole story about having to enforce the WordPress trademark against a company reselling rebranded GPL WordPress plugins as \"pro\" versions, jus a few weeks ago? Where did you stop watching? This comes up just after the first appearance of the cat.\n \nreply",
      "> I believe discussion is the best way to resolve conflict, that\u2019s why my door is open to Lee Wittlinger, Heather Brunner, Brian Gardner, or any WP Engine or Silver Lake representative who wants to talk to resolve things.I can't blame them if they don't want to talk to him, since he called WP Engine a cancer. I don't think he meant it to sound so dehumanizing, but it's a hell of an insult to throw around.\n \nreply",
      "They've been talking for over a year.\n \nreply",
      "Some feedback:\n- The constant interrupting each other made it hard to listen to\n- Also the interviewer Theo/T3.gg giving his CEO take on strategy to sandbag silverlake after finding out more context behind silverlake and automattic's relationship led me to have an unfavorable impression of the guy\n \nreply"
    ],
    "link": "https://ma.tt/2024/09/t3/",
    "first_paragraph": "On Thursday a prominent developer YouTuber, Twitch streamer, and journalist posted a video titled This might be the end of WordPress. It was very harsh. In that video you\u2019ll hear him say about me, \u201che\u2019s a chronic hater\u201d (7:55), \u201cseems like he\u2019s been a pretty petty bastard for a long time now\u201d (10:22), \u201cI hate this shit, I hate when people are assholes and they get away with it because I\u2019m doing it for the greater good, the fake nice guy shit. I\u2019ll take an asshole over a fake nice guy any day, people whose whole aesthetic is being nice, I hated it.\u201d (11:25), \u201cHonestly I\u2019d rather the license just be explicit about it than this weird reality of \u2018If you get popular enough you can still use it but the guy who made WordPress is going to be an asshole to you.\u2019 That seems much worse than most open source models.\u201d (14:39)\u2026 it goes on.Ouch!However, one of my colleagues Batuhan is a follower of Theo\u2019s and suggested I engage with him. It turns out we were both in San Francisco, and he was game for"
  },
  {
    "title": "Sitina1 Open-Source Camera (gitlab.com/zephray)",
    "points": 125,
    "submitter": "zdw",
    "submit_time": "2024-09-29T15:27:54.000000Z",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=41688018",
    "comments": [
      "I\u2019ve thought for years that there had been dearth of open source cameras. It\u2019s nice to see them picking up steam, with a few recent posts of them.\n \nreply",
      "Love it. I really wish classical mirrorless camera makers would get their head out of their collective asses, and make a camera that is not stuck in the 80-s mentality.Give me a large sunlight-readable touchscreen, with multitouch. Also GPS, WiFi, Bluetooth, and 5G/LTE for connectivity and geotagging. Add automatic uploads to Google Photos, iPhoto, WebDAV, etc. Put in a small editor for on-device photo touchups.Also, ditch the old-timey film-camera look. I don't need 15 physical switches, most of which should be automatic anyway. A physical button for the shutter and an analog knob for fine tuning are fine, but I don't need a manual switch for AF/MF. Or a \"shutter delay\" selector that is too easy to accidentally bump.\n \nreply",
      "https://petapixel.com/2021/07/10/yongnuo-yn455-a-new-android...A few have tried, and they all fail. Most people are just going to use their phone, and the ones that won't _want_ the old-timey looks and hardware dials.https://newatlas.com/photography/switchlens-m43-smartphone-c...This one I think has promise though\n \nreply",
      "There have been a few different attempts that look like this. Samsung Nx, Samsung Galaxy Camera, Sony has tried phone add on accessories. Basically they all sort of flop in the market.People that don\u2019t want to think about their photos use a smartphone. People that want to think about their photos still want a camera that they can control. I use a mirrorless Nikon camera and to take a single picture I normally want physical controls that can handle exposure, focus, zoom level and shutter release independently, but simultaneously without having to remove my attention from the image. The ability to do all that with physical, not menu controls, is a tremendous asset for most people that want to spend the money on a camera. If you slapped the latest technology inside a camera that didn\u2019t have all the physical controls, photographers wouldn\u2019t want anything to do with it.I wouldn\u2019t say that camera design is stuck in the 80s, either. The form factor is necessarily constrained by needing a tubular lens projecting in front of a flat imaging plane. The photographer is going to want to view the image from the opposite side as the lens. There\u2019s only so much you can change the form factor with those constraints. Camera companies do have a few retro models, but even stodgy old Leica is making modern designs these days.If you take tens of thousands of photos per year, you sort of realize that all cameras have more or less the same interface and form factor as they have for a while because it is what works best.\n \nreply",
      "> There have been a few different attempts that look like this. Samsung Nx, Samsung Galaxy Camera, Sony has tried phone add on accessories. Basically they all sort of flop in the market.There was exactly ONE attempt. One. And it was pretty successful, at that: Samsung NX1. I had it, it was pretty good, but with a first-gen teething issues.Phone add-on accessories don't work because they're clumsy and connectivity just sucks. And ultra-professional $6k cameras from Zeiss miss the mark entirely, you need to target a prosumer market (i.e. me).> I wouldn\u2019t say that camera design is stuck in the 80s, either. The form factor is necessarily constrained by needing a tubular lens projecting in front of a flat imaging plane.But why do you need a large protrusion on the right? You don't have a film canister anymore. I already wrote about a myriad of physical controls. Just make it large enough to hold the camera.\n \nreply",
      "There was one interchangeable lens attempt, and multiple non interchangeable ones. As mentioned, the Samsung galaxy camera, as well as Polaroid branded android cameras.You need the large protrusion on the right because you have to hold the thing. It\u2019s a handle. It needs to be somewhere, most people are right eye, right hand dominant. It makes a lot of sense to have it that way. The primary hand holds the camera, the other hand holds and supports the lens.In the olden days, the film canister was physically stored on the left in almost all cameras (and certainly in all SLRs), so the protrusion on the right isn\u2019t really a remnant of film designs.Older film cameras actually have smaller less ergonomic protrusions on the right (look at a Nikon F2 vs. the modern Z8). The big ergonomic protrusion on the right has been an evolution of newer modern technology and expectations.You can get a camera with gps, wifi, Bluetooth etc. do they have you screens that don\u2019t have multitouch? It\u2019s pretty hard not to get all that TBH. I can do crops and color treatments on my Nikon if I don\u2019t want to just transfer directly to my phone and do the editing there. Yeah, the camera doesn\u2019t automatically put it all in my iPhoto, but that is literally just a few taps.There are MILC cameras that have minimal physical controls and touchscreens so I\u2019m not really sure what you\u2019re looking for? The sigma FP is pretty minimal, and you just strap on what you need.\n \nreply",
      "I agree.  Maybe the breakdown is between:1) taking a picture2) doing something with the picturePeople coming to photography from smartphones want the priorities reversed.But the deeper you get into it, the more you want #1 and the more control you want over #1.  The worst is #2 getting in the way of the shot.And actually, lots of people into photography think it is about the camera, but it is really about the lenses.You buy lenses, then buy/upgrade bodies around them.\n \nreply",
      "I would add that Zeiss (ZX1) and Leica (T typ 701, TL2) tried this modern touch-first approach at a premium and both products weren't exactly hits. The Zeiss was even running Android with Lightroom preinstalled.\n \nreply",
      "I mean... It's a camera that was retailing for $6k without lenses. It's already a niche market, and a pretty conservative one.\n \nreply",
      "Samsung did make a camera with most of those features (it was before 5G, so 3G I think). I had it, it sucked a lot.Turns out physical buttons for most things is very important if you want to be able to rapidly change settings as required for capturing a moment. Whenever I tried using that camera I lost so many shots due to the delay of fiddling with menus or the startup time.\n \nreply"
    ],
    "link": "https://gitlab.com/zephray/sitina1",
    "first_paragraph": "Created on"
  },
  {
    "title": "The Teacher Who Made Mistakes on Purpose (nik.art)",
    "points": 7,
    "submitter": "herbertl",
    "submit_time": "2024-09-29T23:54:06.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://nik.art/the-teacher-who-made-mistakes-on-purpose/",
    "first_paragraph": ""
  },
  {
    "title": "Ruby Meetups (rubyconferences.org)",
    "points": 42,
    "submitter": "mooreds",
    "submit_time": "2024-09-29T18:45:15.000000Z",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=41689449",
    "comments": [
      "Had a flashback to twenty odd years ago in Sydney when there weren't enough Rubyists to get a reservation at the pub for a meetup so we had to team up with the Smalltalk guys. Ahhh, different times.\n \nreply",
      "It gave me a flashback to 2007, when I was a hobbyist programmer and signed up for a Ruby meetup on a whim, and a recruiter called me 5 minutes later and ended up getting me my first programming job. Crazy to think how much that changed my life.\n \nreply",
      "Interestingly, Sydney does not seem to have an event listed on this site when I checked. Adelaide and Auckland lead the charge, with an occasional Melbourne meetup.As an aside, I dislike the strong association between Rails and Ruby. Ruby can be a fun scripting language. In my experience I'm generally about as productive writing Ruby as I am with writing Python, but Ruby seems to get bucketed into a very Rails centric world of \"not the worst choice you could make if you wanted to make a web service\" (at least when it comes to meetups).Maybe it's just that the web service guys are more likely to need a support group! :)\n \nreply",
      "I agree with you, but it\u2019s an indisputable fact that Rails is why the overwhelming majority of Ruby programmers have paying jobs.\n \nreply"
    ],
    "link": "https://rubyconferences.org/meetups/",
    "first_paragraph": "No meetup matched your current filter selection.\n    But don't let that stop you! You could be the one to spark the Ruby community in your area.\n  \n    Consider organizing your own event.\n    It's a great way to bring developers together, inspire others, and create amazing opportunities.\n    Your initiative could make a real difference!\n  created & maintained by Jon Allureddesign & markup by Cameron Daigle"
  },
  {
    "title": "Web components are okay (nolanlawson.com)",
    "points": 176,
    "submitter": "keybits",
    "submit_time": "2024-09-29T11:57:00.000000Z",
    "num_comments": 185,
    "comments_url": "https://news.ycombinator.com/item?id=41686722",
    "comments": [
      "I tried to understand the referenced article \"Web Components Are Not the Future\" - but found that there weren't many convincing arguments.The current state of Front-end frameworks is an absolute mess. Speaking for myself, I don't want to learn a complex framework. I don't want to learn magic that I don't understand without reading the documentation (useState, createSignal et al). Magic in frameworks is often a hack, unlike magic in libraries. The first library I used was Prototype. It felt like magic, and it truly was. And so was jQuery, and Backbone. I never had to guess what \"useState\" does behind the scenes.There are many things which don't carry over into Web Components from current JS frameworks. But if you start from Web Components (ignoring everything you know about frameworks), it suddenly becomes intuitive. And it brings in abilities which are missing otherwise, such as isolation via Shadow DOM. It grows on you.In my view the only thing we should retain from the React era is JSX (for many reasons, true type-safety, autocomplete etc). I wrote a library last week for using Web Components with JSX. No magic other than JSX. https://webjsx.org\n \nreply",
      "> I don't want to learn a complex framework. I don't want to learn magic that I don't understand without reading the documentation (useState, createSignal et al).I can't really parse this sentence. It seems to have a lot of ideas in it. Do you want to learn a framework at all, or have one that is so magical that it feels like it doesn't need to be learned? Do you want to read documentation or not? Do you think the problem with React is that its primitives are unsuited to the work you do in it? Or to the work anybody needs to do?I've spent most of my professional career in Vue, so I don't have a great perspective on the React ecosystem. But Vue feels like it must be included in your \"complex framework\" statement. I've definitely felt some pain from overuse of the framework, or poor understanding of various features, libraries, etc. The ecosystem around full-on SPAs is indeed complex. I'm just not sure what other systems would let me personally, and us broadly, manage a complex stateful client-side app.(This is entirely separate to overuse of SPAs for things that shouldn't be SPAs.)\n \nreply",
      "I think the point is that frameworks ' magic isn't 100% there yet. You eventually HAVE to dive deep and understand things about the implementation to understand how to use it.\n \nreply",
      "Ryan builds out Solid's reactivity system (createSignal) from scratch in about 20 minutes, live, in this video https://youtu.be/N-Y32BqhoYQ?t=1100I haven't bothered fully grokking it because I've never had to understand the impl details. Solid gives me literal dom elements, and that's low-level enough for me.\n \nreply",
      "I think he was pretty clear that the \"magic\" in frameworks is not something you can easily understand, therefore have to guess how it really works. He doesn't like that.\n \nreply",
      "You don't need to guess. You can actually read the code! Not saying that you should straight away when learning, but later, when you're familiar with your framework, I think reading through the codebase and understanding it is good practice.\n \nreply",
      "You can read the code, but it\u2019s complex and convoluted.He referenced Backbone as a comparison point. If you compare Backbone\u2019s source code to React\u2019s source code, you\u2019ll get what he means.Basically, libraries like Backbone are small and simple enough that you can literally read the source code and fully understand how it works. Compare that to React, where the source code is an order of magnitude larger and very difficult to fully grasp the inner workings.The simplicity and ability to easily understand the source code obviously comes with tradeoffs (e.g. with Backbone, to use it to build a reasonably complex app, you basically have to build your own framework on top of it, compared to React which has more abstractions and therefore is more plug and play.\n \nreply",
      "I'll try to give an example of \"bad magic\".Did you know React renders twice in developer mode to try to expose bugs with side effects?If this doesn't raise an eyebrow, I don't know what will.\n \nreply",
      "That seems like a pragmatic solution. The point of having a dev mode is to help development and catch mistakes. if(devMode) { rerender() } doesn't seem like magic. Though in general I really dislike the term magic for what is just code doing something.\n \nreply",
      "It's because the fundamental model of React's render cycle is unintuitive when combined with state.  It's easy to make mistakes of this class specifically with React.\n \nreply"
    ],
    "link": "https://nolanlawson.com/2024/09/28/web-components-are-okay/",
    "first_paragraph": "\n\n28\nSep\n\n\t\t\tPosted September 28, 2024 by Nolan Lawson in performance, Web, web components.\t\t\t\t\t\tLeave a CommentEvery so often, the web development community gets into a tizzy about something, usually web components. I find these fights tiresome, but I also see them as a good opportunity to reach across \u201cthe great divide\u201d and try to find common ground rather than another opportunity to dunk on each other.Ryan Carniato started the latest round with \u201cWeb Components Are Not the Future\u201d. Cory LaViska followed up with \u201cWeb Components Are Not the Future \u2014 They\u2019re the Present\u201d. I\u2019m not here to escalate, though \u2013 this is a peace mission.I\u2019ve been an avid follower of Ryan Carniato\u2019s work for years. This post and the steady climb of LWC on the js-framework-benchmark demonstrate that I\u2019ve been paying attention to what he has to say, especially about performance and framework design. The guy has single-handedly done more to move the web framework ecosystem forward in the past 5 years than anyone e"
  },
  {
    "title": "Build a serverless ACID database with this one neat trick (atomic PutIfAbsent) (eatonphil.com)",
    "points": 42,
    "submitter": "todsacerdoti",
    "submit_time": "2024-09-29T19:37:29.000000Z",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41689794",
    "comments": [
      "I know the article says \"analytics workloads,\" but I wonder if this pattern could be used for ex. bursty-write workloads.For context, I have a use-case where I have a Meilisearch server that has all the data in it updated once daily, and then every single request outside of that one bulk update is a read. The only exception is that once in a great while, something breaks and the entire index has to be rebuilt. Since it's a hobby project, my workload is too expensive to fit into Meilisearch Cloud or similar solutions. I keep finding myself wishing that there was a serverless search engine that would free me from having to self-host one, keep a dedicated server running and updated, etc. If I could \"just\" run a search engine with Cloudflare Workers + R2 (+ probably ancillary CF services) I'd be very happy.I don't know enough to actually answer my own question unfortunately; I can't intuit the answer just from reading the docs and database implementations aren't my area of expertise.\n \nreply",
      "> I know the article says \"analytics workloads,\" but I wonder if this pattern could be used for ex. bursty-write workloads.The key point is that Delta Lake and Iceberg concurrency control is so coarse-grained. As I mentioned in the article, they did this because it seemed they wanted to avoid an external highly-available metadata store (e.g. FoundationDB which is what Snowflake uses).Just about every Database as a Service (OLTP or OLAP) these days supports storage tiering to cloud blob storage. Delta Lake and Iceberg just took cloud blob storage to the extreme by trying to do everything in it (or as much as possible, Iceberg seems to require a Compare-and-Swap operation which I'm not sure is possible to express with atomic PutIfAbsent alone; seems to require an external HA metadata store for their one current metadata pointer). And in doing this they gave up fine-grained concurrency control.\n \nreply",
      "For folks interested in this topic I highly recommend this talk by Cliff Click about building highly scalable hash tables via Compare And Swap:https://youtu.be/HJ-719EGIts\n \nreply",
      "I wish we generally used solutions like this instead of always reaching for the 200lb database hammer.however, I think the article would benefit from distinguishing this approach from a 'real' database. that is MVCC gets you a lot more concurrency because it spreads out the exclusionary state in both time and space.the optimistic concurrency used in the article works well at low contention and then becomes arbitrarily latent as more and more proposers try to jump into same RTT gap with both their initial attempt and their retries.\n \nreply",
      "> however, I think the article would benefit from distinguishing this approach from a 'real' database. that is MVCC gets you a lot more concurrency because it spreads out the exclusionary state in both time and space.I thought I already was going to be seen as being unfairly critical of the course-ness of the concurrency control.\n \nreply",
      "in any case thanks for writing it up. I was just thinking about doing this in a broadcast domain to provide the same kind of low-throughput bootstrapping consistency that people would normally use zookeeper or etcd for. its certainly very useful in the cases where it fits.\n \nreply"
    ],
    "link": "https://notes.eatonphil.com/2024-09-29-build-a-serverless-acid-database-with-this-one-neat-trick.html",
    "first_paragraph": "Delta Lake is an open protocol for serverless ACID databases. Due to\nits simplicity, scalability, and the number of open-source\nimplementations, it's quickly becoming the DuckDB of serverless\ntransactional databases for analytics workloads. Iceberg is a\ncontender too, and is similar in many ways. But since Delta Lake is\nsimpler (simple != better) that's where we'll focus in this post.Delta Lake has one of the most accessible database papers I've read\n(link). It's\nkind of like the\nmovfuscator of\ndatabases.Thanks to its simplicity, in this post we'll implement a Delta\nLake-inspired serverless ACID database in 500 lines of Go code with\nzero dependencies. It will support creating tables, inserting rows\ninto a table, and scanning all rows in a table. All while allowing\nconcurrent readers and writers and achieving snapshot\nisolation.There are other critical parts of Delta Lake we'll ignore: updating\nrows, deleting rows, checkpointing the transaction metadata log,\ncompaction, and probably muc"
  },
  {
    "title": "JabRef \u2013 Literature Management (jabref.org)",
    "points": 46,
    "submitter": "smartmic",
    "submit_time": "2024-09-25T10:35:38.000000Z",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=41645822",
    "comments": [
      "At Github, https://github.com/JabRef/jabref\n \nreply",
      "I've tried JabRef, Zotero, and Mendeley. The latter two seem more modern and friendly in some ways but I prefer JabRef. Works well with LaTeX/BiBTeX and it looks more old-school, which I like. Mendeley's advantage is that it has free online storage.\n \nreply",
      "I use zotero with the better bibtex extension. But when I finalize a document, I use jabref and its 'make a new library from .aux file' tool which can then create a .bib file with only the references used in the document. Much easier to archive than my full zotero library with thousands of entries. Also makes it easier to fine tune any edits to the .bib references for that specific document and template.\n \nreply",
      "Have you tried zotero 7?It is currently in beta but they polished the UI and the UX is now much better than before. If not, I would recommend that you give it a try.\n \nreply",
      "Zotero 7 is excellent. I also like the official Zotero iPad app, which is quite decent to read and annotate papers in your Zotero library on the go.\n \nreply",
      "The new iPad app for Zotero 7 is great. Editing just seems to work. I use my WebDAV server for storage and my changes just show up across devices without worrying. Really great way to manage papers.Now if only there were an iPad with a screen like the Remarkable (or a Zotero app for the Remarkable).\n \nreply",
      "Zotero 7 is the first usable version in 15 years for me. And it's great.\n \nreply",
      "I\u2019ve recently become a Zotero user. I\u2019m liking the mobile support in the iOS ecosystem. Jabref highlights search and discovery in the docs.  Does anyone have opinions on how that compares to the other apps?\n \nreply",
      "The main reason I haven't adopted Zotero is their lack of a  Android app. Something like that on the road map for JabRef?\n \nreply",
      "Zoo for zotero is pretty good ;)I think the dev do not work on it anymore, but it's in a very usable state and open source.\n \nreply"
    ],
    "link": "https://www.jabref.org/",
    "first_paragraph": " Read more about it below or get going straight away.  JabRef was founded 2003 and has since been used by many students and researchers. Our mission is to advance knowledge and improve scientific research. We value open access to information and believe modern science can built on an open institutional structure. This is why we develop JabRef as  free open-source software  and save your data in a  simple text-based file format  with no vendor lock-in.  Created by researchers, for researchers.  JabRef is developed and maintained by a multidisciplinary core team of PhD students, postdocs, and researchers in industry who work on JabRef in their free time. Without the support of numerous volunteers, none of this would have been possible. We welcome anyone who would like to contribute to be part of an active user and developer community!  You do not need to be a developer to improve the documentation, translate the user interface and help with support.  Help us pay for project development a"
  },
  {
    "title": "CPU Throttling for containerized Go applications explained (kanishk.io)",
    "points": 50,
    "submitter": "imiric",
    "submit_time": "2024-09-29T18:06:59.000000Z",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=41689159",
    "comments": [
      "I feel like there is a great potential to be explored here by playing with cgroups dynamically, not in a machine learning way but allowing bursts, finding good ratios request/limit to pick up (1s/10s or 0.1s/1s ?) and voluntarily kicking out (eviction) stateless workloads.I even pursued my PhD on it until I quit (unrelated reasons). There was a startup doing this with ML but forgot their name.\n \nreply",
      "I would say that this has relatively little to do with Kubernetes in the end. The Kubelet just turns the knobs and pulls the levers that Linux offers. If you understand how Linux runs your program, then what K8s does will seem obvious.A detail I would like to quibble about: GOMAXPROCS is not by default the number of CPUs \"on the node\" as the article states. It is the number of set bits in the task's CPU mask at startup. This will not generally be the number of CPUs on the node, since that mask is determined by the number of other tenants and their resource configurations. \"Other tenants\" includes the kubelet and whatever other system containers are present.The problem of using this default scheme arises because GOMAXPROCS is latched in once at startup, but the actual CPU mask may change while the task is running, and if you start 100 replicas of something on 100 different nodes they may all end up with various GOMAXPROCS, which will affect the capacity of each replica. So it is better to explicitly set GOMAXPROCS to something reasonable.\n \nreply",
      "I think it kind of has to do with kubernetes, in that kubernetes embeds assumptions in its design and UI about the existence of a kernel capability which is almost, but not quite, entirely unlike the cpu.max cgroup knob, and then tries to use cpu.max anyway. Leaving CPUs idle when threads are runnable is not normally a desirable thing for a scheduler to do, CPU usage is not measured in \"number of cores\", and a concurrency limit is about the least-energy-efficient way to pretend you have a slower chip than you really do.There is a reason these particular users keep stepping on the same rake.cpu.uclamp.max is a little closer to the mental model k8s is teaching people, but it violates the usage=n_cores model too, and most servers are using the performance governor anyway.\n \nreply",
      "Or just update it at runtime every minute or something.\n \nreply",
      "You can tail some devices can\u2019t you?\n \nreply",
      "The go runtime isn't really dynamic in that regard.\n \nreply",
      "It has been from the first version: https://pkg.go.dev/runtime#GOMAXPROCS\n \nreply",
      "tl;dr: don't set CPU limits in Kubernetes - especially for multi-threaded applications - unless you strictly require CPU bandwidth control [1].[1]: https://docs.kernel.org/scheduler/sched-bwc.html\n \nreply"
    ],
    "link": "https://kanishk.io/posts/cpu-throttling-in-containerized-go-apps/",
    "first_paragraph": "Runes of Undocumented CodeIt\u2019s been a long time since I wrote something here. Past few years I\u2019ve been busy at work which is where most of my writing is done these days. This particular entry comes as an offshoot of a production disaster I saw and then took the opportunity to dive deep and learn more. What seemed like a convoluted problem at the outset, ended up being pretty fascinating in the end.It\u2019s a bit of a shock to me that even though the majority of Go applications are deployed in containerized environments, there\u2019s very little awareness (from what I\u2019ve seen) about this gotcha (as you will come to learn ahead) which can have major consequences.This is a problem I had already solved for some of our services a few months ago, but when it came to explaining WHY it worked, I realized my understanding was somewhat broken. So, when we faced an issue caused by CPU throttling in another one of our services, I took the opportunity to dive deeper and understand why exactly this worked th"
  }
]