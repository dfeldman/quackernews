[
  {
    "title": "Claude Code IDE integration for Emacs (github.com/manzaltu)",
    "points": 551,
    "submitter": "kgwgk",
    "submit_time": "2025-08-06T13:17:38 1754486258",
    "num_comments": 181,
    "comments_url": "https://news.ycombinator.com/item?id=44811567",
    "comments": [
      "Like LSP and tree-sitter, I think AI coding tools like Claude Code or Aider are very good news for niche editors like Emacs or Vim. Instead of struggling about implementing advanced IDE-like features, they can integrate with these tools relatively easily, and focus on other editing related features that set them apart. In fact, IMO it makes these editors more competitive because they are highly customizable and easier to integrate with these tools.reply",
      "Is there a standard for integrating agentic coding tools into an editor similar to how an LSP allows the integration of language-specific features?reply",
      "Its not at anything like the adoption of MCP or especially LSP, and it takes a more \"foundational and composable library of primitives\" approach than \"wire protocol per se\" approach, but `gptel` has quite the vibrant little ecosystem around it and its just god mode, wall hacks on the VSCode stuff, just blows it away. I'm under extreme time pressure at the moment, I cannot afford to fuck around on ideology right now I have to go for the jugular every day, and that means \"fuck the cost\" Opus 4 use in `gptel` (though Qwen and K2 are pushing it out of more and more stuff as I learn the quirks, Opus 4 TTFT under load is unusable and when it starts fighting you on clean merge boundaries because its personality vector has been set to \"token stingy\" its strictly worse).Its not that I dislike Cursor, its that I dont have time to put up with its compromises for non-extreme-power-user accessibility. I need an extreme power, cost indifferent, tuned for the margins stack.That's nothing with a VSCode base that I know about, and I've tried Cline and Roo and Continue and written a bunch MCP servers and I measure it all, not even close.I bet the neovim people have something just as good.reply",
      "cannot afford to fuck around, go for the jugular every daySlow your roll.  Nothing you write will matter in six months.reply",
      "Can't speak for you friend, but I got my ass kicked through a combination of the hiring freezes and absorbing a bunch of famiku-wide expenses around a nasty bereavement like, right before that and got pretty much wiped out. Having been very well off (to put it mildly) from like, 2010-2023, I was pretty unclear on the fact that going broke is straight up existential now in a way that was not true ten or fifteen years ago. If you've been doing alright for a decade or so, I wouldn't blame you for not knowing that.But as a guy who is a known enemy of the Valley establishment to begin with rebuilding from all that? When I say I'm dead serious, I'm being earnest.If you don't have a family/community safety net and/or a plugged-in nepo golden age network?Stack cash on hand like your life depends on it, because it fucking does.reply",
      "being broke was absolutely existential fifteen years ago.signed:someone who was broke fifteen years ago and has been stacking cash on hand ever since.reply",
      "I believe you, my situation might have been different. I never had much growing up and never had good jobs until like my mid 20s, I remember it sucking to be broke but not being scary if that makes sense? You could usually find at least a shitty job and even a shitty job could get you some kind of apartment or room even with bad credit. Nice apartments had hard credit checks but there were independent landlords everywhere, so if you didn't mind the occasional drug deal on your block, it was like, workable. Now its all property management companies with what amounts to one computer system and if you don't like it? AirBnB is happy to absorb every last house, room, carboard box, and park bench.And a shitty job is no guarantee of a shitty room now, you see homeless people still in the Best Buy shirt they were wearing when they got laid off, and Best Buy is nowhere near the worst job.I thought working hard and being really good at computer stuff was basically some kind of bare minimum job guaranteed, that being free with my money might mean not retiring young. Didn't realize tech employment was war.Wrong. Won't make that mistake again.reply",
      "Ditto. Being broke has always been existential, and pretty damn scary even if you had family and other resources you could lean on. Nothing's changed about that, though particular industries/regions may get better or worse.reply",
      "the code that i am least proud of is the code that has lasted the longest :-)reply",
      "My 'beef' with Cursor is that the editor is part of the package and you don't really have the same kind of hooks into the agent that you do with Claude Code or similar, which really means you're at the mercy of the Cursor team to prioritise those things on their roadmap. That includes things like the limit of 40 MCP tools that you can only enable globally (and MCP proxies that try to do this dynamically are a bit flakey) - even just using the GitHub MCP blows through that limit because it's all or nothing.It's good for what it is but I don't love that I have to change to a whole-ass new editor to get access to the agentic additions, when alternatives that require an API key or a more flexible CLI tool can do a better job.reply"
    ],
    "link": "https://github.com/manzaltu/claude-code-ide.el",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Claude Code IDE integration for Emacs\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\nClaude Code IDE for Emacs provides native integration with Claude Code CLI through the Model Context Protocol (MCP). Unlike simple terminal wrappers, this package creates a bidirectional bridge between Claude and Emacs, enabling Claude to understand and leverage Emacs\u2019 powerful features\u2014from LSP and project management to custom Elisp functions. This transforms Claude into a true Emacs-aware AI assistant that works within your existing workflow and can interact with your entire Emacs ecosystem.This package enables Claude Code to leverage the full power of Emacs through MCP tools integration. Claude can directly access and utilize Emacs capabilities including:This deep inte"
  },
  {
    "title": "Rules by Which a Great Empire May Be Reduced to a Small One (1773) (archives.gov)",
    "points": 36,
    "submitter": "freediver",
    "submit_time": "2025-08-06T23:29:11 1754522951",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=44819037",
    "comments": [
      "Interesting that all nouns are capitalized, like in modern German and unlike in most other modern languages that use the Latin alphabet.reply",
      "It\u2019s not uncommon for the time. E.g. \u201cin Order to form a more perfect Union, establish Justice, insure domestic Tranquility, provide for the common defence, promote the general Welfare, and secure the Blessings of Liberty to ourselves and our Posterity\u2026\u201dreply",
      "Satire, Piece, and Virtues are the first Nouns that I find not capitalized.  They occur within the first few Sentences, and I trust that my Observation and Diligence in this Matter might not go without Recognition.reply",
      "The Declaration of Independence and the original US Constitution (the main portion plus the Bill of Rights) are also written in this style, though not all nouns are consistently capitalized.reply",
      "Now, we can't even get people to capitalize proper nouns to disambiguate soil from a planet.reply",
      "Is this like the prince or art of war where we are supposed to draw some lesson from very specific critiques and extrapolate it to every scenario.reply",
      "Timeless rules\u2026 They can be applied generally to large organisations, and serve as an excellent summary of symptoms of elite blindnessreply"
    ],
    "link": "https://founders.archives.gov/documents/Franklin/01-20-02-0213",
    "first_paragraph": "Printed in The Public Advertiser, September 11, 1773; incomplete draft and notes:6 American Philosophical SocietyFranklin was pleased with this satire, which was a companion piece to \u201cAn Edict by the King of Prussia.\u201d7 Both had the virtues, he believed, of brevity, comprehensiveness, and \u201cout-of-the-way forms\u201d that caught attention; but he preferred the \u201cRules\u201d to the \u201cEdict\u201d for the breadth and variety of its contents and for \u201ca kind of spirited ending of each paragraph.\u201d8 His technique in the two was different: in this one he challenged his readers to see their government\u2019s policy through colonial eyes; in the \u201cEdict\u201d he jolted them with the fiction that they were colonists themselves. The two essays had a single purpose, to induce the public to take a fresh look at the American problem. When Parliament reconvened in the autumn, that problem promised to be a major subject of discussion; and the sensational demand from Massachusetts for the removal of Hutchinson and Oliver was sure, w"
  },
  {
    "title": "Project Hyperion: Interstellar ship design competition (projecthyperion.org)",
    "points": 127,
    "submitter": "codeulike",
    "submit_time": "2025-08-06T20:40:17 1754512817",
    "num_comments": 118,
    "comments_url": "https://news.ycombinator.com/item?id=44817539",
    "comments": [
      "This feels like the grown-up ideological successor to the International Space Settlement Design Competition for high school students. That was (is? anyone still in the know?) a competition that ran for years out of NASA Houston as a pet project of some engineers and contractors who wanted to engage and cultivate the next generation of aerospace minds.Teams would submit proposals for the design of a permanent space settlement (sometimes on the surface of a body, sometimes orbiting). Winners from across the world were invited to compete together live in 4 huge multi-national teams to design and pitch another settlement over a long sleepless weekend. As a two-time finalist, I can say it was an incredible experience for so many reasons.This new competition seems like its goal is to actually take the design/ideation of working professionals as a serious output, as opposed to the educational value of simulating this sort of thing for students, which is what drove the ISSDC.reply",
      "It was indeed incredible. Battled out in a pan Asia round, won it, and got invited to the ISSDC at the Kennedy Space Center in Florida. Felt so fortunate learning from engineers at Boeing and NASA.  Incredible experience for a 15yo kid from India.Coincidentally, it has been exactly 10 years since and my photos app resurfaced some of the memories. Good times.reply",
      "Link to Canva presentation for the winning entryhttps://www.canva.com/design/DAGmr3ubC8E/LHHAeeAIGGQe_TkZVs-...reply",
      "Reading through this in detail just cements that we are never leaving this solar system unless we discover some new physics to get around our speed limitations.reply",
      "> we are never leaving this solar system unless we discover some new physics to get around our speed limitationsThe winning proposal coasts at 0.01c. Propulsion systems--not the speed of light--and thus engineering, not phsyics, are the relevant limitors.reply",
      "I am increasingly certain that culture is by far the biggest limiting factor when it comes to large-scale problem solving now and in the future.We couldn't even reliably get people to put a piece of fabric over their face to stop killing their own relatives. Even if we could build a generation ship, it would turn into an Event Horizon hellscape if we don't figure out better cultural, communication, and sociological tools to enable us to get along and work together effectively.reply",
      "> We couldn't even reliably get people to put a piece of fabric over their faceRural Americans couldn\u2019t. But I don\u2019t see anyone proposing we put high school dropouts in space.China, India and Japan managed to pass that test just fine. I imagine one of the former two will be the first to colonise deep space.reply",
      "We're one good new religion away from colonizing the solar system.Cathedrals were built over 100s of years. Imaging just living in a massive one and your whole holy purpose is to survive and thrive and spread.It's entirely reasonable we'd have the will to make it happen, and pretty reasonable we'd be able to build it with planet scale effort, but sadly quite difficult to imagine it surviving even dust impacts for 400 years.reply",
      "> quite difficult to imagine it surviving even dust impacts for 400 yearsWhipple shields [1].[1] https://en.wikipedia.org/wiki/Whipple_shieldreply",
      "Whipple shields are consumed by impacts.reply"
    ],
    "link": "https://www.projecthyperion.org",
    "first_paragraph": "Design for CenturiesProject Hyperion explores the feasibility of crewed interstellar travel via generation ships, using current and near-future technologies. A generation ship is a hypothetical spacecraft designed for long-duration interstellar travel, where the journey may take centuries to complete. The idea behind a generation ship is that the initial crew would live, reproduce, and die on the ship, with their descendants continuing the journey until reaching the destination. These ships are often envisioned as self-sustaining ecosystems, featuring agriculture, habitation, and other necessary life-support systems to ensure survival across multiple generations.\u00a0\u200bThe Initiative for Interstellar Studies (i4is) is delighted to reveal the winners of the Project Hyperion Design Competition, a landmark global challenge that called upon interdisciplinary teams to envision a generation ship\u2014a crewed interstellar spacecraft designed for a 250-year journey to a habitable planet. The teams desi"
  },
  {
    "title": "Litestar is worth a look (b-list.org)",
    "points": 168,
    "submitter": "todsacerdoti",
    "submit_time": "2025-08-06T19:43:01 1754509381",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=44816755",
    "comments": [
      "Thank you for writing this, I've been building a large backend with FastAPI for the last year or so and I've gone through all the levels of the purgatory.I began using the standard \"tutorial\" style and started cringing when I saw the official template [1] place all CRUD operations in a single file (I've been doing Rails and Spring for a while before) and the way dependencies where managed... let's just say I wasn't feeling very comfortable.Then came the SQLModel problems. The author pushes it very hard in the FastAPI docs (which imho are terrible because when I'm looking for docs I want that, documentation, not a fancy tutorial) but as an ORM (yes I know its a layer on top of SQLAlchemy) it doesn't even support polymorphic models and the community even has contributed PRs that have gone months without any review (is it even maintained anymore? I honestly can't tell).I guess I'm the only one to blame for choosing FastAPI to build a big project but after having used it quite a lot (and also read its code because again, docs are extremely poor) I wouldn't recommend it for anything serious. Sure, if you want to build a quick CRUD then go ahead and use SQLModel and FastAPI, but keep in mind that its not built for complex applications (at least not without requiring you to write a framework on top, like I've unfortunately done).So yeah, a big thank you to the author of this post because I will migrate to Litestar as soon as I wake up tomorrow.reply",
      "TBH, the FastAPI \"docs\" are at https://github.com/polarsource/polar/tree/main/serverIf you want to actually figure out how to scale FastAPI for a large-ish app, including auth, testing and all that stuff, all with modern practices, \"how they do it in that repo\" is probably a good way to start with.reply",
      "Thank you! I\u2019m actually pretty happy with what I\u2019ve built tbh and how far has FastAPI taken us but this repo is proof that you have to reinvent the wheel if you want to build something serious.In any case, that\u2019s a treasure trove right there!, I actually had no idea Polar was open source, much less that it\u2019s built on FastAPI!It\u2019s such a shame that the actual documentation doesn\u2019t even scratch the surface, I would\u2019ve saved so much time if they just included a disclaimer along the lines of \u201cHey, this architecture we are showing here it\u2019s only valid for toy projects, you will need much more work to build a real production system\u201d but again, I guess I\u2019m the only one to blame.reply",
      "FastAPI used to have an emoji-ridden docs page for concurrency. Criticism was not handled well.This made it clear to me that something about the project is off.https://github.com/fastapi/fastapi/discussions/6656reply",
      "Tiangolo is type who wants to do it his way without a ton of input . One of reasons Litestar was developed.reply",
      "> Then came the SQLModel problems. The author pushes it very hard in the FastAPI docsNo it doesn't? The front page for FastAPI contains a pretty lengthy tutorial with no mention of SQLModel. The only time SQLModel gets a significant mention is on a page explaining connecting a relational DB, but it makes it clear that any DB at all can be used. Something has to be chosen for the tutorial, so it makes sense the author would choose their own.If SQLModel isn't right for you then you're the only person to blame. I've been through that tutorial before and settled on plain old SQLAlchemy.reply",
      "edit: reading the litestar docs, it even has a built-in event system! I spent a couple weeks building something I could use with FastAPI...reply",
      "Looking at the docs and trying to figure out what this is for. Is it essentially when you want to break out of the \"request lifecycle\" and queue something to run after your response has already been returned?It strikes me that I haven't used web frameworks a lot and never even questioned how that may not be an easy thing to do!reply",
      "Doesn't Litestar suffer from some of this too? Do you think Litestar would be better for building complex applications than FastAPI, despite less community adoption / documentation / discussion?reply",
      "Is there really less documentation? FastAPI mostly has tutorials to get started and is light on deep/reference material. A single person can only do so much.reply"
    ],
    "link": "https://www.b-list.org/weblog/2025/aug/06/litestar/",
    "first_paragraph": "\n \nPublished on:\n\n\nAugust 6, 2025\n  \u00a0\u00a0\n  \nCategories:\n\n\n\nDjango, Python\nA few years ago at work, I had a project which offered an opportunity to look at the new generation of async-first, type-hint-driven Python web frameworks. For reasons which aren\u2019t particularly relevant today, on that project I ended up choosing Litestar, which is the one that doesn\u2019t have a ravenous all-consuming hype machine surrounding it. And I\u2019m very glad I did, because today I\u2019m more convinced than ever it was the right choice, and for the last 18 months or so every new project I\u2019ve started at my day job has been built with\u00a0Litestar.But even if you\u2019re someone who does Python web apps for a living, and even if you\u2019re someone who builds asynchronous type-hint-driven web apps, you might not be familiar with this absolute gem of the Python web ecosystem, and today I want to remedy\u00a0that.Here\u2019s the traditional single-file-app\u00a0demo:You save this\u00a0as app.py, run\u00a0with litestar run or hand it directly to the ASGI server"
  },
  {
    "title": "The Inkhaven Blogging Residency (inkhaven.blog)",
    "points": 19,
    "submitter": "venkii",
    "submit_time": "2025-08-07T00:20:53 1754526053",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44819352",
    "comments": [
      "It'd be fun to join in from afar by pledging to do the same things, but for nowhere near the cost. (The place looks super neat, but I'm not paying that much, don't live near there, and need to report to my employer's office twice a week.)I wonder if there'll be an aggregator of the blog posts written as post of this cohort (and others, if there's more cohorts).reply",
      "> It'd be fun to join in from afar by pledging to do the same thingsWhat\u2019s stopping you besides the unsettling truth that it\u2019s more fun to think that it\u2019d be fun to join in from afar by pledging to do the same things than it is to actually do the same things from afar?reply",
      "Back in the day it cost a round of drinks at the pub to be read and questioned about your work in progress:  Until late 1949, Inklings readings and discussions were usually held on Thursday evenings in C. S. Lewis's rooms at Magdalen. The Inklings and friends also gathered informally on Tuesdays at midday at a local public house, The Eagle and Child, familiarly and alliteratively known in the Oxford community as The Bird and Baby, or simply The Bird.\n\n~ https://en.wikipedia.org/wiki/Inklingsreply",
      "And admission to an Oxford college, of course.reply",
      "For that group of Inklings, sure.University was free for, say, the likes of Greg Egan and others to study physics and math, with a nominal student union fee to be able to join / form clubs and apply for a base beer, wine, and cheese fund to lubricate weekly discussion.reply",
      "500 words a day isn't much for $3,500! I've done that for free before. But given the weirdo cult this is designed to recruit na\u00efve suckers as propagandists for, I suppose that all checks out: requiring a stupid amount of money right up front, for what amounts to a social entr\u00e9e with some rich weirdos and hangers-on, both filters out the sensible and makes the sunk cost fallacy pretty easy to invoke.reply"
    ],
    "link": "https://www.inkhaven.blog/",
    "first_paragraph": "\n                                    A residency for ~30 people to grow into great writers.For the month of November, you'll publish a blogpost every day. Or pack your bags.\n                                Decision in 10 days$3,500 (incl. Housing)Scholarships availableNov 1 \u2014 Nov 30, Berkeley CAScott Alexander,Scott Aaronson,& Gwern(more to be announced)Ben Pace,Oliver Habryka,& Lightcone Infrastructure\n                                    If you want to be excellent at something, it's extremely useful to do it every day. Athletes, musicians, and writers famously live by this advice. Separately, one of the world's strongest motivators is to be surrounded by ambitious, like-minded people.\n                                \n                                    For the month of November, we're running a residency for talented writers to hone their craft by writing and publishing a blogpost every single day. We provide food and housing at-cost, so that you can focus on writing.\n               "
  },
  {
    "title": "You know more Finnish than you think (dannybate.com)",
    "points": 43,
    "submitter": "infinate",
    "submit_time": "2025-08-04T19:08:19 1754334499",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44790132",
    "comments": [
      "I have a Finnish friend here in Switzerland who believes Finnish is impossible to learn as an adult. I think because of the conjugations. She has a son and she is divorced from a Spanish man who remarried a Greek woman. Her son speaks German (Swiss school), French (Swiss school), English (Swiss school and all the other children at school), Spanish (father), Greek (step-mother and step-siblings), and because she makes a point of speaking Finnish with him at home, Finnish.He has no problem with any of the languages including Finnish but she's still convinced that she needs to force it on him before he's an adult so that he can... well, I'm not sure why.reply",
      "I have a(n English) friend who moved to Finland as an adult (in her 30s) and is now fluent in Finnish (and English, just the two languages for her) so it is certainly possible.I have very jealous of your friend\u2019s multi-lingual son though!reply",
      "Finnish or not, it is orders of magnitude harder to learn any language as an adult.reply",
      "IMO the hardest parts of learning a new language as an adult isa) convincing yourself its worth the effort: almost every time an adult runs into a confusing element of a new language, they find themselves calculating how many people in the world speak this language, probability they don't speak english and likelihood of running into this person and circumstance, and it's easy to justify giving up and moving onb) avoiding forcing it into the framework of your first language: if you have one distinctly favored language already, it's very hard not to try shove the new language you are learning into the former's mold, and this can be counterproductive in learning most languages that don't share an ancestor with your favored one.a) is greatly mitigated by forcing yourself to be in said context by living in a place prioritizing that language. b) is greatly mitigated by already being bilingual+ with languages from distinct origins (eg: mandarin chinese and english) before learning a new one, so you can place the new language on a spectrum with the ones you already know instead of confined by the rules of just one.reply",
      "I think this is literally just a function of time and exposure oppirtunity and nothing else.An adult studying a language is spending like maybe 1% of the time studying that a child learning a language spends.reply",
      "Hey neighbour!Growing up bi-(or even multi)-lingual is always a good opportunity when it comes to speaking, especially here in Switzerland.reply",
      "The blog discusses ancient loans, but you know a lot more Finnish than you think if you look at loans happening today:https://en.wikipedia.org/wiki/FinglishEspecially in the IT world. Printteri tilttasi, klikkaa linkki\u00e4, koodi bugittaa, buuttaa serveri!reply",
      "at the time \"proto-Germanic\" is claimed to have been spoken, most of Germany spoke a slavic/celtic/local dialects unrelated to what was being spoken in Norway or Sweden and the association was constructed by german nordicists of the 18th century that drove popular indo-european philology based around grammar protocols established by international trade or diplomacy instead of words and tones used by natives in life and laborreply",
      "Nearly every word in every Uralic language pertaining to a tech level past the stone age is a loan word.reply",
      "Sz\u00e1m\u00edt\u00f3g\u00e9p?reply"
    ],
    "link": "https://dannybate.com/2025/08/03/you-know-more-finnish-than-you-think/",
    "first_paragraph": "Danny L. Bate\n\t\t\tLinguist, broadcaster, writer, cat fanatic\t\tLinguistics illuminates the linguistically obscure \u2013 or so I\u2019ve always thought. It\u2019s a common theme of my online output that a little bit of historical linguistics goes a long way, making helpful connections and breaking down psychological barriers. This theme was present in two old posts of mine that used etymology to elucidate two Old English texts, namely Beowulf and The Wanderer.Now, as an unplanned third installment, allow me to show you how familiar a whole language can be. This is the infamously tricky Finnish language. There are more Finnish words that you, as an English speaker, can recognise than just sauna.To call Finnish \u201ctricky\u201d is only fair depending on your perspective. It has gained a reputation for difficulty through a general European point of view. Most of Europe today is a patchwork of spoken languages belonging to the Indo-European family, from English and Irish in the west, to Russian and Greek in the ea"
  },
  {
    "title": "We'd be better off with 9-bit bytes (pavpanchekha.com)",
    "points": 82,
    "submitter": "luu",
    "submit_time": "2025-08-06T19:39:20 1754509160",
    "num_comments": 155,
    "comments_url": "https://news.ycombinator.com/item?id=44816692",
    "comments": [
      "Non-power-of-2 sizes are awkward from a hardware perspective. A lot of designs for e.g. optimized multipliers depend on the operands being divisible into halves; that doesn't work with units of 9 bits. It's also nice to be able to describe a bit position using a fixed number of bits (e.g. 0-7 in 3 bits, 0-31 in 5 bits, 0-63 in 6 bits), e.g. to represent a number of bitwise shift operations, or to select a bit from a byte; this also falls apart with 9, where you'd have to use four bits and have a bunch of invalid values.reply",
      "The Nintendo 64 RDP(graphics/memory controller) used 9 bit bytes.This was done for graphics reasons, native antialiasing if I understand it. The cpu can't use it. it still only sees 8-bit bytes.https://www.youtube.com/watch?v=DotEVFFv-tk (Kaze Emanuar - The Nintendo 64 has more RAM than you think)To summarize the relevant part of the video. The RDP wants to store pixel color in 18 bits 5 bits red 5 bits blue 5 bits green 3 bits triangle coverage it then uses this coverage information to calculate a primitive but fast antialiasing. so SGI went with two 9-bit bytes for each pixel and magic in the RDP(remember it's also the memory controller) so the cpu sees the 8-bit bytes it expects.Memory on N64 is very weird it is basicly the same idea as PCIE but for the main memory. PCI big fat bus that is hard to speed up. PCIE small narrow super fast bus. So the cpu was clocked at 93 MHz but the memory was clocked at 250 MHz. They were hoping this super fast narrow memory would be enough for everyone but having the graphics card also be the memory controller proved to make the graphics very sensitive to memory load. to the point that the main thing that helps a n64 game get higher frame rate is to have the cpu do as few memory lookups as possible. which in practical terms means having it idle as much as possible.reply",
      "Plato argued that 7! was the ideal number of citizens in a city because it was a highly factorable number.  Being able to cut numbers up is an time-tested favorite.  That's why there are 360 degrees.reply",
      "And many of the conversions between metric and imperial align with the Fibonacci sequence on any order of magnitude. 130km/h is roughly 80mph simply because the fibo sequence has 8 and 13.Obviously not an emergent property but shows how these things were designed.reply",
      "I don\u2019t think any common conversions fall near there other than miles->km. It\u2019s certainly not the case that the systems were designed to have the golden ratio as conversions between the two.reply",
      "Or 60 minutes in an hour1, 2, 3, 4, 5, 6, 10, 12, 15, 20, 30, and 60reply",
      "Or 5280 feet in a mile.reply",
      "And one feet is 4 small foot toes and one big foot toe!reply",
      "Factorio logic applies as always -  powers of 2 for trains belts etc. makes evenly splitting resources trivial.reply",
      "Not really - I worked on a DSP with 9-bit bytes in the 90's (largely because it was focused on MPEG decode for DVDs, new at the time) largely because memory was still very expensive and MPEG2 needed 9-bit frame difference calculations (most people do this as 16-bits these days but back then as I said memory was expensive and you could buy 9-bit parity RAM chips)It had 512 72-bit registers and was very SIMD/VLIW, was probably the only machine ever with 81-bit instructionsreply"
    ],
    "link": "https://pavpanchekha.com/blog/9bit.html",
    "first_paragraph": "Share under CC-BY-SA.\nA number of 70s computing systems had nine-bit bytes, most prominently\nthe PDP-10, but today1 [1 Apparently, it was the System/360 that\nreally set the standard here.] all systems use 8-bit bytes and that\nnow seems natural.2 [2 Though you still see RFCs use \"octet\", and the\nC standard has a CHAR_BITS macro, to handle the possibility of a\ndifferent-sized byte.] As a power of two, eight is definitely nicer.\nBut I think a series of historical coincidences would actually go our\nway with 9-bit bytes.\n\nIPv4: Everyone knows the story: IPv4 had 32-bit addresses, so about 4\nbillion total.3 [3 Less due to various reserved subnets.] That's not\nenough in a world with 8 billion humans, and that's lead to NATs, more\nactive network middleware, and the impossibly glacial pace of IPv6\nroll-out. It's 2025 and Github\u2014Github!\u2014doesn't support IPv6. But in a\nworld with 9-bit bytes IPv4 would have had 36-bit addresses, about 64\nbillion total. That would still be enough right now, and eve"
  },
  {
    "title": "A fast, growable array with stable pointers in C (danielchasehooper.com)",
    "points": 128,
    "submitter": "ibobev",
    "submit_time": "2025-08-06T18:21:28 1754504488",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=44815702",
    "comments": [
      "This is really clever but better to call this a list rather than an array; functions which expect array semantics will simply not work, and there's no way to transparently pass slices of this data structure around.In the past I've abused virtual memory systems to block off a bunch of pages after my array. This lets you use an array data structure, have guard pages to prevent out of bounds access, and to have stable pointers in the data structure.reply",
      "For an expanding array in a 64 bit address space, reserving a big region and mmaping it in as you go is usually the top performing solution by a wide margin. At least on Linux, it is faster to speculatively mmap ahead with MAP_POPULATE rather than relying on page faults, too.And, if you find you didn't reserve enough address space, Linux has mremap() which can grow the reserved region. Or map the region to two places at once (the original place and a new, larger place).reply",
      "Same re: virtual memory systems (using guard pages), that is an old idea that works well  but it did once produce a really unpleasant bug in production... But that was an unfortunate implementation mishap.reply",
      "I believe I've seen problems like this also solved with arena allocators. You have certain very special allocations have an arena unto themselves.reply",
      "Another similar data structure which has a balanced tree (instead of a list) that references array segments is the https://en.wikipedia.org/wiki/Rope_(data_structure)Its main advantages are the O(log n) time complexity for all size changes at any index, meaning you can efficiently insert and delete anywhere, and it is easy to implement copy-on-write version control on top of it.reply",
      "A lot of standard libraries have tried to implement ropes for things like strings and it usually is reverted for a simpler structure.reply",
      "There's a good reason for that. Almost all strings ever created in programs are either very small, immutable or append-only. Eg, text labels in a user interface, body of a downloaded HTTP request or a templated HTML string, respectively. For these use cases, small string optimisations and resizable vecs are better choices. They're simpler and faster for the operations you actually care about.The only time I've ever wanted ropes is in text editing - either in an editor or in a CRDT library. They're a good choice for text editing because they let users type anywhere in a document. But that comes at a cost: Rope implementations are very complex (skip lists have similar complexity to a b-tree) and they can be quite memory inefficient too, depending on how they're implemented. They're a bad choice for small strings, immutable strings and append only strings - which as I said, are the most common string types.Ropes are amazing when you need them. But they don't improve the performance of the average string, or the average program.reply",
      "> Today\u2019s computers use only 48 bits of the 64 bits in a pointerhttps://en.wikipedia.org/wiki/Intel_5-level_paging introduced in Ice Lake 6 years ago.But anyways, isn't this just variant of std::deque? https://en.cppreference.com/w/cpp/container/deque.htmlreply",
      "In principle it's not that different that deque, though:(1) deque uses fixed-sized blocks, not increasing-size blocks.\n(2) dequeue supports prepending, which adds another level of indirection internally.reply",
      "You can support prepending by mirroring the allocations, probably? eg for the \"negative index\" case do an exponential thing in the other direction.Your indexing has some legitimate math to be done now which can be annoying (efficiency perspective) I think you can still get o(1) with careful allocation of powers of 2.reply"
    ],
    "link": "https://danielchasehooper.com/posts/segment_array/",
    "first_paragraph": "August 5, 2025\u30fb7 minute readMy last article about generic data structures in C was written to set the stage for today\u2019s topic: A data structure that can be used in place of dynamic arrays, has stable pointers, and works well with arena allocators. It\u2019s been independently discovered by different programmers over the years and so goes by different names. A 2001 paper called it a \u201clevelwise-allocated pile\u201d (bleh). Zig calls it a \u201cSegmented List\u201d. Then theres C++ with std::deque, which is only somewhat similar. I like the name that Per Vognsen uses: \u201cSegment Array\u201d.You can download my single-header C implementation here: segment_array.h.The core concept is straight forward: items are stored in multiple contiguous segments, and each segment is double the length of its predecessor. New segments are allocated only when needed, and their pointers are kept in a fixed sized array. Here\u2019s how that looks:Unlike standard arrays, pointers to a segment array\u2019s items are always valid because items are"
  },
  {
    "title": "Writing a Rust GPU kernel driver: a brief introduction on how GPU drivers work (collabora.com)",
    "points": 207,
    "submitter": "losgehts",
    "submit_time": "2025-08-06T16:00:54 1754496054",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=44813789",
    "comments": [
      "Great article. But too short. I was just getting excited about it and it ended. I look forward reading the other parts.reply",
      "Tune in next week for the next exciting episode, where we will see a command taken off the queue and executed in the GPU!The abstraction level discussed here is just where data gets passed across the user/kernel boundary. It's mostly queue and buffer management, which is why there are so few operations. The real action happens as queued commands are executed.There's another stream of command completions coming back from the GPU. Looking forward to seeing how that works. All this asynchrony is mostly not the driver's problem. That's kicked up to the user code level, as the driver delivers completions.reply",
      "Oh, that's cool. I use one of the rk3588 things with panfrost as a desktop and it sometimes bugs out with black or transparent patches in firefox. Weird thing.reply",
      "The RK3588 uses the panthor driver that is the subject of the article, not panfrost.reply",
      "Curious as to whether uring_cmd was considered instead of ioctls since this looks green field. Would the benefits have been negligible to nonexistent? If so, why?reply",
      "As GPUs are already asynchronous devices with their own command queue, and the IOCTLS generally just abstracting a relatively cheap write into that command queue, I suspect there's limited utility in making another asynchronous command queue on the CPU to schedule those writes.Unless you mean to make the GPU command queue itself the uring and map that into userspace, but that would likely require significant firmware changes to support the specifics of the io_uring API, if even possible at all due to hardware specifics.reply",
      "The driver described in the article uses the API that the userspace Mesa libraries expect.reply",
      "ah thanks for the clarification. should have read more carefully.reply",
      "very interesting, is there a second part to this? or logical continuation...reply",
      "It came out today, so I am assuming more will come later.reply"
    ],
    "link": "https://www.collabora.com/news-and-blog/blog/2025/08/06/writing-a-rust-gpu-kernel-driver-a-brief-introduction-on-how-gpu-drivers-work/",
    "first_paragraph": "Daniel Almeida August 06, 2025Share this post:\n\n\n\n\n\n\nReading time: This post is the second iteration of a series of posts that provide an in-depth look at the development of Tyr, a state-of-the-art Rust GPU driver for the Linux Kernel, supporting Arm Mali CSF-based GPUs.As promised in the first iteration, we will now explore how GPU drivers work in more detail by exploring an application known as VkCube. As the program name implies, this application uses the Vulkan API to render a rotating cube on the screen. Its simplicity makes it a prime candidate to be used as a learning aid in our journey through GPU drivers.This article will first introduce the concept of User Mode Drivers (UMDs) and Kernel Mode Drivers (KMDs), breaking down the steps needed to actually describe VkCube's workload to the GPU. This will be done in a more compact way for brevity as it's a rather extensive topic that has been detailed in several books.We will wrap up with an overview of the actual API offered by Tyr."
  },
  {
    "title": "The Bluesky Dictionary (avibagla.com)",
    "points": 87,
    "submitter": "gaws",
    "submit_time": "2025-08-06T20:43:08 1754512988",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=44817583",
    "comments": [
      "I'm very curious as to how this works in the backend. I realize it uses Bluesky's firehose to get the posts, but I'm more curious on how it's checking whether a post contains any of the available words. Any guesses?reply",
      "Hey! this is my site - it's not all that complex, i'm just using a sqlite db with two tables - one for stats, the other for all the words that's just word | count | first use | last use | post.I... did not expect this to be so popularreply",
      "What is your source dictionary to compare to? Seems kind of small. Also, how are you handling inflected forms?reply",
      "You can probably fit all words under 10-15MB of memory, but memory optimisations are not even needed for 250k words...Trie data structures are memory-efficient for storing such dictionaries (2-4x better than hashmaps). Although not as fast as hashmaps for retrieving items. You can hash the top 1k of the most common words and check the rest using a trie.The most CPU-intensive task here is text tokenizing, but there are a ton of optimized options developed by orgs that work on LLMs.reply",
      "Probably just a big hashtable mapping word -> the number of times it's been seen, and another hashset of all the words it hasn't seen. When a post comes in you hash all the words in it and look them up in the hashtable, increment it, and if the old value was 0 remove it from the hash set.250k words at a generous 100 bytes per word is only 25MB of memory...reply",
      "I very much hope that the backend uses one of the bluesky jetstream endpoints. \nWhen you only subscribe to new posts, it provides a stream of around 20mbit/s last time I checked, while the firehose was ~200mbit/s.reply",
      "yes it does!reply",
      "Maybe I'm being naive, but with only ~275k words to check against, this doesn't seem like a particularly hard problem. Ingest post, split by words, check each word via some db, hashmap, etc... and update metadata.reply",
      "Is this not working or am I missing something, it just shows as seeing 0 words for me. Firefox on a PC.reply",
      "You may need to allow scripts from the domain avibagla.com, it shows 0 when the scripts are blocked.reply"
    ],
    "link": "https://www.avibagla.com/blueskydictionary/",
    "first_paragraph": ""
  },
  {
    "title": "301party.com: Intentionally open redirect (301party.com)",
    "points": 58,
    "submitter": "nahikoa",
    "submit_time": "2025-08-06T20:54:39 1754513679",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=44817725",
    "comments": [
      "Is there a bug bounty? I found an open redirect.reply",
      "I think you can report them here: http://localhost.301party.comreply",
      "Also of interest: https://redirect.pizza/reply",
      "Fortunately, redirection to a file: URL will result in a browser error. Unfortunately, the browser does not explain what is wrong (although the redirect can be viewed in the developer tools, you might not know to look there, and it still doesn't have an error message to explain the problem).reply",
      "metadata.301party.com: 169.254.169.254\n  ipv6.metadata.301party.com: [::169.254.169.254]\n\nWhy not just one name with both A and AAAA records? ...er, and why not fd00:ec2::254? (I now suspect that there's a subjoke here that I'm missing)reply",
      "It can be nice to have an address that is guaranteed to be one or the other.reply",
      "Created by wtfismyip.com - had a good laughreply",
      "Can someone explain what this is?reply",
      "A simple utility to test 301 redirects in your project.reply",
      "Couple of s/redirct/redirect typosreply"
    ],
    "link": "https://301party.com/",
    "first_paragraph": "Bonus DNS records!localhost.301party.com: 127.0.0.1metadata.301party.com: 169.254.169.254ipv6.metadata.301party.com: [::169.254.169.254]DIYDIY"
  },
  {
    "title": "Show HN: Kitten TTS \u2013 25MB CPU-Only, Open-Source TTS Model (github.com/kittenml)",
    "points": 770,
    "submitter": "divamgupta",
    "submit_time": "2025-08-06T05:04:36 1754456676",
    "num_comments": 322,
    "comments_url": "https://news.ycombinator.com/item?id=44807868",
    "comments": [
      "I ran some quick benchmarks.Ubuntu 24, Razer Blade 16, Intel Core i9-14900HX  Performance Results:\n\n  Initial Latency: ~315ms for short text\n\n  Audio Generation Speed (seconds of audio per second of processing):\n  - Short text (12 chars): 3.35x realtime\n  - Medium text (100 chars): 5.34x realtime\n  - Long text (225 chars): 5.46x realtime\n  - Very Long text (306 chars): 5.50x realtime\n\n  Findings:\n  - Model loads in ~710ms\n  - Generates audio at ~5x realtime speed (excluding initial latency)\n  - Performance is consistent across different voices (4.63x - 5.28x realtime)reply",
      "Thanks for running the benchmarks. Currently the models are not optimized yet. We will optimize loading etc when we release an SDK meant for production :)reply",
      "on my Intel(R) Celeron(R) N4020 CPU @ 1.10GHz it takes 6 seconds to import/load and text generation is roughly 1x realtime on various lengths of text.reply",
      "Reddit post with generated audio sample: https://www.reddit.com/r/LocalLLaMA/comments/1mhyzp7/kitten_...reply",
      "And a quick video with all of the different voices:https://www.youtube.com/watch?v=60Dy3zKBGQgreply",
      "Cool, thanks... aside: the last male voice sounds high/drunk.reply",
      "thank you!reply",
      "The reddit video is awesome. I don't understand how people are calling it an OK model. Under 25MB and cpu only for this quality is amazing.reply",
      "The people calling it \"OK\" probably tried it for themselves. Whatever model is being demoed in that video is not the same as the 25MB model they released.reply",
      "Nope, looks like the default voice is the worst and it's not in the demo. A Reddit user generated these as well https://limewire.com/d/28CRw#UPuRLynIi7reply"
    ],
    "link": "https://github.com/KittenML/KittenTTS",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n         State-of-the-art TTS model under 25MB \ud83d\ude3b \n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Kitten TTS is an open-source realistic text-to-speech model with just 15 million parameters, designed for lightweight deployment and high-quality voice synthesis.Currently in developer previewJoin our discordWorks literally everywhere\n         State-of-the-art TTS model under 25MB \ud83d\ude3b \n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "The 17-character code that runs the automotive world (cardog.app)",
    "points": 5,
    "submitter": "samsullivan",
    "submit_time": "2025-08-07T01:26:14 1754529974",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://cardog.app/blog/whats-a-vin",
    "first_paragraph": "In 1979, the National Highway Traffic Safety Administration faced a problem: how do you track 100+ million vehicles across 50 states when every manufacturer uses different serial number schemes? Their solution became one of the most successful information architecture projects in history - the Vehicle Identification Number standard.What emerged wasn't just a unique identifier. It was a compressed database record, a mathematical validation system, and a regulatory framework that would process 17 million new vehicles annually while maintaining backward compatibility for decades.This is how that system actually works.Before any vehicle can legally be sold in the United States, its manufacturer must submit a \"565 submittal\" to NHTSA. This isn't marketing fluff - it's a comprehensive technical document that defines every measurable aspect of the vehicle.Each 565 submittal contains:Here is a sample 565 submittal for the 2025 Tesla LineupNHTSA reviews these submissions and assigns VIN pattern"
  },
  {
    "title": "Jules, our asynchronous coding agent (blog.google)",
    "points": 219,
    "submitter": "meetpateltech",
    "submit_time": "2025-08-06T16:05:39 1754496339",
    "num_comments": 154,
    "comments_url": "https://news.ycombinator.com/item?id=44813854",
    "comments": [
      "Why has Google totally overcomplicated their subscription models?Looking at \"Google AI Ultra\" it looks like I get this Jules thing, Gemini App, Notebook, etc. But if I want Gemini CLI, then I've got to go through the GCP hellscape of trying to create subscriptions, billing accounts then buying Google Code Assist or something, but then I can't get the Gemini app.Then of course, this Google AI gives me YouTube Premium for some reason (no idea how that's related to anything).reply",
      "And God forbid you were an early Google for Domains adopter and have your own Google Workspace account because nothing fucking works right for those poor saps.reply",
      "You think that's bad? I had my own Google Workspace account with Google Domains and then foolishly linked my Google Fi cellphone to it.Trying to get that stuff resolved was such a pain that I eventually had to ask a friend who knew someone that worked at Google for assistance. Their support team had absolutely no public contact info available. I eventually managed to get my data and migrate the services I actually use (Google Fi and Youtube) to a non-workspace account.The funny thing is that a few months later they tried to send a $60 bill to collections because they reopened the account for 2 days for me to migrate things off. I was originally going to pay it to just get them off my back, but Google's own collections agency wouldn't let me pay through card or check or anything. The only way I could pay was to \"Log into your Google Workspace account\" which NO LONGER EXISTED.Now it's just an amusing story about incompetence to look back on, but at the time it was stressful because I almost lost my domains, cell phone number, and email addresses all at once. Now I never trust anything to a single company.reply",
      "Add \"moving to a different country while owning an account that started as Google Apps for Domains\" for a little more flavor.\"Can't share the subscription because the other person in your family is in another country.\"Okay guess I'll change countr- \"No you can't change your Google Workspace account's country.\"reply",
      "This issue alone is driving me to switch to Microsoft for a particular use-case where I inherited a Google Apps for Domains account. Why anyone who knows the history of Google's behaviour with respect to supporting businesses that are not advertisers, would still choose Google over other options, continues to baffle me.reply",
      "Nobody is getting a promotion for fixing that shitreply",
      "Watch YouTube while AI is coding for you.reply",
      "That\u2019s actually great!reply",
      "Because their main business is selling ads and maintaining their stranglehold on that market via analytics, chrome, Chromebook, android, SSO via google, etc.The dev focused products are a sideshow amongst different fiefdoms at google. They will never get first billing or focus.reply",
      "We\u2019ve been trying to understand Google Workspace subscriptions but it\u2019s a complete mess. It\u2019s not even clear which plans include GMail and which don\u2019t, Google used to be the simple but great company, why do you feel so stranded when subscribing to their product now?When you enter Google Cloud you end up in a shroud of darkness in which admins can\u2019t see the projects created by users.I\u2019m the admin for our Google Workspace, I can\u2019t even tell if we have access to Google AI studio or not, their tutorials are complete bullshit, the docs are just plain wrong because they reference to things that are not reflected in the platform.I had to switch back to English because their automated translations are so awful, didn\u2019t they really think to at least let one person review once each document before releasing it to the public?!It\u2019s a 450 billion dollars company and they can\u2019t realize that they added so many layers of confusion that 99% of their users won\u2019t need. The biggest issue is that they won\u2019t solve this anytime soon, they dug themselves into a limitless pit.reply"
    ],
    "link": "https://blog.google/technology/google-labs/jules-now-available/",
    "first_paragraph": "Jules is officially out of beta and launching publicly, powered by Gemini 2.5.During the beta, thousands of developers tackled tens of thousands of tasks, resulting in over 140,000 code improvements shared publicly. Thanks to developer feedback, we\u2019ve polished the user interface, fixed hundreds of bugs and launched new capabilities including reusing previous setups so new tasks run faster, GitHub issues integration and multimodal support.Jules now uses the advanced thinking capabilities of Gemini 2.5 Pro to develop coding plans, resulting in higher-quality code outputs. We\u2019re also introducing new structured tiers for Jules, including higher limits* for Google AI Pro and Ultra subscribers:These changes will begin rolling out today to Google AI Pro and Ultra subscribers. This includes eligible college students who can sign up for a free year of AI Pro. Get started today at jules.google.*Specific usage limits are listed at jules.google.Let\u2019s stay in touch. Get the latest news from Google "
  },
  {
    "title": "Multics (multicians.org)",
    "points": 93,
    "submitter": "unleaded",
    "submit_time": "2025-08-06T16:57:55 1754499475",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=44814596",
    "comments": [
      "Always fun to see Multics pop up; the influence it had on computing is pretty impressive and its influence lives on in many projects. As just one personally relevant example, the SCOMP mentioned in the glossary [0] and described in more detail on the history page under 5.4.1 [1] became the STOP operating system which is still in active development and is what I still work on today. (Technically, the SCOMP was the whole machine, and STOP \"SCOMP Trusted Operating Program\" was its operating system). Up until pretty recently, we still had a Multician working on STOP, and have a guy from the Honewell days still plugging away on it.[0]https://www.multicians.org/mgs.html#SCOMP\n[1]https://www.multicians.org/history.htmlreply",
      "This operating system sounds very interesting! How active is the development? I would imagine it's the type of thing that eventually gets \"complete\"reply",
      "I've been gainfully employed for well over a decade working on it and it's been around in one form or another for over 40 years. We're constantly improving performance and capabilities, adding support for more hardware, supporting the specific needs of our customers etc... Just like any modern operating system, it's never really \"complete\". STOP is a \"security from the ground up\" OS, where security isn't just a first-order priority, it's the entire point, typically used in/as multilevel security solutions.reply",
      "Are there any documents we can use to learn more about it? What does it look like to the user? Is it intended to be embedded?reply",
      "There's a link in my profile to the company products page for my group, which includes a link to the STOP OS page. There used to be additional documents you could download from those pages, but it looks like they're not working any more.The short version is that it implements three different MAC (mandatory access control) policies (RBAC,  Bell-LaPadula, Biba) and the standard *nix DAC policies. It's designed for safely handling/moving data on/between multiple classification levels. (See the SCOMP section in [0] for history). From a user perspective, it's very similar to Linux, with a largely Linux-like ABI and similar user interfaces, including a full X/xfce GUI environment if you want, though most actual deployments tend to run headless with only required software loaded. It runs on both small embedded boards and large enterprise servers and a bunch in between.[0] https://multicians.org/b2.htmlreply",
      "We used Multics when I was at Bristol Uni in the UK c.1980. I can only remember two things about it:1) The system was initially deemed slow, so they installed an extra 256 KB of RAM (for a system serving dozens/hundreds of students - Bristol was regional computing center), and that made a difference! This was a big deal - apparently quite expensive!2) Notwithstanding 1), it was fast, and typical student FORTRAN assignments of a 100 or so lines of code would compile and link essentially instantly - hit enter and get prompt back. I wish compilers were this fast today on 2025's massively faster hardware!reply",
      "Same where I went at Leeds Uni in the mid 80s.Ours was just for CS undergrads mostly when I was there, and wasn't too overloaded.  I guess we had about fifty terminals maybe on campus at least.I remember we could dial it up from a couple of terminals in our Halls of Residence over JANET.You are right, I never found it that slow either - loved that machine and the terminal to terminal messaging was crazy fun.reply",
      "Quite interesting are the collection of myths,https://www.multicians.org/myths.htmlAnd naturally, B2 Security Evaluation,https://multicians.org/b2.htmlreply",
      "The Data Security page is very interesting as well: https://multicians.org/multics-data-security.htmlAIM and MAC seem like a very interesting system for enforcing security guarantees, and they partially solved the malicious dependencies problem as well.reply",
      "It's also the home of the Three Questions (about each bug you find): https://www.multicians.org/thvv/threeq.htmlreply"
    ],
    "link": "https://www.multicians.org/multics.html",
    "first_paragraph": "\n\t\t\tThe Multicians web site presents the story of the Multics operating system for people interested in the system's history,\n\t\t\tespecially Multicians.\n\t\t\tThe site's goals are to \n\t\t      \n\t\t\tThe Multicians web site contains \n\t\t\t487 HTML files (see the Site Map) comprising over 540K lines,\n\t\t\t1795 PDF files, and \n\t\t\t670 graphic images.\n\t\t\tThe site has benefited from the contributions of many authors. \n\t\t\tContributions are invited: if you have a correction, fact, date, name, anecdote, or picture, \n\t\t\tplease share it with Multicians everywhere by sending mail to the editor. \n\t\t    \nMultics (Multiplexed Information and Computing Service)\n\t\t    was a mainframe time-sharing operating system begun in 1965 and used until 2000. \n\t\t    Multics began as a research project and was an important influence on operating system development. \n\t\t    The system became a commercial product sold by Honeywell to education, government, and industry. \n\t\t  \n\t\t    Multics was a prototype of a Computer Utility, "
  },
  {
    "title": "A Man Who Beat IBM (every.to/feeds)",
    "points": 31,
    "submitter": "vinnyglennon",
    "submit_time": "2025-08-04T01:31:42 1754271102",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=44781343",
    "comments": [
      "It seems that every version of MS-DOS from v2.0 onward was actually developed by Compaq.  I had no idea.> That relationship had been established in late 1982. Back then, Gates had contacted Canion and asked, with some concern, if Compaq was trying to get into the operating system business. Surprised, Canion denied it. Gates told him that Microsoft was hearing worrying reports from the dealer network. People were buying copies of Compaq DOS, rather than Microsoft DOS, without buying a Compaq PC.> Both men knew why: Microsoft DOS had never been a true copy of PC DOS, as Gates had admitted to Canion during the development of Compaq\u2019s first machine. The differences had only increased over time, as Microsoft\u2019s deal with IBM prohibited the same developers working on both versions. Compaq had made its own version of DOS since the beginning. With its singular focus on 100 percent compatibility, the result was a product that was more compatible with PC DOS than Microsoft\u2019s own product.> Word was spreading among computer buyers that Compaq DOS was better. Even people who owned other PC clones were choosing to buy that instead of Microsoft\u2019s own public version. This could have created friction between Compaq and Microsoft. Instead, Canion did something extraordinary. Compaq withdrew Compaq DOS from sale unless it was specifically bundled with a Compaq computer. He then licensed Compaq DOS back to Microsoft.> From Gates\u2019s perspective, this was an incredible deal. He was able to halt all internal development on Microsoft DOS, saving time and money. From this point onward, every version of Microsoft DOS he sold was, in fact, Compaq DOS, with the digital equivalent of its serial numbers filed off. All Canion asked in return was that Microsoft never release the very latest version of DOS that Compaq provided it until after a few months\u2019 delay. This was to make sure that Compaq always had a slight advantage in compatibility over its rivals.> Canion even agreed to Gates\u2019s request that they keep the entire arrangement secret, to avoid souring Microsoft\u2019s relationships with the other clone companies. It would remain secret for almost 40 years.reply",
      "Licensing Compaq DOS back to Microsoft was a mistake. It gave Microsoft\u2019s OS incumbency. The PC industry has been suffering from that decision ever since.reply",
      "> It seems that every version of MS-DOS from v2.0 onward was actually developed by Compaq. I had no idea.The article is wrong about when this occurred\u2014Compaq DOS wouldn't have been in stores in 1982; 1983 is likely the correct year\u2014but regardless, this is an astounding revelation.reply",
      "This is too funny. I got down voted to hell for talking about how Gates never really made anything and was a lucky conman who managed to make his cons a reality by the skin of his teeth, and here we have further proof of just that.reply",
      "While we're wandering down memory lane, we should remember the Stacker/DoubleSpace ripoff: https://en.wikipedia.org/wiki/Stac_Electronics#Microsoft_law...reply",
      "Very interesting. I'm curious what the os2museum.com can say -- if anything -- on this. A deeply technical perspective, as in knowing the actual bit-by-bit internals, can shed much more light.os2museum.com was just recently able to trace how one particular DOS bug (more than two BIOS harddisk drives would make earlier DOS-versions hang at boot) was handled across different companies, and how and when exactly a fix made it into actual MS-DOS.reply",
      "If you want to watch a documentary about the forming of Compaq and its rise, Silicon Cowboys is not bad.Trailer is\nhttps://www.youtube.com/watch?v=7wjJYqUkHd8You can watch the documentary on Tubi\nhttps://tubitv.com/movies/559438/silicon-cowboysreply",
      "As an aside, I worked on fixing computers way back when. Somewhere along the line (maybe late 80s, early 90s) Compaq started using these cheap aluminum screws to hold together the computer case and hard drive mounts and motherboard to the chassis. Those cheap screws would get stripped very easily. Many a day, I would curse Compaq. But then, later, it seemed like all the manufacturers turned to cheaper and cheaper quality parts.reply",
      "I only ever had a laptop from Compaq, and it was the most robust and minimalist thing, like a solemn thinkpad, which is as impossible a statement as sincere. Then they got bought and I got one from their HP days that I returned straight away.reply",
      "I remember reading the quotes asking one of the founders why they left Texas Instruments and his reply was \"the prospect of vast personal wealth\".My understanding is that they had pitched the IBM PC compatible machine to TI and had been rebuffed - TI had its own mostly compatible PC offering and the no one in charge was willing to admit it was a mistake.reply"
    ],
    "link": "https://every.to/feeds/b0e329f3048258e8eeb7/the-man-who-beat-ibm",
    "first_paragraph": "Gareth Edwards is a digital strategist, writer, and historian. He unearths Silicon Valley\u2019s tech history in his monthly column, The Crazy Ones.Compaq\u2019s Rod Canion broke Big Blue\u2019s hold on the PC market\u2014and changed computing forever\n              June 16, 2025\n            The history of the personal computer wasn't just about technology\u2014it was about vision, trust, and the courage to stand up to a monopoly. In his latest piece for The Crazy Ones, Gareth Edwards tells the story of how Compaq challenged IBM's dominance in the 1980s. When IBM tried to reclaim control of the PC market with proprietary technology, Compaq CEO Rod Canion decided to create an open standard and share it with competitors\u2014effectively giving away \"the company jewels\" to preserve innovation. Gareth explains how Canion's leadership style created both a beloved workplace culture and the backbone needed to face down the industry giant. Just think\u2014if IBM had won, we might be living in a very different technological lands"
  },
  {
    "title": "Git-fetch-file \u2013 Sync files from other repos with commit tracking and safety (github.com/andrewmcwattersandco)",
    "points": 24,
    "submitter": "andrewmcwatters",
    "submit_time": "2025-08-06T22:45:27 1754520327",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=44818734",
    "comments": [
      "I\u2019m imagining some sort of art project where people try and figure out the most complicated software you can make entirely off files stitched together from different repos.reply",
      "Or a Fuse filesystem based on it.reply",
      "Haha! That is a pretty creative idea.reply",
      "Hi HN, thanks for sending this to the front page.I'm finding myself needing some resources from other projects in a way that ecosystem-specific dependency management isn't going to help, or I'd be pulling in too many files.Submodules aren't the answer, and some other existing git user-defined commands don't seem to do what I need either.I want a file from another repository, and the ability to pin it, and track it in the future, or just always be up-to-date by using the default HEAD commit value set in `.git-remote-files`.    git fetch-file add https://github.com/octocat/Hello-World README\n    git fetch-file pull\n\nLet's me track the README file from the octocat/Hello-World repository, and pull down the file. A record of it is then saved in `.git-remote-files`.Let me know if you have any questions!reply",
      "been wanting to build something very similar, so sharing some notes (before actually getting to test it):--dry-runa \"push\" subcommand?  \n(especially in combination with 'overwrite to local repository-path\" mentioned below, for remotes rater useless sure ;))also your readme leaves \"kinda open\" what happens with the actual file(s),  \n`.git-remote-files` is mentioned \"should be committed\", but the file it cloned?also a little unclear how `--save` plays into that (since the .git-remote-files example shows only a commit no branch)  \n(and when would one ever run it without save?)cli-arg/secondary `.git-remote-files`-File  \n(possibly as secondary `.local.git-remote-files` or such that can also override repository-URLs)  \nfor local/private repos?option (autodetect?) to also write gitattributes to mark those picked files binary  \n(what may also be done into the repo, or local-only into the .git/ dir of the repo...)since its called `git-fetch-file` and not `.git-remote-files` a overall comment may be nice as refence when first generating the file ;)but by now i\u00b4m just rambling, looking forward to actually try it when home ;)\nthanks in advancereply",
      "Thank you for your comments!I'll thinking about what would be some nice output for --dry-run. Do you have a desired behavior? Maybe something like this?    Would fetch:\n      src/utils.js from https://github.com/user/library.git (a1b2c3d -> f9e8d7c)\n      config/webpack.js from https://github.com/company/tools.git (HEAD -> 1a2b3c4)\n    \n    Would skip (local changes):\n      docs/README.md from https://github.com/org/templates.git (use --force to overwrite)\n    \n    Up to date:\n      package.json from https://github.com/user/library.git (f4e5d6c)\n\nPush seems kinda neat for getting changes back to a remote!I will try to make the README.md a little more clear about what happens after `pull`, because you're right, it's not specified, but files aren't actually committed, just placed in the directory for you to do as you please.I like your ideas! Thank you!reply",
      "for --dry-run that looks pretty good yeps! I like the \"--force hint\" in there too!for the \"push\", I think my idea was mostly about \"local-remotes\", think \"I have both cloned locally, with both IDEs open going back&forth\"one injection there would be `../someupstream/file` vs. `../someupstream/.git/refs/HEAD:file`...   \naka \"pick the file as is\" (potentially marked as \"${HEAD}-dirty\" vs. \"only committed things are truth\" (and if just so one doesn't need a extra `cp` command ;))`just placed in the directory for you to do as you please.` could open a \"--auto-commit\" option -> based on a template similar to the dry run? (ideally overridable in .git-remote-files)reply",
      "Good ideas. You mentioning your locally cloned repo was what spurred this. I wanted to do something a little more robust than just copy and paste the file from the other repository, but I also didn't want to inject the entire project as a dependency for a single file.It feels like it would be excessive to perform a remote call if we already have the repository locally checked out, so I'll think that one over. I would like to add that!I will also think more about automatically committing after `pull`, other standard git commands have --no-commit arguments, so this would be a bit different, since we're behaving a bit like `git-fetch`.Edit: Would you like me to add you to a Contributors section of the README.md? Thanks for your input!reply"
    ],
    "link": "https://github.com/andrewmcwattersandco/git-fetch-file",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Fetch and sync individual files or globs from other Git repositories, with commit tracking and local-change protection\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Fetch and sync individual files or globs from other Git repositories, with commit tracking and local-change protectiongit-fetch-file(1) is a utility for importing specific files from other Git repositories into your own project while keeping a manifest (.git-remote-files) that remembers where they came from and what commit they belong to.It\u2019s like a mini submodule, but for just the files you want.Save the script anywhere and set up a Git alias:Then run it like this:Save the script as git-fetch-file somewhere on your PATH.Track a file (or glob) from a remote Git repository.SYNOPSISDESCRIPTIONAdd"
  },
  {
    "title": "Comptime.ts: compile-time expressions for TypeScript (comptime.js.org)",
    "points": 91,
    "submitter": "excalo",
    "submit_time": "2025-08-03T19:11:40 1754248300",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=44778898",
    "comments": [
      "Would be really great if it could return named functionsreply",
      "import {sum} from './sum.js' with {type: 'comptime'};\n\nis an unfortunate abuse of the `type` import attribute. `type` is the one spec-defined attribute and it's supposed to correspond to the mime-type of the imported module, thus the two web platform supported types are \"json\" and \"css\". The mime-type of the imported file in this case is still `application/javascript`, so if this module had a type it would be \"js\".It would have been better to choose a different import attribute altogether.reply",
      "You\u2019re projecting the mimetype idea from two examples but the proposal is intentionally agnostic about what type might be used for:> This proposal does not specify behavior for any particular attribute key or value. The JSON modules proposal will specify that type: \"json\" must be interpreted as a JSON module, and will specify common semantics for doing so. It is expected the type attribute will be leveraged to support additional module types in future TC39 proposals as well as by hosts.reply",
      "I literally just want Rust style macros and proc macros in JavaScript. e.g. using```\nconst MyComponent = () => jsx!(<div></div>)\n```rather than a .tsx file.That or wasm to be usable so I can just write my web apps in Rustreply",
      "That particular example is odd. What are you gaining by having a macro that needs a compile step vs no macro and just configuring your compile step to use a JSX loader for js files?reply",
      "You want manual memory management for your web apps?reply",
      "Rust memory management is... profoundly not manual?Case in point: I use Rust/WASM in all of my web apps to great effect, and memory is never a consideration. In Rust you pretty much never think about freeing or memory.On top of that, when objects are moved across to be owned by JS, FinalizationRegistry is able to clean up them up pretty much perfectly, so they're GC-ed as normal.reply",
      "One of the most exciting features of Zig, but am I correct that this doesn\u2019t apply to types themselves like comptime generics in Zig? I find that to be one of the most powerful ideas: type level mappings that have the same syntax as the runtime code where you can just set an iteration limit. This would be a great way to get around the \u201ctoo large union\u201d problem in TS, for example.reply",
      "Interesting. I've never seen the import-with syntax, though and it's hard to find any documentation on it. Is this a syntax extension?reply",
      "It\u2019s been introduced as part of ecmascript 2026 https://developer.mozilla.org/en-US/docs/Web/JavaScript/Refe...reply"
    ],
    "link": "https://comptime.js.org/",
    "first_paragraph": "A dead-simple TypeScript compiler that does one thing really well: enables compile-time evaluation of expressions marked with comptime.This is useful for optimising your code by moving computations from runtime to compile time. This project was inspired by Bun macros and Zig comptime (hence the name).Warning: You are responsible for ensuring that the expressions you mark with comptime are safe to evaluate at compile time. comptime.ts does not perform any isolation. However, comptime imports are only allowed in project files, and not in node_modules. You may however import from node_modules as comptime.comptime.ts allows you to evaluate expressions at compile time, similar to compile-time macros in other languages. This can help optimise your code by moving computations from runtime to compile time.Compiles to:Compiles to:Note: The @emotion/css import got removed from the output. You'll need to somehow add the styles back to your project somehow. See running code after comptime evaluati"
  },
  {
    "title": "Why Building Billing Systems Is So Painful (2024) (dmitry.ie)",
    "points": 13,
    "submitter": "Rafsark",
    "submit_time": "2025-08-06T22:58:53 1754521133",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44818836",
    "comments": [
      "I've done a from-scratch billing system build. As well as the complexities in the article, some of the logic required can result in rather exotic SQL.Answering questions like \"what was the maximum number of concurrent sessions per account between these two dates\" with a SQL query is interesting. Making it perform properly adds a layer of fun.reply",
      "This is just an ad for Stripe services.reply"
    ],
    "link": "https://www.dmitry.ie/2024/why-building-billing-systems-is-so-painful",
    "first_paragraph": ""
  },
  {
    "title": "Breaking the sorting barrier for directed single-source shortest paths (quantamagazine.org)",
    "points": 134,
    "submitter": "baruchel",
    "submit_time": "2025-08-06T14:43:02 1754491382",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=44812695",
    "comments": [
      "First, note that this complexity is actually worse for highly dense graphs, where `m` (number of edges) dominates rather than `n` (number of nodes) [note that a useful graph always has `m > n`, and often `m <= 2d  n`, where `d` is the number of dimensions and the 2 is because we're using directed edges. Ugh, how do we compare log powers?].Additionally, the `n` in the complexity only matters if for the Dijkstra approach you actually need a frontier of size proportional to `n` [remember that for open-grid-like graphs, the frontier is limited is limited to `sqrt(n)` for a plane, and for linear-ish graphs, the frontier is even more limited].Also note that the \"sorting barrier\" only applies to comparison-based sorts, not e.g. various kinds of bucket sorts (which are easy to use when your weights are small integers). Which seems to be part of what this algorithm does, though I haven't understood it fully.reply",
      "Very good points. I wonder what this means for real-world street network graphs. In my experience, m can be considered proportional to n in road network graphs (I would estimate m \u2248 2C n, with C being between 2 and 3). This would mean that the asymptotic running time of this new algorithm on a classic road transportation network would be more like O(Cn log^2/3 n) = O(n log^2/3 n), so definitely better than classic Dijkstra (O(n log n) in this scenario). On the other hand, the frontier in road network graphs is usually not very big, and (as you also said for grid graphs) you normally never \"max out\" the priority queue with n nodes, not even close. I would be surprised if the ^2/3 beats the additional constant overhead of the new approach in this case.reply",
      "in the real world djikstra will definitely be faster.reply",
      "It\u2019s not often that you see O(E + V log V) Dijkstra with Fibonacci heaps, either, the O((E + V) log V) version with plain binary heaps is much more popular. I don\u2019t know if that\u2019s because the constants for a Fibonacci heap are worse or just because the data structure is so specialized.reply",
      "So that means it doesn\u2019t work for Traveling Salesman, where the edges are nearly n^2? That might explain why it\u2019s not been found before.reply",
      "It is somewhat funny that it took 12 submissions here on hackernews to bring it to a wider audience :) https://hn.algolia.com/?query=\"2504.17033\"reply",
      "> But curiously, none of the pieces use fancy mathematics.> \u201cThis thing might as well have been discovered 50 years ago, but it wasn\u2019t,\u201d Thorup said. \u201cThat makes it that much more impressive.\u201dthis is so cool to me, it feel like a solution you could* have stumbled upon while doing game development or something*probably wouldn't but stillreply",
      "Gamedevs -I find at least- are so obsessively deep at SOLVING their problem at hand that their headspace is indexed on shipping the game, the project, deadlines, and what to eat for the next meal (probably pizza).Rather than the academia.Just a hunch thoreply",
      "Isn't that just it though? The problem very well could be that some part of the game is running too slow so they just start solving it. No time to read and write academic papers.reply",
      "This algorithm is asymptotically faster than the state of the art, but it isn't faster in practice. At least not yet!reply"
    ],
    "link": "https://www.quantamagazine.org/new-method-is-the-fastest-way-to-find-the-best-routes-20250806/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesAugust 6, 2025DVDP for\u00a0Quanta MagazineStaff WriterAugust 6, 2025If you want to solve a tricky problem, it often helps to get organized. You might, for example, break the problem into pieces and tackle the easiest pieces first. But this kind of sorting has a cost. You may end up spending too much time putting the pieces in order.This dilemma is especially relevant to one of the most iconic problems in computer science: finding the shortest path from a specific starting point in a network to every other point. It\u2019s like a souped-up version of a problem you need to solve each time you move: learning the best route from your new home to work, the gym and the supermarket.\u201cShortest-paths is a bea"
  }
]